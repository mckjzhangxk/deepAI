{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--- Licensed to the Apache Software Foundation (ASF) under one -->\n",
    "<!--- or more contributor license agreements.  See the NOTICE file -->\n",
    "<!--- distributed with this work for additional information -->\n",
    "<!--- regarding copyright ownership.  The ASF licenses this file -->\n",
    "<!--- to you under the Apache License, Version 2.0 (the -->\n",
    "<!--- \"License\"); you may not use this file except in compliance -->\n",
    "<!--- with the License.  You may obtain a copy of the License at -->\n",
    "\n",
    "<!---   http://www.apache.org/licenses/LICENSE-2.0 -->\n",
    "\n",
    "<!--- Unless required by applicable law or agreed to in writing, -->\n",
    "<!--- software distributed under the License is distributed on an -->\n",
    "<!--- \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY -->\n",
    "<!--- KIND, either express or implied.  See the License for the -->\n",
    "<!--- specific language governing permissions and limitations -->\n",
    "<!--- under the License. -->\n",
    "\n",
    "\n",
    "# Module - Neural network training and inference\n",
    "\n",
    "Training a neural network involves quite a few steps. One need to specify how\n",
    "to feed input training data, initialize model parameters, perform forward and\n",
    "backward passes through the network, update weights based on computed gradients, do\n",
    "model checkpoints, etc. During prediction, one ends up repeating most of these\n",
    "steps. All this can be quite daunting to both newcomers as well as experienced\n",
    "developers.\n",
    "\n",
    "Luckily, MXNet modularizes commonly used code for training and inference in\n",
    "the `module` (`mod` for short) package. `Module` provides both high-level and\n",
    "intermediate-level interfaces for executing predefined networks. One can use\n",
    "both interfaces interchangeably. We will show the usage of both interfaces in\n",
    "this tutorial.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "To complete this tutorial, we need:\n",
    "\n",
    "- MXNet. See the instructions for your operating system in [Setup and Installation](http://mxnet.io/install/index.html).  \n",
    "\n",
    "- [Jupyter Notebook](http://jupyter.org/index.html) and [Python Requests](http://docs.python-requests.org/en/master/) packages.\n",
    "```\n",
    "pip install jupyter requests\n",
    "```\n",
    "\n",
    "## Preliminary\n",
    "\n",
    "In this tutorial we will demonstrate `module` usage by training a\n",
    "[Multilayer Perceptron](https://en.wikipedia.org/wiki/Multilayer_perceptron) (MLP)\n",
    "on the [UCI letter recognition](https://archive.ics.uci.edu/ml/datasets/letter+recognition)\n",
    "dataset.\n",
    "\n",
    "The following code downloads the dataset and creates an 80:20 train:test\n",
    "split. It also initializes a training data iterator to return a batch of 32\n",
    "training examples each time. A separate iterator is also created for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:downloaded https://s3.us-east-2.amazonaws.com/mxnet-public/letter_recognition/letter-recognition.data into letter-recognition.data successfully\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import random\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "\n",
    "mx.random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)\n",
    "\n",
    "fname = mx.test_utils.download('https://s3.us-east-2.amazonaws.com/mxnet-public/letter_recognition/letter-recognition.data')\n",
    "data = np.genfromtxt(fname, delimiter=',')[:,1:]\n",
    "label = np.array([ord(l.split(',')[0])-ord('A') for l in open(fname, 'r')])\n",
    "\n",
    "batch_size = 32\n",
    "ntrain = int(data.shape[0]*0.8)\n",
    "train_iter = mx.io.NDArrayIter(data[:ntrain, :], label[:ntrain], batch_size, shuffle=True)\n",
    "val_iter = mx.io.NDArrayIter(data[ntrain:, :], label[ntrain:], batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: plot Pages: 1 -->\n",
       "<svg width=\"264pt\" height=\"442pt\"\n",
       " viewBox=\"0.00 0.00 264.37 442.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 438)\">\n",
       "<title>plot</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-438 260.366,-438 260.366,4 -4,4\"/>\n",
       "<!-- data -->\n",
       "<g id=\"node1\" class=\"node\"><title>data</title>\n",
       "<ellipse fill=\"#8dd3c7\" stroke=\"black\" cx=\"68.1686\" cy=\"-29\" rx=\"47\" ry=\"29\"/>\n",
       "<text text-anchor=\"middle\" x=\"68.1686\" y=\"-25.3\" font-family=\"Times,serif\" font-size=\"14.00\">data</text>\n",
       "</g>\n",
       "<!-- fc1 -->\n",
       "<g id=\"node2\" class=\"node\"><title>fc1</title>\n",
       "<ellipse fill=\"#fb8072\" stroke=\"black\" cx=\"68.1686\" cy=\"-123\" rx=\"68.3377\" ry=\"29\"/>\n",
       "<text text-anchor=\"middle\" x=\"68.1686\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\">FullyConnected</text>\n",
       "<text text-anchor=\"middle\" x=\"68.1686\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\">64</text>\n",
       "</g>\n",
       "<!-- fc1&#45;&gt;data -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>fc1&#45;&gt;data</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M68.1686,-83.7443C68.1686,-75.2043 68.1686,-66.2977 68.1686,-58.2479\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"68.1686,-93.8971 63.6687,-83.897 68.1687,-88.8971 68.1687,-83.8971 68.1687,-83.8971 68.1687,-83.8971 68.1687,-88.8971 72.6687,-83.8971 68.1686,-93.8971 68.1686,-93.8971\"/>\n",
       "</g>\n",
       "<!-- relu1 -->\n",
       "<g id=\"node3\" class=\"node\"><title>relu1</title>\n",
       "<ellipse fill=\"#ffffb3\" stroke=\"black\" cx=\"68.1686\" cy=\"-217\" rx=\"48.9511\" ry=\"29\"/>\n",
       "<text text-anchor=\"middle\" x=\"68.1686\" y=\"-220.8\" font-family=\"Times,serif\" font-size=\"14.00\">Activation</text>\n",
       "<text text-anchor=\"middle\" x=\"68.1686\" y=\"-205.8\" font-family=\"Times,serif\" font-size=\"14.00\">relu</text>\n",
       "</g>\n",
       "<!-- relu1&#45;&gt;fc1 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>relu1&#45;&gt;fc1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M68.1686,-177.744C68.1686,-169.204 68.1686,-160.298 68.1686,-152.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"68.1686,-187.897 63.6687,-177.897 68.1687,-182.897 68.1687,-177.897 68.1687,-177.897 68.1687,-177.897 68.1687,-182.897 72.6687,-177.897 68.1686,-187.897 68.1686,-187.897\"/>\n",
       "</g>\n",
       "<!-- fc2 -->\n",
       "<g id=\"node4\" class=\"node\"><title>fc2</title>\n",
       "<ellipse fill=\"#fb8072\" stroke=\"black\" cx=\"68.1686\" cy=\"-311\" rx=\"68.3377\" ry=\"29\"/>\n",
       "<text text-anchor=\"middle\" x=\"68.1686\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\">FullyConnected</text>\n",
       "<text text-anchor=\"middle\" x=\"68.1686\" y=\"-299.8\" font-family=\"Times,serif\" font-size=\"14.00\">26</text>\n",
       "</g>\n",
       "<!-- fc2&#45;&gt;relu1 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>fc2&#45;&gt;relu1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M68.1686,-271.744C68.1686,-263.204 68.1686,-254.298 68.1686,-246.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"68.1686,-281.897 63.6687,-271.897 68.1687,-276.897 68.1687,-271.897 68.1687,-271.897 68.1687,-271.897 68.1687,-276.897 72.6687,-271.897 68.1686,-281.897 68.1686,-281.897\"/>\n",
       "</g>\n",
       "<!-- softmax_label -->\n",
       "<g id=\"node5\" class=\"node\"><title>softmax_label</title>\n",
       "<ellipse fill=\"#8dd3c7\" stroke=\"black\" cx=\"205.169\" cy=\"-311\" rx=\"51.3959\" ry=\"29\"/>\n",
       "<text text-anchor=\"middle\" x=\"205.169\" y=\"-307.3\" font-family=\"Times,serif\" font-size=\"14.00\">softmax_label</text>\n",
       "</g>\n",
       "<!-- softmax -->\n",
       "<g id=\"node6\" class=\"node\"><title>softmax</title>\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"136.169\" cy=\"-405\" rx=\"47\" ry=\"29\"/>\n",
       "<text text-anchor=\"middle\" x=\"136.169\" y=\"-401.3\" font-family=\"Times,serif\" font-size=\"14.00\">softmax</text>\n",
       "</g>\n",
       "<!-- softmax&#45;&gt;fc2 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>softmax&#45;&gt;fc2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M111.249,-370.285C103.575,-359.903 95.2363,-348.621 87.957,-338.772\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"117.227,-378.373 107.664,-373.006 114.255,-374.352 111.283,-370.331 111.283,-370.331 111.283,-370.331 114.255,-374.352 114.902,-367.656 117.227,-378.373 117.227,-378.373\"/>\n",
       "</g>\n",
       "<!-- softmax&#45;&gt;softmax_label -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>softmax&#45;&gt;softmax_label</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M161.563,-370.141C169.489,-359.572 178.107,-348.082 185.572,-338.129\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"155.389,-378.373 157.789,-367.673 158.389,-374.373 161.389,-370.373 161.389,-370.373 161.389,-370.373 158.389,-374.373 164.989,-373.073 155.389,-378.373 155.389,-378.373\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7efd57d6da58>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = mx.sym.Variable('data')\n",
    "net = mx.sym.FullyConnected(net, name='fc1', num_hidden=64)\n",
    "net = mx.sym.Activation(net, name='relu1', act_type=\"relu\")\n",
    "net = mx.sym.FullyConnected(net, name='fc2', num_hidden=26)\n",
    "net = mx.sym.SoftmaxOutput(net, name='softmax')\n",
    "mx.viz.plot_network(net, node_attrs={\"shape\":\"oval\",\"fixedsize\":\"false\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![svg](https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/doc/tutorials/basic/module/output_3_0.svg?sanitize=true)\n",
    "\n",
    "\n",
    "\n",
    "## Creating a Module\n",
    "\n",
    "Now we are ready to introduce module. The commonly used module class is\n",
    "`Module`. We can construct a module by specifying the following parameters:\n",
    "\n",
    "- `symbol`: the network definition\n",
    "- `context`: the device (or a list of devices) to use for execution\n",
    "- `data_names` : the list of input data variable names\n",
    "- `label_names` : the list of input label variable names\n",
    "\n",
    "For `net`, we have only one data named `data`, and one label named `softmax_label`,\n",
    "which is automatically named for us following the name `softmax` we specified for the `SoftmaxOutput` operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mod = mx.mod.Module(symbol=net,\n",
    "                    context=mx.cpu(),\n",
    "                    data_names=['data'],\n",
    "                   label_names=['softmax_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermediate-level Interface\n",
    "\n",
    "We have created module. Now let us see how to run training and inference using module's intermediate-level APIs. These APIs give developers flexibility to do step-by-step\n",
    "computation by running `forward` and `backward` passes. It's also useful for debugging.\n",
    "\n",
    "To train a module, we need to perform following steps:\n",
    "\n",
    "- `bind` : Prepares environment for the computation by allocating memory.\n",
    "- `init_params` : Assigns and initializes parameters.\n",
    "- `init_optimizer` : Initializes optimizers. Defaults to `sgd`.\n",
    "- `metric.create` : Creates evaluation metric from input metric name.\n",
    "- `forward` : Forward computation.\n",
    "- `update_metric` : Evaluates and accumulates evaluation metric on outputs of the last forward computation.\n",
    "- `backward` : Backward computation.\n",
    "- `update` : Updates parameters according to the installed optimizer and the gradients computed in the previous forward-backward batch.\n",
    "\n",
    "This can be used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Already bound, ignoring bind()\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel/__main__.py:4: UserWarning: Parameters already initialized and force_init=False. init_params call ignored.\n",
      "WARNING:root:optimizer already initialized, ignoring...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Training ('accuracy', 0.765125)\n",
      "Epoch 1, Training ('accuracy', 0.7825)\n",
      "Epoch 2, Training ('accuracy', 0.7893125)\n",
      "Epoch 3, Training ('accuracy', 0.7938125)\n",
      "Epoch 4, Training ('accuracy', 0.8045)\n"
     ]
    }
   ],
   "source": [
    "# allocate memory given the input data and label shapes\n",
    "mod.bind(data_shapes=train_iter.provide_data, label_shapes=train_iter.provide_label)\n",
    "# initialize parameters by uniform random numbers\n",
    "mod.init_params(initializer=mx.init.Uniform(scale=.1))\n",
    "# use SGD with learning rate 0.1 to train\n",
    "mod.init_optimizer(optimizer='sgd', optimizer_params=(('learning_rate', 0.1), ))\n",
    "# use accuracy as the metric\n",
    "metric = mx.metric.create('acc')\n",
    "# train 5 epochs, i.e. going over the data iter one pass\n",
    "for epoch in range(5):\n",
    "    train_iter.reset()\n",
    "    metric.reset()\n",
    "    for batch in train_iter:\n",
    "        mod.forward(batch, is_train=True)       # compute predictions\n",
    "        mod.update_metric(metric, batch.label)  # accumulate prediction accuracy\n",
    "        mod.backward()                          # compute gradients\n",
    "        mod.update()                            # update parameters\n",
    "    print('Epoch %d, Training %s' % (epoch, metric.get()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Already bound, ignoring bind()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy', 0.6046875)\n",
      "('accuracy', 0.730625)\n",
      "('accuracy', 0.754875)\n",
      "('accuracy', 0.7768125)\n",
      "('accuracy', 0.7893125)\n"
     ]
    }
   ],
   "source": [
    "##自己练习\n",
    "\n",
    "#绑定用户 给定输入的 shape\n",
    "mod.bind(data_shapes=train_iter.provide_data,label_shapes=train_iter.provide_label) \n",
    "#分配 并且 初始化 使用的参数\n",
    "# mod.init_params(initializer=mx.init.Uniform(scale=0.1),force_init=True)\n",
    "mod.init_params(initializer=mx.init.Xavier(),force_init=True)\n",
    "mod.init_optimizer(optimizer='adam',optimizer_params=(('learning_rate', 0.01),),force_init=True)\n",
    "acc=mx.metric.create('acc')\n",
    "\n",
    "train_iter.reset()\n",
    "for e in range(5):\n",
    "    #不要忘记数据源的 reset\n",
    "    train_iter.reset()\n",
    "    acc.reset()\n",
    "    for batch in train_iter:\n",
    "        mod.forward(batch,True)\n",
    "        mod.update_metric(acc,batch.label)\n",
    "        mod.backward()\n",
    "        mod.update()\n",
    "    print(acc.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "\n",
    "\n",
    "```\n",
    "Epoch 0, Training ('accuracy', 0.434625)\n",
    "Epoch 1, Training ('accuracy', 0.6516875)\n",
    "Epoch 2, Training ('accuracy', 0.6968125)\n",
    "Epoch 3, Training ('accuracy', 0.7273125)\n",
    "Epoch 4, Training ('accuracy', 0.7575625)\n",
    "```\n",
    "\n",
    "\n",
    "To learn more about these APIs, visit [Module API](http://mxnet.io/api/python/module/module.html).\n",
    "\n",
    "## High-level Interface\n",
    "\n",
    "### Train\n",
    "\n",
    "Module also provides high-level APIs for training, predicting and evaluating for\n",
    "user convenience. Instead of doing all the steps mentioned in the above section,\n",
    "one can simply call [fit API](http://mxnet.io/api/python/module/module.html#mxnet.module.BaseModule.fit)\n",
    "and it internally executes the same steps.\n",
    "\n",
    "To fit a module, call the `fit` function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch[0] Train-accuracy=0.371437\n",
      "INFO:root:Epoch[0] Time cost=0.446\n",
      "INFO:root:Epoch[0] Validation-accuracy=0.568500\n",
      "INFO:root:Epoch[1] Train-accuracy=0.638312\n",
      "INFO:root:Epoch[1] Time cost=0.430\n",
      "INFO:root:Epoch[1] Validation-accuracy=0.644250\n",
      "INFO:root:Epoch[2] Train-accuracy=0.703313\n",
      "INFO:root:Epoch[2] Time cost=0.426\n",
      "INFO:root:Epoch[2] Validation-accuracy=0.718250\n",
      "INFO:root:Epoch[3] Train-accuracy=0.743313\n",
      "INFO:root:Epoch[3] Time cost=0.452\n",
      "INFO:root:Epoch[3] Validation-accuracy=0.724000\n",
      "INFO:root:Epoch[4] Train-accuracy=0.769312\n",
      "INFO:root:Epoch[4] Time cost=0.439\n",
      "INFO:root:Epoch[4] Validation-accuracy=0.762500\n",
      "INFO:root:Epoch[5] Train-accuracy=0.784937\n",
      "INFO:root:Epoch[5] Time cost=0.482\n",
      "INFO:root:Epoch[5] Validation-accuracy=0.730750\n",
      "INFO:root:Epoch[6] Train-accuracy=0.800000\n",
      "INFO:root:Epoch[6] Time cost=0.565\n",
      "INFO:root:Epoch[6] Validation-accuracy=0.772750\n"
     ]
    }
   ],
   "source": [
    "# reset train_iter to the beginning\n",
    "train_iter.reset()\n",
    "\n",
    "# create a module\n",
    "mod = mx.mod.Module(symbol=net,\n",
    "                    context=mx.cpu(),\n",
    "                    data_names=['data'],\n",
    "                    label_names=['softmax_label'])\n",
    "\n",
    "# fit the module\n",
    "mod.fit(train_iter,\n",
    "        eval_data=val_iter,\n",
    "        optimizer='sgd',\n",
    "        optimizer_params={'learning_rate':0.1},\n",
    "        eval_metric='acc',\n",
    "        num_epoch=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "\n",
    "\n",
    "```\n",
    "INFO:root:Epoch[0] Train-accuracy=0.325437\n",
    "INFO:root:Epoch[0] Time cost=0.550\n",
    "INFO:root:Epoch[0] Validation-accuracy=0.568500\n",
    "INFO:root:Epoch[1] Train-accuracy=0.622188\n",
    "INFO:root:Epoch[1] Time cost=0.552\n",
    "INFO:root:Epoch[1] Validation-accuracy=0.656500\n",
    "INFO:root:Epoch[2] Train-accuracy=0.694375\n",
    "INFO:root:Epoch[2] Time cost=0.566\n",
    "INFO:root:Epoch[2] Validation-accuracy=0.703500\n",
    "INFO:root:Epoch[3] Train-accuracy=0.732187\n",
    "INFO:root:Epoch[3] Time cost=0.562\n",
    "INFO:root:Epoch[3] Validation-accuracy=0.748750\n",
    "INFO:root:Epoch[4] Train-accuracy=0.755375\n",
    "INFO:root:Epoch[4] Time cost=0.484\n",
    "INFO:root:Epoch[4] Validation-accuracy=0.761500\n",
    "INFO:root:Epoch[5] Train-accuracy=0.773188\n",
    "INFO:root:Epoch[5] Time cost=0.383\n",
    "INFO:root:Epoch[5] Validation-accuracy=0.715000\n",
    "INFO:root:Epoch[6] Train-accuracy=0.794687\n",
    "INFO:root:Epoch[6] Time cost=0.378\n",
    "INFO:root:Epoch[6] Validation-accuracy=0.802250\n",
    "```\n",
    "\n",
    "By default, `fit` function has `eval_metric` set to `accuracy`, `optimizer` to `sgd`\n",
    "and optimizer_params to `(('learning_rate', 0.01),)`.\n",
    "\n",
    "### Predict and Evaluate\n",
    "\n",
    "To predict with module, we can call `predict()`. It will collect and\n",
    "return all the prediction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = mod.predict(val_iter)\n",
    "assert y.shape == (4000, 26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do not need the prediction outputs, but just need to evaluate on a test\n",
    "set, we can call the `score()` function. It runs prediction in the input validation\n",
    "dataset and evaluates the performance according to the given input metric.\n",
    "\n",
    "It can be used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is 0.772750\n"
     ]
    }
   ],
   "source": [
    "score = mod.score(val_iter, ['acc'])\n",
    "print(\"Accuracy score is %f\" % (score[0][1]))\n",
    "assert score[0][1] > 0.76, \"Achieved accuracy (%f) is less than expected (0.76)\" % score[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "\n",
    "\n",
    "```\n",
    "Accuracy score is 0.802250\n",
    "```\n",
    "\n",
    "Some of the other metrics which can be used are `top_k_acc`(top-k-accuracy),\n",
    "`F1`, `RMSE`, `MSE`, `MAE`, `ce`(CrossEntropy). To learn more about the metrics,\n",
    "visit [Evaluation metric](http://mxnet.io/api/python/metric/metric.html).\n",
    "\n",
    "One can vary number of epochs, learning_rate, optimizer parameters to change the score\n",
    "and tune these parameters to get best score.\n",
    "\n",
    "### Save and Load\n",
    "\n",
    "We can save the module parameters after each training epoch by using a checkpoint callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch[0] Train-accuracy=0.370500\n",
      "INFO:root:Epoch[0] Time cost=0.611\n",
      "INFO:root:Saved checkpoint to \"models/mx_mlp-0001.params\"\n",
      "INFO:root:Epoch[0] Validation-accuracy=0.530000\n",
      "INFO:root:Epoch[1] Train-accuracy=0.600000\n",
      "INFO:root:Epoch[1] Time cost=0.620\n",
      "INFO:root:Saved checkpoint to \"models/mx_mlp-0002.params\"\n",
      "INFO:root:Epoch[1] Validation-accuracy=0.625000\n",
      "INFO:root:Epoch[2] Train-accuracy=0.661188\n",
      "INFO:root:Epoch[2] Time cost=0.544\n",
      "INFO:root:Saved checkpoint to \"models/mx_mlp-0003.params\"\n",
      "INFO:root:Epoch[2] Validation-accuracy=0.668000\n",
      "INFO:root:Epoch[3] Train-accuracy=0.700125\n",
      "INFO:root:Epoch[3] Time cost=0.612\n",
      "INFO:root:Saved checkpoint to \"models/mx_mlp-0004.params\"\n",
      "INFO:root:Epoch[3] Validation-accuracy=0.696750\n",
      "INFO:root:Epoch[4] Train-accuracy=0.724063\n",
      "INFO:root:Epoch[4] Time cost=0.901\n",
      "INFO:root:Saved checkpoint to \"models/mx_mlp-0005.params\"\n",
      "INFO:root:Epoch[4] Validation-accuracy=0.723000\n",
      "INFO:root:Epoch[5] Train-accuracy=0.742875\n",
      "INFO:root:Epoch[5] Time cost=0.615\n",
      "INFO:root:Saved checkpoint to \"models/mx_mlp-0006.params\"\n",
      "INFO:root:Epoch[5] Validation-accuracy=0.731250\n",
      "INFO:root:Epoch[6] Train-accuracy=0.751313\n",
      "INFO:root:Epoch[6] Time cost=0.766\n",
      "INFO:root:Saved checkpoint to \"models/mx_mlp-0007.params\"\n",
      "INFO:root:Epoch[6] Validation-accuracy=0.741250\n",
      "INFO:root:Epoch[7] Train-accuracy=0.761625\n",
      "INFO:root:Epoch[7] Time cost=0.744\n",
      "INFO:root:Saved checkpoint to \"models/mx_mlp-0008.params\"\n",
      "INFO:root:Epoch[7] Validation-accuracy=0.749000\n",
      "INFO:root:Epoch[8] Train-accuracy=0.767125\n",
      "INFO:root:Epoch[8] Time cost=0.893\n",
      "INFO:root:Saved checkpoint to \"models/mx_mlp-0009.params\"\n",
      "INFO:root:Epoch[8] Validation-accuracy=0.762000\n",
      "INFO:root:Epoch[9] Train-accuracy=0.778937\n",
      "INFO:root:Epoch[9] Time cost=1.031\n",
      "INFO:root:Saved checkpoint to \"models/mx_mlp-0010.params\"\n",
      "INFO:root:Epoch[9] Validation-accuracy=0.779000\n"
     ]
    }
   ],
   "source": [
    "# construct a callback function to save checkpoints\n",
    "model_prefix = 'models/mx_mlp'\n",
    "checkpoint = mx.callback.do_checkpoint(model_prefix)\n",
    "\n",
    "mod = mx.mod.Module(symbol=net)\n",
    "train_iter.reset()\n",
    "mod.fit(train_iter,val_iter,\n",
    "        num_epoch=10, \n",
    "        epoch_end_callback=checkpoint,\n",
    "        optimizer='adam',\n",
    "        optimizer_params={'learning_rate':1e-3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "\n",
    "\n",
    "```\n",
    "INFO:root:Epoch[0] Train-accuracy=0.098437\n",
    "INFO:root:Epoch[0] Time cost=0.421\n",
    "INFO:root:Saved checkpoint to \"mx_mlp-0001.params\"\n",
    "INFO:root:Epoch[1] Train-accuracy=0.257437\n",
    "INFO:root:Epoch[1] Time cost=0.520\n",
    "INFO:root:Saved checkpoint to \"mx_mlp-0002.params\"\n",
    "INFO:root:Epoch[2] Train-accuracy=0.457250\n",
    "INFO:root:Epoch[2] Time cost=0.562\n",
    "INFO:root:Saved checkpoint to \"mx_mlp-0003.params\"\n",
    "INFO:root:Epoch[3] Train-accuracy=0.558187\n",
    "INFO:root:Epoch[3] Time cost=0.434\n",
    "INFO:root:Saved checkpoint to \"mx_mlp-0004.params\"\n",
    "INFO:root:Epoch[4] Train-accuracy=0.617750\n",
    "INFO:root:Epoch[4] Time cost=0.414\n",
    "INFO:root:Saved checkpoint to \"mx_mlp-0005.params\"\n",
    "```\n",
    "\n",
    "To load the saved module parameters, call the `load_checkpoint` function. It\n",
    "loads the Symbol and the associated parameters. We can then set the loaded\n",
    "parameters into the module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mod=mx.mod.Module(net)\n",
    "# mod.bind(train_iter.provide_data,train_iter.provide_label)\n",
    "# mod.init_params()\n",
    "sym, arg_params, aux_params = mx.model.load_checkpoint(model_prefix, 10)\n",
    "# assert sym.tojson() == net.tojson()\n",
    "\n",
    "# assign the loaded parameters to the module\n",
    "mod.set_params(arg_params, aux_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('accuracy', 0.7844375)]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.score(train_iter,['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or if we just want to resume training from a saved checkpoint, instead of\n",
    "calling `set_params()`, we can directly call `fit()`, passing the loaded\n",
    "parameters, so that `fit()` knows to start from those parameters instead of\n",
    "initializing randomly from scratch. We also set the `begin_epoch` parameter so that\n",
    "`fit()` knows we are resuming from a previously saved epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch[3] Train-accuracy=0.779813\n",
      "INFO:root:Epoch[3] Time cost=0.460\n",
      "INFO:root:Epoch[4] Train-accuracy=0.782937\n",
      "INFO:root:Epoch[4] Time cost=0.431\n",
      "INFO:root:Epoch[5] Train-accuracy=0.788687\n",
      "INFO:root:Epoch[5] Time cost=0.445\n",
      "INFO:root:Epoch[6] Train-accuracy=0.790000\n",
      "INFO:root:Epoch[6] Time cost=0.464\n",
      "INFO:root:Epoch[7] Train-accuracy=0.793188\n",
      "INFO:root:Epoch[7] Time cost=0.496\n",
      "INFO:root:Epoch[8] Train-accuracy=0.794750\n",
      "INFO:root:Epoch[8] Time cost=0.467\n",
      "INFO:root:Epoch[9] Train-accuracy=0.797875\n",
      "INFO:root:Epoch[9] Time cost=0.475\n",
      "INFO:root:Epoch[10] Train-accuracy=0.801312\n",
      "INFO:root:Epoch[10] Time cost=0.590\n",
      "INFO:root:Epoch[11] Train-accuracy=0.804750\n",
      "INFO:root:Epoch[11] Time cost=0.475\n",
      "INFO:root:Epoch[12] Train-accuracy=0.806187\n",
      "INFO:root:Epoch[12] Time cost=0.568\n",
      "INFO:root:Epoch[13] Train-accuracy=0.808187\n",
      "INFO:root:Epoch[13] Time cost=0.469\n",
      "INFO:root:Epoch[14] Train-accuracy=0.810875\n",
      "INFO:root:Epoch[14] Time cost=0.476\n",
      "INFO:root:Epoch[15] Train-accuracy=0.814375\n",
      "INFO:root:Epoch[15] Time cost=0.619\n",
      "INFO:root:Epoch[16] Train-accuracy=0.815063\n",
      "INFO:root:Epoch[16] Time cost=0.714\n",
      "INFO:root:Epoch[17] Train-accuracy=0.818875\n",
      "INFO:root:Epoch[17] Time cost=0.592\n",
      "INFO:root:Epoch[18] Train-accuracy=0.819562\n",
      "INFO:root:Epoch[18] Time cost=0.716\n",
      "INFO:root:Epoch[19] Train-accuracy=0.823562\n",
      "INFO:root:Epoch[19] Time cost=0.868\n",
      "INFO:root:Epoch[20] Train-accuracy=0.826125\n",
      "INFO:root:Epoch[20] Time cost=0.691\n"
     ]
    }
   ],
   "source": [
    "mod = mx.mod.Module(symbol=sym)\n",
    "train_iter.reset()\n",
    "mod.fit(train_iter,\n",
    "        num_epoch=21,\n",
    "        arg_params=arg_params,\n",
    "        aux_params=aux_params,\n",
    "        begin_epoch=3)\n",
    "assert score[0][1] > 0.77, \"Achieved accuracy (%f) is less than expected (0.77)\" % score[0][1]        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Expected output:\n",
    "\n",
    "\n",
    "```\n",
    "INFO:root:Epoch[3] Train-accuracy=0.555438\n",
    "INFO:root:Epoch[3] Time cost=0.377\n",
    "INFO:root:Epoch[4] Train-accuracy=0.616625\n",
    "INFO:root:Epoch[4] Time cost=0.457\n",
    "INFO:root:Epoch[5] Train-accuracy=0.658438\n",
    "INFO:root:Epoch[5] Time cost=0.518\n",
    "...........................................\n",
    "INFO:root:Epoch[18] Train-accuracy=0.788687\n",
    "INFO:root:Epoch[18] Time cost=0.532\n",
    "INFO:root:Epoch[19] Train-accuracy=0.789562\n",
    "INFO:root:Epoch[19] Time cost=0.531\n",
    "INFO:root:Epoch[20] Train-accuracy=0.796250\n",
    "INFO:root:Epoch[20] Time cost=0.531\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "<!-- INSERT SOURCE DOWNLOAD BUTTONS -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 如何使用一个 预训练的模型？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('accuracy', 0.779)]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained='models/mx_mlp'\n",
    "_sym,_ags,_aux=mx.model.load_checkpoint(pretrained,10)\n",
    "_mode=mx.mod.Module(_sym,data_names=['data'],label_names=['softmax_label']) #查看 _sym.list_arguments(),给出输入输出名\n",
    "N=32\n",
    "_mode.bind(data_shapes=[('data',(N,16))],label_shapes=[('softmax_label',(N,))])\n",
    "_mode.set_params(_ags,_aux)\n",
    "_mode.score(val_iter,['acc'])\n",
    "# _mod.predict(mx.nd.random.uniform(-1,1,shape=(N,16))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pretrained='models/mx_mlp'\n",
    "_sym,_ags,_aux=mx.model.load_checkpoint(pretrained,10)\n",
    "#_sym.list_inputs(),_sym.list_outputs很有用，可以分析哪些是output\n",
    "_sym=_sym['softmax_output'] \n",
    "_mode=mx.mod.Module(_sym,data_names=['data'],label_names=None) #查看 _sym.list_arguments(),给出输入输出名\n",
    "N=32\n",
    "_mode.bind(data_shapes=[('data',(N,16))],label_shapes=None)\n",
    "_mode.set_params(_ags,_aux,allow_missing=True)\n",
    "# _mode.score(val_iter,['acc'])\n",
    "# _mod.predict(mx.nd.random.uniform(-1,1,shape=(N,16)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 如何从 预训练的模型 恢复训练？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch[10] Train-accuracy=0.778687\n",
      "INFO:root:Epoch[10] Time cost=0.423\n",
      "INFO:root:Epoch[10] Validation-accuracy=0.776750\n",
      "INFO:root:Epoch[11] Train-accuracy=0.785000\n",
      "INFO:root:Epoch[11] Time cost=0.552\n",
      "INFO:root:Epoch[11] Validation-accuracy=0.765750\n",
      "INFO:root:Epoch[12] Train-accuracy=0.787188\n",
      "INFO:root:Epoch[12] Time cost=0.611\n",
      "INFO:root:Epoch[12] Validation-accuracy=0.766250\n",
      "INFO:root:Epoch[13] Train-accuracy=0.790063\n",
      "INFO:root:Epoch[13] Time cost=0.517\n",
      "INFO:root:Epoch[13] Validation-accuracy=0.768750\n",
      "INFO:root:Epoch[14] Train-accuracy=0.792500\n",
      "INFO:root:Epoch[14] Time cost=0.590\n",
      "INFO:root:Epoch[14] Validation-accuracy=0.782750\n"
     ]
    }
   ],
   "source": [
    "pretrained='models/mx_mlp'\n",
    "_sym,_args,_aux=mx.model.load_checkpoint(pretrained,10)\n",
    "_mod=mx.mod.Module(_sym)\n",
    "_mod.fit(train_iter,val_iter,arg_params=_args,aux_params=_aux,num_epoch=15,begin_epoch=10)"
   ]
  }
 ],
 "metadata": {
  "display_name": "",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "name": ""
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import  Input,Conv2D,MaxPooling2D,Flatten,Dense,Lambda,LSTM,BatchNormalization,Dropout,TimeDistributed\n",
    "from keras.models import Sequential,Model,load_model\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "from keras.initializers import he_normal,glorot_normal\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam,rmsprop\n",
    "import tensorflow as tf\n",
    "from IPython.display import SVG\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.callbacks import LearningRateScheduler,ModelCheckpoint,ReduceLROnPlateau\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnistPath='/home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnist/MNIST_DATA'\n",
    "plt.rcParams['figure.figsize']=(20,20)\n",
    "plt.rcParams['image.cmap']='gray'\n",
    "% %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# First Train A LeNet for extract feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imshow(X,Y=None,classes=None):\n",
    "    '''\n",
    "        show Batch of image in grids sqrt(h) x sqrt(w)\n",
    "        X is a numpy array,size (m,h,w,c)\n",
    "        Y is a numpy array,size (m,#classes)\n",
    "    '''\n",
    "    m=X.shape[0]\n",
    "    gridSize=int(m**0.5)\n",
    "    for i in range(0,gridSize):\n",
    "        for j in range(0,gridSize):\n",
    "            _idx=i*gridSize+j\n",
    "            im=X[_idx]\n",
    "            plt.subplot(gridSize,gridSize,_idx+1)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(im)\n",
    "            if Y is not None:\n",
    "                label=classes[np.argmax(Y[_idx])]\n",
    "                plt.title(label)\n",
    "\n",
    "def load_dataset(flaten=False,one_hot=True):\n",
    "    def _make_one_hot(d,C=10):\n",
    "        return (np.arange(C)==d[:,None]).astype(np.int32)\n",
    "\n",
    "    mnist=input_data.read_data_sets('MNIST_DATA')\n",
    "    X_train,Y_train=mnist.train.images,mnist.train.labels\n",
    "    X_test,Y_test=mnist.test.images,mnist.test.labels\n",
    "\n",
    "    if flaten==False:\n",
    "        X_train=X_train.reshape((-1,28,28,1))\n",
    "        X_test = X_test.reshape((-1, 28, 28,1))\n",
    "    if one_hot:\n",
    "        Y_train = _make_one_hot(Y_train)\n",
    "        Y_test=_make_one_hot(Y_test)\n",
    "\n",
    "\n",
    "    print('\\n-------------------------------------------------------------------------')\n",
    "    print('load %d train Example,%d Test Example'%(X_train.shape[0],X_test.shape[0]))\n",
    "    print('Train Images  Shape:'+str(X_train.shape))\n",
    "    print('Train Labels  Shape:' + str(Y_train.shape))\n",
    "    print('Test  Images  Shape:'+str(X_test.shape))\n",
    "    print('Test  Labels  Shape:' + str(Y_test.shape))\n",
    "    print('-------------------------------------------------------------------------')\n",
    "    return (X_train,Y_train,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_DATA/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_DATA/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_DATA/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_DATA/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "load 55000 train Example,10000 Test Example\n",
      "Train Images  Shape:(55000, 28, 28, 1)\n",
      "Train Labels  Shape:(55000, 10)\n",
      "Test  Images  Shape:(10000, 28, 28, 1)\n",
      "Test  Labels  Shape:(10000, 10)\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train,X_test,Y_test=load_dataset(one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 5)         130       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 5)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 16)        2016      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "feature (Conv2D)             (None, 1, 1, 120)         94200     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 1, 1, 84)          10164     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 1, 1, 10)          850       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 107,360\n",
      "Trainable params: 107,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def LeNet():    \n",
    "    model=Sequential([\n",
    "        Conv2D(filters=5,strides=1,kernel_size=5,padding='SAME',\n",
    "             kernel_initializer='he_normal',activation='relu',input_shape=(28,28,1)),#28x28x5\n",
    "        MaxPooling2D((2,2)),#14x14x5\n",
    "        Conv2D(filters=16,strides=1,kernel_size=5,padding='SAME',\n",
    "               kernel_initializer='he_normal',activation='relu'),#14x14*16\n",
    "        MaxPooling2D((2,2)),#7x7*16\n",
    "        Conv2D(filters=120,strides=1,kernel_size=7,padding='VALID',\n",
    "               kernel_initializer='he_normal',activation='relu',name='feature'),#1x1x120\n",
    "        Conv2D(filters=84,strides=1,kernel_size=1,padding='VALID',#1x1x84\n",
    "               kernel_initializer='he_normal',activation='relu'),\n",
    "        Conv2D(filters=10,strides=1,kernel_size=1,padding='VALID',#1x1x10\n",
    "               kernel_initializer='he_normal',activation='softmax'),\n",
    "        Flatten()\n",
    "    ])\n",
    "    model.summary()\n",
    "    return model\n",
    "model=LeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "55000/55000 [==============================] - 20s 361us/step - loss: 0.2740 - acc: 0.9139 - val_loss: 0.1106 - val_acc: 0.9640\n",
      "Epoch 2/20\n",
      "55000/55000 [==============================] - 20s 357us/step - loss: 0.0937 - acc: 0.9710 - val_loss: 0.0832 - val_acc: 0.9707\n",
      "Epoch 3/20\n",
      "55000/55000 [==============================] - 19s 351us/step - loss: 0.0678 - acc: 0.9789 - val_loss: 0.0541 - val_acc: 0.9831\n",
      "Epoch 4/20\n",
      "55000/55000 [==============================] - 19s 353us/step - loss: 0.0544 - acc: 0.9838 - val_loss: 0.0591 - val_acc: 0.9813\n",
      "Epoch 5/20\n",
      "55000/55000 [==============================] - 20s 360us/step - loss: 0.0449 - acc: 0.9863 - val_loss: 0.0406 - val_acc: 0.9877\n",
      "Epoch 6/20\n",
      "55000/55000 [==============================] - 19s 337us/step - loss: 0.0406 - acc: 0.9881 - val_loss: 0.1010 - val_acc: 0.9753\n",
      "Epoch 7/20\n",
      "55000/55000 [==============================] - 19s 342us/step - loss: 0.0404 - acc: 0.9883 - val_loss: 0.0869 - val_acc: 0.9810\n",
      "Epoch 8/20\n",
      "55000/55000 [==============================] - 19s 347us/step - loss: 0.0389 - acc: 0.9897 - val_loss: 0.0627 - val_acc: 0.9849\n",
      "Epoch 9/20\n",
      "55000/55000 [==============================] - 19s 346us/step - loss: 0.0363 - acc: 0.9903 - val_loss: 0.0573 - val_acc: 0.9874\n",
      "Epoch 10/20\n",
      "55000/55000 [==============================] - 19s 346us/step - loss: 0.0315 - acc: 0.9919 - val_loss: 0.0687 - val_acc: 0.9868\n",
      "Epoch 11/20\n",
      "55000/55000 [==============================] - 20s 359us/step - loss: 0.0363 - acc: 0.9916 - val_loss: 0.0874 - val_acc: 0.9874\n",
      "Epoch 12/20\n",
      "55000/55000 [==============================] - 20s 370us/step - loss: 0.0365 - acc: 0.9920 - val_loss: 0.0756 - val_acc: 0.9875\n",
      "Epoch 13/20\n",
      "55000/55000 [==============================] - 19s 344us/step - loss: 0.0392 - acc: 0.9920 - val_loss: 0.0929 - val_acc: 0.9878\n",
      "Epoch 14/20\n",
      "55000/55000 [==============================] - 19s 345us/step - loss: 0.0402 - acc: 0.9926 - val_loss: 0.1528 - val_acc: 0.9805\n",
      "Epoch 15/20\n",
      "55000/55000 [==============================] - 19s 345us/step - loss: 0.0401 - acc: 0.9925 - val_loss: 0.1324 - val_acc: 0.9844\n",
      "Epoch 16/20\n",
      "55000/55000 [==============================] - 19s 345us/step - loss: 0.0455 - acc: 0.9924 - val_loss: 0.1110 - val_acc: 0.9862\n",
      "Epoch 17/20\n",
      "55000/55000 [==============================] - 19s 344us/step - loss: 0.0597 - acc: 0.9916 - val_loss: 0.3271 - val_acc: 0.9657\n",
      "Epoch 18/20\n",
      "55000/55000 [==============================] - 19s 344us/step - loss: 0.0645 - acc: 0.9916 - val_loss: 0.1321 - val_acc: 0.9882\n",
      "Epoch 19/20\n",
      "55000/55000 [==============================] - 19s 343us/step - loss: 0.0649 - acc: 0.9919 - val_loss: 0.1194 - val_acc: 0.9882\n",
      "Epoch 20/20\n",
      "55000/55000 [==============================] - 19s 343us/step - loss: 0.0878 - acc: 0.9903 - val_loss: 0.1725 - val_acc: 0.9841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe3f904fba8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchSize=128\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# augment=ImageDataGenerator(horizontal_flip=True,height_shift_range=0.025,width_shift_range=0.025)\n",
    "# gen=augment.flow(X_train,Y_train,batchSize)\n",
    "# model.fit_generator(generator=gen,epochs=20,shuffle=True,validation_data=(X_test,Y_test))\n",
    "model.fit(X_train,Y_train,batch_size=batchSize,epochs=20,shuffle=True,validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist_model_path='/home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnist.h5'\n",
    "# model.save(mnist_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model=load_model(mnist_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Using above model to create a feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1_input (InputLayer)  (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 5)         130       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 5)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 16)        2016      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "feature (Conv2D)             (None, 1, 1, 120)         94200     \n",
      "=================================================================\n",
      "Total params: 96,346\n",
      "Trainable params: 0\n",
      "Non-trainable params: 96,346\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "feature_model=Model(model.input,model.get_layer('feature').output)\n",
    "#I freeze the extractor\n",
    "for l in feature_model.layers:\n",
    "    l.trainable=False\n",
    "feature_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.ops.array_ops.squeeze>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature_model can using to any size of Image\n",
    "X=Input(shape=(28,28*10,1))\n",
    "XY=feature_model(X)\n",
    "XY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def SeqModel(cnn,rawNum=10,n_a=64,outdims=11,dropRate=0.8):\n",
    "    '''\n",
    "        a sequence to sequence model,using cnn to extract features,\n",
    "        then pass features to one(Multi) RNN network\n",
    "        architure:\n",
    "        \n",
    "          ---------------\n",
    "          | softmax     |  \n",
    "          ---------------         \n",
    "          ---------------\n",
    "          | Dense(11)    |  \n",
    "          ---------------  \n",
    "                 ^\n",
    "                 |\n",
    "          ---------------\n",
    "          | Dropout(0.8) |          \n",
    "          ---------------  \n",
    "          ---------------\n",
    "          | BatchNormal |  \n",
    "          ---------------  \n",
    "          ---------------\n",
    "          | LSTM(64/128)|  \n",
    "          ---------------  \n",
    "                ^ \n",
    "                |  (1,7n-6,120)\n",
    "          ---------------\n",
    "          |    CNN      |  \n",
    "          ---------------  \n",
    "            ^\n",
    "            |\n",
    "        X(28,28xn,1)\n",
    "        cnnï¼špretained CNN model,convert a Image with shape(28a,28b,1)->(7a,7b,120)\n",
    "        rawNum: the Input  shape is (28,28*rawNum,1),rawNum is how many character in my train Example\n",
    "        n_a:LSTM hidden units\n",
    "        outdims:output dims of Seq model\n",
    "        \n",
    "        return:\n",
    "            model: with Input X:[28,28 x rawNum,1]\n",
    "                        Outputs:Y[7 x rawNum-6,outdims]\n",
    "    '''\n",
    "    X_Input=Input(shape=(28,28*rawNum,1),name='ImageInput')\n",
    "    X=cnn(X_Input) #shape (1,7n-6,120)\n",
    "    X=Lambda(lambda x:tf.squeeze(x,axis=1),name='squeeze')(X) #reshape to (7n-6,120)\n",
    "        #RNN begin\n",
    "    X=LSTM(n_a,return_sequences=True,name='lstm1')(X) #shape (7n-6,n_a)\n",
    "    X=BatchNormalization(name='BN1')(X)\n",
    "    X=Dropout(dropRate,name='dropout1')(X)\n",
    "        \n",
    "        #final classify \n",
    "    densor=Dense(outdims,activation='softmax')\n",
    "    X=TimeDistributed(densor,name='out')(X)  #shape (7n-6,outdims)\n",
    "        \n",
    "        #define model\n",
    "    model=Model(X_Input,X)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seqmodel=SeqModel(feature_model,rawNum=10,n_a=64,outdims=11,dropRate=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "ImageInput (InputLayer)      (None, 28, 280, 1)        0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              multiple                  96346     \n",
      "_________________________________________________________________\n",
      "squeeze (Lambda)             (None, 64, 120)           0         \n",
      "_________________________________________________________________\n",
      "lstm1 (LSTM)                 (None, 64, 64)            47360     \n",
      "_________________________________________________________________\n",
      "BN1 (BatchNormalization)     (None, 64, 64)            256       \n",
      "_________________________________________________________________\n",
      "dropout1 (Dropout)           (None, 64, 64)            0         \n",
      "_________________________________________________________________\n",
      "out (TimeDistributed)        (None, 64, 11)            715       \n",
      "=================================================================\n",
      "Total params: 144,677\n",
      "Trainable params: 48,203\n",
      "Non-trainable params: 96,474\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seqmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"629pt\" viewBox=\"0.00 0.00 215.00 629.00\" width=\"215pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 625)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-625 211,-625 211,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 139793780047712 -->\n",
       "<g class=\"node\" id=\"node1\"><title>139793780047712</title>\n",
       "<polygon fill=\"none\" points=\"42,-511.5 42,-547.5 165,-547.5 165,-511.5 42,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-525.8\">conv2d_1: Conv2D</text>\n",
       "</g>\n",
       "<!-- 139793612583376 -->\n",
       "<g class=\"node\" id=\"node2\"><title>139793612583376</title>\n",
       "<polygon fill=\"none\" points=\"0,-438.5 0,-474.5 207,-474.5 207,-438.5 0,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-452.8\">max_pooling2d_1: MaxPooling2D</text>\n",
       "</g>\n",
       "<!-- 139793780047712&#45;&gt;139793612583376 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>139793780047712-&gt;139793612583376</title>\n",
       "<path d=\"M103.5,-511.313C103.5,-503.289 103.5,-493.547 103.5,-484.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"107,-484.529 103.5,-474.529 100,-484.529 107,-484.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139793612583488 -->\n",
       "<g class=\"node\" id=\"node3\"><title>139793612583488</title>\n",
       "<polygon fill=\"none\" points=\"42,-365.5 42,-401.5 165,-401.5 165,-365.5 42,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-379.8\">conv2d_2: Conv2D</text>\n",
       "</g>\n",
       "<!-- 139793612583376&#45;&gt;139793612583488 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>139793612583376-&gt;139793612583488</title>\n",
       "<path d=\"M103.5,-438.313C103.5,-430.289 103.5,-420.547 103.5,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"107,-411.529 103.5,-401.529 100,-411.529 107,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139793612586848 -->\n",
       "<g class=\"node\" id=\"node4\"><title>139793612586848</title>\n",
       "<polygon fill=\"none\" points=\"0,-292.5 0,-328.5 207,-328.5 207,-292.5 0,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-306.8\">max_pooling2d_2: MaxPooling2D</text>\n",
       "</g>\n",
       "<!-- 139793612583488&#45;&gt;139793612586848 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>139793612583488-&gt;139793612586848</title>\n",
       "<path d=\"M103.5,-365.313C103.5,-357.289 103.5,-347.547 103.5,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"107,-338.529 103.5,-328.529 100,-338.529 107,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139793612799168 -->\n",
       "<g class=\"node\" id=\"node5\"><title>139793612799168</title>\n",
       "<polygon fill=\"none\" points=\"50,-219.5 50,-255.5 157,-255.5 157,-219.5 50,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-233.8\">feature: Conv2D</text>\n",
       "</g>\n",
       "<!-- 139793612586848&#45;&gt;139793612799168 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>139793612586848-&gt;139793612799168</title>\n",
       "<path d=\"M103.5,-292.313C103.5,-284.289 103.5,-274.547 103.5,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"107,-265.529 103.5,-255.529 100,-265.529 107,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139793612710576 -->\n",
       "<g class=\"node\" id=\"node6\"><title>139793612710576</title>\n",
       "<polygon fill=\"none\" points=\"42,-146.5 42,-182.5 165,-182.5 165,-146.5 42,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-160.8\">conv2d_3: Conv2D</text>\n",
       "</g>\n",
       "<!-- 139793612799168&#45;&gt;139793612710576 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>139793612799168-&gt;139793612710576</title>\n",
       "<path d=\"M103.5,-219.313C103.5,-211.289 103.5,-201.547 103.5,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"107,-192.529 103.5,-182.529 100,-192.529 107,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139793612798664 -->\n",
       "<g class=\"node\" id=\"node7\"><title>139793612798664</title>\n",
       "<polygon fill=\"none\" points=\"42,-73.5 42,-109.5 165,-109.5 165,-73.5 42,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-87.8\">conv2d_4: Conv2D</text>\n",
       "</g>\n",
       "<!-- 139793612710576&#45;&gt;139793612798664 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>139793612710576-&gt;139793612798664</title>\n",
       "<path d=\"M103.5,-146.313C103.5,-138.289 103.5,-128.547 103.5,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"107,-119.529 103.5,-109.529 100,-119.529 107,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139793612493320 -->\n",
       "<g class=\"node\" id=\"node8\"><title>139793612493320</title>\n",
       "<polygon fill=\"none\" points=\"48.5,-0.5 48.5,-36.5 158.5,-36.5 158.5,-0.5 48.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-14.8\">flatten_1: Flatten</text>\n",
       "</g>\n",
       "<!-- 139793612798664&#45;&gt;139793612493320 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>139793612798664-&gt;139793612493320</title>\n",
       "<path d=\"M103.5,-73.3129C103.5,-65.2895 103.5,-55.5475 103.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"107,-46.5288 103.5,-36.5288 100,-46.5289 107,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139793780046424 -->\n",
       "<g class=\"node\" id=\"node9\"><title>139793780046424</title>\n",
       "<polygon fill=\"none\" points=\"44.5,-584.5 44.5,-620.5 162.5,-620.5 162.5,-584.5 44.5,-584.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-598.8\">139793780046424</text>\n",
       "</g>\n",
       "<!-- 139793780046424&#45;&gt;139793780047712 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>139793780046424-&gt;139793780047712</title>\n",
       "<path d=\"M103.5,-584.313C103.5,-576.289 103.5,-566.547 103.5,-557.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"107,-557.529 103.5,-547.529 100,-557.529 107,-557.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"483pt\" viewBox=\"0.00 0.00 235.00 483.00\" width=\"235pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 479)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-479 231,-479 231,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 139793330724256 -->\n",
       "<g class=\"node\" id=\"node1\"><title>139793330724256</title>\n",
       "<polygon fill=\"none\" points=\"40,-438.5 40,-474.5 187,-474.5 187,-438.5 40,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113.5\" y=\"-452.8\">ImageInput: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139793780046816 -->\n",
       "<g class=\"node\" id=\"node2\"><title>139793780046816</title>\n",
       "<polygon fill=\"none\" points=\"59.5,-365.5 59.5,-401.5 167.5,-401.5 167.5,-365.5 59.5,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113.5\" y=\"-379.8\">model_1: Model</text>\n",
       "</g>\n",
       "<!-- 139793330724256&#45;&gt;139793780046816 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>139793330724256-&gt;139793780046816</title>\n",
       "<path d=\"M113.5,-438.313C113.5,-430.289 113.5,-420.547 113.5,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117,-411.529 113.5,-401.529 110,-411.529 117,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139793330722744 -->\n",
       "<g class=\"node\" id=\"node3\"><title>139793330722744</title>\n",
       "<polygon fill=\"none\" points=\"57.5,-292.5 57.5,-328.5 169.5,-328.5 169.5,-292.5 57.5,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113.5\" y=\"-306.8\">squeeze: Lambda</text>\n",
       "</g>\n",
       "<!-- 139793780046816&#45;&gt;139793330722744 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>139793780046816-&gt;139793330722744</title>\n",
       "<path d=\"M113.5,-365.313C113.5,-357.289 113.5,-347.547 113.5,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117,-338.529 113.5,-328.529 110,-338.529 117,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139793332224856 -->\n",
       "<g class=\"node\" id=\"node4\"><title>139793332224856</title>\n",
       "<polygon fill=\"none\" points=\"67.5,-219.5 67.5,-255.5 159.5,-255.5 159.5,-219.5 67.5,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113.5\" y=\"-233.8\">lstm1: LSTM</text>\n",
       "</g>\n",
       "<!-- 139793330722744&#45;&gt;139793332224856 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>139793330722744-&gt;139793332224856</title>\n",
       "<path d=\"M113.5,-292.313C113.5,-284.289 113.5,-274.547 113.5,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117,-265.529 113.5,-255.529 110,-265.529 117,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139793613168536 -->\n",
       "<g class=\"node\" id=\"node5\"><title>139793613168536</title>\n",
       "<polygon fill=\"none\" points=\"33.5,-146.5 33.5,-182.5 193.5,-182.5 193.5,-146.5 33.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113.5\" y=\"-160.8\">BN1: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 139793332224856&#45;&gt;139793613168536 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>139793332224856-&gt;139793613168536</title>\n",
       "<path d=\"M113.5,-219.313C113.5,-211.289 113.5,-201.547 113.5,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117,-192.529 113.5,-182.529 110,-192.529 117,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139793293613880 -->\n",
       "<g class=\"node\" id=\"node6\"><title>139793293613880</title>\n",
       "<polygon fill=\"none\" points=\"54.5,-73.5 54.5,-109.5 172.5,-109.5 172.5,-73.5 54.5,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113.5\" y=\"-87.8\">dropout1: Dropout</text>\n",
       "</g>\n",
       "<!-- 139793613168536&#45;&gt;139793293613880 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>139793613168536-&gt;139793293613880</title>\n",
       "<path d=\"M113.5,-146.313C113.5,-138.289 113.5,-128.547 113.5,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117,-119.529 113.5,-109.529 110,-119.529 117,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139793292463296 -->\n",
       "<g class=\"node\" id=\"node7\"><title>139793292463296</title>\n",
       "<polygon fill=\"none\" points=\"0,-0.5 0,-36.5 227,-36.5 227,-0.5 0,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113.5\" y=\"-14.8\">out(dense_1): TimeDistributed(Dense)</text>\n",
       "</g>\n",
       "<!-- 139793293613880&#45;&gt;139793292463296 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>139793293613880-&gt;139793292463296</title>\n",
       "<path d=\"M113.5,-73.3129C113.5,-65.2895 113.5,-55.5475 113.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117,-46.5288 113.5,-36.5288 110,-46.5289 117,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(seqmodel).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Prepare Data For Train,do not forget using oneHot representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seqDataPath='/home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/'\n",
    "def loadSeqData(onehot=True):\n",
    "    def _loadF(f):\n",
    "        hf=h5py.File(f,'r')\n",
    "        X=np.array(hf.get('X'))\n",
    "        Y=np.array(hf.get('Y'))\n",
    "        hf.close()\n",
    "        return X,Y\n",
    "    X_train,Y_train=_loadF(seqDataPath+'mnistSeq55k.h5')\n",
    "    X_test,Y_test=_loadF(seqDataPath+'mnistSeq10k.h5')\n",
    "    if(onehot):\n",
    "        Y_train=to_categorical(Y_train,11)\n",
    "        Y_test=to_categorical(Y_test,11)\n",
    "    print('\\n-------------------------------------------------------------------------')\n",
    "    print('load %d train Example,%d Test Example'%(X_train.shape[0],X_test.shape[0]))\n",
    "    print('Train Images  Shape:'+str(X_train.shape))\n",
    "    print('Train Labels  Shape:' + str(Y_train.shape))\n",
    "    print('Test  Images  Shape:'+str(X_test.shape))\n",
    "    print('Test  Labels  Shape:' + str(Y_test.shape))\n",
    "    print('-------------------------------------------------------------------------')\n",
    "    return (X_train,Y_train,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------------------------------\n",
      "load 55000 train Example,10000 Test Example\n",
      "Train Images  Shape:(55000, 28, 280, 1)\n",
      "Train Labels  Shape:(55000, 64, 11)\n",
      "Test  Images  Shape:(10000, 28, 280, 1)\n",
      "Test  Labels  Shape:(10000, 64, 11)\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train,X_test,Y_test=loadSeqData(onehot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputModelPath='/home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5'\n",
    "def monitorLearning():\n",
    "    def myLearnRateScheduler(epoch,lr):\n",
    "        print('ecpch:%d,learn rate %f'%(epoch,lr))\n",
    "        return lr\n",
    "    lr_scheduler=LearningRateScheduler(myLearnRateScheduler)\n",
    "    checkpoint=ModelCheckpoint(outputModelPath,monitor='val_acc',save_best_only=True,verbose=1)\n",
    "    reduceOnpleateau=ReduceLROnPlateau(monitor='val_loss',min_delta=5e-6,factor=0.9,verbose=1,patience=5)\n",
    "    return [lr_scheduler,checkpoint,reduceOnpleateau]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "ecpch:0,learn rate 0.001000\n",
      "55000/55000 [==============================] - 118s 2ms/step - loss: 1.2401 - acc: 0.6342\n",
      "Epoch 2/20\n",
      "ecpch:1,learn rate 0.001000\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 1.0049 - acc: 0.6780\n",
      "Epoch 3/20\n",
      "ecpch:2,learn rate 0.001000\n",
      "55000/55000 [==============================] - 117s 2ms/step - loss: 0.9689 - acc: 0.6811\n",
      "Epoch 4/20\n",
      "ecpch:3,learn rate 0.001000\n",
      "13888/55000 [======>.......................] - ETA: 1:27 - loss: 0.9505 - acc: 0.6830"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks.py:432: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks.py:1043: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: acc,lr,loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-65686fe54b1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mseqmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rmsprop'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mseqmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmonitorLearning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2665\u001b[0m                     \u001b[1;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2666\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[1;32m-> 2667\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2669\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2647\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2648\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2649\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2650\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1140\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1141\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1321\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1312\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[0;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m             status, run_metadata)\n\u001b[0m\u001b[0;32m   1421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1422\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seqmodel.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "seqmodel.fit(X_train,Y_train,epochs=20,batch_size=64,validation_data=(X_test,Y_test),callbacks=monitorLearning())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import  Input,Conv2D,MaxPooling2D,Flatten,Dense,Lambda,LSTM,BatchNormalization,Dropout,TimeDistributed\n",
    "from keras.models import Sequential,Model,load_model\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "from keras.initializers import he_normal,glorot_normal\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam,rmsprop\n",
    "import tensorflow as tf\n",
    "from IPython.display import SVG\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.callbacks import LearningRateScheduler,ModelCheckpoint,ReduceLROnPlateau\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnistPath='/home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnist/MNIST_DATA'\n",
    "plt.rcParams['figure.figsize']=(20,20)\n",
    "plt.rcParams['image.cmap']='gray'\n",
    "% %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# First Train A LeNet for extract feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imshow(X,Y=None,classes=None):\n",
    "    '''\n",
    "        show Batch of image in grids sqrt(h) x sqrt(w)\n",
    "        X is a numpy array,size (m,h,w,c)\n",
    "        Y is a numpy array,size (m,#classes)\n",
    "    '''\n",
    "    m=X.shape[0]\n",
    "    gridSize=int(m**0.5)\n",
    "    for i in range(0,gridSize):\n",
    "        for j in range(0,gridSize):\n",
    "            _idx=i*gridSize+j\n",
    "            im=X[_idx]\n",
    "            plt.subplot(gridSize,gridSize,_idx+1)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(im)\n",
    "            if Y is not None:\n",
    "                label=classes[np.argmax(Y[_idx])]\n",
    "                plt.title(label)\n",
    "\n",
    "def load_dataset(flaten=False,one_hot=True):\n",
    "    def _make_one_hot(d,C=10):\n",
    "        return (np.arange(C)==d[:,None]).astype(np.int32)\n",
    "\n",
    "    mnist=input_data.read_data_sets('MNIST_DATA')\n",
    "    X_train,Y_train=mnist.train.images,mnist.train.labels\n",
    "    X_test,Y_test=mnist.test.images,mnist.test.labels\n",
    "\n",
    "    if flaten==False:\n",
    "        X_train=X_train.reshape((-1,28,28,1))\n",
    "        X_test = X_test.reshape((-1, 28, 28,1))\n",
    "    if one_hot:\n",
    "        Y_train = _make_one_hot(Y_train)\n",
    "        Y_test=_make_one_hot(Y_test)\n",
    "\n",
    "\n",
    "    print('\\n-------------------------------------------------------------------------')\n",
    "    print('load %d train Example,%d Test Example'%(X_train.shape[0],X_test.shape[0]))\n",
    "    print('Train Images  Shape:'+str(X_train.shape))\n",
    "    print('Train Labels  Shape:' + str(Y_train.shape))\n",
    "    print('Test  Images  Shape:'+str(X_test.shape))\n",
    "    print('Test  Labels  Shape:' + str(Y_test.shape))\n",
    "    print('-------------------------------------------------------------------------')\n",
    "    return (X_train,Y_train,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_DATA/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_DATA/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_DATA/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_DATA/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "load 55000 train Example,10000 Test Example\n",
      "Train Images  Shape:(55000, 28, 28, 1)\n",
      "Train Labels  Shape:(55000, 10)\n",
      "Test  Images  Shape:(10000, 28, 28, 1)\n",
      "Test  Labels  Shape:(10000, 10)\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train,X_test,Y_test=load_dataset(one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 5)         130       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 5)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 16)        2016      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "feature (Conv2D)             (None, 1, 1, 120)         94200     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 1, 1, 84)          10164     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 1, 1, 10)          850       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 107,360\n",
      "Trainable params: 107,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def LeNet():    \n",
    "    model=Sequential([\n",
    "        Conv2D(filters=5,strides=1,kernel_size=5,padding='SAME',\n",
    "             kernel_initializer='he_normal',activation='relu',input_shape=(28,28,1)),#28x28x5\n",
    "        MaxPooling2D((2,2)),#14x14x5\n",
    "        Conv2D(filters=16,strides=1,kernel_size=5,padding='SAME',\n",
    "               kernel_initializer='he_normal',activation='relu'),#14x14*16\n",
    "        MaxPooling2D((2,2)),#7x7*16\n",
    "        Conv2D(filters=120,strides=1,kernel_size=7,padding='VALID',\n",
    "               kernel_initializer='he_normal',activation='relu',name='feature'),#1x1x120\n",
    "        Conv2D(filters=84,strides=1,kernel_size=1,padding='VALID',#1x1x84\n",
    "               kernel_initializer='he_normal',activation='relu'),\n",
    "        Conv2D(filters=10,strides=1,kernel_size=1,padding='VALID',#1x1x10\n",
    "               kernel_initializer='he_normal',activation='softmax'),\n",
    "        Flatten()\n",
    "    ])\n",
    "    model.summary()\n",
    "    return model\n",
    "model=LeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "55000/55000 [==============================] - 20s 361us/step - loss: 0.2740 - acc: 0.9139 - val_loss: 0.1106 - val_acc: 0.9640\n",
      "Epoch 2/20\n",
      "55000/55000 [==============================] - 20s 357us/step - loss: 0.0937 - acc: 0.9710 - val_loss: 0.0832 - val_acc: 0.9707\n",
      "Epoch 3/20\n",
      "55000/55000 [==============================] - 19s 351us/step - loss: 0.0678 - acc: 0.9789 - val_loss: 0.0541 - val_acc: 0.9831\n",
      "Epoch 4/20\n",
      "55000/55000 [==============================] - 19s 353us/step - loss: 0.0544 - acc: 0.9838 - val_loss: 0.0591 - val_acc: 0.9813\n",
      "Epoch 5/20\n",
      "55000/55000 [==============================] - 20s 360us/step - loss: 0.0449 - acc: 0.9863 - val_loss: 0.0406 - val_acc: 0.9877\n",
      "Epoch 6/20\n",
      "55000/55000 [==============================] - 19s 337us/step - loss: 0.0406 - acc: 0.9881 - val_loss: 0.1010 - val_acc: 0.9753\n",
      "Epoch 7/20\n",
      "55000/55000 [==============================] - 19s 342us/step - loss: 0.0404 - acc: 0.9883 - val_loss: 0.0869 - val_acc: 0.9810\n",
      "Epoch 8/20\n",
      "55000/55000 [==============================] - 19s 347us/step - loss: 0.0389 - acc: 0.9897 - val_loss: 0.0627 - val_acc: 0.9849\n",
      "Epoch 9/20\n",
      "55000/55000 [==============================] - 19s 346us/step - loss: 0.0363 - acc: 0.9903 - val_loss: 0.0573 - val_acc: 0.9874\n",
      "Epoch 10/20\n",
      "55000/55000 [==============================] - 19s 346us/step - loss: 0.0315 - acc: 0.9919 - val_loss: 0.0687 - val_acc: 0.9868\n",
      "Epoch 11/20\n",
      "55000/55000 [==============================] - 20s 359us/step - loss: 0.0363 - acc: 0.9916 - val_loss: 0.0874 - val_acc: 0.9874\n",
      "Epoch 12/20\n",
      "55000/55000 [==============================] - 20s 370us/step - loss: 0.0365 - acc: 0.9920 - val_loss: 0.0756 - val_acc: 0.9875\n",
      "Epoch 13/20\n",
      "55000/55000 [==============================] - 19s 344us/step - loss: 0.0392 - acc: 0.9920 - val_loss: 0.0929 - val_acc: 0.9878\n",
      "Epoch 14/20\n",
      "55000/55000 [==============================] - 19s 345us/step - loss: 0.0402 - acc: 0.9926 - val_loss: 0.1528 - val_acc: 0.9805\n",
      "Epoch 15/20\n",
      "55000/55000 [==============================] - 19s 345us/step - loss: 0.0401 - acc: 0.9925 - val_loss: 0.1324 - val_acc: 0.9844\n",
      "Epoch 16/20\n",
      "55000/55000 [==============================] - 19s 345us/step - loss: 0.0455 - acc: 0.9924 - val_loss: 0.1110 - val_acc: 0.9862\n",
      "Epoch 17/20\n",
      "55000/55000 [==============================] - 19s 344us/step - loss: 0.0597 - acc: 0.9916 - val_loss: 0.3271 - val_acc: 0.9657\n",
      "Epoch 18/20\n",
      "55000/55000 [==============================] - 19s 344us/step - loss: 0.0645 - acc: 0.9916 - val_loss: 0.1321 - val_acc: 0.9882\n",
      "Epoch 19/20\n",
      "55000/55000 [==============================] - 19s 343us/step - loss: 0.0649 - acc: 0.9919 - val_loss: 0.1194 - val_acc: 0.9882\n",
      "Epoch 20/20\n",
      "55000/55000 [==============================] - 19s 343us/step - loss: 0.0878 - acc: 0.9903 - val_loss: 0.1725 - val_acc: 0.9841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe3f904fba8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchSize=128\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# augment=ImageDataGenerator(horizontal_flip=True,height_shift_range=0.025,width_shift_range=0.025)\n",
    "# gen=augment.flow(X_train,Y_train,batchSize)\n",
    "# model.fit_generator(generator=gen,epochs=20,shuffle=True,validation_data=(X_test,Y_test))\n",
    "model.fit(X_train,Y_train,batch_size=batchSize,epochs=20,shuffle=True,validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist_model_path='/home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnist.h5'\n",
    "# model.save(mnist_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model=load_model(mnist_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Using above model to create a feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1_input (InputLayer)  (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 5)         130       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 5)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 16)        2016      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "feature (Conv2D)             (None, 1, 1, 120)         94200     \n",
      "=================================================================\n",
      "Total params: 96,346\n",
      "Trainable params: 0\n",
      "Non-trainable params: 96,346\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "feature_model=Model(model.input,model.get_layer('feature').output)\n",
    "#I freeze the extractor\n",
    "for l in feature_model.layers:\n",
    "    l.trainable=False\n",
    "feature_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.ops.array_ops.squeeze>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature_model can using to any size of Image\n",
    "X=Input(shape=(28,28*10,1))\n",
    "XY=feature_model(X)\n",
    "XY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def SeqModel(cnn,rawNum=10,n_a=64,outdims=11,dropRate=0.8):\n",
    "    '''\n",
    "        a sequence to sequence model,using cnn to extract features,\n",
    "        then pass features to one(Multi) RNN network\n",
    "        architure:\n",
    "        \n",
    "          ---------------\n",
    "          | softmax     |  \n",
    "          ---------------         \n",
    "          ---------------\n",
    "          | Dense(11)    |  \n",
    "          ---------------  \n",
    "                 ^\n",
    "                 |\n",
    "          ---------------\n",
    "          | Dropout(0.8) |          \n",
    "          ---------------  \n",
    "          ---------------\n",
    "          | BatchNormal |  \n",
    "          ---------------  \n",
    "          ---------------\n",
    "          | LSTM(64/128)|  \n",
    "          ---------------  \n",
    "                ^ \n",
    "                |  (1,7n-6,120)\n",
    "          ---------------\n",
    "          |    CNN      |  \n",
    "          ---------------  \n",
    "            ^\n",
    "            |\n",
    "        X(28,28xn,1)\n",
    "        cnnï¼špretained CNN model,convert a Image with shape(28a,28b,1)->(7a,7b,120)\n",
    "        rawNum: the Input  shape is (28,28*rawNum,1),rawNum is how many character in my train Example\n",
    "        n_a:LSTM hidden units\n",
    "        outdims:output dims of Seq model\n",
    "        \n",
    "        return:\n",
    "            model: with Input X:[28,28 x rawNum,1]\n",
    "                        Outputs:Y[7 x rawNum-6,outdims]\n",
    "    '''\n",
    "    X_Input=Input(shape=(28,28*rawNum,1),name='ImageInput')\n",
    "    X=cnn(X_Input) #shape (1,7n-6,120)\n",
    "    X=Lambda(lambda x:tf.squeeze(x,axis=1),name='squeeze')(X) #reshape to (7n-6,120)\n",
    "        #RNN begin\n",
    "    X=LSTM(n_a,return_sequences=True,name='lstm1')(X) #shape (7n-6,n_a)\n",
    "    X=BatchNormalization(name='BN1')(X)\n",
    "    X=Dropout(dropRate,name='dropout1')(X)\n",
    "        \n",
    "        #final classify \n",
    "    densor=Dense(outdims,activation='softmax')\n",
    "    X=TimeDistributed(densor,name='out')(X)  #shape (7n-6,outdims)\n",
    "        \n",
    "        #define model\n",
    "    model=Model(X_Input,X)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seqmodel=SeqModel(feature_model,rawNum=10,n_a=64,outdims=11,dropRate=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "ImageInput (InputLayer)      (None, 28, 280, 1)        0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              multiple                  96346     \n",
      "_________________________________________________________________\n",
      "squeeze (Lambda)             (None, 64, 120)           0         \n",
      "_________________________________________________________________\n",
      "lstm1 (LSTM)                 (None, 64, 64)            47360     \n",
      "_________________________________________________________________\n",
      "BN1 (BatchNormalization)     (None, 64, 64)            256       \n",
      "_________________________________________________________________\n",
      "dropout1 (Dropout)           (None, 64, 64)            0         \n",
      "_________________________________________________________________\n",
      "out (TimeDistributed)        (None, 64, 11)            715       \n",
      "=================================================================\n",
      "Total params: 144,677\n",
      "Trainable params: 48,203\n",
      "Non-trainable params: 96,474\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seqmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"629pt\" viewBox=\"0.00 0.00 215.00 629.00\" width=\"215pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 625)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-625 211,-625 211,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 139793780047712 -->\n",
       "<g class=\"node\" id=\"node1\"><title>139793780047712</title>\n",
       "<polygon fill=\"none\" points=\"42,-511.5 42,-547.5 165,-547.5 165,-511.5 42,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-525.8\">conv2d_1: Conv2D</text>\n",
       "</g>\n",
       "<!-- 139793612583376 -->\n",
       "<g class=\"node\" id=\"node2\"><title>139793612583376</title>\n",
       "<polygon fill=\"none\" points=\"0,-438.5 0,-474.5 207,-474.5 207,-438.5 0,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-452.8\">max_pooling2d_1: MaxPooling2D</text>\n",
       "</g>\n",
       "<!-- 139793780047712&#45;&gt;139793612583376 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>139793780047712-&gt;139793612583376</title>\n",
       "<path d=\"M103.5,-511.313C103.5,-503.289 103.5,-493.547 103.5,-484.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"107,-484.529 103.5,-474.529 100,-484.529 107,-484.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139793612583488 -->\n",
       "<g class=\"node\" id=\"node3\"><title>139793612583488</title>\n",
       "<polygon fill=\"none\" points=\"42,-365.5 42,-401.5 165,-401.5 165,-365.5 42,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-379.8\">conv2d_2: Conv2D</text>\n",
       "</g>\n",
       "<!-- 139793612583376&#45;&gt;139793612583488 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>139793612583376-&gt;139793612583488</title>\n",
       "<path d=\"M103.5,-438.313C103.5,-430.289 103.5,-420.547 103.5,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"107,-411.529 103.5,-401.529 100,-411.529 107,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139793612586848 -->\n",
       "<g class=\"node\" id=\"node4\"><title>139793612586848</title>\n",
       "<polygon fill=\"none\" points=\"0,-292.5 0,-328.5 207,-328.5 207,-292.5 0,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-306.8\">max_pooling2d_2: MaxPooling2D</text>\n",
       "</g>\n",
       "<!-- 139793612583488&#45;&gt;139793612586848 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>139793612583488-&gt;139793612586848</title>\n",
       "<path d=\"M103.5,-365.313C103.5,-357.289 103.5,-347.547 103.5,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"107,-338.529 103.5,-328.529 100,-338.529 107,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139793612799168 -->\n",
       "<g class=\"node\" id=\"node5\"><title>139793612799168</title>\n",
       "<polygon fill=\"none\" points=\"50,-219.5 50,-255.5 157,-255.5 157,-219.5 50,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-233.8\">feature: Conv2D</text>\n",
       "</g>\n",
       "<!-- 139793612586848&#45;&gt;139793612799168 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>139793612586848-&gt;139793612799168</title>\n",
       "<path d=\"M103.5,-292.313C103.5,-284.289 103.5,-274.547 103.5,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"107,-265.529 103.5,-255.529 100,-265.529 107,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139793612710576 -->\n",
       "<g class=\"node\" id=\"node6\"><title>139793612710576</title>\n",
       "<polygon fill=\"none\" points=\"42,-146.5 42,-182.5 165,-182.5 165,-146.5 42,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-160.8\">conv2d_3: Conv2D</text>\n",
       "</g>\n",
       "<!-- 139793612799168&#45;&gt;139793612710576 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>139793612799168-&gt;139793612710576</title>\n",
       "<path d=\"M103.5,-219.313C103.5,-211.289 103.5,-201.547 103.5,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"107,-192.529 103.5,-182.529 100,-192.529 107,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139793612798664 -->\n",
       "<g class=\"node\" id=\"node7\"><title>139793612798664</title>\n",
       "<polygon fill=\"none\" points=\"42,-73.5 42,-109.5 165,-109.5 165,-73.5 42,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-87.8\">conv2d_4: Conv2D</text>\n",
       "</g>\n",
       "<!-- 139793612710576&#45;&gt;139793612798664 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>139793612710576-&gt;139793612798664</title>\n",
       "<path d=\"M103.5,-146.313C103.5,-138.289 103.5,-128.547 103.5,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"107,-119.529 103.5,-109.529 100,-119.529 107,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139793612493320 -->\n",
       "<g class=\"node\" id=\"node8\"><title>139793612493320</title>\n",
       "<polygon fill=\"none\" points=\"48.5,-0.5 48.5,-36.5 158.5,-36.5 158.5,-0.5 48.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-14.8\">flatten_1: Flatten</text>\n",
       "</g>\n",
       "<!-- 139793612798664&#45;&gt;139793612493320 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>139793612798664-&gt;139793612493320</title>\n",
       "<path d=\"M103.5,-73.3129C103.5,-65.2895 103.5,-55.5475 103.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"107,-46.5288 103.5,-36.5288 100,-46.5289 107,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139793780046424 -->\n",
       "<g class=\"node\" id=\"node9\"><title>139793780046424</title>\n",
       "<polygon fill=\"none\" points=\"44.5,-584.5 44.5,-620.5 162.5,-620.5 162.5,-584.5 44.5,-584.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-598.8\">139793780046424</text>\n",
       "</g>\n",
       "<!-- 139793780046424&#45;&gt;139793780047712 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>139793780046424-&gt;139793780047712</title>\n",
       "<path d=\"M103.5,-584.313C103.5,-576.289 103.5,-566.547 103.5,-557.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"107,-557.529 103.5,-547.529 100,-557.529 107,-557.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"483pt\" viewBox=\"0.00 0.00 235.00 483.00\" width=\"235pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 479)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-479 231,-479 231,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 139793330724256 -->\n",
       "<g class=\"node\" id=\"node1\"><title>139793330724256</title>\n",
       "<polygon fill=\"none\" points=\"40,-438.5 40,-474.5 187,-474.5 187,-438.5 40,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113.5\" y=\"-452.8\">ImageInput: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139793780046816 -->\n",
       "<g class=\"node\" id=\"node2\"><title>139793780046816</title>\n",
       "<polygon fill=\"none\" points=\"59.5,-365.5 59.5,-401.5 167.5,-401.5 167.5,-365.5 59.5,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113.5\" y=\"-379.8\">model_1: Model</text>\n",
       "</g>\n",
       "<!-- 139793330724256&#45;&gt;139793780046816 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>139793330724256-&gt;139793780046816</title>\n",
       "<path d=\"M113.5,-438.313C113.5,-430.289 113.5,-420.547 113.5,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117,-411.529 113.5,-401.529 110,-411.529 117,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139793330722744 -->\n",
       "<g class=\"node\" id=\"node3\"><title>139793330722744</title>\n",
       "<polygon fill=\"none\" points=\"57.5,-292.5 57.5,-328.5 169.5,-328.5 169.5,-292.5 57.5,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113.5\" y=\"-306.8\">squeeze: Lambda</text>\n",
       "</g>\n",
       "<!-- 139793780046816&#45;&gt;139793330722744 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>139793780046816-&gt;139793330722744</title>\n",
       "<path d=\"M113.5,-365.313C113.5,-357.289 113.5,-347.547 113.5,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117,-338.529 113.5,-328.529 110,-338.529 117,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139793332224856 -->\n",
       "<g class=\"node\" id=\"node4\"><title>139793332224856</title>\n",
       "<polygon fill=\"none\" points=\"67.5,-219.5 67.5,-255.5 159.5,-255.5 159.5,-219.5 67.5,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113.5\" y=\"-233.8\">lstm1: LSTM</text>\n",
       "</g>\n",
       "<!-- 139793330722744&#45;&gt;139793332224856 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>139793330722744-&gt;139793332224856</title>\n",
       "<path d=\"M113.5,-292.313C113.5,-284.289 113.5,-274.547 113.5,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117,-265.529 113.5,-255.529 110,-265.529 117,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139793613168536 -->\n",
       "<g class=\"node\" id=\"node5\"><title>139793613168536</title>\n",
       "<polygon fill=\"none\" points=\"33.5,-146.5 33.5,-182.5 193.5,-182.5 193.5,-146.5 33.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113.5\" y=\"-160.8\">BN1: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 139793332224856&#45;&gt;139793613168536 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>139793332224856-&gt;139793613168536</title>\n",
       "<path d=\"M113.5,-219.313C113.5,-211.289 113.5,-201.547 113.5,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117,-192.529 113.5,-182.529 110,-192.529 117,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139793293613880 -->\n",
       "<g class=\"node\" id=\"node6\"><title>139793293613880</title>\n",
       "<polygon fill=\"none\" points=\"54.5,-73.5 54.5,-109.5 172.5,-109.5 172.5,-73.5 54.5,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113.5\" y=\"-87.8\">dropout1: Dropout</text>\n",
       "</g>\n",
       "<!-- 139793613168536&#45;&gt;139793293613880 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>139793613168536-&gt;139793293613880</title>\n",
       "<path d=\"M113.5,-146.313C113.5,-138.289 113.5,-128.547 113.5,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117,-119.529 113.5,-109.529 110,-119.529 117,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139793292463296 -->\n",
       "<g class=\"node\" id=\"node7\"><title>139793292463296</title>\n",
       "<polygon fill=\"none\" points=\"0,-0.5 0,-36.5 227,-36.5 227,-0.5 0,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113.5\" y=\"-14.8\">out(dense_1): TimeDistributed(Dense)</text>\n",
       "</g>\n",
       "<!-- 139793293613880&#45;&gt;139793292463296 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>139793293613880-&gt;139793292463296</title>\n",
       "<path d=\"M113.5,-73.3129C113.5,-65.2895 113.5,-55.5475 113.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117,-46.5288 113.5,-36.5288 110,-46.5289 117,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(seqmodel).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Prepare Data For Train,do not forget using oneHot representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seqDataPath='/home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/'\n",
    "def loadSeqData(onehot=True):\n",
    "    def _loadF(f):\n",
    "        hf=h5py.File(f,'r')\n",
    "        X=np.array(hf.get('X'))\n",
    "        Y=np.array(hf.get('Y'))\n",
    "        hf.close()\n",
    "        return X,Y\n",
    "    X_train,Y_train=_loadF(seqDataPath+'mnistSeq55k.h5')\n",
    "    X_test,Y_test=_loadF(seqDataPath+'mnistSeq10k.h5')\n",
    "    if(onehot):\n",
    "        Y_train=to_categorical(Y_train,11)\n",
    "        Y_test=to_categorical(Y_test,11)\n",
    "    print('\\n-------------------------------------------------------------------------')\n",
    "    print('load %d train Example,%d Test Example'%(X_train.shape[0],X_test.shape[0]))\n",
    "    print('Train Images  Shape:'+str(X_train.shape))\n",
    "    print('Train Labels  Shape:' + str(Y_train.shape))\n",
    "    print('Test  Images  Shape:'+str(X_test.shape))\n",
    "    print('Test  Labels  Shape:' + str(Y_test.shape))\n",
    "    print('-------------------------------------------------------------------------')\n",
    "    return (X_train,Y_train,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------------------------------\n",
      "load 55000 train Example,10000 Test Example\n",
      "Train Images  Shape:(55000, 28, 280, 1)\n",
      "Train Labels  Shape:(55000, 64, 11)\n",
      "Test  Images  Shape:(10000, 28, 280, 1)\n",
      "Test  Labels  Shape:(10000, 64, 11)\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train,X_test,Y_test=loadSeqData(onehot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputModelPath='/home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5'\n",
    "def monitorLearning():\n",
    "    def myLearnRateScheduler(epoch,lr):\n",
    "        print('ecpch:%d,learn rate %f'%(epoch,lr))\n",
    "        return lr\n",
    "    lr_scheduler=LearningRateScheduler(myLearnRateScheduler)\n",
    "    checkpoint=ModelCheckpoint(outputModelPath,monitor='val_acc',save_best_only=True,verbose=1)\n",
    "    reduceOnpleateau=ReduceLROnPlateau(monitor='val_loss',min_delta=5e-6,factor=0.9,verbose=1,patience=5)\n",
    "    return [lr_scheduler,checkpoint,reduceOnpleateau]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 10000 samples\n",
      "Epoch 1/500\n",
      "ecpch:0,learn rate 0.001000\n",
      "55000/55000 [==============================] - 134s 2ms/step - loss: 0.8430 - acc: 0.6982 - val_loss: 0.8451 - val_acc: 0.6970\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.69700, saving model to /home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 2/500\n",
      "ecpch:1,learn rate 0.001000\n",
      "55000/55000 [==============================] - 133s 2ms/step - loss: 0.8229 - acc: 0.7022 - val_loss: 0.8368 - val_acc: 0.6994\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.69700 to 0.69937, saving model to /home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 3/500\n",
      "ecpch:2,learn rate 0.001000\n",
      "55000/55000 [==============================] - 133s 2ms/step - loss: 0.8100 - acc: 0.7042 - val_loss: 0.8150 - val_acc: 0.7049\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.69937 to 0.70491, saving model to /home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 4/500\n",
      "ecpch:3,learn rate 0.001000\n",
      "55000/55000 [==============================] - 133s 2ms/step - loss: 0.7966 - acc: 0.7070 - val_loss: 0.7954 - val_acc: 0.7077\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.70491 to 0.70773, saving model to /home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 5/500\n",
      "ecpch:4,learn rate 0.001000\n",
      "55000/55000 [==============================] - 133s 2ms/step - loss: 0.7858 - acc: 0.7089 - val_loss: 0.7946 - val_acc: 0.7059\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.70773\n",
      "Epoch 6/500\n",
      "ecpch:5,learn rate 0.001000\n",
      "55000/55000 [==============================] - 133s 2ms/step - loss: 0.7775 - acc: 0.7107 - val_loss: 0.7753 - val_acc: 0.7113\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.70773 to 0.71128, saving model to /home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 7/500\n",
      "ecpch:6,learn rate 0.001000\n",
      "55000/55000 [==============================] - 133s 2ms/step - loss: 0.7650 - acc: 0.7136 - val_loss: 0.7642 - val_acc: 0.7139\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.71128 to 0.71391, saving model to /home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 8/500\n",
      "ecpch:7,learn rate 0.001000\n",
      "55000/55000 [==============================] - 133s 2ms/step - loss: 0.7504 - acc: 0.7170 - val_loss: 0.7629 - val_acc: 0.7142\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.71391 to 0.71417, saving model to /home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 9/500\n",
      "ecpch:8,learn rate 0.001000\n",
      "55000/55000 [==============================] - 133s 2ms/step - loss: 0.7395 - acc: 0.7200 - val_loss: 0.7443 - val_acc: 0.7198\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.71417 to 0.71976, saving model to /home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 10/500\n",
      "ecpch:9,learn rate 0.001000\n",
      "55000/55000 [==============================] - 133s 2ms/step - loss: 0.7299 - acc: 0.7224 - val_loss: 0.7626 - val_acc: 0.7168\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.71976\n",
      "Epoch 11/500\n",
      "ecpch:10,learn rate 0.001000\n",
      "55000/55000 [==============================] - 133s 2ms/step - loss: 0.7215 - acc: 0.7243 - val_loss: 0.7375 - val_acc: 0.7228\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.71976 to 0.72275, saving model to /home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 12/500\n",
      "ecpch:11,learn rate 0.001000\n",
      "55000/55000 [==============================] - 133s 2ms/step - loss: 0.7131 - acc: 0.7266 - val_loss: 0.7303 - val_acc: 0.7242\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.72275 to 0.72422, saving model to /home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 13/500\n",
      "ecpch:12,learn rate 0.001000\n",
      "55000/55000 [==============================] - 134s 2ms/step - loss: 0.7053 - acc: 0.7287 - val_loss: 0.7198 - val_acc: 0.7290\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.72422 to 0.72899, saving model to /home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 14/500\n",
      "ecpch:13,learn rate 0.001000\n",
      "55000/55000 [==============================] - 134s 2ms/step - loss: 0.6962 - acc: 0.7317 - val_loss: 0.7088 - val_acc: 0.7311\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.72899 to 0.73107, saving model to /home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 15/500\n",
      "ecpch:14,learn rate 0.001000\n",
      "55000/55000 [==============================] - 133s 2ms/step - loss: 0.6889 - acc: 0.7342 - val_loss: 0.7044 - val_acc: 0.7317\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.73107 to 0.73165, saving model to /home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 16/500\n",
      "ecpch:15,learn rate 0.001000\n",
      "55000/55000 [==============================] - 134s 2ms/step - loss: 0.6816 - acc: 0.7368 - val_loss: 0.7075 - val_acc: 0.7283\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.73165\n",
      "Epoch 17/500\n",
      "ecpch:16,learn rate 0.001000\n",
      "55000/55000 [==============================] - 134s 2ms/step - loss: 0.6746 - acc: 0.7393 - val_loss: 0.6949 - val_acc: 0.7377\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.73165 to 0.73773, saving model to /home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 18/500\n",
      "ecpch:17,learn rate 0.001000\n",
      "55000/55000 [==============================] - 133s 2ms/step - loss: 0.6682 - acc: 0.7419 - val_loss: 0.6838 - val_acc: 0.7340\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.73773\n",
      "Epoch 19/500\n",
      "ecpch:18,learn rate 0.001000\n",
      "55000/55000 [==============================] - 134s 2ms/step - loss: 0.6626 - acc: 0.7442 - val_loss: 0.6781 - val_acc: 0.7441\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.73773 to 0.74412, saving model to /home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 20/500\n",
      "ecpch:19,learn rate 0.001000\n",
      "55000/55000 [==============================] - 134s 2ms/step - loss: 0.6569 - acc: 0.7465 - val_loss: 0.6671 - val_acc: 0.7458\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.74412 to 0.74579, saving model to /home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 21/500\n",
      "ecpch:20,learn rate 0.001000\n",
      "55000/55000 [==============================] - 134s 2ms/step - loss: 0.6524 - acc: 0.7487 - val_loss: 0.6620 - val_acc: 0.7521\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.74579 to 0.75207, saving model to /home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 22/500\n",
      "ecpch:21,learn rate 0.001000\n",
      "55000/55000 [==============================] - 134s 2ms/step - loss: 0.6477 - acc: 0.7506 - val_loss: 0.6815 - val_acc: 0.7446\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.75207\n",
      "Epoch 23/500\n",
      "ecpch:22,learn rate 0.001000\n",
      "55000/55000 [==============================] - 134s 2ms/step - loss: 0.6435 - acc: 0.7527 - val_loss: 0.6660 - val_acc: 0.7481\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.75207\n",
      "Epoch 24/500\n",
      "ecpch:23,learn rate 0.001000\n",
      "55000/55000 [==============================] - 134s 2ms/step - loss: 0.6390 - acc: 0.7548 - val_loss: 0.6588 - val_acc: 0.7533\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.75207 to 0.75331, saving model to /home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 25/500\n",
      "ecpch:24,learn rate 0.001000\n",
      "55000/55000 [==============================] - 134s 2ms/step - loss: 0.6350 - acc: 0.7572 - val_loss: 0.6593 - val_acc: 0.7458\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.75331\n",
      "Epoch 26/500\n",
      "ecpch:25,learn rate 0.001000\n",
      "55000/55000 [==============================] - 134s 2ms/step - loss: 0.6303 - acc: 0.7598 - val_loss: 0.6869 - val_acc: 0.7479\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.75331\n",
      "Epoch 27/500\n",
      "ecpch:26,learn rate 0.001000\n",
      "55000/55000 [==============================] - 134s 2ms/step - loss: 0.6267 - acc: 0.7622 - val_loss: 0.6415 - val_acc: 0.7622\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.75331 to 0.76219, saving model to /home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 28/500\n",
      "ecpch:27,learn rate 0.001000\n",
      "55000/55000 [==============================] - 134s 2ms/step - loss: 0.6226 - acc: 0.7643 - val_loss: 0.6304 - val_acc: 0.7592\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.76219\n",
      "Epoch 29/500\n",
      "ecpch:28,learn rate 0.001000\n",
      "55000/55000 [==============================] - 134s 2ms/step - loss: 0.6185 - acc: 0.7673 - val_loss: 0.6561 - val_acc: 0.7562\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.76219\n",
      "Epoch 30/500\n",
      "ecpch:29,learn rate 0.001000\n",
      "55000/55000 [==============================] - 134s 2ms/step - loss: 0.6155 - acc: 0.7691 - val_loss: 0.6862 - val_acc: 0.7551\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.76219\n",
      "Epoch 31/500\n",
      "ecpch:30,learn rate 0.001000\n",
      "55000/55000 [==============================] - 134s 2ms/step - loss: 0.6118 - acc: 0.7714 - val_loss: 0.6158 - val_acc: 0.7734\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.76219 to 0.77340, saving model to /home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 32/500\n",
      "ecpch:31,learn rate 0.001000\n",
      "55000/55000 [==============================] - 135s 2ms/step - loss: 0.6065 - acc: 0.7741 - val_loss: 0.6252 - val_acc: 0.7699\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.77340\n",
      "Epoch 33/500\n",
      "ecpch:32,learn rate 0.001000\n",
      "55000/55000 [==============================] - 135s 2ms/step - loss: 0.6010 - acc: 0.7780 - val_loss: 0.6165 - val_acc: 0.7725\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.77340\n",
      "Epoch 34/500\n",
      "ecpch:33,learn rate 0.001000\n",
      "55000/55000 [==============================] - 135s 2ms/step - loss: 0.5974 - acc: 0.7803 - val_loss: 0.6054 - val_acc: 0.7798\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.77340 to 0.77982, saving model to /home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 35/500\n",
      "ecpch:34,learn rate 0.001000\n",
      "55000/55000 [==============================] - 135s 2ms/step - loss: 0.5929 - acc: 0.7834 - val_loss: 0.6103 - val_acc: 0.7731\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.77982\n",
      "Epoch 36/500\n",
      "ecpch:35,learn rate 0.001000\n",
      "55000/55000 [==============================] - 135s 2ms/step - loss: 0.5867 - acc: 0.7874 - val_loss: 0.5924 - val_acc: 0.7866\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.77982 to 0.78661, saving model to /home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 37/500\n",
      "ecpch:36,learn rate 0.001000\n",
      "55000/55000 [==============================] - 135s 2ms/step - loss: 0.5810 - acc: 0.7917 - val_loss: 0.6427 - val_acc: 0.7679\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.78661\n",
      "Epoch 38/500\n",
      "ecpch:37,learn rate 0.001000\n",
      "55000/55000 [==============================] - 135s 2ms/step - loss: 0.5740 - acc: 0.7978 - val_loss: 0.5642 - val_acc: 0.7994\n",
      "\n",
      "Epoch 00038: val_acc improved from 0.78661 to 0.79938, saving model to /home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 39/500\n",
      "ecpch:38,learn rate 0.001000\n",
      "55000/55000 [==============================] - 135s 2ms/step - loss: 0.5678 - acc: 0.8031 - val_loss: 0.6072 - val_acc: 0.7936\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.79938\n",
      "Epoch 40/500\n",
      "ecpch:39,learn rate 0.001000\n",
      "55000/55000 [==============================] - 135s 2ms/step - loss: 0.5659 - acc: 0.8073 - val_loss: 0.6229 - val_acc: 0.7879\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.79938\n",
      "Epoch 41/500\n",
      "ecpch:40,learn rate 0.001000\n",
      "55000/55000 [==============================] - 135s 2ms/step - loss: 0.5579 - acc: 0.8128 - val_loss: 0.5478 - val_acc: 0.8186\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.79938 to 0.81865, saving model to /home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 42/500\n",
      "ecpch:41,learn rate 0.001000\n",
      "55000/55000 [==============================] - 135s 2ms/step - loss: 0.5625 - acc: 0.8130 - val_loss: 0.5637 - val_acc: 0.8142\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.81865\n",
      "Epoch 43/500\n",
      "ecpch:42,learn rate 0.001000\n",
      "55000/55000 [==============================] - 135s 2ms/step - loss: 0.5589 - acc: 0.8162 - val_loss: 0.6287 - val_acc: 0.7930\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.81865\n",
      "Epoch 44/500\n",
      "ecpch:43,learn rate 0.001000\n",
      "55000/55000 [==============================] - 136s 2ms/step - loss: 0.5643 - acc: 0.8153 - val_loss: 0.5823 - val_acc: 0.8101\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.81865\n",
      "Epoch 45/500\n",
      "ecpch:44,learn rate 0.001000\n",
      "55000/55000 [==============================] - 149s 3ms/step - loss: 0.5650 - acc: 0.8154 - val_loss: 0.5417 - val_acc: 0.8261\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.81865 to 0.82612, saving model to /home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 46/500\n",
      "ecpch:45,learn rate 0.001000\n",
      "55000/55000 [==============================] - 168s 3ms/step - loss: 0.5514 - acc: 0.8217 - val_loss: 0.5379 - val_acc: 0.8258\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.82612\n",
      "Epoch 47/500\n",
      "ecpch:46,learn rate 0.001000\n",
      "55000/55000 [==============================] - 169s 3ms/step - loss: 0.5465 - acc: 0.8247 - val_loss: 0.5462 - val_acc: 0.8299\n",
      "\n",
      "Epoch 00047: val_acc improved from 0.82612 to 0.82993, saving model to /home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 48/500\n",
      "ecpch:47,learn rate 0.001000\n",
      "55000/55000 [==============================] - 171s 3ms/step - loss: 0.5587 - acc: 0.8206 - val_loss: 0.5353 - val_acc: 0.8310\n",
      "\n",
      "Epoch 00048: val_acc improved from 0.82993 to 0.83105, saving model to /home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 49/500\n",
      "ecpch:48,learn rate 0.001000\n",
      "55000/55000 [==============================] - 142s 3ms/step - loss: 0.5761 - acc: 0.8138 - val_loss: 0.6628 - val_acc: 0.7824\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.83105\n",
      "Epoch 50/500\n",
      "ecpch:49,learn rate 0.001000\n",
      "55000/55000 [==============================] - 138s 3ms/step - loss: 0.5636 - acc: 0.8199 - val_loss: 0.5106 - val_acc: 0.8406\n",
      "\n",
      "Epoch 00050: val_acc improved from 0.83105 to 0.84059, saving model to /home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 51/500\n",
      "ecpch:50,learn rate 0.001000\n",
      "55000/55000 [==============================] - 166s 3ms/step - loss: 0.5618 - acc: 0.8213 - val_loss: 0.5583 - val_acc: 0.8232\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.84059\n",
      "Epoch 52/500\n",
      "ecpch:51,learn rate 0.001000\n",
      "55000/55000 [==============================] - 170s 3ms/step - loss: 0.5643 - acc: 0.8210 - val_loss: 0.5150 - val_acc: 0.8404\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.84059\n",
      "Epoch 53/500\n",
      "ecpch:52,learn rate 0.001000\n",
      "55000/55000 [==============================] - 168s 3ms/step - loss: 0.5501 - acc: 0.8265 - val_loss: 0.5032 - val_acc: 0.8413\n",
      "\n",
      "Epoch 00053: val_acc improved from 0.84059 to 0.84131, saving model to /home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 54/500\n",
      "ecpch:53,learn rate 0.001000\n",
      "55000/55000 [==============================] - 155s 3ms/step - loss: 0.5567 - acc: 0.8247 - val_loss: 0.5544 - val_acc: 0.8294\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.84131\n",
      "Epoch 55/500\n",
      "ecpch:54,learn rate 0.001000\n",
      "55000/55000 [==============================] - 138s 3ms/step - loss: 0.5654 - acc: 0.8215 - val_loss: 0.5987 - val_acc: 0.8134\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.84131\n",
      "Epoch 56/500\n",
      "ecpch:55,learn rate 0.001000\n",
      "55000/55000 [==============================] - 142s 3ms/step - loss: 0.5597 - acc: 0.8237 - val_loss: 0.5765 - val_acc: 0.8175\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.84131\n",
      "Epoch 57/500\n",
      "ecpch:56,learn rate 0.001000\n",
      "55000/55000 [==============================] - 169s 3ms/step - loss: 0.5666 - acc: 0.8202 - val_loss: 0.5266 - val_acc: 0.8368\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.84131\n",
      "Epoch 58/500\n",
      "ecpch:57,learn rate 0.001000\n",
      "55000/55000 [==============================] - 167s 3ms/step - loss: 0.5756 - acc: 0.8181 - val_loss: 0.5125 - val_acc: 0.8404\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.84131\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "Epoch 59/500\n",
      "ecpch:58,learn rate 0.000900\n",
      "55000/55000 [==============================] - 172s 3ms/step - loss: 0.5415 - acc: 0.8305 - val_loss: 0.5150 - val_acc: 0.8391\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.84131\n",
      "Epoch 60/500\n",
      "ecpch:59,learn rate 0.000900\n",
      "55000/55000 [==============================] - 161s 3ms/step - loss: 0.5360 - acc: 0.8339 - val_loss: 0.8142 - val_acc: 0.7366\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.84131\n",
      "Epoch 61/500\n",
      "ecpch:60,learn rate 0.000900\n",
      "55000/55000 [==============================] - 139s 3ms/step - loss: 0.5476 - acc: 0.8293 - val_loss: 0.5488 - val_acc: 0.8274\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.84131\n",
      "Epoch 62/500\n",
      "ecpch:61,learn rate 0.000900\n",
      "55000/55000 [==============================] - 165s 3ms/step - loss: 0.5579 - acc: 0.8249 - val_loss: 0.5445 - val_acc: 0.8300\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.84131\n",
      "Epoch 63/500\n",
      "ecpch:62,learn rate 0.000900\n",
      "55000/55000 [==============================] - 143s 3ms/step - loss: 0.5377 - acc: 0.8325 - val_loss: 0.4900 - val_acc: 0.8470\n",
      "\n",
      "Epoch 00063: val_acc improved from 0.84131 to 0.84699, saving model to /home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 64/500\n",
      "ecpch:63,learn rate 0.000900\n",
      "55000/55000 [==============================] - 138s 3ms/step - loss: 0.5334 - acc: 0.8341 - val_loss: 0.5689 - val_acc: 0.8236\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.84699\n",
      "Epoch 65/500\n",
      "ecpch:64,learn rate 0.000900\n",
      "55000/55000 [==============================] - 142s 3ms/step - loss: 0.5435 - acc: 0.8304 - val_loss: 0.5122 - val_acc: 0.8410\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.84699\n",
      "Epoch 66/500\n",
      "ecpch:65,learn rate 0.000900\n",
      "55000/55000 [==============================] - 147s 3ms/step - loss: 0.5360 - acc: 0.8330 - val_loss: 0.5259 - val_acc: 0.8358\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.84699\n",
      "Epoch 67/500\n",
      "ecpch:66,learn rate 0.000900\n",
      "55000/55000 [==============================] - 159s 3ms/step - loss: 0.5390 - acc: 0.8324 - val_loss: 0.5915 - val_acc: 0.8215\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.84699\n",
      "Epoch 68/500\n",
      "ecpch:67,learn rate 0.000900\n",
      "55000/55000 [==============================] - 137s 2ms/step - loss: 0.5373 - acc: 0.8333 - val_loss: 0.5478 - val_acc: 0.8349\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.84699\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "Epoch 69/500\n",
      "ecpch:68,learn rate 0.000810\n",
      "55000/55000 [==============================] - 147s 3ms/step - loss: 0.5360 - acc: 0.8338 - val_loss: 0.4940 - val_acc: 0.8517\n",
      "\n",
      "Epoch 00069: val_acc improved from 0.84699 to 0.85173, saving model to /home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 70/500\n",
      "ecpch:69,learn rate 0.000810\n",
      "55000/55000 [==============================] - 139s 3ms/step - loss: 0.5111 - acc: 0.8433 - val_loss: 0.5383 - val_acc: 0.8348\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.85173\n",
      "Epoch 71/500\n",
      "ecpch:70,learn rate 0.000810\n",
      "55000/55000 [==============================] - 146s 3ms/step - loss: 0.5086 - acc: 0.8439 - val_loss: 0.4895 - val_acc: 0.8494\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.85173\n",
      "Epoch 72/500\n",
      "ecpch:71,learn rate 0.000810\n",
      "55000/55000 [==============================] - 164s 3ms/step - loss: 0.4991 - acc: 0.8474 - val_loss: 0.6178 - val_acc: 0.7985\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.85173\n",
      "Epoch 73/500\n",
      "ecpch:72,learn rate 0.000810\n",
      "55000/55000 [==============================] - 164s 3ms/step - loss: 0.4973 - acc: 0.8482 - val_loss: 0.4838 - val_acc: 0.8550\n",
      "\n",
      "Epoch 00073: val_acc improved from 0.85173 to 0.85503, saving model to /home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 74/500\n",
      "ecpch:73,learn rate 0.000810\n",
      "55000/55000 [==============================] - 156s 3ms/step - loss: 0.5230 - acc: 0.8396 - val_loss: 0.8916 - val_acc: 0.7281\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.85503\n",
      "Epoch 75/500\n",
      "ecpch:74,learn rate 0.000810\n",
      "55000/55000 [==============================] - 149s 3ms/step - loss: 0.5025 - acc: 0.8463 - val_loss: 0.4483 - val_acc: 0.8645\n",
      "\n",
      "Epoch 00075: val_acc improved from 0.85503 to 0.86446, saving model to /home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 76/500\n",
      "ecpch:75,learn rate 0.000810\n",
      "55000/55000 [==============================] - 163s 3ms/step - loss: 0.4929 - acc: 0.8497 - val_loss: 0.4808 - val_acc: 0.8522\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.86446\n",
      "Epoch 77/500\n",
      "ecpch:76,learn rate 0.000810\n",
      "55000/55000 [==============================] - 161s 3ms/step - loss: 0.5006 - acc: 0.8469 - val_loss: 0.4538 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.86446\n",
      "Epoch 78/500\n",
      "ecpch:77,learn rate 0.000810\n",
      "55000/55000 [==============================] - 160s 3ms/step - loss: 0.5329 - acc: 0.8365 - val_loss: 0.6335 - val_acc: 0.7998\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.86446\n",
      "Epoch 79/500\n",
      "ecpch:78,learn rate 0.000810\n",
      "55000/55000 [==============================] - 137s 2ms/step - loss: 0.5018 - acc: 0.8464 - val_loss: 0.4699 - val_acc: 0.8575\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.86446\n",
      "Epoch 80/500\n",
      "ecpch:79,learn rate 0.000810\n",
      "55000/55000 [==============================] - 148s 3ms/step - loss: 0.5090 - acc: 0.8444 - val_loss: 0.4604 - val_acc: 0.8597\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.86446\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
      "Epoch 81/500\n",
      "ecpch:80,learn rate 0.000729\n",
      "55000/55000 [==============================] - 166s 3ms/step - loss: 0.4863 - acc: 0.8523 - val_loss: 0.5667 - val_acc: 0.8274\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.86446\n",
      "Epoch 82/500\n",
      "ecpch:81,learn rate 0.000729\n",
      "55000/55000 [==============================] - 162s 3ms/step - loss: 0.4752 - acc: 0.8562 - val_loss: 0.4916 - val_acc: 0.8481\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.86446\n",
      "Epoch 83/500\n",
      "ecpch:82,learn rate 0.000729\n",
      "55000/55000 [==============================] - 150s 3ms/step - loss: 0.4699 - acc: 0.8580 - val_loss: 0.4340 - val_acc: 0.8700\n",
      "\n",
      "Epoch 00083: val_acc improved from 0.86446 to 0.87001, saving model to /home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 84/500\n",
      "ecpch:83,learn rate 0.000729\n",
      "55000/55000 [==============================] - 137s 2ms/step - loss: 0.4739 - acc: 0.8568 - val_loss: 0.4696 - val_acc: 0.8561\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.87001\n",
      "Epoch 85/500\n",
      "ecpch:84,learn rate 0.000729\n",
      "55000/55000 [==============================] - 136s 2ms/step - loss: 0.4856 - acc: 0.8523 - val_loss: 0.5098 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.87001\n",
      "Epoch 86/500\n",
      "ecpch:85,learn rate 0.000729\n",
      "55000/55000 [==============================] - 137s 2ms/step - loss: 0.4922 - acc: 0.8509 - val_loss: 0.4884 - val_acc: 0.8530\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.87001\n",
      "Epoch 87/500\n",
      "ecpch:86,learn rate 0.000729\n",
      "55000/55000 [==============================] - 162s 3ms/step - loss: 0.4682 - acc: 0.8585 - val_loss: 0.4208 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00087: val_acc improved from 0.87001 to 0.87291, saving model to /home/zhangxk/PycharmProjects/untitled/deepAI/daily/AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 88/500\n",
      "ecpch:87,learn rate 0.000729\n",
      "55000/55000 [==============================] - 165s 3ms/step - loss: 0.4870 - acc: 0.8528 - val_loss: 0.4847 - val_acc: 0.8559\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.87291\n",
      "Epoch 89/500\n",
      "ecpch:88,learn rate 0.000729\n",
      "55000/55000 [==============================] - 156s 3ms/step - loss: 0.4854 - acc: 0.8531 - val_loss: 0.4840 - val_acc: 0.8542\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.87291\n",
      "Epoch 90/500\n",
      "ecpch:89,learn rate 0.000729\n",
      "55000/55000 [==============================] - 161s 3ms/step - loss: 0.4820 - acc: 0.8540 - val_loss: 0.4447 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.87291\n",
      "Epoch 91/500\n",
      "ecpch:90,learn rate 0.000729\n",
      "55000/55000 [==============================] - 136s 2ms/step - loss: 0.4773 - acc: 0.8562 - val_loss: 0.4384 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.87291\n",
      "Epoch 92/500\n",
      "ecpch:91,learn rate 0.000729\n",
      " 4864/55000 [=>............................] - ETA: 1:54 - loss: 0.4724 - acc: 0.8570"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-352cc4c138bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mseqmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rmsprop'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mseqmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmonitorLearning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2665\u001b[0m                     \u001b[1;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2666\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[1;32m-> 2667\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2669\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2647\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2648\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2649\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2650\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1140\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1141\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1321\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1312\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[0;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m             status, run_metadata)\n\u001b[0m\u001b[0;32m   1421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1422\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seqmodel.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "seqmodel.fit(X_train,Y_train,epochs=500,batch_size=64,validation_data=(X_test,Y_test),callbacks=monitorLearning())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

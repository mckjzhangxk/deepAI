{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "problem1  assign value to tensor variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.eager.python import tfe\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# problem1 :assign value to tensor variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6661053\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "W=tf.get_variable('W',shape=[])\n",
    "\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(W.assign(2.0))\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "# sess.run(W.initializer)\n",
    "print(sess.run(W))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### problem1_1:find all uninitialize variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'W1' b'W2']\n",
      "[b'W2']\n",
      "[]\n",
      "[[ 0.45917213  0.11933637]\n",
      " [ 0.24807417 -0.84282833]\n",
      " [ 0.5821041  -0.30012006]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess=tf.Session()\n",
    "W1=tf.get_variable('W1',shape=[2,3])\n",
    "W2=tf.get_variable('W2',shape=[3,2])\n",
    "\n",
    "uninit_vars=tf.report_uninitialized_variables()\n",
    "print(sess.run(uninit_vars))\n",
    "\n",
    "sess.run(W1.assign(np.zeros((2,3))))\n",
    "print(sess.run(uninit_vars))\n",
    "\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "need_init_vars=sess.run(uninit_vars)\n",
    "op=[]\n",
    "with tf.variable_scope('',reuse=True):\n",
    "    for v in need_init_vars:\n",
    "        name=v.decode(\"utf-8\")\n",
    "        init_op=[v.initializer for v in tf.global_variables(name)]\n",
    "        op.extend(init_op)\n",
    "sess.run(op)\n",
    "print(sess.run(uninit_vars))\n",
    "print(sess.run(W2))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# problem2:how to remove trainable variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "def nn():\n",
    "    W1=tf.get_variable('W1',shape=[])\n",
    "    W2=tf.get_variable('W2',shape=[])\n",
    "    cost=W1+W2\n",
    "    return (W1,W2,cost)\n",
    "W1,W2,cost=nn()\n",
    "opt=tf.train.GradientDescentOptimizer(1).minimize(cost)\n",
    "\n",
    "\n",
    "sess=tf.InteractiveSession()\n",
    "sess.run(W1.assign(5.0))\n",
    "sess.run(W2.assign(5.0))\n",
    "\n",
    "for i in range(1):\n",
    "    sess.run(opt)\n",
    "print(tf.trainable_variables())\n",
    "print(cost.eval()) #output 8\n",
    "\n",
    "opt=tf.train.GradientDescentOptimizer(1).minimize(cost,var_list=[W2])\n",
    "#train nn again\n",
    "for i in range(1):\n",
    "    sess.run(opt) \n",
    "print(cost.eval()) #output 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## problem3:share parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "def nn(X):\n",
    "    #create variables if they do not exist, and return them otherwise;\n",
    "    with tf.variable_scope('s1',reuse=tf.AUTO_REUSE):  \n",
    "        W=tf.get_variable('W',shape=[])\n",
    "        out=X*W\n",
    "    return out\n",
    "def compute_cost(f1,f2):\n",
    "    return f1+f2\n",
    "X1=tf.constant(-5.0)\n",
    "X2=tf.constant(3.0)\n",
    "\n",
    "loss=compute_cost(nn(X1),nn(X2)) #loss=-2W,gradient=-2 new loss=-2(w+2)=-2w-4\n",
    "opt=tf.train.GradientDescentOptimizer(1).minimize(loss)\n",
    "\n",
    "sess=tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(3):\n",
    "    sess.run(opt)\n",
    "    _c=sess.run(loss)\n",
    "    #notice grad=X1+X2,cost=X1(W-X1-X2)+X2(W-X1-X2)=cost_old-(X1+X2)**2\n",
    "    print(_c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## problem 4:L2 reugluar\n",
    "    Question:I set regularizationer when create a varible,but not add l2 loss to total_loss,\n",
    "    do l2 redular hava effect?\n",
    "    \n",
    "    conculsion:must add to total loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'W/Regularizer/l2_regularizer:0' shape=() dtype=float32>]\n",
      "Tensor(\"total_regularization_loss:0\", shape=(), dtype=float32)\n",
      "loss= 319.88,w=-8.00,grad=80.02\n",
      "loss= 25931.26,w=72.02,grad=-720.16\n",
      "loss= 2100430.25,w=-648.14,grad=6481.40\n",
      "loss= 170134816.00,w=5833.26,grad=-58332.64\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess=tf.Session()\n",
    "W=tf.get_variable('W',shape=(),regularizer=tf.contrib.layers.l2_regularizer(10.0))\n",
    "print(tf.losses.get_regularization_losses())\n",
    "print(tf.losses.get_regularization_loss())\n",
    "# LOSS=1/W+scale/2*(W^2)\n",
    "LOSS=1/W+tf.losses.get_regularization_loss()\n",
    "sess.run(W.assign(1.0))\n",
    "optimizer=tf.train.GradientDescentOptimizer(1).minimize(LOSS)\n",
    "#grad=1/W^2+w\n",
    "for i in range(4):\n",
    "    sess.run(optimizer)\n",
    "    _loss,_w=sess.run([LOSS,W])\n",
    "    print('loss= %.2f,w=%.2f,grad=%.2f'%(_loss,_w,-10*_w+1/(_w**2)))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## how xavier_initializer work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:mean 0.03,variance 0.96\n",
      "W1:mean -0.00,variance 0.00\n",
      "W1x:mean 0.01,variance 0.64\n",
      "W2:mean -0.00,variance 0.00\n",
      "W2x:mean 0.00,variance 0.52\n",
      "0.0005\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# initializer=tf.initializers.random_normal(0.0,1.0)\n",
    "# initializer=tf.initializers.random_uniform(0.0,1.0)\n",
    "initializer=tf.contrib.layers.xavier_initializer(uniform=True)\n",
    "# initializer=None\n",
    "\n",
    "sess=tf.Session()\n",
    "N,N1,N2=1000,2000,3000\n",
    "X=tf.random.normal(shape=[N,1])\n",
    "W1=tf.get_variable('W1',shape=[N1,N],initializer=initializer)\n",
    "W1_X=tf.matmul(W1,X)\n",
    "\n",
    "W2=tf.get_variable('W2',shape=[N2,N1],initializer=initializer)\n",
    "W2_X=tf.matmul(W2,W1_X)\n",
    "\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(1):\n",
    "    x=sess.run(X)\n",
    "    print('x:mean %.2f,variance %.2f'%(np.mean(x),np.var(x)))\n",
    "\n",
    "    x=sess.run(W1)\n",
    "    print('W1:mean %.2f,variance %.2f'%(np.mean(x),np.var(x)))\n",
    "\n",
    "    \n",
    "    x=sess.run(W1_X)\n",
    "    print('W1x:mean %.2f,variance %.2f'%(np.mean(x),np.var(x)))\n",
    "     \n",
    "    x=sess.run(W2)\n",
    "    print('W2:mean %.2f,variance %.2f'%(np.mean(x),np.var(x)))\n",
    "\n",
    "    x=sess.run(W2_X)\n",
    "    print('W2x:mean %.2f,variance %.2f'%(np.mean(x),np.var(x)))\n",
    "    \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# WEEK 1 <a href='https://www.coursera.org/learn/intro-tensorflow/lecture/n691C/tensors'>turtorial 1</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorboard\n",
    "import numpy as np\n",
    "#tensorflow can work on eager mode,notice  tfe.enable_eager_execution() must be call at startup,call only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tfe.enable_eager_execution()\n",
    "a=tf.constant(1.0)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#evaluate tensor\n",
    "with tf.Session() as sess:\n",
    "    print(a.eval()) #eval mean evaluate a at content of sess,a shortcut of sess.run(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#visualization,using tensorboard\n",
    "\n",
    "x=tf.constant(3.0,name='x')\n",
    "y=tf.constant(3.0,name='y')\n",
    "z=tf.add(x,y,name='z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    #tensorboard --port 8080 --logdir=/home/zhangxk/PycharmProjects/untitled/deepAI/daily/8/summary\n",
    "    with tf.summary.FileWriter('summary',sess.graph) as writer:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/tensor.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='https://www.tensorflow.org/api_docs/python/tf/stack'>stack doc</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tensorEx():\n",
    "    tf.reset_default_graph()\n",
    "    x1=tf.constant([1,2,3],name='x1') #(3,)\n",
    "    x2=tf.stack([x1 ,x1],name='x2') #(2,3)\n",
    "    x3=tf.stack([x2,x2,x2,x2],name='x3') #(4,2,3)\n",
    "    x4=tf.stack([x3,x3],name='x4') #(2,4,2,3)\n",
    "    print('x1 shape:'+str(x1.shape))\n",
    "    print('x2 shape:'+str(x2.shape))\n",
    "    print('x3 shape:'+str(x3.shape))\n",
    "    print('x4 shape:'+str(x4.shape))\n",
    "    \n",
    "    #this is a example of inception implement\n",
    "    conv3=tf.constant(np.random.randn(100,14,14,32),name='3x3')\n",
    "    conv5=tf.constant(np.random.randn(100,14,14,16),name='5x5')\n",
    "    conv7=tf.constant(np.random.randn(100,14,14,8),name='7x7')\n",
    "    out=tf.concat([conv3,conv5,conv7],axis=3,name='out')\n",
    "    print('out shape:'+str(out.shape))\n",
    "    with tf.Session() as sess:\n",
    "        with tf.summary.FileWriter('summary/',sess.graph) as writer:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensorEx()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Common Error\n",
    "### 1.Shape error\n",
    "<a href='https://www.tensorflow.org/api_docs/python/tf/slice'>slice</a> <a href='https://www.tensorflow.org/api_docs/python/tf/squeeze'>squeeze</a> <a href='https://www.tensorflow.org/api_docs/python/tf/expand_dims'>expand_dims</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shape_error():\n",
    "    A=tf.constant(shape=[2,3,4],value=1.0)\n",
    "    B=tf.constant(shape=[2,3],value=1.0)\n",
    "    #to fix error\n",
    "    \n",
    "    #1.B need rank 3,so expend [2,3,1] then brost cast\n",
    "    #B=tf.expand_dims(B,axis=2)\n",
    "    \n",
    "    #2.convert A to a (2,3) matrix\n",
    "    A=tf.slice(A,begin=[0,0,0],size=[2,3,1]) #A[0:2,0:3,0:1],shape[2,3,1]\n",
    "    A=tf.squeeze(A,axis=-1)\n",
    "    \n",
    "    C=A+B\n",
    "    \n",
    "    print(C.get_shape())\n",
    "shape_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.DataType errpr <a href='https://www.tensorflow.org/api_docs/python/tf/cast'>cast</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dataType_error():\n",
    "    A=tf.constant(shape=[2,3],value=1)\n",
    "    B=tf.constant(shape=[2,3],value=1.0)\n",
    "    \n",
    "    B=tf.cast(B,tf.int32)\n",
    "    C=A+B\n",
    "dataType_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. USE debuger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python import debug as tf_debug\n",
    "\n",
    "def mydiv(a, b):\n",
    "    s = tf.div(a,b,name='a/b')\n",
    "    s2 = tf.matmul(s, tf.transpose(s,name='s_transpose'),name='s_normal2')\n",
    "    return tf.sqrt(s2,name='s_normal')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    fake_a = [\n",
    "      [5.0, 3.0, 7.1],\n",
    "      [2.3, 4.1, 4.8],\n",
    "    ]\n",
    "    fake_b = [\n",
    "      [2, 0, 5],\n",
    "      [2, 8, 7]\n",
    "    ]\n",
    "    a = tf.placeholder(tf.float32, shape=[2, 3],name='a')\n",
    "    b = tf.placeholder(tf.float32, shape=[2, 3],name='b')\n",
    "    k = mydiv(a, b)\n",
    "  \n",
    "  # Note: won't work without the ui_type=\"readline\" argument because\n",
    "  # Datalab is not an interactive terminal and doesn't support the default \"curses\" ui_type.\n",
    "  # If you are running this a standalone program, omit the ui_type parameter and add --debug\n",
    "  # when invoking the TensorFlow program\n",
    "  #      --debug (e.g: python debugger.py --debug )\n",
    "    sess = tf_debug.LocalCLIDebugWrapperSession(sess, ui_type=\"readline\")\n",
    "    sess.add_tensor_filter(\"has_inf_or_nan\", tf_debug.has_inf_or_nan)\n",
    "    print(sess.run(k, feed_dict = {a: fake_a, b: fake_b}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the tfdbg> window that comes up, try the following:\n",
    "* run -f has_inf_or_nan\n",
    "* Notice that several tensors are dumped once the filter criterion is met\n",
    "* List the inputs to a specific tensor:\n",
    "* li transpose:0 \n",
    "* Print the value of a tensor\n",
    "* pt transpose:0\n",
    "* Where is the inf?\n",
    "\n",
    "Visit https://www.tensorflow.org/programmers_guide/debugger for usage details of tfdbg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use of tf.train.range_input_producer\n",
    "import tensorflow as tf\n",
    "sess=tf.Session()\n",
    "# m=tf.constant(10,dtype=tf.int32)\n",
    "m=1200\n",
    "epochs=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "range_queue=tf.train.range_input_producer(m,num_epochs=epochs,capacity=32)\n",
    "print(range_queue)\n",
    "one_depart=range_queue.dequeue_many(m)\n",
    "print(one_depart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(one_depart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-3b3411994b35>:2: range_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.range(limit).shuffle(limit).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:318: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:188: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:197: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:197: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    }
   ],
   "source": [
    "NUM_EXPOCHES=3\n",
    "i = tf.train.range_input_producer(NUM_EXPOCHES, num_epochs=2, shuffle=False).dequeue()\n",
    "# inputs = tf.slice(array, [i * BATCH_SIZE], [BATCH_SIZE])\n",
    "sess.run(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

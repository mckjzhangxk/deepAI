{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nn(x,initvalue):\n",
    "    return tf.reduce_sum(x)+initvalue\n",
    "\n",
    "T=8\n",
    "tf.reset_default_graph()\n",
    "g=tf.get_default_graph()\n",
    "\n",
    "\n",
    "source=tf.constant([1,2,3,4,5,6,7,8],dtype=tf.float32)\n",
    "X=tf.get_variable('X',shape=[2])\n",
    "t=tf.placeholder(dtype=tf.int32)\n",
    "x_update_op=tf.assign(X,source[t*2:t*2+2])\n",
    "\n",
    "with g.control_dependencies([x_update_op]):\n",
    "    init_state=tf.get_variable('init_state',shape=[],initializer=tf.zeros_initializer)\n",
    "    final_state=nn(X,init_state)\n",
    "    update_op=tf.assign(init_state,final_state)\n",
    "    op2=tf.group([update_op])\n",
    "\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for _t in range(4):\n",
    "#     print(sess.run(update_op,feed_dict={t:_t}))\n",
    "    print(sess.run(update_op,feed_dict={t:_t}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def randomFile(path,N,T,D):\n",
    "    with open(path,'w') as f:\n",
    "        for n in range(N):\n",
    "            s=''\n",
    "            for t in range(T):\n",
    "                s1=''\n",
    "                for d in range(D):\n",
    "                    s1+=str(n+d)+','\n",
    "                s+=s1\n",
    "            s=s[:-1]\n",
    "            \n",
    "            f.write(s+'\\n')\n",
    "N,T,D=200,30,3\n",
    "randomFile('/home/zhangxk/my.txt',N,T,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_pipe(datafile,batch_size,T,D):\n",
    "    '''\n",
    "        返回一个(batch_size,T,D)的source,表示每一次从文件取出来的一批数据\n",
    "        iterator:迭代对象,用户初始化数据源\n",
    "    '''\n",
    "    dataset=tf.data.TextLineDataset(datafile)\n",
    "    #每一行用,分割开\n",
    "    dataset=dataset.map(lambda line:tf.string_split([line],',').values)\n",
    "    #字符串数组转成float32\n",
    "    dataset=dataset.map(lambda x:tf.string_to_number(x,tf.float32))\n",
    "    #数据分割成batch\n",
    "    dataset=dataset.batch(batch_size)\n",
    "    \n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    #把dataset转成tensor,shape[batch,?]\n",
    "    source_batch=iterator.get_next()\n",
    "    source_batch=tf.reshape(source_batch,shape=[-1,T,D])\n",
    "    return source_batch,iterator\n",
    "def prepareInput(source,period,batch,T,D):\n",
    "    '''\n",
    "    source是一个很长的序列,shape[?,T,D],\n",
    "    创建RNN的一个输入X,shape[batch,period,D],使用一个游标cursor,\n",
    "    每次把source中period序列取出,赋值给X\n",
    "    \n",
    "    返回 :\n",
    "    X:RNN的输入\n",
    "    assign_op:\n",
    "    cursor:一个placeholder,游标\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    #创建一个source的副本,然后把source复制给tmp_source\n",
    "    tmp_source=tf.get_variable('tmp_source',shape=[batch,T,D],trainable=False)\n",
    "    tmp_source_op=tf.assign(tmp_source,source)\n",
    "    \n",
    "    #真实的source,batchsize不一定是batch,所有在刷新数据源的时候要保存实际batch长度\n",
    "    real_batch=tf.get_variable('real_batch',shape=[],dtype=tf.int32,trainable=False)\n",
    "    REAL_BATCH=tf.shape(source)[0]\n",
    "    real_batch_assign_op=tf.assign(real_batch,REAL_BATCH)\n",
    "    \n",
    "    cursor=tf.placeholder(tf.int32)\n",
    "    X=tf.get_variable('input',shape=[batch,period,D],trainable=False)\n",
    "    X=tf.assign(X,tmp_source[:,cursor*period:cursor*period+period])\n",
    "    \n",
    "    op=tf.group([tmp_source_op,real_batch_assign_op])\n",
    "    return X[:real_batch],op,cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N,T,D=200,30,3\n",
    "period=2\n",
    "batch=1\n",
    "\n",
    "tf.reset_default_graph()\n",
    "source,source_iterator=data_pipe('/home/zhangxk/my.txt',batch,T,D)\n",
    "X,assignSource,cursor=prepareInput(source,period,batch,T,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 1. 2.]\n",
      "  [0. 1. 2.]]]\n",
      "[[[0. 1. 2.]\n",
      "  [0. 1. 2.]]]\n",
      "[[[0. 1. 2.]\n",
      "  [0. 1. 2.]]]\n",
      "[[[0. 1. 2.]\n",
      "  [0. 1. 2.]]]\n",
      "[[[0. 1. 2.]\n",
      "  [0. 1. 2.]]]\n",
      "[[[0. 1. 2.]\n",
      "  [0. 1. 2.]]]\n",
      "[[[0. 1. 2.]\n",
      "  [0. 1. 2.]]]\n",
      "[[[0. 1. 2.]\n",
      "  [0. 1. 2.]]]\n",
      "[[[0. 1. 2.]\n",
      "  [0. 1. 2.]]]\n",
      "[[[0. 1. 2.]\n",
      "  [0. 1. 2.]]]\n",
      "[[[0. 1. 2.]\n",
      "  [0. 1. 2.]]]\n",
      "[[[0. 1. 2.]\n",
      "  [0. 1. 2.]]]\n",
      "[[[0. 1. 2.]\n",
      "  [0. 1. 2.]]]\n",
      "[[[0. 1. 2.]\n",
      "  [0. 1. 2.]]]\n",
      "[[[0. 1. 2.]\n",
      "  [0. 1. 2.]]]\n",
      "[[[1. 2. 3.]\n",
      "  [1. 2. 3.]]]\n",
      "[[[1. 2. 3.]\n",
      "  [1. 2. 3.]]]\n",
      "[[[1. 2. 3.]\n",
      "  [1. 2. 3.]]]\n",
      "[[[1. 2. 3.]\n",
      "  [1. 2. 3.]]]\n",
      "[[[1. 2. 3.]\n",
      "  [1. 2. 3.]]]\n",
      "[[[1. 2. 3.]\n",
      "  [1. 2. 3.]]]\n",
      "[[[1. 2. 3.]\n",
      "  [1. 2. 3.]]]\n",
      "[[[1. 2. 3.]\n",
      "  [1. 2. 3.]]]\n",
      "[[[1. 2. 3.]\n",
      "  [1. 2. 3.]]]\n",
      "[[[1. 2. 3.]\n",
      "  [1. 2. 3.]]]\n",
      "[[[1. 2. 3.]\n",
      "  [1. 2. 3.]]]\n",
      "[[[1. 2. 3.]\n",
      "  [1. 2. 3.]]]\n",
      "[[[1. 2. 3.]\n",
      "  [1. 2. 3.]]]\n",
      "[[[1. 2. 3.]\n",
      "  [1. 2. 3.]]]\n",
      "[[[1. 2. 3.]\n",
      "  [1. 2. 3.]]]\n",
      "[[[2. 3. 4.]\n",
      "  [2. 3. 4.]]]\n",
      "[[[2. 3. 4.]\n",
      "  [2. 3. 4.]]]\n",
      "[[[2. 3. 4.]\n",
      "  [2. 3. 4.]]]\n",
      "[[[2. 3. 4.]\n",
      "  [2. 3. 4.]]]\n",
      "[[[2. 3. 4.]\n",
      "  [2. 3. 4.]]]\n",
      "[[[2. 3. 4.]\n",
      "  [2. 3. 4.]]]\n",
      "[[[2. 3. 4.]\n",
      "  [2. 3. 4.]]]\n",
      "[[[2. 3. 4.]\n",
      "  [2. 3. 4.]]]\n",
      "[[[2. 3. 4.]\n",
      "  [2. 3. 4.]]]\n",
      "[[[2. 3. 4.]\n",
      "  [2. 3. 4.]]]\n",
      "[[[2. 3. 4.]\n",
      "  [2. 3. 4.]]]\n",
      "[[[2. 3. 4.]\n",
      "  [2. 3. 4.]]]\n",
      "[[[2. 3. 4.]\n",
      "  [2. 3. 4.]]]\n",
      "[[[2. 3. 4.]\n",
      "  [2. 3. 4.]]]\n",
      "[[[2. 3. 4.]\n",
      "  [2. 3. 4.]]]\n",
      "[[[3. 4. 5.]\n",
      "  [3. 4. 5.]]]\n",
      "[[[3. 4. 5.]\n",
      "  [3. 4. 5.]]]\n",
      "[[[3. 4. 5.]\n",
      "  [3. 4. 5.]]]\n",
      "[[[3. 4. 5.]\n",
      "  [3. 4. 5.]]]\n",
      "[[[3. 4. 5.]\n",
      "  [3. 4. 5.]]]\n",
      "[[[3. 4. 5.]\n",
      "  [3. 4. 5.]]]\n",
      "[[[3. 4. 5.]\n",
      "  [3. 4. 5.]]]\n",
      "[[[3. 4. 5.]\n",
      "  [3. 4. 5.]]]\n",
      "[[[3. 4. 5.]\n",
      "  [3. 4. 5.]]]\n",
      "[[[3. 4. 5.]\n",
      "  [3. 4. 5.]]]\n",
      "[[[3. 4. 5.]\n",
      "  [3. 4. 5.]]]\n",
      "[[[3. 4. 5.]\n",
      "  [3. 4. 5.]]]\n",
      "[[[3. 4. 5.]\n",
      "  [3. 4. 5.]]]\n",
      "[[[3. 4. 5.]\n",
      "  [3. 4. 5.]]]\n",
      "[[[3. 4. 5.]\n",
      "  [3. 4. 5.]]]\n",
      "[[[4. 5. 6.]\n",
      "  [4. 5. 6.]]]\n",
      "[[[4. 5. 6.]\n",
      "  [4. 5. 6.]]]\n",
      "[[[4. 5. 6.]\n",
      "  [4. 5. 6.]]]\n",
      "[[[4. 5. 6.]\n",
      "  [4. 5. 6.]]]\n",
      "[[[4. 5. 6.]\n",
      "  [4. 5. 6.]]]\n",
      "[[[4. 5. 6.]\n",
      "  [4. 5. 6.]]]\n",
      "[[[4. 5. 6.]\n",
      "  [4. 5. 6.]]]\n",
      "[[[4. 5. 6.]\n",
      "  [4. 5. 6.]]]\n",
      "[[[4. 5. 6.]\n",
      "  [4. 5. 6.]]]\n",
      "[[[4. 5. 6.]\n",
      "  [4. 5. 6.]]]\n",
      "[[[4. 5. 6.]\n",
      "  [4. 5. 6.]]]\n",
      "[[[4. 5. 6.]\n",
      "  [4. 5. 6.]]]\n",
      "[[[4. 5. 6.]\n",
      "  [4. 5. 6.]]]\n",
      "[[[4. 5. 6.]\n",
      "  [4. 5. 6.]]]\n",
      "[[[4. 5. 6.]\n",
      "  [4. 5. 6.]]]\n",
      "[[[5. 6. 7.]\n",
      "  [5. 6. 7.]]]\n",
      "[[[5. 6. 7.]\n",
      "  [5. 6. 7.]]]\n",
      "[[[5. 6. 7.]\n",
      "  [5. 6. 7.]]]\n",
      "[[[5. 6. 7.]\n",
      "  [5. 6. 7.]]]\n",
      "[[[5. 6. 7.]\n",
      "  [5. 6. 7.]]]\n",
      "[[[5. 6. 7.]\n",
      "  [5. 6. 7.]]]\n",
      "[[[5. 6. 7.]\n",
      "  [5. 6. 7.]]]\n",
      "[[[5. 6. 7.]\n",
      "  [5. 6. 7.]]]\n",
      "[[[5. 6. 7.]\n",
      "  [5. 6. 7.]]]\n",
      "[[[5. 6. 7.]\n",
      "  [5. 6. 7.]]]\n",
      "[[[5. 6. 7.]\n",
      "  [5. 6. 7.]]]\n",
      "[[[5. 6. 7.]\n",
      "  [5. 6. 7.]]]\n",
      "[[[5. 6. 7.]\n",
      "  [5. 6. 7.]]]\n",
      "[[[5. 6. 7.]\n",
      "  [5. 6. 7.]]]\n",
      "[[[5. 6. 7.]\n",
      "  [5. 6. 7.]]]\n",
      "[[[6. 7. 8.]\n",
      "  [6. 7. 8.]]]\n",
      "[[[6. 7. 8.]\n",
      "  [6. 7. 8.]]]\n",
      "[[[6. 7. 8.]\n",
      "  [6. 7. 8.]]]\n",
      "[[[6. 7. 8.]\n",
      "  [6. 7. 8.]]]\n",
      "[[[6. 7. 8.]\n",
      "  [6. 7. 8.]]]\n",
      "[[[6. 7. 8.]\n",
      "  [6. 7. 8.]]]\n",
      "[[[6. 7. 8.]\n",
      "  [6. 7. 8.]]]\n",
      "[[[6. 7. 8.]\n",
      "  [6. 7. 8.]]]\n",
      "[[[6. 7. 8.]\n",
      "  [6. 7. 8.]]]\n",
      "[[[6. 7. 8.]\n",
      "  [6. 7. 8.]]]\n",
      "[[[6. 7. 8.]\n",
      "  [6. 7. 8.]]]\n",
      "[[[6. 7. 8.]\n",
      "  [6. 7. 8.]]]\n",
      "[[[6. 7. 8.]\n",
      "  [6. 7. 8.]]]\n",
      "[[[6. 7. 8.]\n",
      "  [6. 7. 8.]]]\n",
      "[[[6. 7. 8.]\n",
      "  [6. 7. 8.]]]\n",
      "[[[7. 8. 9.]\n",
      "  [7. 8. 9.]]]\n",
      "[[[7. 8. 9.]\n",
      "  [7. 8. 9.]]]\n",
      "[[[7. 8. 9.]\n",
      "  [7. 8. 9.]]]\n",
      "[[[7. 8. 9.]\n",
      "  [7. 8. 9.]]]\n",
      "[[[7. 8. 9.]\n",
      "  [7. 8. 9.]]]\n",
      "[[[7. 8. 9.]\n",
      "  [7. 8. 9.]]]\n",
      "[[[7. 8. 9.]\n",
      "  [7. 8. 9.]]]\n",
      "[[[7. 8. 9.]\n",
      "  [7. 8. 9.]]]\n",
      "[[[7. 8. 9.]\n",
      "  [7. 8. 9.]]]\n",
      "[[[7. 8. 9.]\n",
      "  [7. 8. 9.]]]\n",
      "[[[7. 8. 9.]\n",
      "  [7. 8. 9.]]]\n",
      "[[[7. 8. 9.]\n",
      "  [7. 8. 9.]]]\n",
      "[[[7. 8. 9.]\n",
      "  [7. 8. 9.]]]\n",
      "[[[7. 8. 9.]\n",
      "  [7. 8. 9.]]]\n",
      "[[[7. 8. 9.]\n",
      "  [7. 8. 9.]]]\n",
      "[[[ 8.  9. 10.]\n",
      "  [ 8.  9. 10.]]]\n",
      "[[[ 8.  9. 10.]\n",
      "  [ 8.  9. 10.]]]\n",
      "[[[ 8.  9. 10.]\n",
      "  [ 8.  9. 10.]]]\n",
      "[[[ 8.  9. 10.]\n",
      "  [ 8.  9. 10.]]]\n",
      "[[[ 8.  9. 10.]\n",
      "  [ 8.  9. 10.]]]\n",
      "[[[ 8.  9. 10.]\n",
      "  [ 8.  9. 10.]]]\n",
      "[[[ 8.  9. 10.]\n",
      "  [ 8.  9. 10.]]]\n",
      "[[[ 8.  9. 10.]\n",
      "  [ 8.  9. 10.]]]\n",
      "[[[ 8.  9. 10.]\n",
      "  [ 8.  9. 10.]]]\n",
      "[[[ 8.  9. 10.]\n",
      "  [ 8.  9. 10.]]]\n",
      "[[[ 8.  9. 10.]\n",
      "  [ 8.  9. 10.]]]\n",
      "[[[ 8.  9. 10.]\n",
      "  [ 8.  9. 10.]]]\n",
      "[[[ 8.  9. 10.]\n",
      "  [ 8.  9. 10.]]]\n",
      "[[[ 8.  9. 10.]\n",
      "  [ 8.  9. 10.]]]\n",
      "[[[ 8.  9. 10.]\n",
      "  [ 8.  9. 10.]]]\n",
      "[[[ 9. 10. 11.]\n",
      "  [ 9. 10. 11.]]]\n",
      "[[[ 9. 10. 11.]\n",
      "  [ 9. 10. 11.]]]\n",
      "[[[ 9. 10. 11.]\n",
      "  [ 9. 10. 11.]]]\n",
      "[[[ 9. 10. 11.]\n",
      "  [ 9. 10. 11.]]]\n",
      "[[[ 9. 10. 11.]\n",
      "  [ 9. 10. 11.]]]\n",
      "[[[ 9. 10. 11.]\n",
      "  [ 9. 10. 11.]]]\n",
      "[[[ 9. 10. 11.]\n",
      "  [ 9. 10. 11.]]]\n",
      "[[[ 9. 10. 11.]\n",
      "  [ 9. 10. 11.]]]\n",
      "[[[ 9. 10. 11.]\n",
      "  [ 9. 10. 11.]]]\n",
      "[[[ 9. 10. 11.]\n",
      "  [ 9. 10. 11.]]]\n",
      "[[[ 9. 10. 11.]\n",
      "  [ 9. 10. 11.]]]\n",
      "[[[ 9. 10. 11.]\n",
      "  [ 9. 10. 11.]]]\n",
      "[[[ 9. 10. 11.]\n",
      "  [ 9. 10. 11.]]]\n",
      "[[[ 9. 10. 11.]\n",
      "  [ 9. 10. 11.]]]\n",
      "[[[ 9. 10. 11.]\n",
      "  [ 9. 10. 11.]]]\n"
     ]
    }
   ],
   "source": [
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(source_iterator.initializer)\n",
    "\n",
    "sess.run(assignSource)\n",
    "for i in range(10):\n",
    "    for t in range(T//period):\n",
    "        print(sess.run(X,feed_dict={cursor:t}))\n",
    "    sess.run(assignSource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "2000//128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "source=tf.random_uniform(shape=[2])\n",
    "X=tf.get_variable('X',shape=[2])\n",
    "assign_X=tf.assign(X,source)\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(3):\n",
    "    print(sess.run(assign_X))\n",
    "    print(sess.run(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def valid_unit(cursor,times):\n",
    "    tf.whr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from keras.layers import Activation,Dense,Input,Lambda\n",
    "from keras.losses import mean_squared_error,mse\n",
    "from keras.models import Sequential,Model,save_model,load_model\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.callbacks import LearningRateScheduler,ModelCheckpoint,ReduceLROnPlateau\n",
    "from keras.preprocessing.image import  ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize']=(10,10)\n",
    "plt.rcParams['image.cmap']='viridis'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Step, Prepare Mnist Dataset\n",
    "* different from supervise learning,I only using X\n",
    "* using dense Layer as encoder and decoder,so X is 784 dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data_path='../AI_database/mnist/MNIST_DATA'\n",
    "def imshow(X,Y=None,classes=None):\n",
    "    '''\n",
    "        show Batch of image in grids sqrt(h) x sqrt(w)\n",
    "        X is a numpy array,size (m,h,w,c)\n",
    "        Y is a numpy array,size (m,#classes)\n",
    "    '''\n",
    "    m=X.shape[0]\n",
    "    gridSize=int(m**0.5)\n",
    "    for i in range(0,gridSize):\n",
    "        for j in range(0,gridSize):\n",
    "            _idx=i*gridSize+j\n",
    "            im=X[_idx]\n",
    "            plt.subplot(gridSize,gridSize,_idx+1)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(im)\n",
    "            if Y is not None:\n",
    "                label=classes[np.argmax(Y[_idx])]\n",
    "                plt.title(label)\n",
    "\n",
    "def load_dataset(flaten=False,one_hot=True):\n",
    "    def _make_one_hot(d,C=10):\n",
    "        return (np.arange(C)==d[:,None]).astype(np.int32)\n",
    "\n",
    "    mnist=input_data.read_data_sets(mnist_data_path)\n",
    "    X_train,Y_train=mnist.train.images,mnist.train.labels\n",
    "    X_test,Y_test=mnist.test.images,mnist.test.labels\n",
    "\n",
    "    if flaten==False:\n",
    "        X_train=X_train.reshape((-1,28,28,1))\n",
    "        X_test = X_test.reshape((-1, 28, 28,1))\n",
    "    if one_hot:\n",
    "        Y_train = _make_one_hot(Y_train)\n",
    "        Y_test=_make_one_hot(Y_test)\n",
    "\n",
    "\n",
    "    print('\\n-------------------------------------------------------------------------')\n",
    "    print('load %d train Example,%d Test Example'%(X_train.shape[0],X_test.shape[0]))\n",
    "    print('Train Images  Shape:'+str(X_train.shape))\n",
    "    print('Train Labels  Shape:' + str(Y_train.shape))\n",
    "    print('Test  Images  Shape:'+str(X_test.shape))\n",
    "    print('Test  Labels  Shape:' + str(Y_test.shape))\n",
    "    print('-------------------------------------------------------------------------')\n",
    "    return (X_train,Y_train,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,Y_train,X_test,Y_test=load_dataset(flaten=True,one_hot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define show Help function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshaper(X):\n",
    "    m=X.shape[0]\n",
    "    return X.reshape((m,28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a encoder\n",
    "* ###  the struct is X---->H1---->(Uz,logVarz,z) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_encoder(n_x=784,n_h=512,n_z=2):\n",
    "    '''\n",
    "        n_x:dim of Image\n",
    "        n_x:dim of hidden units\n",
    "        n_z:dim of latent variable\n",
    "        return:,a model with outputs=[u_z,logvar_z,z] all have same dims n_z\n",
    "    '''\n",
    "    def sample(args):\n",
    "        '''\n",
    "            args:u,logvar,2 tensor object\n",
    "            sample from N(0,I),then transform it to N(u,exp(logvar))\n",
    "            return:a tensor \n",
    "        '''\n",
    "        u,logvar=args\n",
    "        batch,ndim=tf.shape(u)[0],tf.shape(u)[1]\n",
    "        \n",
    "        z=K.random_normal(shape=[batch,ndim])\n",
    "        return u+K.exp(0.5*logvar)*z\n",
    "    \n",
    "    X_Input=Input(shape=(n_x,),name='encode_input')\n",
    "    X=Dense(n_h,activation='relu',name='encode_hidden',kernel_initializer='he_normal')(X_Input)\n",
    "    \n",
    "    u_z=Dense(n_z,name='encode_mean',kernel_initializer='he_normal')(X)\n",
    "    logvar_z=Dense(n_z,name='encode_log_var',kernel_initializer='he_normal')(X)\n",
    "    Z=Lambda(sample,name='encoder_z')([u_z,logvar_z])\n",
    "    \n",
    "    model=Model(inputs=X_Input,outputs=[u_z,logvar_z,Z],name='encoder')\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=vae_encoder()\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVG(model_to_dot(encoder,show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Decoder\n",
    "* ###  the struct is Z---->H1---->Xhat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_decoder(n_x=784,n_h=512,n_z=2):\n",
    "    '''\n",
    "        n_x:the shape(dims) of reconstruct Image\n",
    "        n_h:hidden Units\n",
    "        n_z:latent dims\n",
    "        return:a model with outputs is reconstruct Image\n",
    "    '''\n",
    "    Z_Input=Input(shape=(n_z,),name='decoder_input')\n",
    "    X=Dense(n_h,activation='relu',name='decoder_hidden',kernel_initializer='he_normal')(Z_Input)\n",
    "    X=Dense(n_x,activation='sigmoid',name='decoder_reconstruct',kernel_initializer='he_normal')(X)\n",
    "    \n",
    "    model=Model(inputs=Z_Input,outputs=X,name='decoder')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder=vae_decoder()\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVG(model_to_dot(decoder,show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine Encoder and Decoder(vae_mlp)\n",
    "<img src='images/vae_loss.png' />\n",
    "<img src='images/vae_kl_loss.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_mlp(encoder,decoder,n_x=784):\n",
    "    '''\n",
    "        encoder: X(784)---->[uz,logvar_z,z]\n",
    "        decoder:Z(2)-------->Xhat(784)\n",
    "        \n",
    "        loss=(X-Xhat)**2+KL{ qz|x |N(0,I)}\n",
    "        notice Pz =N(0,I)\n",
    "    '''\n",
    "    \n",
    "    X=Input(shape=(n_x,),name='MyInput')\n",
    "    uz,logvar_z,z=encoder(X)\n",
    "    Xhat=decoder(z)\n",
    "    \n",
    "    \n",
    "    #work out the loss\n",
    "    Re_loss=K.sum((X-Xhat)**2,axis=-1) #shape (?,)\n",
    "    KL_loss=1+logvar_z-K.square(uz)-K.exp(logvar_z) #shape(?,n_z)\n",
    "    KL_loss=-0.5*K.sum(KL_loss,axis=-1)  #shape(?,)\n",
    "    loss=K.mean(Re_loss+0*KL_loss)  #shape(?)\n",
    "    \n",
    "    model=Model(inputs=X,outputs=Xhat)\n",
    "    model.add_loss(loss)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae=vae_mlp(encoder,decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVG(model_to_dot(vae,show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path='outputs/vae.h5'\n",
    "def callback():\n",
    "    def myLearnRateScheduler(epoch,lr):\n",
    "        print('ecpch:%d,learn rate %f'%(epoch,lr))\n",
    "        return lr\n",
    "    lr_scheduler=LearningRateScheduler(myLearnRateScheduler)\n",
    "    checkpoint=ModelCheckpoint(model_path,monitor='val_loss',save_best_only=True,verbose=1)\n",
    "    reduceOnpleateau=ReduceLROnPlateau(monitor='val_loss',min_delta=5e-5,factor=0.9,verbose=1,patience=50)\n",
    "    return [lr_scheduler,checkpoint,reduceOnpleateau]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch=64\n",
    "epoch=50\n",
    "vae.fit(X_train,batch_size=batch,epochs=epoch,validation_data=(X_test,None),callbacks=callback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save or load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_path='outputs/vae_encoder'\n",
    "decoder_path='outputs/vae_decoder'\n",
    "encoder.save(encoder_path)\n",
    "decoder.save(decoder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=load_model(encoder_path,custom_objects={'tf':tf})\n",
    "decoder=load_model(decoder_path,custom_objects={'tf':tf})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the distribution of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(encoder,X,Y):\n",
    "    plt.rcParams['figure.figsize']=(15,15)\n",
    "    plt.rcParams['image.cmap']='hsv'\n",
    "    Z=encoder.predict(X,batch_size=512)[0]\n",
    "    plt.scatter(Z[:,0],Z[:,1],c=Y)\n",
    "    plt.colorbar()\n",
    "plot_distribution(encoder,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## view how letent z affect Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(decoder,n=15,dim=28,reshaper=None,channels=1):\n",
    "    '''\n",
    "        using decoder to generate image\n",
    "        n:is num per axis\n",
    "        dim:one image size\n",
    "    '''\n",
    "    plt.rcParams['figure.figsize']=(15,15)\n",
    "    xrange=np.linspace(-4,4,n)\n",
    "    yrange=np.linspace(4,-4,n)\n",
    "    zx,zy=np.meshgrid(xrange,yrange)\n",
    "\n",
    "    z=np.stack([zx.ravel(),zy.ravel()],axis=1) #shape[10000,2]\n",
    "    I=reshaper(decoder.predict(z))\n",
    "    F=np.zeros((n*dim,n*dim,channels),dtype=np.float32)\n",
    "    F=np.squeeze(F)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            F[i*dim:i*dim+dim,j*dim:j*dim+dim]=I[i*n+j]\n",
    "    xlabels=np.round(xrange,2)\n",
    "    ylabels=np.round(yrange,2)\n",
    "    xloc=np.arange(dim//2,dim*n+dim//2,dim)\n",
    "    yloc=xloc.copy()\n",
    "    plt.xticks(xloc,xlabels,size='large',rotation=45)\n",
    "    plt.yticks(yloc,ylabels,size='large',rotation=45)\n",
    "    plt.xlabel('z1')\n",
    "    plt.ylabel('z2')\n",
    "    plt.imshow(F)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(decoder,n=15,dim=28,reshaper=reshaper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Try Cifar10 set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cifar.CIFAR10Utils import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,Y_train,X_test,Y_test,_=load_dataset(flaten=True,one_hot=False,filename='../AI_database/cifar/CIFAR10_DATA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_cifar=vae_encoder(n_x=3072,n_h=512,n_z=2)\n",
    "SVG(model_to_dot(encoder_cifar,show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_cifar=vae_decoder(n_x=3072,n_h=512,n_z=2)\n",
    "SVG(model_to_dot(decoder_cifar,show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_cifar=vae_mlp(encoder_cifar,decoder_cifar,n_x=3072)\n",
    "SVG(model_to_dot(vae_cifar,show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_cifar.compile(optimizer=Adam(4e-4))\n",
    "gen=ImageDataGenerator(\n",
    "    width_shift_range=0,\n",
    "    height_shift_range=0,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=[0.5,1.0],  #<1 mean zoom in,>1 zoom out  \n",
    "    rescale=1.0   ,  #mul image by rescale\n",
    "#     zca_whitening=True,\n",
    "#     zca_epsilon=0.1\n",
    ").flow(X_train.reshape(-1,32,32,3),None)\n",
    "def myGen(gen):\n",
    "    while True:\n",
    "        x=next(gen)\n",
    "        x=x.reshape(-1,3*32*32)\n",
    "        yield (x,None)\n",
    "generator=myGen(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch=64\n",
    "epoch=5000\n",
    "\n",
    "vae_cifar.fit(X_train[0:64],batch_size=batch,epochs=epoch,validation_data=(X_test,None),callbacks=callback())\n",
    "# vae_cifar.fit_generator(generator,epochs=epoch,steps_per_epoch=50000//batch,\n",
    "#                         validation_data=(X_test,None),callbacks=callback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_encoder='outputs/cifar_encoder'\n",
    "cifar_decoder='outputs/cifar_decoder'\n",
    "encoder_cifar.save(cifar_encoder)\n",
    "decoder_cifar.save(cifar_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(encoder_cifar,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(decoder_cifar,n=5,dim=32,reshaper=lambda x:np.reshape(x,(-1,32,32,3)),channels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(3,3)\n",
    "plt.imshow(np.reshape(X_test[11],(32,32,3)))\n",
    "# print(np.reshape(X_test[9],(32,32,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

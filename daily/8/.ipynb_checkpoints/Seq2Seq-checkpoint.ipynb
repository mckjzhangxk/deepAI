{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import  Input,Conv2D,MaxPooling2D,Flatten,Dense,Lambda,LSTM,BatchNormalization,Dropout,TimeDistributed\n",
    "from keras.models import Sequential,Model,load_model\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "from keras.initializers import he_normal,glorot_normal\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam,rmsprop\n",
    "import tensorflow as tf\n",
    "from IPython.display import SVG\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.callbacks import LearningRateScheduler,ModelCheckpoint,ReduceLROnPlateau\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "plt.rcParams['figure.figsize']=(20,20)\n",
    "plt.rcParams['image.cmap']='gray'\n",
    "% %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# First Train A LeNet for extract feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist_data_path='../AI_database/mnist/MNIST_DATA'\n",
    "def imshow(X,Y=None,classes=None):\n",
    "    '''\n",
    "        show Batch of image in grids sqrt(h) x sqrt(w)\n",
    "        X is a numpy array,size (m,h,w,c)\n",
    "        Y is a numpy array,size (m,#classes)\n",
    "    '''\n",
    "    m=X.shape[0]\n",
    "    gridSize=int(m**0.5)\n",
    "    for i in range(0,gridSize):\n",
    "        for j in range(0,gridSize):\n",
    "            _idx=i*gridSize+j\n",
    "            im=X[_idx]\n",
    "            plt.subplot(gridSize,gridSize,_idx+1)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(im)\n",
    "            if Y is not None:\n",
    "                label=classes[np.argmax(Y[_idx])]\n",
    "                plt.title(label)\n",
    "\n",
    "def load_dataset(flaten=False,one_hot=True):\n",
    "    def _make_one_hot(d,C=10):\n",
    "        return (np.arange(C)==d[:,None]).astype(np.int32)\n",
    "\n",
    "    mnist=input_data.read_data_sets(mnist_data_path)\n",
    "    X_train,Y_train=mnist.train.images,mnist.train.labels\n",
    "    X_test,Y_test=mnist.test.images,mnist.test.labels\n",
    "\n",
    "    if flaten==False:\n",
    "        X_train=X_train.reshape((-1,28,28,1))\n",
    "        X_test = X_test.reshape((-1, 28, 28,1))\n",
    "    if one_hot:\n",
    "        Y_train = _make_one_hot(Y_train)\n",
    "        Y_test=_make_one_hot(Y_test)\n",
    "\n",
    "\n",
    "    print('\\n-------------------------------------------------------------------------')\n",
    "    print('load %d train Example,%d Test Example'%(X_train.shape[0],X_test.shape[0]))\n",
    "    print('Train Images  Shape:'+str(X_train.shape))\n",
    "    print('Train Labels  Shape:' + str(Y_train.shape))\n",
    "    print('Test  Images  Shape:'+str(X_test.shape))\n",
    "    print('Test  Labels  Shape:' + str(Y_test.shape))\n",
    "    print('-------------------------------------------------------------------------')\n",
    "    return (X_train,Y_train,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../AI_database/mnist/MNIST_DATA/train-images-idx3-ubyte.gz\n",
      "Extracting ../AI_database/mnist/MNIST_DATA/train-labels-idx1-ubyte.gz\n",
      "Extracting ../AI_database/mnist/MNIST_DATA/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../AI_database/mnist/MNIST_DATA/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "load 55000 train Example,10000 Test Example\n",
      "Train Images  Shape:(55000, 28, 28, 1)\n",
      "Train Labels  Shape:(55000, 10)\n",
      "Test  Images  Shape:(10000, 28, 28, 1)\n",
      "Test  Labels  Shape:(10000, 10)\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train,X_test,Y_test=load_dataset(one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 5)         130       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 5)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 16)        2016      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "feature (Conv2D)             (None, 1, 1, 120)         94200     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 1, 1, 84)          10164     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 1, 1, 10)          850       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 107,360\n",
      "Trainable params: 107,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def LeNet():    \n",
    "    model=Sequential([\n",
    "        Conv2D(filters=5,strides=1,kernel_size=5,padding='SAME',\n",
    "             kernel_initializer='he_normal',activation='relu',input_shape=(28,28,1)),#28x28x5\n",
    "        MaxPooling2D((2,2)),#14x14x5\n",
    "        Conv2D(filters=16,strides=1,kernel_size=5,padding='SAME',\n",
    "               kernel_initializer='he_normal',activation='relu'),#14x14*16\n",
    "        MaxPooling2D((2,2)),#7x7*16\n",
    "        Conv2D(filters=120,strides=1,kernel_size=7,padding='VALID',\n",
    "               kernel_initializer='he_normal',activation='relu',name='feature'),#1x1x120\n",
    "        Conv2D(filters=84,strides=1,kernel_size=1,padding='VALID',#1x1x84\n",
    "               kernel_initializer='he_normal',activation='relu'),\n",
    "        Conv2D(filters=10,strides=1,kernel_size=1,padding='VALID',#1x1x10\n",
    "               kernel_initializer='he_normal',activation='softmax'),\n",
    "        Flatten()\n",
    "    ])\n",
    "    model.summary()\n",
    "    return model\n",
    "model=LeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "55000/55000 [==============================] - 14s 263us/step - loss: 0.2433 - acc: 0.9275 - val_loss: 0.0786 - val_acc: 0.9746\n",
      "Epoch 2/20\n",
      "55000/55000 [==============================] - 5s 96us/step - loss: 0.0707 - acc: 0.9786 - val_loss: 0.0527 - val_acc: 0.9837\n",
      "Epoch 3/20\n",
      "55000/55000 [==============================] - 5s 95us/step - loss: 0.0487 - acc: 0.9841 - val_loss: 0.0427 - val_acc: 0.9858\n",
      "Epoch 4/20\n",
      "55000/55000 [==============================] - 5s 90us/step - loss: 0.0379 - acc: 0.9887 - val_loss: 0.0419 - val_acc: 0.9867\n",
      "Epoch 5/20\n",
      "55000/55000 [==============================] - 5s 83us/step - loss: 0.0306 - acc: 0.9899 - val_loss: 0.0460 - val_acc: 0.9857\n",
      "Epoch 6/20\n",
      "55000/55000 [==============================] - 4s 80us/step - loss: 0.0236 - acc: 0.9925 - val_loss: 0.0476 - val_acc: 0.9853\n",
      "Epoch 7/20\n",
      "55000/55000 [==============================] - 4s 80us/step - loss: 0.0207 - acc: 0.9932 - val_loss: 0.0365 - val_acc: 0.9874\n",
      "Epoch 8/20\n",
      "55000/55000 [==============================] - 5s 88us/step - loss: 0.0178 - acc: 0.9942 - val_loss: 0.0344 - val_acc: 0.9894\n",
      "Epoch 9/20\n",
      "55000/55000 [==============================] - 5s 90us/step - loss: 0.0134 - acc: 0.9959 - val_loss: 0.0599 - val_acc: 0.9827\n",
      "Epoch 10/20\n",
      "55000/55000 [==============================] - 4s 78us/step - loss: 0.0137 - acc: 0.9954 - val_loss: 0.0433 - val_acc: 0.9871\n",
      "Epoch 11/20\n",
      "55000/55000 [==============================] - 5s 98us/step - loss: 0.0105 - acc: 0.9966 - val_loss: 0.0465 - val_acc: 0.9862\n",
      "Epoch 12/20\n",
      "55000/55000 [==============================] - 5s 89us/step - loss: 0.0106 - acc: 0.9969 - val_loss: 0.0383 - val_acc: 0.9886\n",
      "Epoch 13/20\n",
      "55000/55000 [==============================] - 5s 83us/step - loss: 0.0112 - acc: 0.9961 - val_loss: 0.0391 - val_acc: 0.9892\n",
      "Epoch 14/20\n",
      "55000/55000 [==============================] - 4s 79us/step - loss: 0.0099 - acc: 0.9967 - val_loss: 0.0418 - val_acc: 0.9891\n",
      "Epoch 15/20\n",
      "55000/55000 [==============================] - 4s 80us/step - loss: 0.0080 - acc: 0.9975 - val_loss: 0.0398 - val_acc: 0.9895\n",
      "Epoch 16/20\n",
      "55000/55000 [==============================] - 5s 82us/step - loss: 0.0102 - acc: 0.9963 - val_loss: 0.0494 - val_acc: 0.9876\n",
      "Epoch 17/20\n",
      "55000/55000 [==============================] - 4s 80us/step - loss: 0.0087 - acc: 0.9970 - val_loss: 0.0379 - val_acc: 0.9900\n",
      "Epoch 18/20\n",
      "55000/55000 [==============================] - 4s 79us/step - loss: 0.0046 - acc: 0.9986 - val_loss: 0.0444 - val_acc: 0.9883\n",
      "Epoch 19/20\n",
      "55000/55000 [==============================] - 5s 82us/step - loss: 0.0057 - acc: 0.9981 - val_loss: 0.0548 - val_acc: 0.9877\n",
      "Epoch 20/20\n",
      "55000/55000 [==============================] - 4s 79us/step - loss: 0.0086 - acc: 0.9970 - val_loss: 0.0433 - val_acc: 0.9889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd7fec48208>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchSize=128\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# augment=ImageDataGenerator(horizontal_flip=True,height_shift_range=0.025,width_shift_range=0.025)\n",
    "# gen=augment.flow(X_train,Y_train,batchSize)\n",
    "# model.fit_generator(generator=gen,epochs=20,shuffle=True,validation_data=(X_test,Y_test))\n",
    "model.fit(X_train,Y_train,batch_size=batchSize,epochs=20,shuffle=True,validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist_model_path='../AI_database/mnistSeq/outputs/mnist.h5'\n",
    "# model.save(mnist_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pretrained model\n",
    "model=load_model(mnist_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Using above model to create a feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1_input (InputLayer)  (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 5)         130       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 5)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 16)        2016      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "feature (Conv2D)             (None, 1, 1, 120)         94200     \n",
      "=================================================================\n",
      "Total params: 96,346\n",
      "Trainable params: 0\n",
      "Non-trainable params: 96,346\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "feature_model=Model(model.input,model.get_layer('feature').output)\n",
    "#I freeze the extractor\n",
    "for l in feature_model.layers:\n",
    "    l.trainable=False\n",
    "feature_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.ops.array_ops.squeeze>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature_model can using to any size of Image\n",
    "X=Input(shape=(28,28*10,1))\n",
    "XY=feature_model(X)\n",
    "XY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SeqModel(cnn,rawNum=10,n_a=64,outdims=11,dropRate=0.8):\n",
    "    '''\n",
    "        a sequence to sequence model,using cnn to extract features,\n",
    "        then pass features to one(Multi) RNN network\n",
    "        architure:\n",
    "        \n",
    "          ---------------\n",
    "          | softmax     |  \n",
    "          ---------------         \n",
    "          ---------------\n",
    "          | Dense(11)    |  \n",
    "          ---------------  \n",
    "                 ^\n",
    "                 |\n",
    "          ---------------\n",
    "          | Dropout(0.8) |          \n",
    "          ---------------  \n",
    "          ---------------\n",
    "          | BatchNormal |  \n",
    "          ---------------  \n",
    "          ---------------\n",
    "          | LSTM(64/128)|  \n",
    "          ---------------  \n",
    "                ^ \n",
    "                |  (1,7n-6,120)\n",
    "          ---------------\n",
    "          |    CNN      |  \n",
    "          ---------------  \n",
    "            ^\n",
    "            |\n",
    "        X(28,28xn,1)\n",
    "        cnn：pretained CNN model,convert a Image with shape(28a,28b,1)->(7a,7b,120)\n",
    "        rawNum: the Input  shape is (28,28*rawNum,1),rawNum is how many character in my train Example\n",
    "        n_a:LSTM hidden units\n",
    "        outdims:output dims of Seq model\n",
    "        \n",
    "        return:\n",
    "            model: with Input X:[28,28 x rawNum,1]\n",
    "                        Outputs:Y[7 x rawNum-6,outdims]\n",
    "    '''\n",
    "    X_Input=Input(shape=(28,28*rawNum,1),name='ImageInput')\n",
    "    X=cnn(X_Input) #shape (1,7n-6,120)\n",
    "    X=Lambda(lambda x:tf.squeeze(x,axis=1),name='squeeze')(X) #reshape to (7n-6,120)\n",
    "        #RNN begin\n",
    "    X=LSTM(n_a,return_sequences=True,name='lstm1')(X) #shape (7n-6,n_a)\n",
    "    X=BatchNormalization(name='BN1')(X)\n",
    "    X=Dropout(dropRate,name='dropout1')(X)\n",
    "        \n",
    "        #final classify \n",
    "    densor=Dense(outdims,activation='softmax')\n",
    "    X=TimeDistributed(densor,name='out')(X)  #shape (7n-6,outdims)\n",
    "        \n",
    "        #define model\n",
    "    model=Model(X_Input,X)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seqmodel=SeqModel(feature_model,rawNum=10,n_a=64,outdims=11,dropRate=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "ImageInput (InputLayer)      (None, 28, 280, 1)        0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              multiple                  96346     \n",
      "_________________________________________________________________\n",
      "squeeze (Lambda)             (None, 64, 120)           0         \n",
      "_________________________________________________________________\n",
      "lstm1 (LSTM)                 (None, 64, 64)            47360     \n",
      "_________________________________________________________________\n",
      "BN1 (BatchNormalization)     (None, 64, 64)            256       \n",
      "_________________________________________________________________\n",
      "dropout1 (Dropout)           (None, 64, 64)            0         \n",
      "_________________________________________________________________\n",
      "out (TimeDistributed)        (None, 64, 11)            715       \n",
      "=================================================================\n",
      "Total params: 144,677\n",
      "Trainable params: 48,203\n",
      "Non-trainable params: 96,474\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seqmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"629pt\" viewBox=\"0.00 0.00 215.00 629.00\" width=\"215pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 625)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-625 211,-625 211,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140565668900592 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140565668900592</title>\n",
       "<polygon fill=\"none\" points=\"42,-511.5 42,-547.5 165,-547.5 165,-511.5 42,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-525.8\">conv2d_1: Conv2D</text>\n",
       "</g>\n",
       "<!-- 140565668899192 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140565668899192</title>\n",
       "<polygon fill=\"none\" points=\"0,-438.5 0,-474.5 207,-474.5 207,-438.5 0,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-452.8\">max_pooling2d_1: MaxPooling2D</text>\n",
       "</g>\n",
       "<!-- 140565668900592&#45;&gt;140565668899192 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140565668900592-&gt;140565668899192</title>\n",
       "<path d=\"M103.5,-511.313C103.5,-503.289 103.5,-493.547 103.5,-484.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"107,-484.529 103.5,-474.529 100,-484.529 107,-484.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140565668898968 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140565668898968</title>\n",
       "<polygon fill=\"none\" points=\"42,-365.5 42,-401.5 165,-401.5 165,-365.5 42,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-379.8\">conv2d_2: Conv2D</text>\n",
       "</g>\n",
       "<!-- 140565668899192&#45;&gt;140565668898968 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140565668899192-&gt;140565668898968</title>\n",
       "<path d=\"M103.5,-438.313C103.5,-430.289 103.5,-420.547 103.5,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"107,-411.529 103.5,-401.529 100,-411.529 107,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140565668898184 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140565668898184</title>\n",
       "<polygon fill=\"none\" points=\"0,-292.5 0,-328.5 207,-328.5 207,-292.5 0,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-306.8\">max_pooling2d_2: MaxPooling2D</text>\n",
       "</g>\n",
       "<!-- 140565668898968&#45;&gt;140565668898184 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140565668898968-&gt;140565668898184</title>\n",
       "<path d=\"M103.5,-365.313C103.5,-357.289 103.5,-347.547 103.5,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"107,-338.529 103.5,-328.529 100,-338.529 107,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140565668270264 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140565668270264</title>\n",
       "<polygon fill=\"none\" points=\"50,-219.5 50,-255.5 157,-255.5 157,-219.5 50,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-233.8\">feature: Conv2D</text>\n",
       "</g>\n",
       "<!-- 140565668898184&#45;&gt;140565668270264 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140565668898184-&gt;140565668270264</title>\n",
       "<path d=\"M103.5,-292.313C103.5,-284.289 103.5,-274.547 103.5,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"107,-265.529 103.5,-255.529 100,-265.529 107,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140565668270656 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140565668270656</title>\n",
       "<polygon fill=\"none\" points=\"42,-146.5 42,-182.5 165,-182.5 165,-146.5 42,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-160.8\">conv2d_3: Conv2D</text>\n",
       "</g>\n",
       "<!-- 140565668270264&#45;&gt;140565668270656 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>140565668270264-&gt;140565668270656</title>\n",
       "<path d=\"M103.5,-219.313C103.5,-211.289 103.5,-201.547 103.5,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"107,-192.529 103.5,-182.529 100,-192.529 107,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140565668271048 -->\n",
       "<g class=\"node\" id=\"node7\"><title>140565668271048</title>\n",
       "<polygon fill=\"none\" points=\"42,-73.5 42,-109.5 165,-109.5 165,-73.5 42,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-87.8\">conv2d_4: Conv2D</text>\n",
       "</g>\n",
       "<!-- 140565668270656&#45;&gt;140565668271048 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>140565668270656-&gt;140565668271048</title>\n",
       "<path d=\"M103.5,-146.313C103.5,-138.289 103.5,-128.547 103.5,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"107,-119.529 103.5,-109.529 100,-119.529 107,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140565668271440 -->\n",
       "<g class=\"node\" id=\"node8\"><title>140565668271440</title>\n",
       "<polygon fill=\"none\" points=\"48.5,-0.5 48.5,-36.5 158.5,-36.5 158.5,-0.5 48.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-14.8\">flatten_1: Flatten</text>\n",
       "</g>\n",
       "<!-- 140565668271048&#45;&gt;140565668271440 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>140565668271048-&gt;140565668271440</title>\n",
       "<path d=\"M103.5,-73.3129C103.5,-65.2895 103.5,-55.5475 103.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"107,-46.5288 103.5,-36.5288 100,-46.5289 107,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140565668271664 -->\n",
       "<g class=\"node\" id=\"node9\"><title>140565668271664</title>\n",
       "<polygon fill=\"none\" points=\"44.5,-584.5 44.5,-620.5 162.5,-620.5 162.5,-584.5 44.5,-584.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-598.8\">140565668271664</text>\n",
       "</g>\n",
       "<!-- 140565668271664&#45;&gt;140565668900592 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140565668271664-&gt;140565668900592</title>\n",
       "<path d=\"M103.5,-584.313C103.5,-576.289 103.5,-566.547 103.5,-557.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"107,-557.529 103.5,-547.529 100,-557.529 107,-557.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"483pt\" viewBox=\"0.00 0.00 235.00 483.00\" width=\"235pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 479)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-479 231,-479 231,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140565840764264 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140565840764264</title>\n",
       "<polygon fill=\"none\" points=\"40,-438.5 40,-474.5 187,-474.5 187,-438.5 40,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113.5\" y=\"-452.8\">ImageInput: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140565840763256 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140565840763256</title>\n",
       "<polygon fill=\"none\" points=\"59.5,-365.5 59.5,-401.5 167.5,-401.5 167.5,-365.5 59.5,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113.5\" y=\"-379.8\">model_1: Model</text>\n",
       "</g>\n",
       "<!-- 140565840764264&#45;&gt;140565840763256 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140565840764264-&gt;140565840763256</title>\n",
       "<path d=\"M113.5,-438.313C113.5,-430.289 113.5,-420.547 113.5,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117,-411.529 113.5,-401.529 110,-411.529 117,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140565840764768 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140565840764768</title>\n",
       "<polygon fill=\"none\" points=\"57.5,-292.5 57.5,-328.5 169.5,-328.5 169.5,-292.5 57.5,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113.5\" y=\"-306.8\">squeeze: Lambda</text>\n",
       "</g>\n",
       "<!-- 140565840763256&#45;&gt;140565840764768 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140565840763256-&gt;140565840764768</title>\n",
       "<path d=\"M113.5,-365.313C113.5,-357.289 113.5,-347.547 113.5,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117,-338.529 113.5,-328.529 110,-338.529 117,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140569868492584 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140569868492584</title>\n",
       "<polygon fill=\"none\" points=\"67.5,-219.5 67.5,-255.5 159.5,-255.5 159.5,-219.5 67.5,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113.5\" y=\"-233.8\">lstm1: LSTM</text>\n",
       "</g>\n",
       "<!-- 140565840764768&#45;&gt;140569868492584 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140565840764768-&gt;140569868492584</title>\n",
       "<path d=\"M113.5,-292.313C113.5,-284.289 113.5,-274.547 113.5,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117,-265.529 113.5,-255.529 110,-265.529 117,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140569709445808 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140569709445808</title>\n",
       "<polygon fill=\"none\" points=\"33.5,-146.5 33.5,-182.5 193.5,-182.5 193.5,-146.5 33.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113.5\" y=\"-160.8\">BN1: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 140569868492584&#45;&gt;140569709445808 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140569868492584-&gt;140569709445808</title>\n",
       "<path d=\"M113.5,-219.313C113.5,-211.289 113.5,-201.547 113.5,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117,-192.529 113.5,-182.529 110,-192.529 117,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140569868562672 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140569868562672</title>\n",
       "<polygon fill=\"none\" points=\"54.5,-73.5 54.5,-109.5 172.5,-109.5 172.5,-73.5 54.5,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113.5\" y=\"-87.8\">dropout1: Dropout</text>\n",
       "</g>\n",
       "<!-- 140569709445808&#45;&gt;140569868562672 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140569709445808-&gt;140569868562672</title>\n",
       "<path d=\"M113.5,-146.313C113.5,-138.289 113.5,-128.547 113.5,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117,-119.529 113.5,-109.529 110,-119.529 117,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140570325696864 -->\n",
       "<g class=\"node\" id=\"node7\"><title>140570325696864</title>\n",
       "<polygon fill=\"none\" points=\"0,-0.5 0,-36.5 227,-36.5 227,-0.5 0,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113.5\" y=\"-14.8\">out(dense_1): TimeDistributed(Dense)</text>\n",
       "</g>\n",
       "<!-- 140569868562672&#45;&gt;140570325696864 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>140569868562672-&gt;140570325696864</title>\n",
       "<path d=\"M113.5,-73.3129C113.5,-65.2895 113.5,-55.5475 113.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117,-46.5288 113.5,-36.5288 110,-46.5289 117,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(seqmodel).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Prepare Data For Train,do not forget using oneHot representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqDataPath='../AI_database/mnistSeq/'\n",
    "def loadSeqData(onehot=True):\n",
    "    def _loadF(f):\n",
    "        hf=h5py.File(f,'r')\n",
    "        X=np.array(hf.get('X'))\n",
    "        Y=np.array(hf.get('Y'))\n",
    "        hf.close()\n",
    "        return X,Y\n",
    "    X_train,Y_train=_loadF(seqDataPath+'mnistSeq55k.h5')\n",
    "    X_test,Y_test=_loadF(seqDataPath+'mnistSeq10k.h5')\n",
    "    if(onehot):\n",
    "        Y_train=to_categorical(Y_train,11)\n",
    "        Y_test=to_categorical(Y_test,11)\n",
    "    print('\\n-------------------------------------------------------------------------')\n",
    "    print('load %d train Example,%d Test Example'%(X_train.shape[0],X_test.shape[0]))\n",
    "    print('Train Images  Shape:'+str(X_train.shape))\n",
    "    print('Train Labels  Shape:' + str(Y_train.shape))\n",
    "    print('Test  Images  Shape:'+str(X_test.shape))\n",
    "    print('Test  Labels  Shape:' + str(Y_test.shape))\n",
    "    print('-------------------------------------------------------------------------')\n",
    "    return (X_train,Y_train,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------------------------------\n",
      "load 55000 train Example,10000 Test Example\n",
      "Train Images  Shape:(55000, 28, 280, 1)\n",
      "Train Labels  Shape:(55000, 64, 11)\n",
      "Test  Images  Shape:(10000, 28, 280, 1)\n",
      "Test  Labels  Shape:(10000, 64, 11)\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train,X_test,Y_test=loadSeqData(onehot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputModelPath='../AI_database/mnistSeq/outputs/mnistSeq.h5'\n",
    "def monitorLearning():\n",
    "    def myLearnRateScheduler(epoch,lr):\n",
    "        print('ecpch:%d,learn rate %f'%(epoch,lr))\n",
    "        return lr\n",
    "    lr_scheduler=LearningRateScheduler(myLearnRateScheduler)\n",
    "    checkpoint=ModelCheckpoint(outputModelPath,monitor='val_acc',save_best_only=True,verbose=1)\n",
    "    reduceOnpleateau=ReduceLROnPlateau(monitor='val_loss',min_delta=5e-6,factor=0.9,verbose=1,patience=5)\n",
    "    return [lr_scheduler,checkpoint,reduceOnpleateau]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 10000 samples\n",
      "Epoch 1/500\n",
      "ecpch:0,learn rate 0.001000\n",
      "55000/55000 [==============================] - 82s 1ms/step - loss: 0.0536 - acc: 0.9841 - val_loss: 0.0554 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.98300, saving model to ../AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 2/500\n",
      "ecpch:1,learn rate 0.001000\n",
      "55000/55000 [==============================] - 81s 1ms/step - loss: 0.0519 - acc: 0.9840 - val_loss: 0.0662 - val_acc: 0.9812\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.98300\n",
      "Epoch 3/500\n",
      "ecpch:2,learn rate 0.001000\n",
      "55000/55000 [==============================] - 78s 1ms/step - loss: 0.0514 - acc: 0.9841 - val_loss: 0.0522 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.98300 to 0.98403, saving model to ../AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 4/500\n",
      "ecpch:3,learn rate 0.001000\n",
      "55000/55000 [==============================] - 80s 1ms/step - loss: 0.0519 - acc: 0.9840 - val_loss: 0.0553 - val_acc: 0.9833\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.98403\n",
      "Epoch 5/500\n",
      "ecpch:4,learn rate 0.001000\n",
      "55000/55000 [==============================] - 79s 1ms/step - loss: 0.0513 - acc: 0.9841 - val_loss: 0.0526 - val_acc: 0.9838\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.98403\n",
      "Epoch 6/500\n",
      "ecpch:5,learn rate 0.001000\n",
      "55000/55000 [==============================] - 77s 1ms/step - loss: 0.0512 - acc: 0.9841 - val_loss: 0.0541 - val_acc: 0.9832\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.98403\n",
      "Epoch 7/500\n",
      "ecpch:6,learn rate 0.001000\n",
      "55000/55000 [==============================] - 81s 1ms/step - loss: 0.0510 - acc: 0.9842 - val_loss: 0.0576 - val_acc: 0.9828\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.98403\n",
      "Epoch 8/500\n",
      "ecpch:7,learn rate 0.001000\n",
      "55000/55000 [==============================] - 82s 1ms/step - loss: 0.0508 - acc: 0.9841 - val_loss: 0.0529 - val_acc: 0.9838\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.98403\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "Epoch 9/500\n",
      "ecpch:8,learn rate 0.000900\n",
      "55000/55000 [==============================] - 80s 1ms/step - loss: 0.0500 - acc: 0.9844 - val_loss: 0.0562 - val_acc: 0.9832\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.98403\n",
      "Epoch 10/500\n",
      "ecpch:9,learn rate 0.000900\n",
      "55000/55000 [==============================] - 80s 1ms/step - loss: 0.0492 - acc: 0.9846 - val_loss: 0.0525 - val_acc: 0.9838\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.98403\n",
      "Epoch 11/500\n",
      "ecpch:10,learn rate 0.000900\n",
      "55000/55000 [==============================] - 80s 1ms/step - loss: 0.0491 - acc: 0.9846 - val_loss: 0.0522 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.98403\n",
      "Epoch 12/500\n",
      "ecpch:11,learn rate 0.000900\n",
      "55000/55000 [==============================] - 83s 2ms/step - loss: 0.0487 - acc: 0.9846 - val_loss: 0.0545 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.98403\n",
      "Epoch 13/500\n",
      "ecpch:12,learn rate 0.000900\n",
      "55000/55000 [==============================] - 81s 1ms/step - loss: 0.0510 - acc: 0.9844 - val_loss: 0.0509 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.98403\n",
      "Epoch 14/500\n",
      "ecpch:13,learn rate 0.000900\n",
      "55000/55000 [==============================] - 82s 1ms/step - loss: 0.0490 - acc: 0.9845 - val_loss: 0.0524 - val_acc: 0.9838\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.98403\n",
      "Epoch 15/500\n",
      "ecpch:14,learn rate 0.000900\n",
      "55000/55000 [==============================] - 83s 2ms/step - loss: 0.0494 - acc: 0.9846 - val_loss: 0.0589 - val_acc: 0.9823\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.98403\n",
      "Epoch 16/500\n",
      "ecpch:15,learn rate 0.000900\n",
      "55000/55000 [==============================] - 82s 1ms/step - loss: 0.0488 - acc: 0.9846 - val_loss: 0.0514 - val_acc: 0.9841\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.98403 to 0.98415, saving model to ../AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 17/500\n",
      "ecpch:16,learn rate 0.000900\n",
      "55000/55000 [==============================] - 81s 1ms/step - loss: 0.0487 - acc: 0.9846 - val_loss: 0.0519 - val_acc: 0.9841\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.98415\n",
      "Epoch 18/500\n",
      "ecpch:17,learn rate 0.000900\n",
      "55000/55000 [==============================] - 82s 1ms/step - loss: 0.0486 - acc: 0.9847 - val_loss: 0.0526 - val_acc: 0.9841\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.98415\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "Epoch 19/500\n",
      "ecpch:18,learn rate 0.000810\n",
      "55000/55000 [==============================] - 79s 1ms/step - loss: 0.0473 - acc: 0.9849 - val_loss: 0.0510 - val_acc: 0.9843\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.98415 to 0.98431, saving model to ../AI_database/mnistSeq/outputs/mnistSeq.h5\n",
      "Epoch 20/500\n",
      "ecpch:19,learn rate 0.000810\n",
      "18304/55000 [========>.....................] - ETA: 49s - loss: 0.0466 - acc: 0.9851"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-82831395ea20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mseqmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mseqmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmonitorLearning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seqmodel.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "seqmodel.fit(X_train,Y_train,epochs=500,batch_size=128,validation_data=(X_test,Y_test),callbacks=monitorLearning())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load pretrained model,your should pay attention to this function\n",
    "<a href='https://keras.io/getting-started/faq/'>load_model</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqmodel=load_model(outputModelPath,custom_objects={'tf':tf})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "ImageInput (InputLayer)      (None, 28, 280, 1)        0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              multiple                  96346     \n",
      "_________________________________________________________________\n",
      "squeeze (Lambda)             (None, 64, 120)           0         \n",
      "_________________________________________________________________\n",
      "lstm1 (LSTM)                 (None, 64, 64)            47360     \n",
      "_________________________________________________________________\n",
      "BN1 (BatchNormalization)     (None, 64, 64)            256       \n",
      "_________________________________________________________________\n",
      "dropout1 (Dropout)           (None, 64, 64)            0         \n",
      "_________________________________________________________________\n",
      "out (TimeDistributed)        (None, 64, 11)            715       \n",
      "=================================================================\n",
      "Total params: 144,677\n",
      "Trainable params: 48,203\n",
      "Non-trainable params: 96,474\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seqmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,X,Y):\n",
    "    '''\n",
    "        X:(?,28,28n,1)\n",
    "    '''\n",
    "    \n",
    "    def find_majority(k):\n",
    "        myMap = {}\n",
    "        maximum = ( '', 0 ) # (occurring element, occurrences)\n",
    "        for n in k:\n",
    "            if n in myMap: myMap[n] += 1\n",
    "            else: myMap[n] = 1\n",
    "\n",
    "            # Keep track of maximum on the go\n",
    "            if myMap[n] > maximum[1]: maximum = (n,myMap[n])\n",
    "\n",
    "        return maximum[0]\n",
    "    def toLabel(y):\n",
    "        out=[]\n",
    "        m=y.shape[0]\n",
    "        for i in range(m):\n",
    "            yi=y[i] #yi is a sequence ,range of 0-10,10 is blank word,\n",
    "            yi_label=[] #seperate the sequence by blank word,then collape repeat words eg:5 5 5 10 4 4 ->5 4\n",
    "            prev=[] #temply store all digital before blank,when blank occur,convert prev to a single,digital,using\n",
    "                #major voke\n",
    "            for c in yi:\n",
    "                if c==10 and len(prev)>0:\n",
    "                    yi_label.append(str(find_majority(prev)))\n",
    "                    prev=[]\n",
    "                elif c!=10:prev.append(c)\n",
    "            yi_label=''.join(yi_label)\n",
    "            out.append(yi_label)\n",
    "        return out\n",
    "    yhat=np.argmax(model.predict(X),axis=2)  #shape (?,64,11) ->(?,64,11)\n",
    "\n",
    "    out_pred=toLabel(yhat)\n",
    "    out_true=toLabel(Y)\n",
    "    return out_pred,out_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['957387', '4618375403', '7820966626', '203', '72995841']\n",
      "['957387', '4618375403', '7820966626', '203', '72995841']\n"
     ]
    }
   ],
   "source": [
    "idx=80\n",
    "num=5\n",
    "x=X_test[idx:idx+num]\n",
    "y=np.argmax(Y_test[idx:idx+num],axis=-1)\n",
    "out_pred,out_true=predict(seqmodel,x,y)\n",
    "print(out_pred)\n",
    "print(out_true)\n",
    "# plt.imshow(np.squeeze(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now I want know the true accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pred,out_true=predict(seqmodel,X_test,np.argmax(Y_test,axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error rate: 0.13070\n",
      "mislabel:0.11140\n",
      "length don\"t match:0.00720\n",
      "others error:0.01210\n"
     ]
    }
   ],
   "source": [
    "m=X_test.shape[0]\n",
    "error_rate=0#\n",
    "#classify error into 3 types\n",
    "error_mislabel_rate=0      #yhat(i) have same length with y(i),but mislabel some digitals\n",
    "error_lenDisMatch_rate=0   #yhat(i) is a prefix of y(i),or y(i) is prefix of yhat(i),mean redulent output occur\n",
    "error_others_rate=0             #all remain errors\n",
    "\n",
    "for i in range(m):\n",
    "    yp,yt=out_pred[i],out_true[i]\n",
    "    if yt==yp:continue\n",
    "    elif len(yt)==len(yp):\n",
    "        error_mislabel_rate+=1\n",
    "    elif yp.startswith(yt) or yt.startswith(yp):\n",
    "        error_lenDisMatch_rate+=1\n",
    "    else:error_others_rate+=1\n",
    "    error_rate+=1\n",
    "    \n",
    "print('error rate: %.5f'%(error_rate/m))\n",
    "print('mislabel:%.5f'%(error_mislabel_rate/m))\n",
    "print('length don\"t match:%.5f'%(error_lenDisMatch_rate/m))\n",
    "print('others error:%.5f'%(error_others_rate/m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1079"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

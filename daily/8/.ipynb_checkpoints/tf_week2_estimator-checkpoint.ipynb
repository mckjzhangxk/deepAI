{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this notebook,I will learn the high level of tensorflow API invoke :\n",
    "    1.using predefine Model\n",
    "    2.create dataset out of memory\n",
    "    3.distribution train\n",
    "    4.monitor training processing\n",
    "    5.deploy your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. PreDefine Model\n",
    "<a href='https://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor#train'>LinearRegressor</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MyModel():\n",
    "    def __init__(self,filename='outputs/tf_week2/model1'):\n",
    "        self.columns=['pickuplon','pickuplat','dropofflon','dropofflat','passengers']\n",
    "        features=[tf.feature_column.numeric_column(f) for f in self.columns]\n",
    "        self.model=tf.estimator.LinearRegressor(feature_columns=features,model_dir=filename)\n",
    "        tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    def make_train_input_fn(self,epochs):\n",
    "        df_train=pd.read_csv('../AI_database/trips/taxi-train.csv')\n",
    "        return tf.estimator.inputs.pandas_input_fn(x=df_train,\n",
    "                                        y=df_train['fare_amount'],\n",
    "                                        batch_size=128,\n",
    "                                        num_epochs=epochs,\n",
    "                                        shuffle=True,\n",
    "                                        queue_capacity=1000)\n",
    "    def make_valid_input_fn(self):\n",
    "        df_dev=pd.read_csv('../AI_database/trips/taxi-valid.csv')\n",
    "        return tf.estimator.inputs.pandas_input_fn(x=df_dev,\n",
    "                                              y=df_dev[\"fare_amount\"],\n",
    "                                              batch_size=128,\n",
    "                                              num_epochs=1,\n",
    "                                              shuffle=True,\n",
    "                                              queue_capacity=1000)\n",
    "    def make_predict_input_fn(self):\n",
    "        df_test=pd.read_csv('../AI_database/trips/taxi-test.csv')\n",
    "        return tf.estimator.inputs.pandas_input_fn(x=df_test,y=None,\n",
    "                                              batch_size=128,num_epochs=1,\n",
    "                                              shuffle=False)\n",
    "    def fit(self,epochs=10):\n",
    "        self.model.train(self.make_train_input_fn(epochs))\n",
    "    def evaluate(self):\n",
    "        result=self.model.evaluate(self.make_valid_input_fn())\n",
    "        print('Eval rms is {}'.format(np.sqrt(result['average_loss'])))\n",
    "    def predict(self):\n",
    "        return self.model.predict(self.make_predict_input_fn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from outputs/tf_week2/model1/model.ckpt-2400\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 2401 into outputs/tf_week2/model1/model.ckpt.\n",
      "INFO:tensorflow:loss = 678.924, step = 2401\n",
      "INFO:tensorflow:global_step/sec: 547.873\n",
      "INFO:tensorflow:loss = 957.712, step = 2501 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 708.121\n",
      "INFO:tensorflow:loss = 25784.0, step = 2601 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 719.784\n",
      "INFO:tensorflow:loss = 2585.38, step = 2701 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 691.814\n",
      "INFO:tensorflow:loss = 21.2, step = 2801 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 654.913\n",
      "INFO:tensorflow:loss = 47634.2, step = 2901 (0.153 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2973 into outputs/tf_week2/model1/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 59.8961.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train  Step:\n",
      "Evaluatuin Step:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-09-11-03:14:12\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from outputs/tf_week2/model1/model.ckpt-2973\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-09-11-03:14:12\n",
      "INFO:tensorflow:Saving dict for global step 2973: average_loss = 116.415, global_step = 2973, loss = 14882.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval rms is 10.789559364318848\n"
     ]
    }
   ],
   "source": [
    "model=MyModel('outputs/tf_week2/model1')\n",
    "print('Train  Step:')\n",
    "model.fit(1)\n",
    "print('Evaluatuin Step:')\n",
    "model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'dropofflon': <tf.Tensor 'random_shuffle_queue_DequeueUpTo:4' shape=(?,) dtype=float64>, 'pickuplat': <tf.Tensor 'random_shuffle_queue_DequeueUpTo:3' shape=(?,) dtype=float64>, 'key': <tf.Tensor 'random_shuffle_queue_DequeueUpTo:7' shape=(?,) dtype=int64>, 'fare_amount': <tf.Tensor 'random_shuffle_queue_DequeueUpTo:1' shape=(?,) dtype=float64>, 'pickuplon': <tf.Tensor 'random_shuffle_queue_DequeueUpTo:2' shape=(?,) dtype=float64>, 'dropofflat': <tf.Tensor 'random_shuffle_queue_DequeueUpTo:5' shape=(?,) dtype=float64>, 'passengers': <tf.Tensor 'random_shuffle_queue_DequeueUpTo:6' shape=(?,) dtype=float64>}, <tf.Tensor 'random_shuffle_queue_DequeueUpTo:8' shape=(?,) dtype=float64>)\n",
      "--------------------------------------\n",
      "({'dropofflon': <tf.Tensor 'random_shuffle_queue_DequeueUpTo_1:4' shape=(?,) dtype=float64>, 'pickuplat': <tf.Tensor 'random_shuffle_queue_DequeueUpTo_1:3' shape=(?,) dtype=float64>, 'key': <tf.Tensor 'random_shuffle_queue_DequeueUpTo_1:7' shape=(?,) dtype=int64>, 'fare_amount': <tf.Tensor 'random_shuffle_queue_DequeueUpTo_1:1' shape=(?,) dtype=float64>, 'pickuplon': <tf.Tensor 'random_shuffle_queue_DequeueUpTo_1:2' shape=(?,) dtype=float64>, 'dropofflat': <tf.Tensor 'random_shuffle_queue_DequeueUpTo_1:5' shape=(?,) dtype=float64>, 'passengers': <tf.Tensor 'random_shuffle_queue_DequeueUpTo_1:6' shape=(?,) dtype=float64>}, <tf.Tensor 'random_shuffle_queue_DequeueUpTo_1:8' shape=(?,) dtype=float64>)\n",
      "--------------------------------------\n",
      "{'dropofflon': <tf.Tensor 'fifo_queue_DequeueUpTo:4' shape=(?,) dtype=float64>, 'pickuplat': <tf.Tensor 'fifo_queue_DequeueUpTo:3' shape=(?,) dtype=float64>, 'key': <tf.Tensor 'fifo_queue_DequeueUpTo:7' shape=(?,) dtype=int64>, 'fare_amount': <tf.Tensor 'fifo_queue_DequeueUpTo:1' shape=(?,) dtype=float64>, 'pickuplon': <tf.Tensor 'fifo_queue_DequeueUpTo:2' shape=(?,) dtype=float64>, 'dropofflat': <tf.Tensor 'fifo_queue_DequeueUpTo:5' shape=(?,) dtype=float64>, 'passengers': <tf.Tensor 'fifo_queue_DequeueUpTo:6' shape=(?,) dtype=float64>}\n"
     ]
    }
   ],
   "source": [
    "#take a look at train,valid,test input function\n",
    "print(model.make_train_input_fn(1)()) #give 2 node, features(map) and label(a tensor)\n",
    "print('--------------------------------------')\n",
    "print(model.make_valid_input_fn()()) #give 2 node, features(map) and label(a tensor)\n",
    "print('--------------------------------------')\n",
    "print(model.make_predict_input_fn()())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. training on large dataset,using tf.data.* instead of  tf.estimator.input.pandas_input_fn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#input a raw line,return features and labels\n",
    "def decoder(row):\n",
    "    cols=tf.decode_csv(row,[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]])\n",
    "    features={'pickuplon':cols[1],'pockuplat':cols[2]}\n",
    "    label=cols[0]\n",
    "    return features,label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first let's see how dataset tensor work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fare_amount,pickuplon,pickuplat,dropofflon,dropofflat,passengers,key\r\n",
      "2.5,-74.005559,40.740673,-73.956682,40.663655,2.0,0\r\n",
      "2.5,-73.970619,40.764209,-73.965857,40.789753,2.0,1\r\n",
      "2.5,-74.005465,40.740818,-73.973177,40.752603,2.0,2\r\n",
      "2.5,-73.966332,40.758127,-73.966482,40.75808,2.0,3\r\n",
      "2.5,-73.977088,40.774907,-73.977378,40.77444,2.0,4\r\n",
      "2.5,-73.966111,40.762474,-73.945065,40.782581,2.0,5\r\n",
      "2.5,-73.993483,40.72108,-73.993397,40.720987,2.0,6\r\n",
      "2.5,-73.864043,40.765769,-73.864043,40.765769,2.0,7\r\n",
      "2.5,-73.987632,40.702428,-73.987548,40.702332,2.0,8\r\n",
      "2.5,-73.790031,40.645675,-73.789944,40.644809,2.0,9\r\n"
     ]
    }
   ],
   "source": [
    "! head ../AI_database/trips/taxi-train.csv -n11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'pockuplat': array([ 40.74067307,  40.76420975,  40.74081802], dtype=float32), 'pickuplon': array([-74.00556183, -73.9706192 , -74.00546265], dtype=float32)}, array([ 2.5,  2.5,  2.5], dtype=float32))\n",
      "({'pockuplat': array([ 40.75812531,  40.77490616,  40.76247406], dtype=float32), 'pickuplon': array([-73.96633148, -73.97708893, -73.96611023], dtype=float32)}, array([ 2.5,  2.5,  2.5], dtype=float32))\n",
      "({'pockuplat': array([ 40.72108078,  40.76576996,  40.70242691], dtype=float32), 'pickuplon': array([-73.9934845 , -73.86404419, -73.98763275], dtype=float32)}, array([ 2.5,  2.5,  2.5], dtype=float32))\n",
      "({'pockuplat': array([ 40.64567566,  40.72658539,  40.76021576], dtype=float32), 'pickuplon': array([-73.79003143, -73.98907471, -73.97946167], dtype=float32)}, array([ 2.5,  2.5,  3. ], dtype=float32))\n",
      "({'pockuplat': array([ 40.77260971,  40.7104187 ,  40.76414871], dtype=float32), 'pickuplon': array([-73.96065521, -73.95875549, -73.97486877], dtype=float32)}, array([ 3.,  3.,  3.], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "#the workflow look like follow:\n",
    "'''\n",
    "    filename->TextDataset->shuffle->batch->repeat->map->iterator->next\n",
    "    all about are node or tensor in TF\n",
    "    \n",
    "    the output should have the format for model.train()\n",
    "    {featurename:tensor},label tensor\n",
    "'''\n",
    "dataset=tf.data.TextLineDataset('../AI_database/trips/taxi-train.csv')\n",
    "dataset=dataset.skip(1)\n",
    "\n",
    "dataset=dataset.map(decoder)\n",
    "dataset=dataset.batch(3)\n",
    "dataset.shuffle(1000)\n",
    "mynext=dataset.make_one_shot_iterator().get_next()\n",
    "with tf.Session() as sess:\n",
    "    for i in range(5):\n",
    "        print(sess.run(mynext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MyModel2(MyModel):\n",
    "    def decoder_line(self,row):\n",
    "        DEFAULTS = [[0.0], [-74.0], [40.0], [-74.0], [40.7], [1.0], ['nokey']]\n",
    "        cols=tf.decode_csv(row,DEFAULTS)\n",
    "        features={self.columns[i]:cols[i+1] for i in range(0,len(self.columns))}\n",
    "        labels=cols[0]\n",
    "        return features,labels\n",
    "    def _getDataset(self,filename,epochs):\n",
    "        def ret_func():\n",
    "            dataset=tf.data.Dataset.list_files(filename)\n",
    "            dataset=dataset.flat_map(tf.data.TextLineDataset)\n",
    "            dataset=dataset.skip(1)\n",
    "            dataset=dataset.shuffle(1000)\n",
    "            dataset=dataset.batch(128)\n",
    "            dataset=dataset.repeat(epochs)\n",
    "            dataset=dataset.map(lambda r:self.decoder_line(r))   \n",
    "            features,labels=dataset.make_one_shot_iterator().get_next()\n",
    "            return features,labels\n",
    "        return ret_func\n",
    "    \n",
    "    def make_train_input_fn(self,epochs):\n",
    "        print('======================Model 2 using large dataset======================')\n",
    "        return self._getDataset('../AI_database/trips/taxi-train.csv',epochs)\n",
    "    def make_valid_input_fn(self):\n",
    "        print('======================Model 2 using large dataset======================')\n",
    "        return self._getDataset('../AI_database/trips/taxi-valid.csv',1)\n",
    "    def make_predict_input_fn(self):\n",
    "        print('======================Model 2 using large dataset======================')\n",
    "        return self._getDataset('../AI_database/trips/taxi-test.csv',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_master': '', '_global_id_in_cluster': 0, '_save_checkpoints_steps': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fce10df83c8>, '_save_checkpoints_secs': 600, '_keep_checkpoint_max': 5, '_model_dir': 'outputs/tf_week2/model2', '_session_config': None, '_service': None, '_num_ps_replicas': 0, '_evaluation_master': '', '_task_type': 'worker', '_task_id': 0, '_tf_random_seed': None, '_is_chief': True, '_num_worker_replicas': 1, '_log_step_count_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from outputs/tf_week2/model2/model.ckpt-21204\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 21205 into outputs/tf_week2/model2/model.ckpt.\n",
      "INFO:tensorflow:loss = 8183.4, step = 21205\n",
      "INFO:tensorflow:global_step/sec: 396.794\n",
      "INFO:tensorflow:loss = 12496.6, step = 21305 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.862\n",
      "INFO:tensorflow:loss = 54.3312, step = 21405 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.294\n",
      "INFO:tensorflow:loss = 66.1275, step = 21505 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.462\n",
      "INFO:tensorflow:loss = 30675.0, step = 21605 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 471.557\n",
      "INFO:tensorflow:loss = 3714.32, step = 21705 (0.212 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 21777 into outputs/tf_week2/model2/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1920.24.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step:\n",
      "======================Model 2 using large dataset======================\n",
      "Evaluation step:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-09-11-03:14:15\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from outputs/tf_week2/model2/model.ckpt-21777\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-09-11-03:14:16\n",
      "INFO:tensorflow:Saving dict for global step 21777: average_loss = 95.8622, global_step = 21777, loss = 12255.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================Model 2 using large dataset======================\n",
      "Eval rms is 9.790925025939941\n"
     ]
    }
   ],
   "source": [
    "model=MyModel2('outputs/tf_week2/model2')\n",
    "print('Train step:')\n",
    "model.fit(1)\n",
    "print('Evaluation step:')\n",
    "model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from outputs/tf_week2/model2/model.ckpt-21777\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================Model 2 using large dataset======================\n",
      "{'predictions': array([ 12.6932354], dtype=float32)}\n",
      "{'predictions': array([ 12.69159222], dtype=float32)}\n",
      "{'predictions': array([ 12.69203568], dtype=float32)}\n",
      "{'predictions': array([ 12.69083309], dtype=float32)}\n",
      "{'predictions': array([ 12.69321632], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "gen=model.predict()\n",
    "for i in range(5):\n",
    "    print(next(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step : 21777\n",
      "linear/linear_model/bias_weights : [ 0.07922519]\n",
      "linear/linear_model/bias_weights/part_0/Ftrl : [  7.15194982e+09]\n",
      "linear/linear_model/bias_weights/part_0/Ftrl_1 : [-33500.0546875]\n",
      "linear/linear_model/dropofflat/weights : [[ 0.05595937]]\n",
      "linear/linear_model/dropofflat/weights/part_0/Ftrl : [[  1.18752752e+13]]\n",
      "linear/linear_model/dropofflat/weights/part_0/Ftrl_1 : [[-964194.4375]]\n",
      "linear/linear_model/dropofflon/weights : [[-0.04970539]]\n",
      "linear/linear_model/dropofflon/weights/part_0/Ftrl : [[  3.91313464e+13]]\n",
      "linear/linear_model/dropofflon/weights/part_0/Ftrl_1 : [[ 1554661.75]]\n",
      "linear/linear_model/passengers/weights : [[ 0.91858155]]\n",
      "linear/linear_model/passengers/weights/part_0/Ftrl : [[  2.57518326e+10]]\n",
      "linear/linear_model/passengers/weights/part_0/Ftrl_1 : [[-737041.25]]\n",
      "linear/linear_model/pickuplat/weights : [[ 0.05207495]]\n",
      "linear/linear_model/pickuplat/weights/part_0/Ftrl : [[  1.18743777e+13]]\n",
      "linear/linear_model/pickuplat/weights/part_0/Ftrl_1 : [[-897231.]]\n",
      "linear/linear_model/pickuplon/weights : [[-0.0364482]]\n",
      "linear/linear_model/pickuplon/weights/part_0/Ftrl : [[  3.91254240e+13]]\n",
      "linear/linear_model/pickuplon/weights/part_0/Ftrl_1 : [[ 1139923.125]]\n"
     ]
    }
   ],
   "source": [
    "for v_name in model.model.get_variable_names():\n",
    "    print('{} : {}'.format(v_name,model.model.get_variable_value(v_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickuplon</th>\n",
       "      <th>pickuplat</th>\n",
       "      <th>dropofflon</th>\n",
       "      <th>dropofflat</th>\n",
       "      <th>passengers</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.5</td>\n",
       "      <td>-73.988954</td>\n",
       "      <td>40.758612</td>\n",
       "      <td>-73.952118</td>\n",
       "      <td>40.776227</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fare_amount  pickuplon  pickuplat  dropofflon  dropofflat  passengers  key\n",
       "0          2.5 -73.988954  40.758612  -73.952118   40.776227         2.0    0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../AI_database/trips/taxi-valid.csv').head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.843309126564572"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-73.988954*-0.03677155+40.758612*0.05220714+-73.952118*-0.04987059+40.776227*0.05605096*2*0.92487079+0.07902358"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3.big jobs distribution training\n",
    "        1.define a run_config \n",
    "        2.define your model LinearRegression\n",
    "        3.Define trainSpec  <a href='http://ss'>TrainSpec</a>\n",
    "        4.Define evalSpec <a href=''>EvalSpec</a>\n",
    "        5.call tf.estimator.train_and_eval(model,train_spec,eval_spec)\n",
    "<a href='https://www.tensorflow.org/api_docs/python/tf/estimator/RunConfig'>RunConfig</a> <a href='https://www.tensorflow.org/api_docs/python/tf/estimator/TrainSpec'>TrainSpec</a> <a href='https://www.tensorflow.org/api_docs/python/tf/estimator/EvalSpec#__new__'>EvalSpec</a>\n",
    " <a href='https://www.tensorflow.org/api_docs/python/tf/estimator/export/ServingInputReceiver#__new__'>ServingInputReceiver</a>\n",
    "  <a href='https://www.tensorflow.org/api_docs/python/tf/estimator/LatestExporter'>LatestExporter</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyModel3(MyModel2):\n",
    "    def __init__(self,filename='outputs/tf_week2/model1'):\n",
    "        self.columns=['pickuplon','pickuplat','dropofflon','dropofflat','passengers']\n",
    "        features=[tf.feature_column.numeric_column(f) for f in self.columns]\n",
    "        runconfig=tf.estimator.RunConfig(filename,save_summary_steps=100,save_checkpoints_steps=1000)\n",
    "        self.model=tf.estimator.LinearRegressor(feature_columns=features,config=runconfig)\n",
    "    \n",
    "    def fit(self):\n",
    "        # Defines the expected shape of the JSON feed that the model,will receive once \n",
    "        #deployed behind a REST API in production.\n",
    "        def serving_input_fn():\n",
    "            feature_placeholders = {\n",
    "                'pickuplon' : tf.placeholder(tf.float32, [None]),\n",
    "                'pickuplat' : tf.placeholder(tf.float32, [None]),\n",
    "                'dropofflat' : tf.placeholder(tf.float32, [None]),\n",
    "                'dropofflon' : tf.placeholder(tf.float32, [None]),\n",
    "                'passengers' : tf.placeholder(tf.float32, [None])\n",
    "            }\n",
    "            #You can transforma data here from the input format to the format expected by your model.\n",
    "            features = feature_placeholders # no transformation needed\n",
    "            return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)\n",
    "\n",
    "        train_spec=tf.estimator.TrainSpec(input_fn=self.make_train_input_fn())\n",
    "        \n",
    "        eval_spec=tf.estimator.EvalSpec(input_fn=self.make_valid_input_fn(),\n",
    "                                        steps=572,\n",
    "                                        exporters=tf.estimator.LatestExporter('exporter',serving_input_fn),\n",
    "                                        throttle_secs=600)\n",
    "        tf.estimator.train_and_evaluate(self.model,train_spec,eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_keep_checkpoint_max': 5, '_tf_random_seed': None, '_global_id_in_cluster': 0, '_save_checkpoints_steps': 1000, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fce056e85c0>, '_num_worker_replicas': 1, '_save_checkpoints_secs': None, '_log_step_count_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'outputs/tf_week2/model3', '_session_config': None, '_is_chief': True, '_service': None, '_num_ps_replicas': 0, '_save_summary_steps': 100, '_evaluation_master': '', '_master': '', '_task_type': 'worker', '_task_id': 0}\n"
     ]
    }
   ],
   "source": [
    "model=MyModel3('outputs/tf_week2/model3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

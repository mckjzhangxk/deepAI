{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# from torch.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "provinces = [\"皖\", \"沪\", \"津\", \"渝\", \"冀\", \"晋\", \"蒙\", \"辽\", \"吉\", \"黑\", \"苏\", \"浙\", \"京\", \"闽\", \"赣\", \"鲁\", \"豫\", \"鄂\", \"湘\", \"粤\", \"桂\", \"琼\", \"川\", \"贵\", \"云\", \"藏\", \"陕\", \"甘\", \"青\", \"宁\", \"新\", \"警\", \"学\", \"O\"]\n",
    "alphabets = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W',\n",
    "             'X', 'Y', 'Z', 'O']\n",
    "ads = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X',\n",
    "       'Y', 'Z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'O']\n",
    "def decode(Y):\n",
    "    P=provinces[Y[0]]\n",
    "    S=alphabets[Y[1]]\n",
    "    C=[ads[y] for y in Y[2:]]\n",
    "    return P+S+''.join(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'c', 'b']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "a=['a','b','c']\n",
    "random.shuffle(a)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate file for detection task(using darknet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing data,patient!: 40000it [06:59, 95.31it/s] \n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import numpy.random as npr\n",
    "import random\n",
    "def createDetectDataSet(src,tgt,num=None):\n",
    "    imglist=glob.glob(src)\n",
    "#     random.shuffle(imglist)\n",
    "    if num:imglist=imglist[:num]\n",
    "    def decodeBox(imgname):\n",
    "#         I=cv2.imread(imgname)\n",
    "#         H,W,_=I.shape\n",
    "        W,H=Image.open(imgname).size\n",
    "        \n",
    "        basename=os.path.basename(imgname)\n",
    "        sps=basename.split('-')\n",
    "\n",
    "        bbox=sps[2]\n",
    "        bbox=bbox.split('_')\n",
    "        pp1=bbox[0].split('&')\n",
    "        pp2=bbox[1].split('&')\n",
    "        x1,y1,x2,y2=int(pp1[0]),int(pp1[1]),int(pp2[0]),int(pp2[1])\n",
    "        return x1/W,y1/H,x2/W,y2/H\n",
    "    for i,imgpath in tqdm(enumerate(imglist),'processing data,patient!'):\n",
    "        ##open file\n",
    "        \n",
    "        x1,y1,x2,y2=decodeBox(imgpath)\n",
    "        content=','.join(map(str,[0,x1,y1,x2,y2]))\n",
    "        \n",
    "        tgt_img=os.path.join(tgt,'%d.jpg'%i)\n",
    "        tgt_label=os.path.join(tgt,'%d.txt'%i)\n",
    "        shutil.copy(imgpath,tgt_img)\n",
    "        with open(tgt_label,'w') as fs:\n",
    "            fs.write(content)\n",
    "def splitDataset(src,tgt,testnum=1000,prefix=''):\n",
    "    imglist=glob.glob(src)\n",
    "    idx=np.arange(len(imglist))\n",
    "    npr.shuffle(idx)\n",
    "    with open(os.path.join(tgt,'train.txt'),'w') as fs:\n",
    "        for index in idx[:-testnum]:\n",
    "            s=imglist[index]\n",
    "            s=os.path.join(prefix,os.path.basename(s))\n",
    "            fs.write(s+'\\n')\n",
    "    with open(os.path.join(tgt,'test.txt'),'w') as fs:\n",
    "        for index in idx[-testnum:]:\n",
    "            s=imglist[index]\n",
    "            s=os.path.join(prefix,os.path.basename(s))\n",
    "            fs.write(s+'\\n')\n",
    "db_src='/home/zxk/AI/data/CCPD2019/ccpd_base/*.jpg'\n",
    "db_my='/home/zxk/AI/darknet/mymodel/ccpd/obj/'\n",
    "db_train_test='/home/zxk/AI/darknet/mymodel/ccpd'\n",
    "prefix_anno='ccpd/obj'\n",
    "if os.path.exists(db_my):\n",
    "    shutil.rmtree(db_my)\n",
    "os.mkdir(db_my)\n",
    "createDetectDataSet(db_src,db_my,num=40000)\n",
    "splitDataset(db_my+'*.jpg',db_train_test,testnum=2000,prefix=prefix_anno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  obj.data  obj.names  test.txt  train.txt  yolov-obj.cfg\r\n"
     ]
    }
   ],
   "source": [
    "! ls /home/zxk/AI/darknet/mymodel/ccpd/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataSet For recognition Task(MyModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset: 179993\n",
      "teset: 20000\n",
      "(32, 64)\n",
      "皖AGN328\n",
      "torch.Size([64, 1, 32, 64]) torch.Size([64, 7])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class CCPD_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self,basedir,train,seed=0):\n",
    "        super().__init__()   \n",
    "        db=glob.glob(basedir)\n",
    "        n=len(db)\n",
    "        np.random.seed(seed)\n",
    "        totalidx=set(np.arange(n))\n",
    "        trainidx=set(np.random.choice(n,int(n*0.9),False))\n",
    "        testidx=totalidx-trainidx\n",
    "        \n",
    "        if train:\n",
    "            self._db=[db[idx] for idx in trainidx]\n",
    "        else:\n",
    "            self._db=[db[idx] for idx in testidx]\n",
    "        self._init_processing_fn()\n",
    "    def _init_processing_fn(self):\n",
    "        t1=transforms.FiveCrop((24,24))\n",
    "        t2=transforms.Lambda(lambda imgs:[transforms.RandomHorizontalFlip(0.5)(img) for img in imgs])\n",
    "        t3=transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop)  for crop in crops]))\n",
    "        \n",
    "        t_affine=transforms.RandomAffine(5,(0.05,0.05),(0.9,1.1))\n",
    "        t_color=transforms.ColorJitter(brightness=.3, contrast=.3)\n",
    "        t_resize=transforms.Resize((32,64))\n",
    "        t_tensor=transforms.ToTensor()\n",
    "        \n",
    "        t_norm=transforms.Lambda(lambda t:(t-0.5)/0.5)\n",
    "        \n",
    "        self.process=transforms.Compose([t_color,t_affine,t_resize,t_tensor])\n",
    "        \n",
    "        \n",
    "#         self._db=['/home/zhangxk/AIProject/CCPD/sample/rotate/025-95_113-154&383_386&473-386&473_177&454_154&383_363&402-0_0_22_27_27_33_16-37-15.jpg']\n",
    "    def __getitem__(self,k):\n",
    "        imagename=self._db[k]  \n",
    "        basename=os.path.basename(imagename)\n",
    "        sps=basename.split('-')\n",
    "        #label\n",
    "        label=sps[4]\n",
    "        labels=label.split('_')\n",
    "        Y=np.array([int(k) for k in labels])\n",
    "        #image\n",
    "#         \"025-95_113-154&383_386&473-386&473_177&454_154&383_363&402-0_0_22_27_27_33_16-37-15.jpg\"\n",
    "        bbox=sps[2]\n",
    "        bbox=bbox.split('_')\n",
    "        pp1=bbox[0].split('&')\n",
    "        pp2=bbox[1].split('&')\n",
    "        x1,y1,x2,y2=int(pp1[0]),int(pp1[1]),int(pp2[0]),int(pp2[1])\n",
    "#         cv2.imread(imagename)\n",
    "        I=Image.open(imagename,mode='r').convert(\"L\")\n",
    "        X=I.crop((x1,y1,x2,y2))\n",
    "#         X=I[y1:y2,x1:x2]\n",
    "#         X=cv2.cvtColor(X,cv2.COLOR_BGR2GRAY)\n",
    "        return self.process(X),torch.tensor(Y)\n",
    "    def __len__(self):\n",
    "        return len(self._db)\n",
    "dbpath='/home/zxk/AI/data/CCPD2019/ccpd_base/*.jpg'\n",
    "trainset=CCPD_Dataset(dbpath,True)\n",
    "testset=CCPD_Dataset(dbpath,False)\n",
    "print('trainset:',len(trainset))\n",
    "print('teset:',len(testset))\n",
    "batch_size=64\n",
    "trainloader=DataLoader(trainset,batch_size,shuffle=True,num_workers=4)\n",
    "testloader=DataLoader(trainset,batch_size,shuffle=False,num_workers=4)\n",
    "#########test code#############\n",
    "N=8765\n",
    "ds=trainset\n",
    "print(ds[N][0].squeeze(0).numpy().shape)\n",
    "plt.imshow(ds[N][0].squeeze(0).numpy(),cmap='gray')\n",
    "print(decode(ds[N][1]))\n",
    "for k in trainloader:\n",
    "    print(k[0].size(),k[1].size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4771882\n",
      "torch.Size([16, 234])\n"
     ]
    }
   ],
   "source": [
    "class BlockLayer(nn.Module):\n",
    "    def __init__(self,in_ch,out_ch,stride=1):\n",
    "        super(BlockLayer,self).__init__()\n",
    "        H=out_ch//4\n",
    "        model=nn.Sequential()\n",
    "        model.add_module('conv1',nn.Conv2d(in_ch,H,3,1,1,bias=False))\n",
    "        model.add_module('bn1',nn.BatchNorm2d(H))\n",
    "        model.add_module('relu1',nn.ReLU())\n",
    "        \n",
    "        model.add_module('conv2',nn.Conv2d(H,H,3,stride,1,bias=False))\n",
    "        model.add_module('bn2',nn.BatchNorm2d(H))\n",
    "        model.add_module('relu2',nn.ReLU())\n",
    "        \n",
    "        model.add_module('conv3',nn.Conv2d(H,out_ch,3,1,1,bias=False))\n",
    "        model.add_module('bn3',nn.BatchNorm2d(out_ch))\n",
    "        model.add_module('relu3',nn.ReLU())\n",
    "        if in_ch==out_ch and stride==1:\n",
    "            self.shortcut=nn.Identity()\n",
    "        else:\n",
    "            self.shortcut=nn.Conv2d(in_ch,out_ch,3,stride,1)\n",
    "        self.block=model\n",
    "    def forward(self,X):\n",
    "        route1=self.block(X)\n",
    "        route2=self.shortcut(X)\n",
    "        return route1+route2\n",
    "class GroupLayer(nn.Module):\n",
    "    def __init__(self,in_ch,out_ch,count):\n",
    "        super(GroupLayer,self).__init__()\n",
    "        model=nn.Sequential()\n",
    "        model.add_module('p1',BlockLayer(in_ch,out_ch,2))\n",
    "        for i in range(2,count+1):\n",
    "            model.add_module('p%d'%i,BlockLayer(out_ch,out_ch,1))\n",
    "        self.model=model\n",
    "    def forward(self,X):\n",
    "        return self.model(X)\n",
    "class CNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNet,self).__init__()\n",
    "        model=nn.Sequential()\n",
    "        \n",
    "        model.add_module('c1',nn.Conv2d(1,64,3,2,1,bias=False))\n",
    "        model.add_module('b1',nn.BatchNorm2d(64))\n",
    "        model.add_module('r1',nn.ReLU())\n",
    "        \n",
    "        model.add_module('stage1',GroupLayer(64,128,2))\n",
    "        model.add_module('stage2',GroupLayer(128,256,2))\n",
    "        model.add_module('stage3',GroupLayer(256,512,2))\n",
    "        \n",
    "        self.features=model\n",
    "        self.cls=nn.Linear(512,34+25+35*5)\n",
    "#         self.cls2=nn.Linear(512,25)\n",
    "#         self.cls3=nn.Linear(512,35*5)\n",
    "        \n",
    "    def forward(self,X):\n",
    "        Y=self.features(X)\n",
    "        Y=F.adaptive_avg_pool2d(Y,(1,1))\n",
    "        Y=Y.view(-1,512)\n",
    "        \n",
    "        Yhat=self.cls(Y)\n",
    "#         alphabets_logit=self.cls2(Y)\n",
    "#         ads_logit=self.cls3(Y)\n",
    "        \n",
    "        return Yhat\n",
    "    def pcount(self):\n",
    "        c=0\n",
    "        for x in self.parameters():\n",
    "            c+=x.numel()\n",
    "        return c\n",
    "def compute_loss(Yhat,Y):\n",
    "    Yhats=torch.split(Yhat,[34,25,35,35,35,35,35],1)\n",
    "    Ys=torch.split(Y,1,1)\n",
    "    \n",
    "    loss=[0,0,0,0,0,0,0]\n",
    "    for i,y,yhat in enumerate(Ys,Yhats):\n",
    "        loss[i]+=nn.CrossEntropyLoss()(yhat,y)\n",
    "    total_loss=0\n",
    "    for l in loss:total_loss+=l\n",
    "    return loss,total_loss\n",
    "def get_optimizer(model):\n",
    "    return optim.Adam(model.parameters())\n",
    "\n",
    "X=torch.randn(16,1,32,48)\n",
    "# B1=BlockLayer(32,64,2)\n",
    "# Y=B1(X)\n",
    "# print(Y.size()) #16,64,24,32\n",
    "# print()\n",
    "# for x in B1.model.parameters():\n",
    "#     print(x.size())\n",
    "# print()\n",
    "# for x in B1.shortcut.parameters():\n",
    "#     print(x.size())\n",
    "G1=CNet()\n",
    "X1=G1(X)\n",
    "print(G1.pcount())\n",
    "print(X1.shape)\n",
    "# print(X2.shape)\n",
    "# print(X3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([129, 34])\n",
      "torch.Size([129, 25])\n",
      "torch.Size([129, 35])\n",
      "torch.Size([129, 35])\n",
      "torch.Size([129, 35])\n",
      "torch.Size([129, 35])\n",
      "torch.Size([129, 35])\n"
     ]
    }
   ],
   "source": [
    "X=torch.rand(129,34+25+35*5)\n",
    "xx=torch.split(X,[34,25,35,35,35,35,35],1)\n",
    "for x in xx:\n",
    "    print(x.shape)\n",
    "# xx=torch.split(X,35,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

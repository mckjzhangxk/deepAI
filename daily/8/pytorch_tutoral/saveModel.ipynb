{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "class TheModelClass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TheModelClass, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model=TheModelClass()\n",
    "solver=optim.SGD(model.parameters(),lr=1e-3,momentum=0.9,weight_decay=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight : torch.Size([6, 3, 5, 5])\n",
      "conv1.bias : torch.Size([6])\n",
      "conv2.weight : torch.Size([16, 6, 5, 5])\n",
      "conv2.bias : torch.Size([16])\n",
      "fc1.weight : torch.Size([120, 400])\n",
      "fc1.bias : torch.Size([120])\n",
      "fc2.weight : torch.Size([84, 120])\n",
      "fc2.bias : torch.Size([84])\n",
      "fc3.weight : torch.Size([10, 84])\n",
      "fc3.bias : torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "#show state_dict\n",
    "for vname,vvars in model.state_dict().items():\n",
    "        print(vname,':',vvars.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state : {}\n",
      "param_groups : [{'nesterov': False, 'dampening': 0, 'lr': 0.001, 'params': [140333420703464, 140333420703104, 140333420702672, 140333420701016, 140333420701232, 140333420700728, 140333420700512, 140333420703608, 140333420748016, 140333420746792], 'weight_decay': 0.9, 'momentum': 0.9}]\n"
     ]
    }
   ],
   "source": [
    "for vname,vvars in solver.state_dict().items():\n",
    "        print(vname,':',vvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0956,  0.1622,  0.0561,  0.1320, -0.0684,  0.0030, -0.0197, -0.0924,\n",
       "          0.0181, -0.0959],\n",
       "        [ 0.0828,  0.1817,  0.0557,  0.1211, -0.0850,  0.0026, -0.0338, -0.1032,\n",
       "          0.0109, -0.1165],\n",
       "        [ 0.1125,  0.1723,  0.0262,  0.1144, -0.0741,  0.0027,  0.0074, -0.1032,\n",
       "          0.0069, -0.0858],\n",
       "        [ 0.0641,  0.1601,  0.0607,  0.1220, -0.0796,  0.0024, -0.0532, -0.1067,\n",
       "          0.0293, -0.1130],\n",
       "        [ 0.0879,  0.1398,  0.0615,  0.1218, -0.1160, -0.0021, -0.0351, -0.0939,\n",
       "          0.0303, -0.1369]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "X=torch.Tensor(np.random.randn(5,3,32,32))\n",
    "model.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save model\n",
    "PATH='weights/classifier.pt'\n",
    "torch.save(model.state_dict(),PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TheModelClass(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reload model\n",
    "PATH='weights/classifier.pt'\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "# model.eval() to set dropout and batch normalization layers to \n",
    "# evaluation mode before running inference. \n",
    "# Failing to do this will yield inconsistent inference results.\n",
    "model.eval()\n",
    "#then run above code, see follow result!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensor([[ 0.0956,  0.1622,  0.0561,  0.1320, -0.0684,  0.0030, -0.0197, -0.0924,\n",
    "          0.0181, -0.0959],\n",
    "        [ 0.0828,  0.1817,  0.0557,  0.1211, -0.0850,  0.0026, -0.0338, -0.1032,\n",
    "          0.0109, -0.1165],\n",
    "        [ 0.1125,  0.1723,  0.0262,  0.1144, -0.0741,  0.0027,  0.0074, -0.1032,\n",
    "          0.0069, -0.0858],\n",
    "        [ 0.0641,  0.1601,  0.0607,  0.1220, -0.0796,  0.0024, -0.0532, -0.1067,\n",
    "          0.0293, -0.1130],\n",
    "        [ 0.0879,  0.1398,  0.0615,  0.1218, -0.1160, -0.0021, -0.0351, -0.0939,\n",
    "          0.0303, -0.1369]], grad_fn=<AddmmBackward>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now let save a general model\n",
    "model=TheModelClass()\n",
    "lr=torch.Tensor([0.5])\n",
    "lr.requires_grad\n",
    "solver=optim.Adam(model.parameters(),lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save(model,solver,PATH):\n",
    "    state={'model':model.state_dict(),\n",
    "          'solver':solver.state_dict()}\n",
    "    torch.save(state,PATH)\n",
    "PATH='weights/general_model.tar'\n",
    "save(model,solver,PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load(model,solver,PATH):\n",
    "    state=torch.load(PATH)\n",
    "    model.load_state_dict(state['model'])\n",
    "    solver.load_state_dict(state['solver'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.9\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model=TheModelClass()\n",
    "solver=optim.Adam(model.parameters(),0.9)\n",
    "print(solver)\n",
    "PATH='weights/general_model.tar'\n",
    "load(model,solver,PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loose load,strict=False will allow mismatch error\n",
    "class AnotherModel(TheModelClass):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        #foo layer\n",
    "        self.foo=nn.Linear(22,22)\n",
    "        self.xx=torch.rand((3,2),requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model=AnotherModel()\n",
    "PATH='weights/general_model.tar'\n",
    "model.load_state_dict(torch.load(PATH)['model'],strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save on GPU, Load on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module.wR2.module.features.0.0.weight\n",
      "module.wR2.module.features.0.0.bias\n",
      "module.wR2.module.features.0.1.weight\n",
      "module.wR2.module.features.0.1.bias\n",
      "module.wR2.module.features.0.1.running_mean\n",
      "module.wR2.module.features.0.1.running_var\n",
      "module.wR2.module.features.1.0.weight\n",
      "module.wR2.module.features.1.0.bias\n",
      "module.wR2.module.features.1.1.weight\n",
      "module.wR2.module.features.1.1.bias\n",
      "module.wR2.module.features.1.1.running_mean\n",
      "module.wR2.module.features.1.1.running_var\n",
      "module.wR2.module.features.2.0.weight\n",
      "module.wR2.module.features.2.0.bias\n",
      "module.wR2.module.features.2.1.weight\n",
      "module.wR2.module.features.2.1.bias\n",
      "module.wR2.module.features.2.1.running_mean\n",
      "module.wR2.module.features.2.1.running_var\n",
      "module.wR2.module.features.3.0.weight\n",
      "module.wR2.module.features.3.0.bias\n",
      "module.wR2.module.features.3.1.weight\n",
      "module.wR2.module.features.3.1.bias\n",
      "module.wR2.module.features.3.1.running_mean\n",
      "module.wR2.module.features.3.1.running_var\n",
      "module.wR2.module.features.4.0.weight\n",
      "module.wR2.module.features.4.0.bias\n",
      "module.wR2.module.features.4.1.weight\n",
      "module.wR2.module.features.4.1.bias\n",
      "module.wR2.module.features.4.1.running_mean\n",
      "module.wR2.module.features.4.1.running_var\n",
      "module.wR2.module.features.5.0.weight\n",
      "module.wR2.module.features.5.0.bias\n",
      "module.wR2.module.features.5.1.weight\n",
      "module.wR2.module.features.5.1.bias\n",
      "module.wR2.module.features.5.1.running_mean\n",
      "module.wR2.module.features.5.1.running_var\n",
      "module.wR2.module.features.6.0.weight\n",
      "module.wR2.module.features.6.0.bias\n",
      "module.wR2.module.features.6.1.weight\n",
      "module.wR2.module.features.6.1.bias\n",
      "module.wR2.module.features.6.1.running_mean\n",
      "module.wR2.module.features.6.1.running_var\n",
      "module.wR2.module.features.7.0.weight\n",
      "module.wR2.module.features.7.0.bias\n",
      "module.wR2.module.features.7.1.weight\n",
      "module.wR2.module.features.7.1.bias\n",
      "module.wR2.module.features.7.1.running_mean\n",
      "module.wR2.module.features.7.1.running_var\n",
      "module.wR2.module.features.8.0.weight\n",
      "module.wR2.module.features.8.0.bias\n",
      "module.wR2.module.features.8.1.weight\n",
      "module.wR2.module.features.8.1.bias\n",
      "module.wR2.module.features.8.1.running_mean\n",
      "module.wR2.module.features.8.1.running_var\n",
      "module.wR2.module.features.9.0.weight\n",
      "module.wR2.module.features.9.0.bias\n",
      "module.wR2.module.features.9.1.weight\n",
      "module.wR2.module.features.9.1.bias\n",
      "module.wR2.module.features.9.1.running_mean\n",
      "module.wR2.module.features.9.1.running_var\n",
      "module.wR2.module.classifier.0.weight\n",
      "module.wR2.module.classifier.0.bias\n",
      "module.wR2.module.classifier.1.weight\n",
      "module.wR2.module.classifier.1.bias\n",
      "module.wR2.module.classifier.2.weight\n",
      "module.wR2.module.classifier.2.bias\n",
      "module.classifier1.0.weight\n",
      "module.classifier1.0.bias\n",
      "module.classifier1.1.weight\n",
      "module.classifier1.1.bias\n",
      "module.classifier2.0.weight\n",
      "module.classifier2.0.bias\n",
      "module.classifier2.1.weight\n",
      "module.classifier2.1.bias\n",
      "module.classifier3.0.weight\n",
      "module.classifier3.0.bias\n",
      "module.classifier3.1.weight\n",
      "module.classifier3.1.bias\n",
      "module.classifier4.0.weight\n",
      "module.classifier4.0.bias\n",
      "module.classifier4.1.weight\n",
      "module.classifier4.1.bias\n",
      "module.classifier5.0.weight\n",
      "module.classifier5.0.bias\n",
      "module.classifier5.1.weight\n",
      "module.classifier5.1.bias\n",
      "module.classifier6.0.weight\n",
      "module.classifier6.0.bias\n",
      "module.classifier6.1.weight\n",
      "module.classifier6.1.bias\n",
      "module.classifier7.0.weight\n",
      "module.classifier7.0.bias\n",
      "module.classifier7.1.weight\n",
      "module.classifier7.1.bias\n"
     ]
    }
   ],
   "source": [
    "device=torch.device('cpu')\n",
    "state_dict=torch.load('/home/zhangxk/AIProject/CCPD/weight/fh02.pth',map_location=device)\n",
    "for name in state_dict:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a='module.wR2.module.features.0.0.weight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wR2.module.features.0.0.weight\n"
     ]
    }
   ],
   "source": [
    "if a.startswith('module.wR2'):\n",
    "    print(a[len('modele.'):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a.replace('.module','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

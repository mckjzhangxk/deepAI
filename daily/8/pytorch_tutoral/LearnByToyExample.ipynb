{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recall from numpy\n",
    ">numpy is a general math framework,so I use it to optimize a random net.\n",
    "\n",
    "$$Y=X W$$\n",
    "\n",
    "$$\\frac{\\partial Loss}{\\partial X}=\\frac{\\partial Loss}{\\partial Y} W^T$$\n",
    "\n",
    "$$\\frac{\\partial Loss}{\\partial W}=X^T \\frac{\\partial Loss}{\\partial Y}$$\n",
    "\n",
    "$$Loss=\\frac{1}{2}\\|Y-\\hat{Y}\\|^2$$\n",
    "$$\\frac{\\partial Loss}{\\partial Y}=\\hat{Y}-Y$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from IPython.display import clear_output\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00028473321216456864\n",
      "2.387462615966797\n"
     ]
    }
   ],
   "source": [
    "#try replace randn with rand\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "np.random.seed(0)\n",
    "X=np.random.randn(N,D_in)\n",
    "W1=np.random.randn(D_in,H)\n",
    "W2=np.random.randn(H,D_out)\n",
    "Y=np.random.randn(N,D_out)\n",
    "lr=1e-6\n",
    "start_time=time()\n",
    "for i in range(500):\n",
    "    #forward \n",
    "    Z1=X.dot(W1)\n",
    "    H1=np.maximum(Z1,0)\n",
    "#     print(np.sum(H1))\n",
    "    Z2=H1.dot(W2)\n",
    "    Loss=0.5*np.sum((Y-Z2)**2)/N\n",
    "    print(Loss)\n",
    "    #backward\n",
    "    dZ2=Z2-Y\n",
    "    dW2=H1.T.dot(dZ2)\n",
    "    dH1=dZ2.dot(W2.T)\n",
    "    dZ1=dH1\n",
    "    dZ1[Z1<0]=0\n",
    "    dW1=X.T.dot(dZ1)\n",
    "\n",
    "    W1=W1-lr*dW1\n",
    "    W2=W2-lr*dW2\n",
    "clear_output()\n",
    "print(Loss)\n",
    "print(time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using torch to compute graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0016)\n",
      "0.9933171272277832\n"
     ]
    }
   ],
   "source": [
    "#try replace randn with rand\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "# torch.random.set_rng_state()\n",
    "X=torch.randn(N,D_in)\n",
    "W1=torch.randn(D_in,H)\n",
    "W2=torch.randn(H,D_out)\n",
    "Y=torch.randn(N,D_out)\n",
    "lr=1e-6\n",
    "start_time=time()\n",
    "for i in range(500):\n",
    "    #forward \n",
    "    Z1=X.mm(W1)\n",
    "    H1=torch.clamp(Z1,min=0)\n",
    "    Z2=H1.mm(W2)\n",
    "    Loss=0.5*torch.sum((Y-Z2)**2)/N\n",
    "    print(Loss.item())\n",
    "    #backward\n",
    "    dZ2=Z2-Y\n",
    "    dW2=H1.t().mm(dZ2)\n",
    "    dH1=dZ2.mm(W2.t())\n",
    "    dZ1=torch.clone(dH1)\n",
    "    dZ1[Z1<0]=0\n",
    "    dW1=X.t().mm(dZ1)\n",
    "\n",
    "    W1=W1-lr*dW1\n",
    "    W2=W2-lr*dW2\n",
    "clear_output()\n",
    "print(Loss)\n",
    "print(time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoGradient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0472, grad_fn=<MulBackward0>)\n",
      "1.0727624893188477\n"
     ]
    }
   ],
   "source": [
    "#try replace randn with rand\n",
    "device = torch.device(\"cpu\")\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "# torch.random.set_rng_state()\n",
    "X=torch.randn(N,D_in,device=device)\n",
    "W1=torch.randn(D_in,H,requires_grad=True,device=device)\n",
    "W2=torch.randn(H,D_out,requires_grad=True,device=device)\n",
    "Y=torch.randn(N,D_out,device=device)\n",
    "lr=1e-6\n",
    "start_time=time()\n",
    "for i in range(500):\n",
    "    #forward \n",
    "    Z=X.mm(W1).clamp(min=0).mm(W2)\n",
    "    Loss=0.5*torch.sum((Y-Z)**2)\n",
    "    print(Loss.item())\n",
    "    #backward\n",
    "    Loss.backward()\n",
    "    with torch.no_grad():\n",
    "        W1.sub_(lr*W1.grad)\n",
    "        W2.sub_(lr*W2.grad)\n",
    "        W1.grad.zero_()\n",
    "        W2.grad.zero_()\n",
    "clear_output()\n",
    "print(Loss)\n",
    "print(time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### some bug I made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9.]) tensor([9.])\n",
      "tensor([9.]) tensor([10.])\n"
     ]
    }
   ],
   "source": [
    "W=torch.Tensor([10])\n",
    "W1=W\n",
    "W-=1 #same as W.sub_(1)\n",
    "print(W,W1)\n",
    "W=torch.Tensor([10])\n",
    "W1=W\n",
    "W=W-1\n",
    "print(W,W1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "W=torch.tensor((10.0),requires_grad=True)\n",
    "\n",
    "for i in range(3):\n",
    "    W.backward()\n",
    "    print(W.grad)\n",
    "    with torch.no_grad():\n",
    "        W-=W.grad\n",
    "    W.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Define Custom Function,This Function like a graph operator in Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyReLU(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    We can implement our own custom autograd Functions by subclassing\n",
    "    torch.autograd.Function and implementing the forward and backward passes\n",
    "    which operate on Tensors.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        \"\"\"\n",
    "        In the forward pass we receive a Tensor containing the input and return\n",
    "        a Tensor containing the output. ctx is a context object that can be used\n",
    "        to stash information for backward computation. You can cache arbitrary\n",
    "        objects for use in the backward pass using the ctx.save_for_backward method.\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(input)\n",
    "        return input.clamp(min=0)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
    "        with respect to the output, and we need to compute the gradient of the loss\n",
    "        with respect to the input.\n",
    "        \"\"\"\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input[input < 0] = 0\n",
    "        return grad_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 2.], grad_fn=<MyReLUBackward>)\n",
      "tensor([2., 0., 4.])\n"
     ]
    }
   ],
   "source": [
    "W=torch.tensor([1,-1,2],requires_grad=True,dtype=torch.float32)\n",
    "relu=MyReLU.apply\n",
    "Y=relu(W)\n",
    "print(Y)\n",
    "Z=torch.sum(Y**2)\n",
    "Z.backward()\n",
    "print(W.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence Module Can Help Me manager all learnable parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0949088817834305e-12\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "# torch.random.set_rng_state()\n",
    "X=torch.randn(N,D_in,device=device)\n",
    "Y=torch.randn(N,D_out,device=device)\n",
    "lr=1e-3\n",
    "\n",
    "model=nn.Sequential(nn.Linear(D_in,H),nn.ReLU(),nn.Linear(H,D_out))\n",
    "criterion=nn.MSELoss(reduction='sum')\n",
    "for i in range(300):\n",
    "    Yhat=model(X)\n",
    "    loss=criterion(Yhat,Y)\n",
    "    print(loss.item())\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "#     with torch.no_grad():\n",
    "    for v in model.parameters():\n",
    "        v.data-=lr*v.grad.data\n",
    "clear_output()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### why not use predefine optimizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.504963167975326e-11\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "# torch.random.set_rng_state()\n",
    "X=torch.randn(N,D_in,device=device)\n",
    "Y=torch.randn(N,D_out,device=device)\n",
    "lr=1e-3\n",
    "\n",
    "model=nn.Sequential(nn.Linear(D_in,H),nn.ReLU(),nn.Linear(H,D_out))\n",
    "criterion=nn.MSELoss(reduction='sum')\n",
    "solver=optim.Adam(model.parameters(),lr)\n",
    "for i in range(300):\n",
    "    Yhat=model(X)\n",
    "    loss=criterion(Yhat,Y)\n",
    "    print(loss.item())\n",
    "    solver.zero_grad()\n",
    "    loss.backward()\n",
    "    solver.step()\n",
    "clear_output()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[3, 8, 8,  ..., 1, 2, 8],\n",
      "          [0, 0, 6,  ..., 5, 0, 2],\n",
      "          [1, 7, 2,  ..., 2, 4, 2],\n",
      "          ...,\n",
      "          [3, 7, 8,  ..., 4, 3, 5],\n",
      "          [6, 0, 7,  ..., 2, 4, 4],\n",
      "          [5, 1, 6,  ..., 4, 8, 6]],\n",
      "\n",
      "         [[0, 1, 6,  ..., 2, 4, 1],\n",
      "          [3, 7, 7,  ..., 5, 8, 7],\n",
      "          [8, 8, 0,  ..., 3, 8, 1],\n",
      "          ...,\n",
      "          [4, 5, 1,  ..., 5, 0, 0],\n",
      "          [0, 3, 0,  ..., 6, 4, 6],\n",
      "          [0, 7, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "         [[5, 6, 5,  ..., 2, 3, 4],\n",
      "          [7, 6, 3,  ..., 3, 4, 4],\n",
      "          [7, 4, 4,  ..., 6, 6, 5],\n",
      "          ...,\n",
      "          [7, 3, 5,  ..., 2, 5, 6],\n",
      "          [5, 4, 2,  ..., 7, 5, 3],\n",
      "          [4, 8, 2,  ..., 8, 6, 2]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[4, 4, 2,  ..., 0, 7, 0],\n",
      "          [0, 8, 2,  ..., 0, 2, 2],\n",
      "          [3, 2, 8,  ..., 2, 7, 3],\n",
      "          ...,\n",
      "          [2, 5, 1,  ..., 2, 5, 8],\n",
      "          [4, 2, 8,  ..., 8, 7, 5],\n",
      "          [1, 5, 7,  ..., 4, 6, 0]],\n",
      "\n",
      "         [[3, 5, 0,  ..., 6, 8, 0],\n",
      "          [0, 3, 2,  ..., 8, 5, 8],\n",
      "          [1, 5, 7,  ..., 2, 4, 6],\n",
      "          ...,\n",
      "          [2, 7, 7,  ..., 0, 2, 2],\n",
      "          [0, 8, 7,  ..., 2, 6, 4],\n",
      "          [8, 8, 4,  ..., 2, 5, 6]],\n",
      "\n",
      "         [[2, 3, 3,  ..., 0, 2, 5],\n",
      "          [2, 0, 3,  ..., 5, 7, 1],\n",
      "          [0, 6, 4,  ..., 4, 3, 2],\n",
      "          ...,\n",
      "          [3, 6, 8,  ..., 5, 5, 2],\n",
      "          [4, 6, 0,  ..., 8, 3, 7],\n",
      "          [3, 5, 2,  ..., 1, 0, 4]]],\n",
      "\n",
      "\n",
      "        [[[0, 6, 1,  ..., 5, 1, 5],\n",
      "          [8, 8, 6,  ..., 1, 4, 0],\n",
      "          [0, 3, 7,  ..., 8, 3, 7],\n",
      "          ...,\n",
      "          [4, 1, 1,  ..., 8, 7, 4],\n",
      "          [7, 5, 1,  ..., 7, 8, 5],\n",
      "          [6, 5, 0,  ..., 3, 3, 6]],\n",
      "\n",
      "         [[8, 6, 6,  ..., 1, 7, 5],\n",
      "          [2, 3, 5,  ..., 5, 0, 6],\n",
      "          [0, 1, 5,  ..., 1, 4, 3],\n",
      "          ...,\n",
      "          [5, 4, 2,  ..., 7, 7, 4],\n",
      "          [4, 7, 5,  ..., 1, 2, 0],\n",
      "          [7, 0, 7,  ..., 5, 5, 8]],\n",
      "\n",
      "         [[2, 8, 8,  ..., 6, 8, 4],\n",
      "          [6, 2, 0,  ..., 7, 0, 1],\n",
      "          [7, 8, 6,  ..., 6, 7, 0],\n",
      "          ...,\n",
      "          [5, 8, 5,  ..., 7, 7, 1],\n",
      "          [5, 4, 4,  ..., 8, 8, 7],\n",
      "          [8, 1, 0,  ..., 6, 4, 1]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[6, 2, 1,  ..., 6, 8, 2],\n",
      "          [8, 8, 2,  ..., 2, 3, 8],\n",
      "          [8, 6, 2,  ..., 4, 5, 6],\n",
      "          ...,\n",
      "          [6, 7, 4,  ..., 0, 5, 6],\n",
      "          [3, 5, 0,  ..., 3, 5, 5],\n",
      "          [0, 2, 1,  ..., 7, 2, 1]],\n",
      "\n",
      "         [[4, 5, 7,  ..., 0, 6, 6],\n",
      "          [3, 4, 5,  ..., 0, 0, 4],\n",
      "          [0, 8, 6,  ..., 8, 6, 6],\n",
      "          ...,\n",
      "          [5, 7, 3,  ..., 5, 6, 5],\n",
      "          [4, 5, 0,  ..., 0, 2, 2],\n",
      "          [1, 7, 7,  ..., 6, 2, 4]],\n",
      "\n",
      "         [[4, 3, 0,  ..., 5, 8, 8],\n",
      "          [0, 2, 5,  ..., 8, 2, 2],\n",
      "          [6, 7, 7,  ..., 1, 7, 3],\n",
      "          ...,\n",
      "          [8, 6, 1,  ..., 0, 5, 3],\n",
      "          [1, 0, 1,  ..., 8, 5, 2],\n",
      "          [4, 1, 3,  ..., 0, 8, 7]]],\n",
      "\n",
      "\n",
      "        [[[8, 6, 0,  ..., 5, 4, 0],\n",
      "          [1, 3, 2,  ..., 7, 7, 8],\n",
      "          [8, 5, 1,  ..., 0, 5, 4],\n",
      "          ...,\n",
      "          [8, 0, 6,  ..., 8, 2, 8],\n",
      "          [1, 0, 7,  ..., 3, 1, 7],\n",
      "          [2, 5, 8,  ..., 2, 2, 6]],\n",
      "\n",
      "         [[6, 7, 4,  ..., 5, 8, 3],\n",
      "          [0, 6, 5,  ..., 8, 0, 2],\n",
      "          [7, 7, 6,  ..., 7, 5, 3],\n",
      "          ...,\n",
      "          [5, 3, 6,  ..., 5, 3, 4],\n",
      "          [3, 0, 2,  ..., 2, 3, 4],\n",
      "          [3, 8, 2,  ..., 7, 4, 3]],\n",
      "\n",
      "         [[4, 2, 3,  ..., 4, 5, 7],\n",
      "          [3, 5, 6,  ..., 2, 7, 3],\n",
      "          [8, 0, 7,  ..., 7, 5, 5],\n",
      "          ...,\n",
      "          [6, 5, 0,  ..., 8, 8, 6],\n",
      "          [7, 4, 6,  ..., 7, 6, 8],\n",
      "          [8, 4, 7,  ..., 8, 3, 2]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[5, 1, 6,  ..., 4, 1, 6],\n",
      "          [2, 7, 7,  ..., 6, 6, 1],\n",
      "          [0, 8, 0,  ..., 4, 4, 6],\n",
      "          ...,\n",
      "          [6, 8, 4,  ..., 1, 5, 6],\n",
      "          [4, 1, 8,  ..., 7, 7, 3],\n",
      "          [6, 0, 4,  ..., 3, 3, 8]],\n",
      "\n",
      "         [[2, 7, 6,  ..., 3, 7, 2],\n",
      "          [7, 1, 1,  ..., 2, 2, 1],\n",
      "          [2, 3, 1,  ..., 3, 5, 7],\n",
      "          ...,\n",
      "          [8, 6, 7,  ..., 6, 3, 2],\n",
      "          [8, 7, 7,  ..., 4, 5, 1],\n",
      "          [8, 0, 3,  ..., 4, 6, 7]],\n",
      "\n",
      "         [[6, 1, 8,  ..., 2, 5, 8],\n",
      "          [0, 4, 8,  ..., 7, 2, 0],\n",
      "          [8, 5, 0,  ..., 7, 2, 2],\n",
      "          ...,\n",
      "          [3, 8, 2,  ..., 6, 6, 0],\n",
      "          [2, 6, 7,  ..., 4, 4, 4],\n",
      "          [7, 5, 4,  ..., 1, 5, 6]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[2, 3, 5,  ..., 6, 7, 8],\n",
      "          [4, 1, 7,  ..., 8, 3, 8],\n",
      "          [0, 0, 5,  ..., 4, 0, 8],\n",
      "          ...,\n",
      "          [3, 6, 4,  ..., 2, 5, 2],\n",
      "          [1, 0, 3,  ..., 0, 7, 7],\n",
      "          [5, 7, 8,  ..., 7, 4, 4]],\n",
      "\n",
      "         [[2, 5, 5,  ..., 2, 4, 2],\n",
      "          [8, 2, 2,  ..., 1, 5, 5],\n",
      "          [5, 4, 2,  ..., 2, 4, 7],\n",
      "          ...,\n",
      "          [1, 1, 5,  ..., 1, 6, 6],\n",
      "          [8, 1, 4,  ..., 5, 4, 5],\n",
      "          [1, 6, 5,  ..., 2, 2, 6]],\n",
      "\n",
      "         [[8, 4, 2,  ..., 3, 2, 0],\n",
      "          [4, 3, 5,  ..., 7, 4, 0],\n",
      "          [1, 1, 8,  ..., 2, 1, 4],\n",
      "          ...,\n",
      "          [5, 6, 1,  ..., 4, 2, 4],\n",
      "          [6, 1, 2,  ..., 5, 8, 2],\n",
      "          [3, 2, 6,  ..., 8, 7, 1]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0, 8, 6,  ..., 7, 2, 8],\n",
      "          [3, 8, 1,  ..., 7, 3, 4],\n",
      "          [0, 4, 4,  ..., 5, 3, 8],\n",
      "          ...,\n",
      "          [4, 0, 5,  ..., 4, 6, 8],\n",
      "          [5, 7, 6,  ..., 3, 0, 3],\n",
      "          [7, 5, 4,  ..., 4, 4, 3]],\n",
      "\n",
      "         [[1, 5, 5,  ..., 3, 5, 5],\n",
      "          [1, 1, 3,  ..., 0, 7, 3],\n",
      "          [4, 7, 6,  ..., 5, 8, 0],\n",
      "          ...,\n",
      "          [4, 0, 5,  ..., 2, 4, 5],\n",
      "          [6, 7, 2,  ..., 4, 2, 6],\n",
      "          [4, 1, 6,  ..., 7, 8, 3]],\n",
      "\n",
      "         [[5, 3, 6,  ..., 5, 3, 1],\n",
      "          [4, 1, 1,  ..., 5, 1, 7],\n",
      "          [2, 2, 3,  ..., 1, 1, 2],\n",
      "          ...,\n",
      "          [1, 7, 5,  ..., 3, 7, 3],\n",
      "          [6, 1, 2,  ..., 0, 4, 1],\n",
      "          [1, 1, 0,  ..., 0, 4, 3]]],\n",
      "\n",
      "\n",
      "        [[[0, 7, 0,  ..., 0, 7, 3],\n",
      "          [0, 7, 2,  ..., 5, 5, 2],\n",
      "          [4, 0, 7,  ..., 5, 5, 5],\n",
      "          ...,\n",
      "          [7, 1, 4,  ..., 5, 4, 5],\n",
      "          [8, 5, 3,  ..., 4, 7, 4],\n",
      "          [1, 7, 6,  ..., 4, 1, 4]],\n",
      "\n",
      "         [[8, 4, 8,  ..., 6, 0, 8],\n",
      "          [6, 6, 4,  ..., 0, 8, 7],\n",
      "          [0, 7, 7,  ..., 4, 6, 6],\n",
      "          ...,\n",
      "          [2, 4, 2,  ..., 3, 3, 3],\n",
      "          [1, 4, 3,  ..., 7, 0, 4],\n",
      "          [7, 6, 7,  ..., 5, 0, 6]],\n",
      "\n",
      "         [[0, 2, 1,  ..., 2, 2, 2],\n",
      "          [6, 1, 0,  ..., 4, 4, 8],\n",
      "          [0, 3, 7,  ..., 0, 8, 0],\n",
      "          ...,\n",
      "          [8, 0, 1,  ..., 4, 8, 5],\n",
      "          [7, 7, 1,  ..., 2, 5, 7],\n",
      "          [4, 6, 7,  ..., 1, 0, 0]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2, 1, 8,  ..., 4, 1, 7],\n",
      "          [4, 3, 7,  ..., 6, 8, 6],\n",
      "          [6, 1, 5,  ..., 5, 0, 3],\n",
      "          ...,\n",
      "          [5, 5, 1,  ..., 7, 5, 8],\n",
      "          [4, 3, 7,  ..., 4, 6, 3],\n",
      "          [6, 8, 4,  ..., 8, 1, 4]],\n",
      "\n",
      "         [[8, 5, 6,  ..., 4, 6, 7],\n",
      "          [5, 1, 0,  ..., 7, 2, 2],\n",
      "          [7, 8, 4,  ..., 1, 6, 1],\n",
      "          ...,\n",
      "          [1, 2, 8,  ..., 4, 3, 0],\n",
      "          [2, 6, 3,  ..., 8, 0, 6],\n",
      "          [2, 4, 4,  ..., 0, 8, 5]],\n",
      "\n",
      "         [[4, 7, 8,  ..., 3, 0, 0],\n",
      "          [6, 2, 0,  ..., 7, 8, 3],\n",
      "          [8, 6, 2,  ..., 7, 4, 5],\n",
      "          ...,\n",
      "          [0, 5, 5,  ..., 8, 8, 1],\n",
      "          [1, 1, 7,  ..., 6, 3, 1],\n",
      "          [7, 7, 8,  ..., 8, 4, 2]]],\n",
      "\n",
      "\n",
      "        [[[8, 1, 3,  ..., 2, 5, 3],\n",
      "          [8, 0, 2,  ..., 6, 1, 8],\n",
      "          [5, 8, 5,  ..., 1, 6, 5],\n",
      "          ...,\n",
      "          [5, 0, 7,  ..., 6, 7, 2],\n",
      "          [1, 4, 7,  ..., 3, 7, 6],\n",
      "          [7, 6, 3,  ..., 2, 8, 5]],\n",
      "\n",
      "         [[8, 4, 0,  ..., 2, 8, 4],\n",
      "          [0, 3, 7,  ..., 2, 0, 1],\n",
      "          [6, 1, 5,  ..., 3, 4, 5],\n",
      "          ...,\n",
      "          [7, 2, 1,  ..., 7, 1, 4],\n",
      "          [1, 1, 1,  ..., 7, 2, 4],\n",
      "          [3, 7, 5,  ..., 8, 7, 0]],\n",
      "\n",
      "         [[6, 4, 4,  ..., 6, 6, 7],\n",
      "          [3, 8, 8,  ..., 6, 4, 2],\n",
      "          [8, 6, 5,  ..., 0, 2, 3],\n",
      "          ...,\n",
      "          [7, 7, 4,  ..., 7, 8, 5],\n",
      "          [0, 0, 7,  ..., 2, 0, 1],\n",
      "          [8, 6, 5,  ..., 2, 5, 8]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[4, 7, 0,  ..., 3, 5, 2],\n",
      "          [3, 1, 5,  ..., 3, 2, 8],\n",
      "          [5, 4, 3,  ..., 7, 3, 1],\n",
      "          ...,\n",
      "          [4, 5, 4,  ..., 6, 2, 1],\n",
      "          [2, 4, 2,  ..., 0, 3, 2],\n",
      "          [1, 5, 6,  ..., 7, 3, 8]],\n",
      "\n",
      "         [[1, 8, 5,  ..., 5, 7, 3],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [4, 3, 7,  ..., 1, 4, 8],\n",
      "          ...,\n",
      "          [2, 4, 1,  ..., 3, 3, 5],\n",
      "          [7, 2, 1,  ..., 6, 8, 2],\n",
      "          [6, 2, 5,  ..., 5, 2, 3]],\n",
      "\n",
      "         [[0, 2, 3,  ..., 2, 8, 7],\n",
      "          [1, 2, 7,  ..., 1, 6, 0],\n",
      "          [8, 4, 6,  ..., 6, 5, 1],\n",
      "          ...,\n",
      "          [7, 4, 2,  ..., 0, 0, 4],\n",
      "          [0, 3, 4,  ..., 6, 5, 2],\n",
      "          [2, 6, 0,  ..., 0, 3, 4]]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "#a max pool\n",
    "def maxPoolForward(X):\n",
    "    N,C,H,W=X.size()\n",
    "    s=3\n",
    "    Hnew,Wnew=H//s,W//s\n",
    "    \n",
    "    X=X.view(N*C,H,W) #view using same tensor as before\n",
    " \n",
    "    Y=torch.zeros(N*C,Hnew,Wnew)\n",
    "    Yidx=torch.zeros(N*C,Hnew,Wnew,dtype=torch.int)\n",
    "    \n",
    "    for h in range(0,H-s,s):\n",
    "        for w in range(0,W-s,s):\n",
    "            tmp=X[:,h:h+s,w:w+s].clone()\n",
    "            tmp=tmp.view(N*C,-1)\n",
    "            v,idx=torch.max(tmp,dim=1) #(NC,)\n",
    "            Y[:,h//s,w//s]=v\n",
    "            Yidx[:,h//s,w//s]=idx\n",
    "    Y=Y.view(N,C,Hnew,Wnew)\n",
    "    Yidx=Yidx.view(N,C,Hnew,Wnew)\n",
    "    return Y\n",
    "X=torch.rand((32,32,64,64))\n",
    "Y=maxPoolForward(X)\n",
    "# print(Y.size())\n",
    "# A,B=torch.max(X.flatten(),dim=(0,1))\n",
    "# print(A)\n",
    "# print(X.flatten()[B])\n",
    "# print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9473],\n",
      "        [0.9870]])\n"
     ]
    }
   ],
   "source": [
    "X=torch.rand(2,1)\n",
    "Y=\n",
    "Y[0]=11\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0085, 0.1422, 0.0841, 0.0159],\n",
       "        [0.6125, 0.9052, 0.3643, 0.8606],\n",
       "        [0.8837, 0.8688, 0.7011, 0.9851],\n",
       "        [0.6369, 0.2326, 0.5140, 0.4784],\n",
       "        [0.1734, 0.1631, 0.9880, 0.9613],\n",
       "        [0.3081, 0.9198, 0.8727, 0.3004],\n",
       "        [0.3395, 0.7368, 0.8652, 0.4882],\n",
       "        [0.3953, 0.4048, 0.2693, 0.6423],\n",
       "        [0.2239, 0.1508, 0.3040, 0.1762],\n",
       "        [0.1835, 0.6734, 0.5466, 0.7143]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

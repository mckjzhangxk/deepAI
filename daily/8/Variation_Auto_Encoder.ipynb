{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from keras.layers import Activation,Dense,Input,Lambda\n",
    "from keras.losses import mean_squared_error,mse\n",
    "from keras.models import Sequential,Model,save_model,load_model\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.callbacks import LearningRateScheduler,ModelCheckpoint,ReduceLROnPlateau\n",
    "from keras.preprocessing.image import  ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize']=(10,10)\n",
    "plt.rcParams['image.cmap']='viridis'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Step, Prepare Mnist Dataset\n",
    "* different from supervise learning,I only using X\n",
    "* using dense Layer as encoder and decoder,so X is 784 dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data_path='../AI_database/mnist/MNIST_DATA'\n",
    "def imshow(X,Y=None,classes=None):\n",
    "    '''\n",
    "        show Batch of image in grids sqrt(h) x sqrt(w)\n",
    "        X is a numpy array,size (m,h,w,c)\n",
    "        Y is a numpy array,size (m,#classes)\n",
    "    '''\n",
    "    m=X.shape[0]\n",
    "    gridSize=int(m**0.5)\n",
    "    for i in range(0,gridSize):\n",
    "        for j in range(0,gridSize):\n",
    "            _idx=i*gridSize+j\n",
    "            im=X[_idx]\n",
    "            plt.subplot(gridSize,gridSize,_idx+1)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(im)\n",
    "            if Y is not None:\n",
    "                label=classes[np.argmax(Y[_idx])]\n",
    "                plt.title(label)\n",
    "\n",
    "def load_dataset(flaten=False,one_hot=True):\n",
    "    def _make_one_hot(d,C=10):\n",
    "        return (np.arange(C)==d[:,None]).astype(np.int32)\n",
    "\n",
    "    mnist=input_data.read_data_sets(mnist_data_path)\n",
    "    X_train,Y_train=mnist.train.images,mnist.train.labels\n",
    "    X_test,Y_test=mnist.test.images,mnist.test.labels\n",
    "\n",
    "    if flaten==False:\n",
    "        X_train=X_train.reshape((-1,28,28,1))\n",
    "        X_test = X_test.reshape((-1, 28, 28,1))\n",
    "    if one_hot:\n",
    "        Y_train = _make_one_hot(Y_train)\n",
    "        Y_test=_make_one_hot(Y_test)\n",
    "\n",
    "\n",
    "    print('\\n-------------------------------------------------------------------------')\n",
    "    print('load %d train Example,%d Test Example'%(X_train.shape[0],X_test.shape[0]))\n",
    "    print('Train Images  Shape:'+str(X_train.shape))\n",
    "    print('Train Labels  Shape:' + str(Y_train.shape))\n",
    "    print('Test  Images  Shape:'+str(X_test.shape))\n",
    "    print('Test  Labels  Shape:' + str(Y_test.shape))\n",
    "    print('-------------------------------------------------------------------------')\n",
    "    return (X_train,Y_train,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-e9d9f4d93096>:25: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../AI_database/mnist/MNIST_DATA/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../AI_database/mnist/MNIST_DATA/train-labels-idx1-ubyte.gz\n",
      "Extracting ../AI_database/mnist/MNIST_DATA/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../AI_database/mnist/MNIST_DATA/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "load 55000 train Example,10000 Test Example\n",
      "Train Images  Shape:(55000, 784)\n",
      "Train Labels  Shape:(55000,)\n",
      "Test  Images  Shape:(10000, 784)\n",
      "Test  Labels  Shape:(10000,)\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train,X_test,Y_test=load_dataset(flaten=True,one_hot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define show Help function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshaper(X):\n",
    "    m=X.shape[0]\n",
    "    return X.reshape((m,28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a encoder\n",
    "* ###  the struct is X---->H1---->(Uz,logVarz,z) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_encoder(n_x=784,n_h=512,n_z=2):\n",
    "    '''\n",
    "        n_x:dim of Image\n",
    "        n_x:dim of hidden units\n",
    "        n_z:dim of latent variable\n",
    "        return:,a model with outputs=[u_z,logvar_z,z] all have same dims n_z\n",
    "    '''\n",
    "    def sample(args):\n",
    "        '''\n",
    "            args:u,logvar,2 tensor object\n",
    "            sample from N(0,I),then transform it to N(u,exp(logvar))\n",
    "            return:a tensor \n",
    "        '''\n",
    "        u,logvar=args\n",
    "        batch,ndim=tf.shape(u)[0],tf.shape(u)[1]\n",
    "        \n",
    "        z=K.random_normal(shape=[batch,ndim])\n",
    "        return u+K.exp(0.5*logvar)*z\n",
    "    \n",
    "    X_Input=Input(shape=(n_x,),name='encode_input')\n",
    "    X=Dense(n_h,activation='relu',name='encode_hidden',kernel_initializer='he_normal')(X_Input)\n",
    "    \n",
    "    u_z=Dense(n_z,name='encode_mean',kernel_initializer='he_normal')(X)\n",
    "    logvar_z=Dense(n_z,name='encode_log_var',kernel_initializer='he_normal')(X)\n",
    "    Z=Lambda(sample,name='encoder_z')([u_z,logvar_z])\n",
    "    \n",
    "    model=Model(inputs=X_Input,outputs=[u_z,logvar_z,Z],name='encoder')\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encode_input (InputLayer)       (None, 784)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encode_hidden (Dense)           (None, 512)          401920      encode_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "encode_mean (Dense)             (None, 2)            1026        encode_hidden[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "encode_log_var (Dense)          (None, 2)            1026        encode_hidden[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "encoder_z (Lambda)              (None, 2)            0           encode_mean[0][0]                \n",
      "                                                                 encode_log_var[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 403,972\n",
      "Trainable params: 403,972\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder=vae_encoder()\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"304pt\" viewBox=\"0.00 0.00 579.50 304.00\" width=\"580pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 300)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-300 575.5,-300 575.5,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 139999004690920 -->\n",
       "<g class=\"node\" id=\"node1\"><title>139999004690920</title>\n",
       "<polygon fill=\"none\" points=\"135,-249.5 135,-295.5 430,-295.5 430,-249.5 135,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213.5\" y=\"-268.8\">encode_input: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"292,-249.5 292,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"319.5\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"292,-272.5 347,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"319.5\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"347,-249.5 347,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"388.5\" y=\"-280.3\">(None, 784)</text>\n",
       "<polyline fill=\"none\" points=\"347,-272.5 430,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"388.5\" y=\"-257.3\">(None, 784)</text>\n",
       "</g>\n",
       "<!-- 139999004691928 -->\n",
       "<g class=\"node\" id=\"node2\"><title>139999004691928</title>\n",
       "<polygon fill=\"none\" points=\"143.5,-166.5 143.5,-212.5 421.5,-212.5 421.5,-166.5 143.5,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213.5\" y=\"-185.8\">encode_hidden: Dense</text>\n",
       "<polyline fill=\"none\" points=\"283.5,-166.5 283.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"311\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"283.5,-189.5 338.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"311\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"338.5,-166.5 338.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"380\" y=\"-197.3\">(None, 784)</text>\n",
       "<polyline fill=\"none\" points=\"338.5,-189.5 421.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"380\" y=\"-174.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 139999004690920&#45;&gt;139999004691928 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>139999004690920-&gt;139999004691928</title>\n",
       "<path d=\"M282.5,-249.366C282.5,-241.152 282.5,-231.658 282.5,-222.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"286,-222.607 282.5,-212.607 279,-222.607 286,-222.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139999004691536 -->\n",
       "<g class=\"node\" id=\"node3\"><title>139999004691536</title>\n",
       "<polygon fill=\"none\" points=\"0,-83.5 0,-129.5 271,-129.5 271,-83.5 0,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"66.5\" y=\"-102.8\">encode_mean: Dense</text>\n",
       "<polyline fill=\"none\" points=\"133,-83.5 133,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"160.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"133,-106.5 188,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"160.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"188,-83.5 188,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"229.5\" y=\"-114.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"188,-106.5 271,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"229.5\" y=\"-91.3\">(None, 2)</text>\n",
       "</g>\n",
       "<!-- 139999004691928&#45;&gt;139999004691536 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>139999004691928-&gt;139999004691536</title>\n",
       "<path d=\"M242.332,-166.366C224.507,-156.544 203.363,-144.894 184.609,-134.56\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"186.067,-131.368 175.62,-129.607 182.689,-137.498 186.067,-131.368\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139999004692040 -->\n",
       "<g class=\"node\" id=\"node4\"><title>139999004692040</title>\n",
       "<polygon fill=\"none\" points=\"289.5,-83.5 289.5,-129.5 571.5,-129.5 571.5,-83.5 289.5,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"361.5\" y=\"-102.8\">encode_log_var: Dense</text>\n",
       "<polyline fill=\"none\" points=\"433.5,-83.5 433.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"461\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"433.5,-106.5 488.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"461\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"488.5,-83.5 488.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"530\" y=\"-114.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"488.5,-106.5 571.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"530\" y=\"-91.3\">(None, 2)</text>\n",
       "</g>\n",
       "<!-- 139999004691928&#45;&gt;139999004692040 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>139999004691928-&gt;139999004692040</title>\n",
       "<path d=\"M322.942,-166.366C340.97,-156.5 362.369,-144.788 381.314,-134.419\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"383.015,-137.478 390.107,-129.607 379.655,-131.338 383.015,-137.478\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139998995974408 -->\n",
       "<g class=\"node\" id=\"node5\"><title>139998995974408</title>\n",
       "<polygon fill=\"none\" points=\"123.5,-0.5 123.5,-46.5 441.5,-46.5 441.5,-0.5 123.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"186\" y=\"-19.8\">encoder_z: Lambda</text>\n",
       "<polyline fill=\"none\" points=\"248.5,-0.5 248.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"276\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"248.5,-23.5 303.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"276\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"303.5,-0.5 303.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"372.5\" y=\"-31.3\">[(None, 2), (None, 2)]</text>\n",
       "<polyline fill=\"none\" points=\"303.5,-23.5 441.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"372.5\" y=\"-8.3\">(None, 2)</text>\n",
       "</g>\n",
       "<!-- 139999004691536&#45;&gt;139998995974408 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>139999004691536-&gt;139998995974408</title>\n",
       "<path d=\"M175.668,-83.3664C193.493,-73.5444 214.637,-61.894 233.391,-51.5602\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"235.311,-54.4984 242.38,-46.6068 231.933,-48.3675 235.311,-54.4984\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139999004692040&#45;&gt;139998995974408 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>139999004692040-&gt;139998995974408</title>\n",
       "<path d=\"M390.058,-83.3664C372.03,-73.4998 350.631,-61.7881 331.686,-51.4194\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"333.345,-48.3376 322.893,-46.6068 329.985,-54.4781 333.345,-48.3376\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(encoder,show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Decoder\n",
    "* ###  the struct is Z---->H1---->Xhat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_decoder(n_x=784,n_h=512,n_z=2):\n",
    "    '''\n",
    "        n_x:the shape(dims) of reconstruct Image\n",
    "        n_h:hidden Units\n",
    "        n_z:latent dims\n",
    "        return:a model with outputs is reconstruct Image\n",
    "    '''\n",
    "    Z_Input=Input(shape=(n_z,),name='decoder_input')\n",
    "    X=Dense(n_h,activation='relu',name='decoder_hidden',kernel_initializer='he_normal')(Z_Input)\n",
    "    X=Dense(n_x,activation='sigmoid',name='decoder_reconstruct',kernel_initializer='he_normal')(X)\n",
    "    \n",
    "    model=Model(inputs=Z_Input,outputs=X,name='decoder')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "decoder_hidden (Dense)       (None, 512)               1536      \n",
      "_________________________________________________________________\n",
      "decoder_reconstruct (Dense)  (None, 784)               402192    \n",
      "=================================================================\n",
      "Total params: 403,728\n",
      "Trainable params: 403,728\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder=vae_decoder()\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"221pt\" viewBox=\"0.00 0.00 313.00 221.00\" width=\"313pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 217)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-217 309,-217 309,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140015463945720 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140015463945720</title>\n",
       "<polygon fill=\"none\" points=\"10,-166.5 10,-212.5 295,-212.5 295,-166.5 10,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"90.5\" y=\"-185.8\">decoder_input: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"171,-166.5 171,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"198.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"171,-189.5 226,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"198.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"226,-166.5 226,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"260.5\" y=\"-197.3\">(None, 2)</text>\n",
       "<polyline fill=\"none\" points=\"226,-189.5 295,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"260.5\" y=\"-174.3\">(None, 2)</text>\n",
       "</g>\n",
       "<!-- 140020898493160 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140020898493160</title>\n",
       "<polygon fill=\"none\" points=\"11.5,-83.5 11.5,-129.5 293.5,-129.5 293.5,-83.5 11.5,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83.5\" y=\"-102.8\">decoder_hidden: Dense</text>\n",
       "<polyline fill=\"none\" points=\"155.5,-83.5 155.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"183\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"155.5,-106.5 210.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"183\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"210.5,-83.5 210.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"252\" y=\"-114.3\">(None, 2)</text>\n",
       "<polyline fill=\"none\" points=\"210.5,-106.5 293.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"252\" y=\"-91.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 140015463945720&#45;&gt;140020898493160 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140015463945720-&gt;140020898493160</title>\n",
       "<path d=\"M152.5,-166.366C152.5,-158.152 152.5,-148.658 152.5,-139.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"156,-139.607 152.5,-129.607 149,-139.607 156,-139.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140020898774656 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140020898774656</title>\n",
       "<polygon fill=\"none\" points=\"0,-0.5 0,-46.5 305,-46.5 305,-0.5 0,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83.5\" y=\"-19.8\">decoder_reconstruct: Dense</text>\n",
       "<polyline fill=\"none\" points=\"167,-0.5 167,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"167,-23.5 222,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194.5\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"222,-0.5 222,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"263.5\" y=\"-31.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"222,-23.5 305,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"263.5\" y=\"-8.3\">(None, 784)</text>\n",
       "</g>\n",
       "<!-- 140020898493160&#45;&gt;140020898774656 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140020898493160-&gt;140020898774656</title>\n",
       "<path d=\"M152.5,-83.3664C152.5,-75.1516 152.5,-65.6579 152.5,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"156,-56.6068 152.5,-46.6068 149,-56.6069 156,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(decoder,show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine Encoder and Decoder(vae_mlp)\n",
    "<img src='images/vae_loss.png' />\n",
    "<img src='images/vae_kl_loss.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_mlp(encoder,decoder,n_x=784):\n",
    "    '''\n",
    "        encoder: X(784)---->[uz,logvar_z,z]\n",
    "        decoder:Z(2)-------->Xhat(784)\n",
    "        \n",
    "        loss=(X-Xhat)**2+KL{ qz|x |N(0,I)}\n",
    "        notice Pz =N(0,I)\n",
    "    '''\n",
    "    \n",
    "    X=Input(shape=(n_x,),name='MyInput')\n",
    "    uz,logvar_z,z=encoder(X)\n",
    "    Xhat=decoder(z)\n",
    "    \n",
    "    \n",
    "    #work out the loss\n",
    "    Re_loss=K.sum((X-Xhat)**2,axis=-1) #shape (?,)\n",
    "    KL_loss=1+logvar_z-K.square(uz)-K.exp(logvar_z) #shape(?,n_z)\n",
    "    KL_loss=-0.5*K.sum(KL_loss,axis=-1)  #shape(?,)\n",
    "    loss=K.mean(Re_loss+0*KL_loss)  #shape(?)\n",
    "    \n",
    "    model=Model(inputs=X,outputs=Xhat)\n",
    "    model.add_loss(loss)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae=vae_mlp(encoder,decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "MyInput (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              [(None, 2), (None, 2), (N 403972    \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 784)               403728    \n",
      "=================================================================\n",
      "Total params: 807,700\n",
      "Trainable params: 807,700\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"221pt\" viewBox=\"0.00 0.00 364.00 221.00\" width=\"364pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 217)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-217 360,-217 360,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140015463066256 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140015463066256</title>\n",
       "<polygon fill=\"none\" points=\"43,-166.5 43,-212.5 313,-212.5 313,-166.5 43,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"109\" y=\"-185.8\">MyInput: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"175,-166.5 175,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"175,-189.5 230,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"230,-166.5 230,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"271.5\" y=\"-197.3\">(None, 784)</text>\n",
       "<polyline fill=\"none\" points=\"230,-189.5 313,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"271.5\" y=\"-174.3\">(None, 784)</text>\n",
       "</g>\n",
       "<!-- 140015296272368 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140015296272368</title>\n",
       "<polygon fill=\"none\" points=\"-2.84217e-14,-83.5 -2.84217e-14,-129.5 356,-129.5 356,-83.5 -2.84217e-14,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"51.5\" y=\"-102.8\">encoder: Model</text>\n",
       "<polyline fill=\"none\" points=\"103,-83.5 103,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"130.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"103,-106.5 158,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"130.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"158,-83.5 158,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257\" y=\"-114.3\">(None, 784)</text>\n",
       "<polyline fill=\"none\" points=\"158,-106.5 356,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257\" y=\"-91.3\">[(None, 2), (None, 2), (None, 2)]</text>\n",
       "</g>\n",
       "<!-- 140015463066256&#45;&gt;140015296272368 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140015463066256-&gt;140015296272368</title>\n",
       "<path d=\"M178,-166.366C178,-158.152 178,-148.658 178,-139.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"181.5,-139.607 178,-129.607 174.5,-139.607 181.5,-139.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140015463638632 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140015463638632</title>\n",
       "<polygon fill=\"none\" points=\"57.5,-0.5 57.5,-46.5 298.5,-46.5 298.5,-0.5 57.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"109\" y=\"-19.8\">decoder: Model</text>\n",
       "<polyline fill=\"none\" points=\"160.5,-0.5 160.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"188\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"160.5,-23.5 215.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"188\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"215.5,-0.5 215.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257\" y=\"-31.3\">(None, 2)</text>\n",
       "<polyline fill=\"none\" points=\"215.5,-23.5 298.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257\" y=\"-8.3\">(None, 784)</text>\n",
       "</g>\n",
       "<!-- 140015296272368&#45;&gt;140015463638632 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140015296272368-&gt;140015463638632</title>\n",
       "<path d=\"M178,-83.3664C178,-75.1516 178,-65.6579 178,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"181.5,-56.6068 178,-46.6068 174.5,-56.6069 181.5,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(vae,show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path='outputs/vae.h5'\n",
    "def callback():\n",
    "    def myLearnRateScheduler(epoch,lr):\n",
    "        print('ecpch:%d,learn rate %f'%(epoch,lr))\n",
    "        return lr\n",
    "    lr_scheduler=LearningRateScheduler(myLearnRateScheduler)\n",
    "    checkpoint=ModelCheckpoint(model_path,monitor='val_loss',save_best_only=True,verbose=1)\n",
    "    reduceOnpleateau=ReduceLROnPlateau(monitor='val_loss',min_delta=5e-5,factor=0.9,verbose=1,patience=50)\n",
    "    return [lr_scheduler,checkpoint,reduceOnpleateau]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "ecpch:0,learn rate 0.001000\n",
      "55000/55000 [==============================] - 6s 115us/step - loss: 35.8559 - val_loss: 37.3411\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 37.34110, saving model to outputs/vae.h5\n",
      "Epoch 2/50\n",
      "ecpch:1,learn rate 0.001000\n",
      "55000/55000 [==============================] - 5s 99us/step - loss: 35.8565 - val_loss: 37.4887\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 37.34110\n",
      "Epoch 3/50\n",
      "ecpch:2,learn rate 0.001000\n",
      "55000/55000 [==============================] - 6s 101us/step - loss: 35.8222 - val_loss: 37.4341\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 37.34110\n",
      "Epoch 4/50\n",
      "ecpch:3,learn rate 0.001000\n",
      "55000/55000 [==============================] - 6s 103us/step - loss: 35.8506 - val_loss: 37.5229\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 37.34110\n",
      "Epoch 5/50\n",
      "ecpch:4,learn rate 0.001000\n",
      "55000/55000 [==============================] - 6s 104us/step - loss: 35.8092 - val_loss: 37.3337\n",
      "\n",
      "Epoch 00005: val_loss improved from 37.34110 to 37.33372, saving model to outputs/vae.h5\n",
      "Epoch 6/50\n",
      "ecpch:5,learn rate 0.001000\n",
      "55000/55000 [==============================] - 7s 127us/step - loss: 35.8078 - val_loss: 37.5002\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 37.33372\n",
      "Epoch 7/50\n",
      "ecpch:6,learn rate 0.001000\n",
      "55000/55000 [==============================] - 6s 115us/step - loss: 35.7919 - val_loss: 37.4081\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 37.33372\n",
      "Epoch 8/50\n",
      "ecpch:7,learn rate 0.001000\n",
      "55000/55000 [==============================] - 7s 127us/step - loss: 35.7728 - val_loss: 37.2607\n",
      "\n",
      "Epoch 00008: val_loss improved from 37.33372 to 37.26067, saving model to outputs/vae.h5\n",
      "Epoch 9/50\n",
      "ecpch:8,learn rate 0.001000\n",
      "55000/55000 [==============================] - 7s 128us/step - loss: 35.7864 - val_loss: 37.2777\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 37.26067\n",
      "Epoch 10/50\n",
      "ecpch:9,learn rate 0.001000\n",
      "55000/55000 [==============================] - 7s 121us/step - loss: 35.7896 - val_loss: 37.3077\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 37.26067\n",
      "Epoch 11/50\n",
      "ecpch:10,learn rate 0.001000\n",
      "55000/55000 [==============================] - 6s 118us/step - loss: 35.7391 - val_loss: 37.5573\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 37.26067\n",
      "Epoch 12/50\n",
      "ecpch:11,learn rate 0.001000\n",
      "55000/55000 [==============================] - 6s 101us/step - loss: 35.7630 - val_loss: 37.4013\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 37.26067\n",
      "Epoch 13/50\n",
      "ecpch:12,learn rate 0.001000\n",
      "55000/55000 [==============================] - 7s 119us/step - loss: 35.7260 - val_loss: 37.2891\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 37.26067\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "Epoch 14/50\n",
      "ecpch:13,learn rate 0.000900\n",
      "55000/55000 [==============================] - 7s 128us/step - loss: 35.6640 - val_loss: 37.3381\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 37.26067\n",
      "Epoch 15/50\n",
      "ecpch:14,learn rate 0.000900\n",
      "55000/55000 [==============================] - 7s 126us/step - loss: 35.6430 - val_loss: 37.3038\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 37.26067\n",
      "Epoch 16/50\n",
      "ecpch:15,learn rate 0.000900\n",
      "55000/55000 [==============================] - 7s 131us/step - loss: 35.6217 - val_loss: 37.2354\n",
      "\n",
      "Epoch 00016: val_loss improved from 37.26067 to 37.23537, saving model to outputs/vae.h5\n",
      "Epoch 17/50\n",
      "ecpch:16,learn rate 0.000900\n",
      "55000/55000 [==============================] - 7s 126us/step - loss: 35.5929 - val_loss: 37.4157\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 37.23537\n",
      "Epoch 18/50\n",
      "ecpch:17,learn rate 0.000900\n",
      "55000/55000 [==============================] - 7s 125us/step - loss: 35.6179 - val_loss: 37.3354\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 37.23537\n",
      "Epoch 19/50\n",
      "ecpch:18,learn rate 0.000900\n",
      "55000/55000 [==============================] - 7s 129us/step - loss: 35.6026 - val_loss: 37.2783\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 37.23537\n",
      "Epoch 20/50\n",
      "ecpch:19,learn rate 0.000900\n",
      "55000/55000 [==============================] - 7s 125us/step - loss: 35.5841 - val_loss: 37.4042\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 37.23537\n",
      "Epoch 21/50\n",
      "ecpch:20,learn rate 0.000900\n",
      "55000/55000 [==============================] - 7s 129us/step - loss: 35.5740 - val_loss: 37.3529\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 37.23537\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "Epoch 22/50\n",
      "ecpch:21,learn rate 0.000810\n",
      "55000/55000 [==============================] - 7s 121us/step - loss: 35.5015 - val_loss: 37.2298\n",
      "\n",
      "Epoch 00022: val_loss improved from 37.23537 to 37.22979, saving model to outputs/vae.h5\n",
      "Epoch 23/50\n",
      "ecpch:22,learn rate 0.000810\n",
      "55000/55000 [==============================] - 7s 128us/step - loss: 35.4696 - val_loss: 37.2905\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 37.22979\n",
      "Epoch 24/50\n",
      "ecpch:23,learn rate 0.000810\n",
      "55000/55000 [==============================] - 7s 119us/step - loss: 35.4755 - val_loss: 37.3825\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 37.22979\n",
      "Epoch 25/50\n",
      "ecpch:24,learn rate 0.000810\n",
      "55000/55000 [==============================] - 7s 126us/step - loss: 35.4623 - val_loss: 37.1414\n",
      "\n",
      "Epoch 00025: val_loss improved from 37.22979 to 37.14136, saving model to outputs/vae.h5\n",
      "Epoch 26/50\n",
      "ecpch:25,learn rate 0.000810\n",
      "55000/55000 [==============================] - 7s 118us/step - loss: 35.4608 - val_loss: 37.3508\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 37.14136\n",
      "Epoch 27/50\n",
      "ecpch:26,learn rate 0.000810\n",
      "55000/55000 [==============================] - 7s 122us/step - loss: 35.4449 - val_loss: 37.2430\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 37.14136\n",
      "Epoch 28/50\n",
      "ecpch:27,learn rate 0.000810\n",
      "55000/55000 [==============================] - 7s 127us/step - loss: 35.4277 - val_loss: 37.2696\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 37.14136\n",
      "Epoch 29/50\n",
      "ecpch:28,learn rate 0.000810\n",
      "55000/55000 [==============================] - 6s 106us/step - loss: 35.4208 - val_loss: 37.3643\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 37.14136\n",
      "Epoch 30/50\n",
      "ecpch:29,learn rate 0.000810\n",
      "55000/55000 [==============================] - 7s 123us/step - loss: 35.4135 - val_loss: 37.3495\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 37.14136\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
      "Epoch 31/50\n",
      "ecpch:30,learn rate 0.000729\n",
      "55000/55000 [==============================] - 7s 124us/step - loss: 35.3466 - val_loss: 37.1999\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 37.14136\n",
      "Epoch 32/50\n",
      "ecpch:31,learn rate 0.000729\n",
      "55000/55000 [==============================] - 7s 123us/step - loss: 35.3245 - val_loss: 37.2450\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 37.14136\n",
      "Epoch 33/50\n",
      "ecpch:32,learn rate 0.000729\n",
      "55000/55000 [==============================] - 7s 119us/step - loss: 35.3354 - val_loss: 37.2739\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 37.14136\n",
      "Epoch 34/50\n",
      "ecpch:33,learn rate 0.000729\n",
      "55000/55000 [==============================] - 6s 105us/step - loss: 35.3206 - val_loss: 37.1864\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 37.14136\n",
      "Epoch 35/50\n",
      "ecpch:34,learn rate 0.000729\n",
      "55000/55000 [==============================] - 6s 110us/step - loss: 35.3016 - val_loss: 37.2521\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 37.14136\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
      "Epoch 36/50\n",
      "ecpch:35,learn rate 0.000656\n",
      "55000/55000 [==============================] - 6s 104us/step - loss: 35.2612 - val_loss: 37.2488\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 37.14136\n",
      "Epoch 37/50\n",
      "ecpch:36,learn rate 0.000656\n",
      "55000/55000 [==============================] - 6s 102us/step - loss: 35.2372 - val_loss: 37.2006\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 37.14136\n",
      "Epoch 38/50\n",
      "ecpch:37,learn rate 0.000656\n",
      "55000/55000 [==============================] - 5s 99us/step - loss: 35.2045 - val_loss: 37.1766\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 37.14136\n",
      "Epoch 39/50\n",
      "ecpch:38,learn rate 0.000656\n",
      "55000/55000 [==============================] - 5s 99us/step - loss: 35.2196 - val_loss: 37.1385\n",
      "\n",
      "Epoch 00039: val_loss improved from 37.14136 to 37.13846, saving model to outputs/vae.h5\n",
      "Epoch 40/50\n",
      "ecpch:39,learn rate 0.000656\n",
      "55000/55000 [==============================] - 7s 120us/step - loss: 35.2139 - val_loss: 37.2105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00040: val_loss did not improve from 37.13846\n",
      "Epoch 41/50\n",
      "ecpch:40,learn rate 0.000656\n",
      "55000/55000 [==============================] - 6s 102us/step - loss: 35.2129 - val_loss: 37.1947\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 37.13846\n",
      "Epoch 42/50\n",
      "ecpch:41,learn rate 0.000656\n",
      "55000/55000 [==============================] - 5s 95us/step - loss: 35.2120 - val_loss: 37.1920\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 37.13846\n",
      "Epoch 43/50\n",
      "ecpch:42,learn rate 0.000656\n",
      "55000/55000 [==============================] - 5s 98us/step - loss: 35.1922 - val_loss: 37.1770\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 37.13846\n",
      "Epoch 44/50\n",
      "ecpch:43,learn rate 0.000656\n",
      "55000/55000 [==============================] - 7s 120us/step - loss: 35.1858 - val_loss: 37.2018\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 37.13846\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
      "Epoch 45/50\n",
      "ecpch:44,learn rate 0.000590\n",
      "55000/55000 [==============================] - 7s 119us/step - loss: 35.1308 - val_loss: 37.2393\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 37.13846\n",
      "Epoch 46/50\n",
      "ecpch:45,learn rate 0.000590\n",
      "55000/55000 [==============================] - 6s 108us/step - loss: 35.1148 - val_loss: 37.2029\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 37.13846\n",
      "Epoch 47/50\n",
      "ecpch:46,learn rate 0.000590\n",
      "55000/55000 [==============================] - 6s 101us/step - loss: 35.1111 - val_loss: 37.2915\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 37.13846\n",
      "Epoch 48/50\n",
      "ecpch:47,learn rate 0.000590\n",
      "55000/55000 [==============================] - 6s 111us/step - loss: 35.1157 - val_loss: 37.2143\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 37.13846\n",
      "Epoch 49/50\n",
      "ecpch:48,learn rate 0.000590\n",
      "55000/55000 [==============================] - 5s 99us/step - loss: 35.1004 - val_loss: 37.1890\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 37.13846\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
      "Epoch 50/50\n",
      "ecpch:49,learn rate 0.000531\n",
      "55000/55000 [==============================] - 6s 102us/step - loss: 35.0461 - val_loss: 37.1525\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 37.13846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f57e31e79e8>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch=64\n",
    "epoch=50\n",
    "vae.fit(X_train,batch_size=batch,epochs=epoch,validation_data=(X_test,None),callbacks=callback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save or load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_path='outputs/vae_encoder'\n",
    "decoder_path='outputs/vae_decoder'\n",
    "encoder.save(encoder_path)\n",
    "decoder.save(decoder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/saving.py:269: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "encoder=load_model(encoder_path,custom_objects={'tf':tf})\n",
    "decoder=load_model(decoder_path,custom_objects={'tf':tf})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the distribution of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-6bff3d17302c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mplot_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'encoder' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_distribution(encoder,X,Y):\n",
    "    plt.rcParams['figure.figsize']=(15,15)\n",
    "    plt.rcParams['image.cmap']='hsv'\n",
    "    Z=encoder.predict(X,batch_size=512)[0]\n",
    "    plt.scatter(Z[:,0],Z[:,1],c=Y)\n",
    "    plt.colorbar()\n",
    "plot_distribution(encoder,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## view how letent z affect Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(decoder,n=15,dim=28,reshaper=None,channels=1):\n",
    "    '''\n",
    "        using decoder to generate image\n",
    "        n:is num per axis\n",
    "        dim:one image size\n",
    "    '''\n",
    "    plt.rcParams['figure.figsize']=(15,15)\n",
    "    xrange=np.linspace(-4,4,n)\n",
    "    yrange=np.linspace(4,-4,n)\n",
    "    zx,zy=np.meshgrid(xrange,yrange)\n",
    "\n",
    "    z=np.stack([zx.ravel(),zy.ravel()],axis=1) #shape[10000,2]\n",
    "    I=reshaper(decoder.predict(z))\n",
    "    F=np.zeros((n*dim,n*dim,channels),dtype=np.float32)\n",
    "    F=np.squeeze(F)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            F[i*dim:i*dim+dim,j*dim:j*dim+dim]=I[i*n+j]\n",
    "    xlabels=np.round(xrange,2)\n",
    "    ylabels=np.round(yrange,2)\n",
    "    xloc=np.arange(dim//2,dim*n+dim//2,dim)\n",
    "    yloc=xloc.copy()\n",
    "    plt.xticks(xloc,xlabels,size='large',rotation=45)\n",
    "    plt.yticks(yloc,ylabels,size='large',rotation=45)\n",
    "    plt.xlabel('z1')\n",
    "    plt.ylabel('z2')\n",
    "    plt.imshow(F)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(decoder,n=15,dim=28,reshaper=reshaper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Try Cifar10 set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cifar.CIFAR10Utils import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------------------------------\n",
      "load 50000 train Example,10000 Test Example\n",
      "Train Images  Shape:(50000, 3072)\n",
      "Train Labels  Shape:(50000,)\n",
      "Test  Images  Shape:(10000, 3072)\n",
      "Test  Labels  Shape:(10000,)\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train,X_test,Y_test,_=load_dataset(flaten=True,one_hot=False,filename='../AI_database/cifar/CIFAR10_DATA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"304pt\" viewBox=\"0.00 0.00 579.50 304.00\" width=\"580pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 300)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-300 575.5,-300 575.5,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140324571611712 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140324571611712</title>\n",
       "<polygon fill=\"none\" points=\"132,-249.5 132,-295.5 433,-295.5 433,-249.5 132,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"210.5\" y=\"-268.8\">encode_input: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"289,-249.5 289,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"316.5\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"289,-272.5 344,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"316.5\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"344,-249.5 344,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"388.5\" y=\"-280.3\">(None, 3072)</text>\n",
       "<polyline fill=\"none\" points=\"344,-272.5 433,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"388.5\" y=\"-257.3\">(None, 3072)</text>\n",
       "</g>\n",
       "<!-- 140324571613336 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140324571613336</title>\n",
       "<polygon fill=\"none\" points=\"140.5,-166.5 140.5,-212.5 424.5,-212.5 424.5,-166.5 140.5,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"210.5\" y=\"-185.8\">encode_hidden: Dense</text>\n",
       "<polyline fill=\"none\" points=\"280.5,-166.5 280.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"308\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"280.5,-189.5 335.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"308\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"335.5,-166.5 335.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"380\" y=\"-197.3\">(None, 3072)</text>\n",
       "<polyline fill=\"none\" points=\"335.5,-189.5 424.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"380\" y=\"-174.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 140324571611712&#45;&gt;140324571613336 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140324571611712-&gt;140324571613336</title>\n",
       "<path d=\"M282.5,-249.366C282.5,-241.152 282.5,-231.658 282.5,-222.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"286,-222.607 282.5,-212.607 279,-222.607 286,-222.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140328018465288 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140328018465288</title>\n",
       "<polygon fill=\"none\" points=\"0,-83.5 0,-129.5 271,-129.5 271,-83.5 0,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"66.5\" y=\"-102.8\">encode_mean: Dense</text>\n",
       "<polyline fill=\"none\" points=\"133,-83.5 133,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"160.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"133,-106.5 188,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"160.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"188,-83.5 188,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"229.5\" y=\"-114.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"188,-106.5 271,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"229.5\" y=\"-91.3\">(None, 2)</text>\n",
       "</g>\n",
       "<!-- 140324571613336&#45;&gt;140328018465288 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140324571613336-&gt;140328018465288</title>\n",
       "<path d=\"M242.332,-166.366C224.507,-156.544 203.363,-144.894 184.609,-134.56\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"186.067,-131.368 175.62,-129.607 182.689,-137.498 186.067,-131.368\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140328018465904 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140328018465904</title>\n",
       "<polygon fill=\"none\" points=\"289.5,-83.5 289.5,-129.5 571.5,-129.5 571.5,-83.5 289.5,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"361.5\" y=\"-102.8\">encode_log_var: Dense</text>\n",
       "<polyline fill=\"none\" points=\"433.5,-83.5 433.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"461\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"433.5,-106.5 488.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"461\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"488.5,-83.5 488.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"530\" y=\"-114.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"488.5,-106.5 571.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"530\" y=\"-91.3\">(None, 2)</text>\n",
       "</g>\n",
       "<!-- 140324571613336&#45;&gt;140328018465904 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140324571613336-&gt;140328018465904</title>\n",
       "<path d=\"M322.942,-166.366C340.97,-156.5 362.369,-144.788 381.314,-134.419\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"383.015,-137.478 390.107,-129.607 379.655,-131.338 383.015,-137.478\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140323379129816 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140323379129816</title>\n",
       "<polygon fill=\"none\" points=\"123.5,-0.5 123.5,-46.5 441.5,-46.5 441.5,-0.5 123.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"186\" y=\"-19.8\">encoder_z: Lambda</text>\n",
       "<polyline fill=\"none\" points=\"248.5,-0.5 248.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"276\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"248.5,-23.5 303.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"276\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"303.5,-0.5 303.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"372.5\" y=\"-31.3\">[(None, 2), (None, 2)]</text>\n",
       "<polyline fill=\"none\" points=\"303.5,-23.5 441.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"372.5\" y=\"-8.3\">(None, 2)</text>\n",
       "</g>\n",
       "<!-- 140328018465288&#45;&gt;140323379129816 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140328018465288-&gt;140323379129816</title>\n",
       "<path d=\"M175.668,-83.3664C193.493,-73.5444 214.637,-61.894 233.391,-51.5602\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"235.311,-54.4984 242.38,-46.6068 231.933,-48.3675 235.311,-54.4984\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140328018465904&#45;&gt;140323379129816 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140328018465904-&gt;140323379129816</title>\n",
       "<path d=\"M390.058,-83.3664C372.03,-73.4998 350.631,-61.7881 331.686,-51.4194\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"333.345,-48.3376 322.893,-46.6068 329.985,-54.4781 333.345,-48.3376\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_cifar=vae_encoder(n_x=3072,n_h=512,n_z=2)\n",
    "SVG(model_to_dot(encoder_cifar,show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"221pt\" viewBox=\"0.00 0.00 319.00 221.00\" width=\"319pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 217)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-217 315,-217 315,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140322467542128 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140322467542128</title>\n",
       "<polygon fill=\"none\" points=\"13,-166.5 13,-212.5 298,-212.5 298,-166.5 13,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"93.5\" y=\"-185.8\">decoder_input: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"174,-166.5 174,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"201.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"174,-189.5 229,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"201.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"229,-166.5 229,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"263.5\" y=\"-197.3\">(None, 2)</text>\n",
       "<polyline fill=\"none\" points=\"229,-189.5 298,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"263.5\" y=\"-174.3\">(None, 2)</text>\n",
       "</g>\n",
       "<!-- 140328024442080 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140328024442080</title>\n",
       "<polygon fill=\"none\" points=\"14.5,-83.5 14.5,-129.5 296.5,-129.5 296.5,-83.5 14.5,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-102.8\">decoder_hidden: Dense</text>\n",
       "<polyline fill=\"none\" points=\"158.5,-83.5 158.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"186\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"158.5,-106.5 213.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"186\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"213.5,-83.5 213.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"255\" y=\"-114.3\">(None, 2)</text>\n",
       "<polyline fill=\"none\" points=\"213.5,-106.5 296.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"255\" y=\"-91.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 140322467542128&#45;&gt;140328024442080 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140322467542128-&gt;140328024442080</title>\n",
       "<path d=\"M155.5,-166.366C155.5,-158.152 155.5,-148.658 155.5,-139.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"159,-139.607 155.5,-129.607 152,-139.607 159,-139.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140322466822688 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140322466822688</title>\n",
       "<polygon fill=\"none\" points=\"0,-0.5 0,-46.5 311,-46.5 311,-0.5 0,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83.5\" y=\"-19.8\">decoder_reconstruct: Dense</text>\n",
       "<polyline fill=\"none\" points=\"167,-0.5 167,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"167,-23.5 222,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194.5\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"222,-0.5 222,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"266.5\" y=\"-31.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"222,-23.5 311,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"266.5\" y=\"-8.3\">(None, 3072)</text>\n",
       "</g>\n",
       "<!-- 140328024442080&#45;&gt;140322466822688 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140328024442080-&gt;140322466822688</title>\n",
       "<path d=\"M155.5,-83.3664C155.5,-75.1516 155.5,-65.6579 155.5,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"159,-56.6068 155.5,-46.6068 152,-56.6069 159,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_cifar=vae_decoder(n_x=3072,n_h=512,n_z=2)\n",
    "SVG(model_to_dot(decoder_cifar,show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"221pt\" viewBox=\"0.00 0.00 364.00 221.00\" width=\"364pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 217)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-217 360,-217 360,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140324571613504 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140324571613504</title>\n",
       "<polygon fill=\"none\" points=\"40,-166.5 40,-212.5 316,-212.5 316,-166.5 40,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"106\" y=\"-185.8\">MyInput: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"172,-166.5 172,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"199.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"172,-189.5 227,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"199.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"227,-166.5 227,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"271.5\" y=\"-197.3\">(None, 3072)</text>\n",
       "<polyline fill=\"none\" points=\"227,-189.5 316,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"271.5\" y=\"-174.3\">(None, 3072)</text>\n",
       "</g>\n",
       "<!-- 140324622559216 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140324622559216</title>\n",
       "<polygon fill=\"none\" points=\"-2.84217e-14,-83.5 -2.84217e-14,-129.5 356,-129.5 356,-83.5 -2.84217e-14,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"51.5\" y=\"-102.8\">encoder: Model</text>\n",
       "<polyline fill=\"none\" points=\"103,-83.5 103,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"130.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"103,-106.5 158,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"130.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"158,-83.5 158,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257\" y=\"-114.3\">(None, 3072)</text>\n",
       "<polyline fill=\"none\" points=\"158,-106.5 356,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257\" y=\"-91.3\">[(None, 2), (None, 2), (None, 2)]</text>\n",
       "</g>\n",
       "<!-- 140324571613504&#45;&gt;140324622559216 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140324571613504-&gt;140324622559216</title>\n",
       "<path d=\"M178,-166.366C178,-158.152 178,-148.658 178,-139.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"181.5,-139.607 178,-129.607 174.5,-139.607 181.5,-139.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140328024443368 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140328024443368</title>\n",
       "<polygon fill=\"none\" points=\"54.5,-0.5 54.5,-46.5 301.5,-46.5 301.5,-0.5 54.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"106\" y=\"-19.8\">decoder: Model</text>\n",
       "<polyline fill=\"none\" points=\"157.5,-0.5 157.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"185\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"157.5,-23.5 212.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"185\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"212.5,-0.5 212.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257\" y=\"-31.3\">(None, 2)</text>\n",
       "<polyline fill=\"none\" points=\"212.5,-23.5 301.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257\" y=\"-8.3\">(None, 3072)</text>\n",
       "</g>\n",
       "<!-- 140324622559216&#45;&gt;140328024443368 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140324622559216-&gt;140328024443368</title>\n",
       "<path d=\"M178,-83.3664C178,-75.1516 178,-65.6579 178,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"181.5,-56.6068 178,-46.6068 174.5,-56.6069 181.5,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_cifar=vae_mlp(encoder_cifar,decoder_cifar,n_x=3072)\n",
    "SVG(model_to_dot(vae_cifar,show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_cifar.compile(optimizer=Adam(4e-4))\n",
    "gen=ImageDataGenerator(\n",
    "    width_shift_range=0,\n",
    "    height_shift_range=0,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=[0.5,1.0],  #<1 mean zoom in,>1 zoom out  \n",
    "    rescale=1.0   ,  #mul image by rescale\n",
    "#     zca_whitening=True,\n",
    "#     zca_epsilon=0.1\n",
    ").flow(X_train.reshape(-1,32,32,3),None)\n",
    "def myGen(gen):\n",
    "    while True:\n",
    "        x=next(gen)\n",
    "        x=x.reshape(-1,3*32*32)\n",
    "        yield (x,None)\n",
    "generator=myGen(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64 samples, validate on 10000 samples\n",
      "Epoch 1/5000\n",
      "ecpch:0,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 77.7312 - val_loss: 179.7857\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 179.78574, saving model to outputs/vae.h5\n",
      "Epoch 2/5000\n",
      "ecpch:1,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 72.0980 - val_loss: 180.9243\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 179.78574\n",
      "Epoch 3/5000\n",
      "ecpch:2,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 78.1041 - val_loss: 181.0259\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 179.78574\n",
      "Epoch 4/5000\n",
      "ecpch:3,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 77.7417 - val_loss: 180.2452\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 179.78574\n",
      "Epoch 5/5000\n",
      "ecpch:4,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 71.6789 - val_loss: 180.4312\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 179.78574\n",
      "Epoch 6/5000\n",
      "ecpch:5,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 74.5463 - val_loss: 180.3513\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 179.78574\n",
      "Epoch 7/5000\n",
      "ecpch:6,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 75.9709 - val_loss: 179.5656\n",
      "\n",
      "Epoch 00007: val_loss improved from 179.78574 to 179.56564, saving model to outputs/vae.h5\n",
      "Epoch 8/5000\n",
      "ecpch:7,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 72.7217 - val_loss: 179.8100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 179.56564\n",
      "Epoch 9/5000\n",
      "ecpch:8,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 72.2007 - val_loss: 181.5666\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 179.56564\n",
      "Epoch 10/5000\n",
      "ecpch:9,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 74.6305 - val_loss: 181.4030\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 179.56564\n",
      "Epoch 11/5000\n",
      "ecpch:10,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 72.5907 - val_loss: 179.9983\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 179.56564\n",
      "Epoch 12/5000\n",
      "ecpch:11,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 71.3390 - val_loss: 179.7128\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 179.56564\n",
      "Epoch 13/5000\n",
      "ecpch:12,learn rate 0.000400\n",
      "64/64 [==============================] - 0s 8ms/step - loss: 73.7105 - val_loss: 179.4820\n",
      "\n",
      "Epoch 00013: val_loss improved from 179.56564 to 179.48197, saving model to outputs/vae.h5\n",
      "Epoch 14/5000\n",
      "ecpch:13,learn rate 0.000400\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 71.9420 - val_loss: 180.4024\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 179.48197\n",
      "Epoch 15/5000\n",
      "ecpch:14,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 70.9879 - val_loss: 181.4049\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 179.48197\n",
      "Epoch 16/5000\n",
      "ecpch:15,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 72.8704 - val_loss: 180.2680\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 179.48197\n",
      "Epoch 17/5000\n",
      "ecpch:16,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 71.0640 - val_loss: 179.4961\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 179.48197\n",
      "Epoch 18/5000\n",
      "ecpch:17,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 71.1017 - val_loss: 179.7470\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 179.48197\n",
      "Epoch 19/5000\n",
      "ecpch:18,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 71.9916 - val_loss: 180.2136\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 179.48197\n",
      "Epoch 20/5000\n",
      "ecpch:19,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 70.7475 - val_loss: 180.7391\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 179.48197\n",
      "Epoch 21/5000\n",
      "ecpch:20,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 71.0296 - val_loss: 180.5148\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 179.48197\n",
      "Epoch 22/5000\n",
      "ecpch:21,learn rate 0.000400\n",
      "64/64 [==============================] - 0s 8ms/step - loss: 71.5357 - val_loss: 180.0691\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 179.48197\n",
      "Epoch 23/5000\n",
      "ecpch:22,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 70.3684 - val_loss: 180.3361\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 179.48197\n",
      "Epoch 24/5000\n",
      "ecpch:23,learn rate 0.000400\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 71.2024 - val_loss: 180.3891\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 179.48197\n",
      "Epoch 25/5000\n",
      "ecpch:24,learn rate 0.000400\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 71.0336 - val_loss: 180.2105\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 179.48197\n",
      "Epoch 26/5000\n",
      "ecpch:25,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 70.3038 - val_loss: 180.5470\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 179.48197\n",
      "Epoch 27/5000\n",
      "ecpch:26,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 71.0134 - val_loss: 180.6778\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 179.48197\n",
      "Epoch 28/5000\n",
      "ecpch:27,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 70.3885 - val_loss: 180.3827\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 179.48197\n",
      "Epoch 29/5000\n",
      "ecpch:28,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 70.4290 - val_loss: 180.0362\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 179.48197\n",
      "Epoch 30/5000\n",
      "ecpch:29,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 70.6354 - val_loss: 180.0686\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 179.48197\n",
      "Epoch 31/5000\n",
      "ecpch:30,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 70.1309 - val_loss: 180.7411\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 179.48197\n",
      "Epoch 32/5000\n",
      "ecpch:31,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 70.4970 - val_loss: 180.5274\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 179.48197\n",
      "Epoch 33/5000\n",
      "ecpch:32,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 70.1981 - val_loss: 179.8884\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 179.48197\n",
      "Epoch 34/5000\n",
      "ecpch:33,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 70.1848 - val_loss: 179.8463\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 179.48197\n",
      "Epoch 35/5000\n",
      "ecpch:34,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 70.3138 - val_loss: 180.2462\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 179.48197\n",
      "Epoch 36/5000\n",
      "ecpch:35,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.9891 - val_loss: 180.4108\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 179.48197\n",
      "Epoch 37/5000\n",
      "ecpch:36,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 70.2344 - val_loss: 179.9955\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 179.48197\n",
      "Epoch 38/5000\n",
      "ecpch:37,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 70.0033 - val_loss: 179.9181\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 179.48197\n",
      "Epoch 39/5000\n",
      "ecpch:38,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 70.0559 - val_loss: 180.0611\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 179.48197\n",
      "Epoch 40/5000\n",
      "ecpch:39,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 70.0134 - val_loss: 180.1218\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 179.48197\n",
      "Epoch 41/5000\n",
      "ecpch:40,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 69.9373 - val_loss: 180.2214\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 179.48197\n",
      "Epoch 42/5000\n",
      "ecpch:41,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 70.0090 - val_loss: 180.2272\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 179.48197\n",
      "Epoch 43/5000\n",
      "ecpch:42,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.8501 - val_loss: 180.0554\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 179.48197\n",
      "Epoch 44/5000\n",
      "ecpch:43,learn rate 0.000400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 9ms/step - loss: 69.9565 - val_loss: 180.0837\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 179.48197\n",
      "Epoch 45/5000\n",
      "ecpch:44,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.8192 - val_loss: 180.4677\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 179.48197\n",
      "Epoch 46/5000\n",
      "ecpch:45,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.8974 - val_loss: 180.3681\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 179.48197\n",
      "Epoch 47/5000\n",
      "ecpch:46,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.7727 - val_loss: 180.0648\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 179.48197\n",
      "Epoch 48/5000\n",
      "ecpch:47,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.8483 - val_loss: 180.2307\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 179.48197\n",
      "Epoch 49/5000\n",
      "ecpch:48,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.7333 - val_loss: 180.5492\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 179.48197\n",
      "Epoch 50/5000\n",
      "ecpch:49,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.7924 - val_loss: 180.2955\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 179.48197\n",
      "Epoch 51/5000\n",
      "ecpch:50,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.7205 - val_loss: 180.2267\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 179.48197\n",
      "Epoch 52/5000\n",
      "ecpch:51,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.7206 - val_loss: 180.3914\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 179.48197\n",
      "Epoch 53/5000\n",
      "ecpch:52,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.6877 - val_loss: 180.4175\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 179.48197\n",
      "Epoch 54/5000\n",
      "ecpch:53,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.6940 - val_loss: 180.4415\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 179.48197\n",
      "Epoch 55/5000\n",
      "ecpch:54,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.6414 - val_loss: 180.4146\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 179.48197\n",
      "Epoch 56/5000\n",
      "ecpch:55,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.6610 - val_loss: 180.3396\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 179.48197\n",
      "Epoch 57/5000\n",
      "ecpch:56,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.6087 - val_loss: 180.5781\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 179.48197\n",
      "Epoch 58/5000\n",
      "ecpch:57,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.6113 - val_loss: 180.5686\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 179.48197\n",
      "Epoch 59/5000\n",
      "ecpch:58,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 69.5642 - val_loss: 180.4168\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 179.48197\n",
      "Epoch 60/5000\n",
      "ecpch:59,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 69.5830 - val_loss: 180.5859\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 179.48197\n",
      "Epoch 61/5000\n",
      "ecpch:60,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.5255 - val_loss: 180.6626\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 179.48197\n",
      "Epoch 62/5000\n",
      "ecpch:61,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.5325 - val_loss: 180.5704\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 179.48197\n",
      "Epoch 63/5000\n",
      "ecpch:62,learn rate 0.000400\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.4976 - val_loss: 180.6745\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.00035999999090563506.\n",
      "Epoch 64/5000\n",
      "ecpch:63,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.5082 - val_loss: 180.6401\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 179.48197\n",
      "Epoch 65/5000\n",
      "ecpch:64,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.4697 - val_loss: 180.7523\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 179.48197\n",
      "Epoch 66/5000\n",
      "ecpch:65,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.4606 - val_loss: 180.7427\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 179.48197\n",
      "Epoch 67/5000\n",
      "ecpch:66,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 69.4384 - val_loss: 180.6316\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 179.48197\n",
      "Epoch 68/5000\n",
      "ecpch:67,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 69.4341 - val_loss: 180.7950\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 179.48197\n",
      "Epoch 69/5000\n",
      "ecpch:68,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 69.4057 - val_loss: 180.7900\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 179.48197\n",
      "Epoch 70/5000\n",
      "ecpch:69,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 69.3869 - val_loss: 180.7155\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 179.48197\n",
      "Epoch 71/5000\n",
      "ecpch:70,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.3775 - val_loss: 180.8407\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 179.48197\n",
      "Epoch 72/5000\n",
      "ecpch:71,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.3597 - val_loss: 180.7724\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 179.48197\n",
      "Epoch 73/5000\n",
      "ecpch:72,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 69.3542 - val_loss: 180.8720\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 179.48197\n",
      "Epoch 74/5000\n",
      "ecpch:73,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.3271 - val_loss: 180.7958\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 179.48197\n",
      "Epoch 75/5000\n",
      "ecpch:74,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 69.3121 - val_loss: 180.9101\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 179.48197\n",
      "Epoch 76/5000\n",
      "ecpch:75,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.2952 - val_loss: 180.8634\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 179.48197\n",
      "Epoch 77/5000\n",
      "ecpch:76,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.2784 - val_loss: 180.9222\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 179.48197\n",
      "Epoch 78/5000\n",
      "ecpch:77,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.2688 - val_loss: 180.8671\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 179.48197\n",
      "Epoch 79/5000\n",
      "ecpch:78,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.2559 - val_loss: 181.0286\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 179.48197\n",
      "Epoch 80/5000\n",
      "ecpch:79,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.2461 - val_loss: 180.8438\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 179.48197\n",
      "Epoch 81/5000\n",
      "ecpch:80,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.2373 - val_loss: 181.0679\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 179.48197\n",
      "Epoch 82/5000\n",
      "ecpch:81,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.2158 - val_loss: 180.9239\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 179.48197\n",
      "Epoch 83/5000\n",
      "ecpch:82,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.2034 - val_loss: 181.0743\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 179.48197\n",
      "Epoch 84/5000\n",
      "ecpch:83,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 69.1800 - val_loss: 180.9459\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 179.48197\n",
      "Epoch 85/5000\n",
      "ecpch:84,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.1695 - val_loss: 181.1859\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 179.48197\n",
      "Epoch 86/5000\n",
      "ecpch:85,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.1650 - val_loss: 180.9604\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 179.48197\n",
      "Epoch 87/5000\n",
      "ecpch:86,learn rate 0.000360\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 69.1416 - val_loss: 181.1668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00087: val_loss did not improve from 179.48197\n",
      "Epoch 88/5000\n",
      "ecpch:87,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 69.1238 - val_loss: 181.0040\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 179.48197\n",
      "Epoch 89/5000\n",
      "ecpch:88,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 69.1352 - val_loss: 181.2511\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 179.48197\n",
      "Epoch 90/5000\n",
      "ecpch:89,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 69.1227 - val_loss: 180.9687\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 179.48197\n",
      "Epoch 91/5000\n",
      "ecpch:90,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.1096 - val_loss: 181.2639\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 179.48197\n",
      "Epoch 92/5000\n",
      "ecpch:91,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.0694 - val_loss: 181.0810\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 179.48197\n",
      "Epoch 93/5000\n",
      "ecpch:92,learn rate 0.000360\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 69.0391 - val_loss: 181.2089\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 179.48197\n",
      "Epoch 94/5000\n",
      "ecpch:93,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.0148 - val_loss: 181.2285\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 179.48197\n",
      "Epoch 95/5000\n",
      "ecpch:94,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.9954 - val_loss: 181.1589\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 179.48197\n",
      "Epoch 96/5000\n",
      "ecpch:95,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.9929 - val_loss: 181.4144\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 179.48197\n",
      "Epoch 97/5000\n",
      "ecpch:96,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.0027 - val_loss: 181.0728\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 179.48197\n",
      "Epoch 98/5000\n",
      "ecpch:97,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.0484 - val_loss: 181.5208\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 179.48197\n",
      "Epoch 99/5000\n",
      "ecpch:98,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 69.0264 - val_loss: 181.2112\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 179.48197\n",
      "Epoch 100/5000\n",
      "ecpch:99,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.9818 - val_loss: 181.4651\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 179.48197\n",
      "Epoch 101/5000\n",
      "ecpch:100,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.9281 - val_loss: 181.2559\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 179.48197\n",
      "Epoch 102/5000\n",
      "ecpch:101,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 68.9114 - val_loss: 181.5116\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 179.48197\n",
      "Epoch 103/5000\n",
      "ecpch:102,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.9014 - val_loss: 181.2342\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 179.48197\n",
      "Epoch 104/5000\n",
      "ecpch:103,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 68.9213 - val_loss: 181.5995\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 179.48197\n",
      "Epoch 105/5000\n",
      "ecpch:104,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.9203 - val_loss: 181.2249\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 179.48197\n",
      "Epoch 106/5000\n",
      "ecpch:105,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.9059 - val_loss: 181.6063\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 179.48197\n",
      "Epoch 107/5000\n",
      "ecpch:106,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.8546 - val_loss: 181.2950\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 179.48197\n",
      "Epoch 108/5000\n",
      "ecpch:107,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.8300 - val_loss: 181.5894\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 179.48197\n",
      "Epoch 109/5000\n",
      "ecpch:108,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.7876 - val_loss: 181.4069\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 179.48197\n",
      "Epoch 110/5000\n",
      "ecpch:109,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.7673 - val_loss: 181.6026\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 179.48197\n",
      "Epoch 111/5000\n",
      "ecpch:110,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.7438 - val_loss: 181.4695\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 179.48197\n",
      "Epoch 112/5000\n",
      "ecpch:111,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.7353 - val_loss: 181.6845\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 179.48197\n",
      "Epoch 113/5000\n",
      "ecpch:112,learn rate 0.000360\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.7310 - val_loss: 181.4470\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 0.00032400000491179527.\n",
      "Epoch 114/5000\n",
      "ecpch:113,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.7743 - val_loss: 181.8551\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 179.48197\n",
      "Epoch 115/5000\n",
      "ecpch:114,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.7705 - val_loss: 181.4782\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 179.48197\n",
      "Epoch 116/5000\n",
      "ecpch:115,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.7138 - val_loss: 181.7564\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 179.48197\n",
      "Epoch 117/5000\n",
      "ecpch:116,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 68.6466 - val_loss: 181.6631\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 179.48197\n",
      "Epoch 118/5000\n",
      "ecpch:117,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.6214 - val_loss: 181.6759\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 179.48197\n",
      "Epoch 119/5000\n",
      "ecpch:118,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.6112 - val_loss: 181.7689\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 179.48197\n",
      "Epoch 120/5000\n",
      "ecpch:119,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.6030 - val_loss: 181.5927\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 179.48197\n",
      "Epoch 121/5000\n",
      "ecpch:120,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.6189 - val_loss: 181.8927\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 179.48197\n",
      "Epoch 122/5000\n",
      "ecpch:121,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 68.6168 - val_loss: 181.5583\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 179.48197\n",
      "Epoch 123/5000\n",
      "ecpch:122,learn rate 0.000324\n",
      "64/64 [==============================] - 0s 8ms/step - loss: 68.6218 - val_loss: 181.9407\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 179.48197\n",
      "Epoch 124/5000\n",
      "ecpch:123,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.5954 - val_loss: 181.6626\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 179.48197\n",
      "Epoch 125/5000\n",
      "ecpch:124,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.5777 - val_loss: 181.9316\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 179.48197\n",
      "Epoch 126/5000\n",
      "ecpch:125,learn rate 0.000324\n",
      "64/64 [==============================] - 0s 8ms/step - loss: 68.5382 - val_loss: 181.7070\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 179.48197\n",
      "Epoch 127/5000\n",
      "ecpch:126,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.5207 - val_loss: 181.9429\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 179.48197\n",
      "Epoch 128/5000\n",
      "ecpch:127,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.4835 - val_loss: 181.7378\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 179.48197\n",
      "Epoch 129/5000\n",
      "ecpch:128,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.4784 - val_loss: 182.0140\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 179.48197\n",
      "Epoch 130/5000\n",
      "ecpch:129,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.4626 - val_loss: 181.7923\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 179.48197\n",
      "Epoch 131/5000\n",
      "ecpch:130,learn rate 0.000324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 9ms/step - loss: 68.4382 - val_loss: 182.0260\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 179.48197\n",
      "Epoch 132/5000\n",
      "ecpch:131,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.4122 - val_loss: 181.8606\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 179.48197\n",
      "Epoch 133/5000\n",
      "ecpch:132,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.4088 - val_loss: 182.0904\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 179.48197\n",
      "Epoch 134/5000\n",
      "ecpch:133,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.3994 - val_loss: 181.8002\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 179.48197\n",
      "Epoch 135/5000\n",
      "ecpch:134,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.4623 - val_loss: 182.2901\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 179.48197\n",
      "Epoch 136/5000\n",
      "ecpch:135,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.4909 - val_loss: 181.7555\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 179.48197\n",
      "Epoch 137/5000\n",
      "ecpch:136,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.4749 - val_loss: 182.2169\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 179.48197\n",
      "Epoch 138/5000\n",
      "ecpch:137,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 68.3762 - val_loss: 181.9263\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 179.48197\n",
      "Epoch 139/5000\n",
      "ecpch:138,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 68.3320 - val_loss: 182.1006\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 179.48197\n",
      "Epoch 140/5000\n",
      "ecpch:139,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.2939 - val_loss: 182.0388\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 179.48197\n",
      "Epoch 141/5000\n",
      "ecpch:140,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.2745 - val_loss: 182.0504\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 179.48197\n",
      "Epoch 142/5000\n",
      "ecpch:141,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.2429 - val_loss: 182.1126\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 179.48197\n",
      "Epoch 143/5000\n",
      "ecpch:142,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 68.2210 - val_loss: 182.1114\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 179.48197\n",
      "Epoch 144/5000\n",
      "ecpch:143,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.2026 - val_loss: 182.1880\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 179.48197\n",
      "Epoch 145/5000\n",
      "ecpch:144,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.1949 - val_loss: 182.1391\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 179.48197\n",
      "Epoch 146/5000\n",
      "ecpch:145,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.2118 - val_loss: 182.3873\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 179.48197\n",
      "Epoch 147/5000\n",
      "ecpch:146,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.2437 - val_loss: 181.9985\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 179.48197\n",
      "Epoch 148/5000\n",
      "ecpch:147,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.3101 - val_loss: 182.6376\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 179.48197\n",
      "Epoch 149/5000\n",
      "ecpch:148,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.3302 - val_loss: 181.9810\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 179.48197\n",
      "Epoch 150/5000\n",
      "ecpch:149,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.2912 - val_loss: 182.4975\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 179.48197\n",
      "Epoch 151/5000\n",
      "ecpch:150,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.1815 - val_loss: 182.1573\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 179.48197\n",
      "Epoch 152/5000\n",
      "ecpch:151,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.1624 - val_loss: 182.4426\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 179.48197\n",
      "Epoch 153/5000\n",
      "ecpch:152,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.1294 - val_loss: 182.0691\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 179.48197\n",
      "Epoch 154/5000\n",
      "ecpch:153,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.1310 - val_loss: 182.5766\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 179.48197\n",
      "Epoch 155/5000\n",
      "ecpch:154,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.1689 - val_loss: 181.9872\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 179.48197\n",
      "Epoch 156/5000\n",
      "ecpch:155,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.2071 - val_loss: 182.5792\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 179.48197\n",
      "Epoch 157/5000\n",
      "ecpch:156,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.1228 - val_loss: 182.1539\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 179.48197\n",
      "Epoch 158/5000\n",
      "ecpch:157,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.0758 - val_loss: 182.5202\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 179.48197\n",
      "Epoch 159/5000\n",
      "ecpch:158,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.0169 - val_loss: 182.2564\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 179.48197\n",
      "Epoch 160/5000\n",
      "ecpch:159,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 67.9983 - val_loss: 182.6196\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 179.48197\n",
      "Epoch 161/5000\n",
      "ecpch:160,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 67.9844 - val_loss: 182.2154\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 179.48197\n",
      "Epoch 162/5000\n",
      "ecpch:161,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 68.0183 - val_loss: 182.7803\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 179.48197\n",
      "Epoch 163/5000\n",
      "ecpch:162,learn rate 0.000324\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.0179 - val_loss: 182.2302\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 00163: ReduceLROnPlateau reducing learning rate to 0.00029159999394323677.\n",
      "Epoch 164/5000\n",
      "ecpch:163,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 68.0419 - val_loss: 182.7543\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 179.48197\n",
      "Epoch 165/5000\n",
      "ecpch:164,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 67.9558 - val_loss: 182.4650\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 179.48197\n",
      "Epoch 166/5000\n",
      "ecpch:165,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 67.8809 - val_loss: 182.5577\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 179.48197\n",
      "Epoch 167/5000\n",
      "ecpch:166,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.8268 - val_loss: 182.7078\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 179.48197\n",
      "Epoch 168/5000\n",
      "ecpch:167,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.8326 - val_loss: 182.3675\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 179.48197\n",
      "Epoch 169/5000\n",
      "ecpch:168,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 67.9072 - val_loss: 182.8775\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 179.48197\n",
      "Epoch 170/5000\n",
      "ecpch:169,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.9304 - val_loss: 182.4100\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 179.48197\n",
      "Epoch 171/5000\n",
      "ecpch:170,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.8855 - val_loss: 182.7587\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 179.48197\n",
      "Epoch 172/5000\n",
      "ecpch:171,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.7711 - val_loss: 182.6003\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 179.48197\n",
      "Epoch 173/5000\n",
      "ecpch:172,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.7419 - val_loss: 182.7080\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 179.48197\n",
      "Epoch 174/5000\n",
      "ecpch:173,learn rate 0.000292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 10ms/step - loss: 67.7411 - val_loss: 182.7564\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 179.48197\n",
      "Epoch 175/5000\n",
      "ecpch:174,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.7189 - val_loss: 182.6101\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 179.48197\n",
      "Epoch 176/5000\n",
      "ecpch:175,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 67.7108 - val_loss: 182.9186\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 179.48197\n",
      "Epoch 177/5000\n",
      "ecpch:176,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.7107 - val_loss: 182.5470\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 179.48197\n",
      "Epoch 178/5000\n",
      "ecpch:177,learn rate 0.000292\n",
      "64/64 [==============================] - 0s 8ms/step - loss: 67.7420 - val_loss: 182.9941\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 179.48197\n",
      "Epoch 179/5000\n",
      "ecpch:178,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.6944 - val_loss: 182.6519\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 179.48197\n",
      "Epoch 180/5000\n",
      "ecpch:179,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.6598 - val_loss: 182.9735\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 179.48197\n",
      "Epoch 181/5000\n",
      "ecpch:180,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 67.6478 - val_loss: 182.6802\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 179.48197\n",
      "Epoch 182/5000\n",
      "ecpch:181,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 67.7052 - val_loss: 183.0647\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 179.48197\n",
      "Epoch 183/5000\n",
      "ecpch:182,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.6717 - val_loss: 182.6206\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 179.48197\n",
      "Epoch 184/5000\n",
      "ecpch:183,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.6636 - val_loss: 183.1119\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 179.48197\n",
      "Epoch 185/5000\n",
      "ecpch:184,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.6350 - val_loss: 182.6263\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 179.48197\n",
      "Epoch 186/5000\n",
      "ecpch:185,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.6233 - val_loss: 183.1063\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 179.48197\n",
      "Epoch 187/5000\n",
      "ecpch:186,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 67.5755 - val_loss: 182.7169\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 179.48197\n",
      "Epoch 188/5000\n",
      "ecpch:187,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.5455 - val_loss: 183.0711\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 179.48197\n",
      "Epoch 189/5000\n",
      "ecpch:188,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.5228 - val_loss: 182.8279\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 179.48197\n",
      "Epoch 190/5000\n",
      "ecpch:189,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.5633 - val_loss: 183.0754\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 179.48197\n",
      "Epoch 191/5000\n",
      "ecpch:190,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 67.5037 - val_loss: 182.8485\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 179.48197\n",
      "Epoch 192/5000\n",
      "ecpch:191,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.4708 - val_loss: 183.2248\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 179.48197\n",
      "Epoch 193/5000\n",
      "ecpch:192,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 67.4647 - val_loss: 182.7989\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 179.48197\n",
      "Epoch 194/5000\n",
      "ecpch:193,learn rate 0.000292\n",
      "64/64 [==============================] - 0s 8ms/step - loss: 67.5001 - val_loss: 183.3935\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 179.48197\n",
      "Epoch 195/5000\n",
      "ecpch:194,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.5103 - val_loss: 182.8145\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 179.48197\n",
      "Epoch 196/5000\n",
      "ecpch:195,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.4889 - val_loss: 183.3667\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 179.48197\n",
      "Epoch 197/5000\n",
      "ecpch:196,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.4432 - val_loss: 182.8950\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 179.48197\n",
      "Epoch 198/5000\n",
      "ecpch:197,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.4403 - val_loss: 183.3469\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 179.48197\n",
      "Epoch 199/5000\n",
      "ecpch:198,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 67.4252 - val_loss: 182.9300\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 179.48197\n",
      "Epoch 200/5000\n",
      "ecpch:199,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.4270 - val_loss: 183.3239\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 179.48197\n",
      "Epoch 201/5000\n",
      "ecpch:200,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 67.3410 - val_loss: 182.9555\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 179.48197\n",
      "Epoch 202/5000\n",
      "ecpch:201,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.3197 - val_loss: 183.3416\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 179.48197\n",
      "Epoch 203/5000\n",
      "ecpch:202,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.2790 - val_loss: 183.0416\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 179.48197\n",
      "Epoch 204/5000\n",
      "ecpch:203,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 67.2698 - val_loss: 183.3623\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 179.48197\n",
      "Epoch 205/5000\n",
      "ecpch:204,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.2401 - val_loss: 183.1690\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 179.48197\n",
      "Epoch 206/5000\n",
      "ecpch:205,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.2106 - val_loss: 183.3709\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 179.48197\n",
      "Epoch 207/5000\n",
      "ecpch:206,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.1765 - val_loss: 183.2861\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 179.48197\n",
      "Epoch 208/5000\n",
      "ecpch:207,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.1543 - val_loss: 183.4227\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 179.48197\n",
      "Epoch 209/5000\n",
      "ecpch:208,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.1380 - val_loss: 183.3329\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 179.48197\n",
      "Epoch 210/5000\n",
      "ecpch:209,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.1317 - val_loss: 183.5011\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 179.48197\n",
      "Epoch 211/5000\n",
      "ecpch:210,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.1453 - val_loss: 183.2010\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 179.48197\n",
      "Epoch 212/5000\n",
      "ecpch:211,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.2624 - val_loss: 183.8273\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 179.48197\n",
      "Epoch 213/5000\n",
      "ecpch:212,learn rate 0.000292\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.3707 - val_loss: 182.9931\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 00213: ReduceLROnPlateau reducing learning rate to 0.0002624400076456368.\n",
      "Epoch 214/5000\n",
      "ecpch:213,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.4333 - val_loss: 183.6976\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 179.48197\n",
      "Epoch 215/5000\n",
      "ecpch:214,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.1541 - val_loss: 183.3735\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 179.48197\n",
      "Epoch 216/5000\n",
      "ecpch:215,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 67.0243 - val_loss: 183.3022\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 179.48197\n",
      "Epoch 217/5000\n",
      "ecpch:216,learn rate 0.000262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 9ms/step - loss: 67.0293 - val_loss: 183.7044\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 179.48197\n",
      "Epoch 218/5000\n",
      "ecpch:217,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.0919 - val_loss: 183.1432\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 179.48197\n",
      "Epoch 219/5000\n",
      "ecpch:218,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.1200 - val_loss: 183.6947\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 179.48197\n",
      "Epoch 220/5000\n",
      "ecpch:219,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.0519 - val_loss: 183.3544\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 179.48197\n",
      "Epoch 221/5000\n",
      "ecpch:220,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.0339 - val_loss: 183.5870\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 179.48197\n",
      "Epoch 222/5000\n",
      "ecpch:221,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 66.9666 - val_loss: 183.5463\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 179.48197\n",
      "Epoch 223/5000\n",
      "ecpch:222,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 66.9299 - val_loss: 183.5998\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 179.48197\n",
      "Epoch 224/5000\n",
      "ecpch:223,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 66.8924 - val_loss: 183.6591\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 179.48197\n",
      "Epoch 225/5000\n",
      "ecpch:224,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 66.8745 - val_loss: 183.6007\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 179.48197\n",
      "Epoch 226/5000\n",
      "ecpch:225,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 66.8787 - val_loss: 183.8464\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 179.48197\n",
      "Epoch 227/5000\n",
      "ecpch:226,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 66.9017 - val_loss: 183.4719\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 179.48197\n",
      "Epoch 228/5000\n",
      "ecpch:227,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.0039 - val_loss: 184.1135\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 179.48197\n",
      "Epoch 229/5000\n",
      "ecpch:228,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 67.0425 - val_loss: 183.4238\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 179.48197\n",
      "Epoch 230/5000\n",
      "ecpch:229,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 66.9959 - val_loss: 183.9304\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 179.48197\n",
      "Epoch 231/5000\n",
      "ecpch:230,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 66.8643 - val_loss: 183.6475\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 179.48197\n",
      "Epoch 232/5000\n",
      "ecpch:231,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 66.8082 - val_loss: 183.7433\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 179.48197\n",
      "Epoch 233/5000\n",
      "ecpch:232,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 66.7724 - val_loss: 183.7677\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 179.48197\n",
      "Epoch 234/5000\n",
      "ecpch:233,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 66.7571 - val_loss: 183.6501\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 179.48197\n",
      "Epoch 235/5000\n",
      "ecpch:234,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 66.7470 - val_loss: 183.9097\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 179.48197\n",
      "Epoch 236/5000\n",
      "ecpch:235,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 66.7401 - val_loss: 183.5537\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 179.48197\n",
      "Epoch 237/5000\n",
      "ecpch:236,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 66.7713 - val_loss: 184.0856\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 179.48197\n",
      "Epoch 238/5000\n",
      "ecpch:237,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 66.7778 - val_loss: 183.5630\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 179.48197\n",
      "Epoch 239/5000\n",
      "ecpch:238,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 66.7963 - val_loss: 184.1408\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 179.48197\n",
      "Epoch 240/5000\n",
      "ecpch:239,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 66.8189 - val_loss: 183.6783\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 179.48197\n",
      "Epoch 241/5000\n",
      "ecpch:240,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 66.8430 - val_loss: 184.0799\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 179.48197\n",
      "Epoch 242/5000\n",
      "ecpch:241,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 66.6604 - val_loss: 183.7428\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 179.48197\n",
      "Epoch 243/5000\n",
      "ecpch:242,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 66.6402 - val_loss: 184.0657\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 179.48197\n",
      "Epoch 244/5000\n",
      "ecpch:243,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 66.6478 - val_loss: 183.8287\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 179.48197\n",
      "Epoch 245/5000\n",
      "ecpch:244,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 66.5945 - val_loss: 184.0304\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 179.48197\n",
      "Epoch 246/5000\n",
      "ecpch:245,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 66.5472 - val_loss: 183.8513\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 179.48197\n",
      "Epoch 247/5000\n",
      "ecpch:246,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 66.5417 - val_loss: 184.1413\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 179.48197\n",
      "Epoch 248/5000\n",
      "ecpch:247,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 66.5749 - val_loss: 183.7862\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 179.48197\n",
      "Epoch 249/5000\n",
      "ecpch:248,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 66.7445 - val_loss: 184.3452\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 179.48197\n",
      "Epoch 250/5000\n",
      "ecpch:249,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 66.6755 - val_loss: 183.7043\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 179.48197\n",
      "Epoch 251/5000\n",
      "ecpch:250,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 66.6757 - val_loss: 184.3968\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 179.48197\n",
      "Epoch 252/5000\n",
      "ecpch:251,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 66.6034 - val_loss: 183.8281\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 179.48197\n",
      "Epoch 253/5000\n",
      "ecpch:252,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 66.5222 - val_loss: 184.2622\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 179.48197\n",
      "Epoch 254/5000\n",
      "ecpch:253,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 66.4619 - val_loss: 183.8624\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 179.48197\n",
      "Epoch 255/5000\n",
      "ecpch:254,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 66.4563 - val_loss: 184.3187\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 179.48197\n",
      "Epoch 256/5000\n",
      "ecpch:255,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 66.4638 - val_loss: 183.7874\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 179.48197\n",
      "Epoch 257/5000\n",
      "ecpch:256,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 66.5271 - val_loss: 184.4598\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 179.48197\n",
      "Epoch 258/5000\n",
      "ecpch:257,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 66.5554 - val_loss: 183.8019\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 179.48197\n",
      "Epoch 259/5000\n",
      "ecpch:258,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 66.6424 - val_loss: 184.4344\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 179.48197\n",
      "Epoch 260/5000\n",
      "ecpch:259,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 66.4592 - val_loss: 183.9756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00260: val_loss did not improve from 179.48197\n",
      "Epoch 261/5000\n",
      "ecpch:260,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 66.3828 - val_loss: 184.3640\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 179.48197\n",
      "Epoch 262/5000\n",
      "ecpch:261,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 66.3322 - val_loss: 184.0439\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 179.48197\n",
      "Epoch 263/5000\n",
      "ecpch:262,learn rate 0.000262\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 66.3354 - val_loss: 184.3938\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 00263: ReduceLROnPlateau reducing learning rate to 0.00023619600688107312.\n",
      "Epoch 264/5000\n",
      "ecpch:263,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 66.3236 - val_loss: 184.0933\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 179.48197\n",
      "Epoch 265/5000\n",
      "ecpch:264,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 66.3376 - val_loss: 184.3417\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 179.48197\n",
      "Epoch 266/5000\n",
      "ecpch:265,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 66.2425 - val_loss: 184.2850\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 179.48197\n",
      "Epoch 267/5000\n",
      "ecpch:266,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 66.1943 - val_loss: 184.2125\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 179.48197\n",
      "Epoch 268/5000\n",
      "ecpch:267,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 66.1983 - val_loss: 184.4751\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 179.48197\n",
      "Epoch 269/5000\n",
      "ecpch:268,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 66.2390 - val_loss: 184.1228\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 179.48197\n",
      "Epoch 270/5000\n",
      "ecpch:269,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 66.3186 - val_loss: 184.5703\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 179.48197\n",
      "Epoch 271/5000\n",
      "ecpch:270,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 66.2419 - val_loss: 184.1811\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 179.48197\n",
      "Epoch 272/5000\n",
      "ecpch:271,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 66.1842 - val_loss: 184.5247\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 179.48197\n",
      "Epoch 273/5000\n",
      "ecpch:272,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 66.1358 - val_loss: 184.2627\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 179.48197\n",
      "Epoch 274/5000\n",
      "ecpch:273,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 66.1219 - val_loss: 184.5132\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 179.48197\n",
      "Epoch 275/5000\n",
      "ecpch:274,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 66.1142 - val_loss: 184.3476\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 179.48197\n",
      "Epoch 276/5000\n",
      "ecpch:275,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 66.0945 - val_loss: 184.4657\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 179.48197\n",
      "Epoch 277/5000\n",
      "ecpch:276,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 66.0531 - val_loss: 184.4801\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 179.48197\n",
      "Epoch 278/5000\n",
      "ecpch:277,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 66.0249 - val_loss: 184.3992\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 179.48197\n",
      "Epoch 279/5000\n",
      "ecpch:278,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 66.0129 - val_loss: 184.5902\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 179.48197\n",
      "Epoch 280/5000\n",
      "ecpch:279,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 66.0114 - val_loss: 184.2817\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 179.48197\n",
      "Epoch 281/5000\n",
      "ecpch:280,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 66.0693 - val_loss: 184.8686\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 179.48197\n",
      "Epoch 282/5000\n",
      "ecpch:281,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 66.1327 - val_loss: 184.2351\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 179.48197\n",
      "Epoch 283/5000\n",
      "ecpch:282,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 66.1437 - val_loss: 184.8186\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 179.48197\n",
      "Epoch 284/5000\n",
      "ecpch:283,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 66.1261 - val_loss: 184.3729\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 179.48197\n",
      "Epoch 285/5000\n",
      "ecpch:284,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 66.1029 - val_loss: 184.7249\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 179.48197\n",
      "Epoch 286/5000\n",
      "ecpch:285,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.9534 - val_loss: 184.3985\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 179.48197\n",
      "Epoch 287/5000\n",
      "ecpch:286,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.9328 - val_loss: 184.7904\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 179.48197\n",
      "Epoch 288/5000\n",
      "ecpch:287,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.9697 - val_loss: 184.3321\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 179.48197\n",
      "Epoch 289/5000\n",
      "ecpch:288,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.9766 - val_loss: 184.7285\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 179.48197\n",
      "Epoch 290/5000\n",
      "ecpch:289,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.8770 - val_loss: 184.4817\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 179.48197\n",
      "Epoch 291/5000\n",
      "ecpch:290,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.8489 - val_loss: 184.7181\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 179.48197\n",
      "Epoch 292/5000\n",
      "ecpch:291,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 65.8587 - val_loss: 184.6055\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 179.48197\n",
      "Epoch 293/5000\n",
      "ecpch:292,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 65.9797 - val_loss: 184.8575\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 179.48197\n",
      "Epoch 294/5000\n",
      "ecpch:293,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 65.8671 - val_loss: 184.5032\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 179.48197\n",
      "Epoch 295/5000\n",
      "ecpch:294,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 65.8746 - val_loss: 185.0949\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 179.48197\n",
      "Epoch 296/5000\n",
      "ecpch:295,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.9148 - val_loss: 184.4388\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 179.48197\n",
      "Epoch 297/5000\n",
      "ecpch:296,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.9473 - val_loss: 185.0981\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 179.48197\n",
      "Epoch 298/5000\n",
      "ecpch:297,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 65.8673 - val_loss: 184.5732\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 179.48197\n",
      "Epoch 299/5000\n",
      "ecpch:298,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 65.8130 - val_loss: 184.9491\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 179.48197\n",
      "Epoch 300/5000\n",
      "ecpch:299,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 65.7688 - val_loss: 184.6486\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 179.48197\n",
      "Epoch 301/5000\n",
      "ecpch:300,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.8211 - val_loss: 184.9488\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 179.48197\n",
      "Epoch 302/5000\n",
      "ecpch:301,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.7454 - val_loss: 184.5528\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 179.48197\n",
      "Epoch 303/5000\n",
      "ecpch:302,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.7579 - val_loss: 185.0990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00303: val_loss did not improve from 179.48197\n",
      "Epoch 304/5000\n",
      "ecpch:303,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.7597 - val_loss: 184.4902\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 179.48197\n",
      "Epoch 305/5000\n",
      "ecpch:304,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 65.7757 - val_loss: 185.0975\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 179.48197\n",
      "Epoch 306/5000\n",
      "ecpch:305,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.7004 - val_loss: 184.6431\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 179.48197\n",
      "Epoch 307/5000\n",
      "ecpch:306,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.6518 - val_loss: 185.0224\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 179.48197\n",
      "Epoch 308/5000\n",
      "ecpch:307,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.5928 - val_loss: 184.8739\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 179.48197\n",
      "Epoch 309/5000\n",
      "ecpch:308,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.5602 - val_loss: 184.9454\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 179.48197\n",
      "Epoch 310/5000\n",
      "ecpch:309,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.5705 - val_loss: 185.0462\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 179.48197\n",
      "Epoch 311/5000\n",
      "ecpch:310,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.5563 - val_loss: 184.8522\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 179.48197\n",
      "Epoch 312/5000\n",
      "ecpch:311,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.6251 - val_loss: 185.2897\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 179.48197\n",
      "Epoch 313/5000\n",
      "ecpch:312,learn rate 0.000236\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.6509 - val_loss: 184.6395\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 00313: ReduceLROnPlateau reducing learning rate to 0.0002125764061929658.\n",
      "Epoch 314/5000\n",
      "ecpch:313,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.7643 - val_loss: 185.3546\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 179.48197\n",
      "Epoch 315/5000\n",
      "ecpch:314,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.6139 - val_loss: 184.9255\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 179.48197\n",
      "Epoch 316/5000\n",
      "ecpch:315,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.4526 - val_loss: 184.9710\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 179.48197\n",
      "Epoch 317/5000\n",
      "ecpch:316,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.4399 - val_loss: 185.3597\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 179.48197\n",
      "Epoch 318/5000\n",
      "ecpch:317,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.5704 - val_loss: 184.6717\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 179.48197\n",
      "Epoch 319/5000\n",
      "ecpch:318,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.7235 - val_loss: 185.3146\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 179.48197\n",
      "Epoch 320/5000\n",
      "ecpch:319,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.4743 - val_loss: 185.0694\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 179.48197\n",
      "Epoch 321/5000\n",
      "ecpch:320,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 65.3545 - val_loss: 184.9547\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 179.48197\n",
      "Epoch 322/5000\n",
      "ecpch:321,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.4141 - val_loss: 185.3793\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 179.48197\n",
      "Epoch 323/5000\n",
      "ecpch:322,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.5087 - val_loss: 184.8329\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 179.48197\n",
      "Epoch 324/5000\n",
      "ecpch:323,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 65.5242 - val_loss: 185.3056\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 179.48197\n",
      "Epoch 325/5000\n",
      "ecpch:324,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 65.3550 - val_loss: 185.0807\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 179.48197\n",
      "Epoch 326/5000\n",
      "ecpch:325,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 65.2944 - val_loss: 185.1445\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 179.48197\n",
      "Epoch 327/5000\n",
      "ecpch:326,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 65.3210 - val_loss: 185.2579\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 179.48197\n",
      "Epoch 328/5000\n",
      "ecpch:327,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 65.3169 - val_loss: 185.0413\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 179.48197\n",
      "Epoch 329/5000\n",
      "ecpch:328,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.3305 - val_loss: 185.4540\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 179.48197\n",
      "Epoch 330/5000\n",
      "ecpch:329,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.3178 - val_loss: 184.9712\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 179.48197\n",
      "Epoch 331/5000\n",
      "ecpch:330,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 65.3427 - val_loss: 185.4840\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 179.48197\n",
      "Epoch 332/5000\n",
      "ecpch:331,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 65.2997 - val_loss: 185.1640\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 179.48197\n",
      "Epoch 333/5000\n",
      "ecpch:332,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.2130 - val_loss: 185.2939\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 179.48197\n",
      "Epoch 334/5000\n",
      "ecpch:333,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.1619 - val_loss: 185.4092\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 179.48197\n",
      "Epoch 335/5000\n",
      "ecpch:334,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.1676 - val_loss: 185.0819\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 179.48197\n",
      "Epoch 336/5000\n",
      "ecpch:335,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 65.2408 - val_loss: 185.6382\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 179.48197\n",
      "Epoch 337/5000\n",
      "ecpch:336,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 65.2648 - val_loss: 185.0999\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 179.48197\n",
      "Epoch 338/5000\n",
      "ecpch:337,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.2146 - val_loss: 185.5401\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 179.48197\n",
      "Epoch 339/5000\n",
      "ecpch:338,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.1718 - val_loss: 185.2849\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 179.48197\n",
      "Epoch 340/5000\n",
      "ecpch:339,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.2558 - val_loss: 185.4550\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 179.48197\n",
      "Epoch 341/5000\n",
      "ecpch:340,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 65.1208 - val_loss: 185.3305\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 179.48197\n",
      "Epoch 342/5000\n",
      "ecpch:341,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.0521 - val_loss: 185.4552\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 179.48197\n",
      "Epoch 343/5000\n",
      "ecpch:342,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 65.0331 - val_loss: 185.2686\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 179.48197\n",
      "Epoch 344/5000\n",
      "ecpch:343,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.0698 - val_loss: 185.5923\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 179.48197\n",
      "Epoch 345/5000\n",
      "ecpch:344,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 65.1033 - val_loss: 185.2482\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 179.48197\n",
      "Epoch 346/5000\n",
      "ecpch:345,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 65.0608 - val_loss: 185.6772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00346: val_loss did not improve from 179.48197\n",
      "Epoch 347/5000\n",
      "ecpch:346,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.0430 - val_loss: 185.2275\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 179.48197\n",
      "Epoch 348/5000\n",
      "ecpch:347,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.1221 - val_loss: 185.8226\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 179.48197\n",
      "Epoch 349/5000\n",
      "ecpch:348,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.1376 - val_loss: 185.2729\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 179.48197\n",
      "Epoch 350/5000\n",
      "ecpch:349,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.1450 - val_loss: 185.7339\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 179.48197\n",
      "Epoch 351/5000\n",
      "ecpch:350,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 64.9995 - val_loss: 185.3611\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 179.48197\n",
      "Epoch 352/5000\n",
      "ecpch:351,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 64.9640 - val_loss: 185.7162\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 179.48197\n",
      "Epoch 353/5000\n",
      "ecpch:352,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 64.9515 - val_loss: 185.3242\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 179.48197\n",
      "Epoch 354/5000\n",
      "ecpch:353,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.0249 - val_loss: 185.8105\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 179.48197\n",
      "Epoch 355/5000\n",
      "ecpch:354,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.0109 - val_loss: 185.3082\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 179.48197\n",
      "Epoch 356/5000\n",
      "ecpch:355,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 65.0054 - val_loss: 185.8061\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 179.48197\n",
      "Epoch 357/5000\n",
      "ecpch:356,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 64.9090 - val_loss: 185.3641\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 179.48197\n",
      "Epoch 358/5000\n",
      "ecpch:357,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 64.8961 - val_loss: 185.8426\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 179.48197\n",
      "Epoch 359/5000\n",
      "ecpch:358,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 64.8883 - val_loss: 185.4224\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 179.48197\n",
      "Epoch 360/5000\n",
      "ecpch:359,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 64.8736 - val_loss: 185.8226\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 179.48197\n",
      "Epoch 361/5000\n",
      "ecpch:360,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 64.8125 - val_loss: 185.5341\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 179.48197\n",
      "Epoch 362/5000\n",
      "ecpch:361,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 64.7750 - val_loss: 185.7996\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 179.48197\n",
      "Epoch 363/5000\n",
      "ecpch:362,learn rate 0.000213\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 64.7390 - val_loss: 185.6563\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 00363: ReduceLROnPlateau reducing learning rate to 0.00019131876033497974.\n",
      "Epoch 364/5000\n",
      "ecpch:363,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 64.7210 - val_loss: 185.8274\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 179.48197\n",
      "Epoch 365/5000\n",
      "ecpch:364,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 64.7071 - val_loss: 185.6724\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 179.48197\n",
      "Epoch 366/5000\n",
      "ecpch:365,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 64.7058 - val_loss: 185.9335\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 179.48197\n",
      "Epoch 367/5000\n",
      "ecpch:366,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 64.7232 - val_loss: 185.6401\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 179.48197\n",
      "Epoch 368/5000\n",
      "ecpch:367,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 64.7938 - val_loss: 185.9481\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 179.48197\n",
      "Epoch 369/5000\n",
      "ecpch:368,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 64.7283 - val_loss: 185.7072\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 179.48197\n",
      "Epoch 370/5000\n",
      "ecpch:369,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 64.6796 - val_loss: 185.8913\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 179.48197\n",
      "Epoch 371/5000\n",
      "ecpch:370,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 64.6317 - val_loss: 185.7714\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 179.48197\n",
      "Epoch 372/5000\n",
      "ecpch:371,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 64.6070 - val_loss: 185.8649\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 179.48197\n",
      "Epoch 373/5000\n",
      "ecpch:372,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 64.6079 - val_loss: 185.8131\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 179.48197\n",
      "Epoch 374/5000\n",
      "ecpch:373,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 64.6133 - val_loss: 185.8383\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 179.48197\n",
      "Epoch 375/5000\n",
      "ecpch:374,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 64.5926 - val_loss: 185.8398\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 179.48197\n",
      "Epoch 376/5000\n",
      "ecpch:375,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 64.5745 - val_loss: 185.8560\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 179.48197\n",
      "Epoch 377/5000\n",
      "ecpch:376,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 64.5365 - val_loss: 185.9214\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 179.48197\n",
      "Epoch 378/5000\n",
      "ecpch:377,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 64.5104 - val_loss: 185.7833\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 179.48197\n",
      "Epoch 379/5000\n",
      "ecpch:378,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 64.5246 - val_loss: 186.1642\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 179.48197\n",
      "Epoch 380/5000\n",
      "ecpch:379,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 64.5769 - val_loss: 185.6429\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 179.48197\n",
      "Epoch 381/5000\n",
      "ecpch:380,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 64.6577 - val_loss: 186.2576\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 179.48197\n",
      "Epoch 382/5000\n",
      "ecpch:381,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 64.5816 - val_loss: 185.8206\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 179.48197\n",
      "Epoch 383/5000\n",
      "ecpch:382,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 64.5022 - val_loss: 186.1278\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 179.48197\n",
      "Epoch 384/5000\n",
      "ecpch:383,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 64.4766 - val_loss: 185.8823\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 179.48197\n",
      "Epoch 385/5000\n",
      "ecpch:384,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 64.5388 - val_loss: 186.1687\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 179.48197\n",
      "Epoch 386/5000\n",
      "ecpch:385,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 64.5128 - val_loss: 185.7663\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 179.48197\n",
      "Epoch 387/5000\n",
      "ecpch:386,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 64.5265 - val_loss: 186.2632\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 179.48197\n",
      "Epoch 388/5000\n",
      "ecpch:387,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 64.4855 - val_loss: 185.7336\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 179.48197\n",
      "Epoch 389/5000\n",
      "ecpch:388,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 64.4986 - val_loss: 186.2289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00389: val_loss did not improve from 179.48197\n",
      "Epoch 390/5000\n",
      "ecpch:389,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 64.4359 - val_loss: 185.8760\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 179.48197\n",
      "Epoch 391/5000\n",
      "ecpch:390,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 64.3892 - val_loss: 186.1312\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 179.48197\n",
      "Epoch 392/5000\n",
      "ecpch:391,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 64.3263 - val_loss: 186.0443\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 179.48197\n",
      "Epoch 393/5000\n",
      "ecpch:392,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 64.3032 - val_loss: 186.1656\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 179.48197\n",
      "Epoch 394/5000\n",
      "ecpch:393,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 64.2985 - val_loss: 186.0112\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 179.48197\n",
      "Epoch 395/5000\n",
      "ecpch:394,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 64.3256 - val_loss: 186.2925\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 179.48197\n",
      "Epoch 396/5000\n",
      "ecpch:395,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 64.3611 - val_loss: 186.0349\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 179.48197\n",
      "Epoch 397/5000\n",
      "ecpch:396,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 64.3072 - val_loss: 186.3185\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 179.48197\n",
      "Epoch 398/5000\n",
      "ecpch:397,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 64.2698 - val_loss: 186.0233\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 179.48197\n",
      "Epoch 399/5000\n",
      "ecpch:398,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 64.2795 - val_loss: 186.5346\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 179.48197\n",
      "Epoch 400/5000\n",
      "ecpch:399,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 64.3692 - val_loss: 185.8818\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 179.48197\n",
      "Epoch 401/5000\n",
      "ecpch:400,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 64.5147 - val_loss: 186.5173\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 179.48197\n",
      "Epoch 402/5000\n",
      "ecpch:401,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 64.3386 - val_loss: 186.1363\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 179.48197\n",
      "Epoch 403/5000\n",
      "ecpch:402,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 64.2452 - val_loss: 186.3153\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 179.48197\n",
      "Epoch 404/5000\n",
      "ecpch:403,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 64.1776 - val_loss: 186.2739\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 179.48197\n",
      "Epoch 405/5000\n",
      "ecpch:404,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 64.1524 - val_loss: 186.2199\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 179.48197\n",
      "Epoch 406/5000\n",
      "ecpch:405,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 64.1369 - val_loss: 186.3549\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 179.48197\n",
      "Epoch 407/5000\n",
      "ecpch:406,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 64.1340 - val_loss: 186.0513\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 179.48197\n",
      "Epoch 408/5000\n",
      "ecpch:407,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 64.1901 - val_loss: 186.6413\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 179.48197\n",
      "Epoch 409/5000\n",
      "ecpch:408,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 64.2549 - val_loss: 185.9982\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 179.48197\n",
      "Epoch 410/5000\n",
      "ecpch:409,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 64.2575 - val_loss: 186.6147\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 179.48197\n",
      "Epoch 411/5000\n",
      "ecpch:410,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 64.1619 - val_loss: 186.1776\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 179.48197\n",
      "Epoch 412/5000\n",
      "ecpch:411,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 64.1138 - val_loss: 186.5568\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 179.48197\n",
      "Epoch 413/5000\n",
      "ecpch:412,learn rate 0.000191\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 64.1323 - val_loss: 186.2186\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 00413: ReduceLROnPlateau reducing learning rate to 0.0001721868829918094.\n",
      "Epoch 414/5000\n",
      "ecpch:413,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 64.1849 - val_loss: 186.5159\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 179.48197\n",
      "Epoch 415/5000\n",
      "ecpch:414,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 64.0496 - val_loss: 186.2793\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 179.48197\n",
      "Epoch 416/5000\n",
      "ecpch:415,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.9920 - val_loss: 186.4834\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 179.48197\n",
      "Epoch 417/5000\n",
      "ecpch:416,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.9719 - val_loss: 186.2390\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 179.48197\n",
      "Epoch 418/5000\n",
      "ecpch:417,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 64.0070 - val_loss: 186.5610\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 179.48197\n",
      "Epoch 419/5000\n",
      "ecpch:418,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.9800 - val_loss: 186.2880\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 179.48197\n",
      "Epoch 420/5000\n",
      "ecpch:419,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.9551 - val_loss: 186.5803\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 179.48197\n",
      "Epoch 421/5000\n",
      "ecpch:420,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.9242 - val_loss: 186.3765\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 179.48197\n",
      "Epoch 422/5000\n",
      "ecpch:421,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.9221 - val_loss: 186.6250\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 179.48197\n",
      "Epoch 423/5000\n",
      "ecpch:422,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 63.9219 - val_loss: 186.3945\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 179.48197\n",
      "Epoch 424/5000\n",
      "ecpch:423,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.9847 - val_loss: 186.6656\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 179.48197\n",
      "Epoch 425/5000\n",
      "ecpch:424,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.9244 - val_loss: 186.4192\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 179.48197\n",
      "Epoch 426/5000\n",
      "ecpch:425,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.8929 - val_loss: 186.7037\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 179.48197\n",
      "Epoch 427/5000\n",
      "ecpch:426,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.8689 - val_loss: 186.3479\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 179.48197\n",
      "Epoch 428/5000\n",
      "ecpch:427,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.8900 - val_loss: 186.7681\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 179.48197\n",
      "Epoch 429/5000\n",
      "ecpch:428,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.8744 - val_loss: 186.3519\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 179.48197\n",
      "Epoch 430/5000\n",
      "ecpch:429,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.8734 - val_loss: 186.7626\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 179.48197\n",
      "Epoch 431/5000\n",
      "ecpch:430,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.8252 - val_loss: 186.4102\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 179.48197\n",
      "Epoch 432/5000\n",
      "ecpch:431,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.8368 - val_loss: 186.7486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00432: val_loss did not improve from 179.48197\n",
      "Epoch 433/5000\n",
      "ecpch:432,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.7821 - val_loss: 186.5001\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 179.48197\n",
      "Epoch 434/5000\n",
      "ecpch:433,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.7676 - val_loss: 186.7613\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 179.48197\n",
      "Epoch 435/5000\n",
      "ecpch:434,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.7321 - val_loss: 186.5345\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 179.48197\n",
      "Epoch 436/5000\n",
      "ecpch:435,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.7312 - val_loss: 186.8269\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 179.48197\n",
      "Epoch 437/5000\n",
      "ecpch:436,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.7300 - val_loss: 186.4719\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 179.48197\n",
      "Epoch 438/5000\n",
      "ecpch:437,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.7730 - val_loss: 186.9766\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 179.48197\n",
      "Epoch 439/5000\n",
      "ecpch:438,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.7881 - val_loss: 186.4881\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 179.48197\n",
      "Epoch 440/5000\n",
      "ecpch:439,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.7488 - val_loss: 186.9306\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 179.48197\n",
      "Epoch 441/5000\n",
      "ecpch:440,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.7213 - val_loss: 186.5563\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 179.48197\n",
      "Epoch 442/5000\n",
      "ecpch:441,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.7922 - val_loss: 186.8906\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 179.48197\n",
      "Epoch 443/5000\n",
      "ecpch:442,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.7196 - val_loss: 186.6554\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 179.48197\n",
      "Epoch 444/5000\n",
      "ecpch:443,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.6610 - val_loss: 186.8583\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 179.48197\n",
      "Epoch 445/5000\n",
      "ecpch:444,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.6060 - val_loss: 186.7001\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 179.48197\n",
      "Epoch 446/5000\n",
      "ecpch:445,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.5793 - val_loss: 186.8026\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 179.48197\n",
      "Epoch 447/5000\n",
      "ecpch:446,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.5521 - val_loss: 186.8375\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 179.48197\n",
      "Epoch 448/5000\n",
      "ecpch:447,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.5382 - val_loss: 186.7134\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 179.48197\n",
      "Epoch 449/5000\n",
      "ecpch:448,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.5481 - val_loss: 186.9806\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 179.48197\n",
      "Epoch 450/5000\n",
      "ecpch:449,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 63.5762 - val_loss: 186.6345\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 179.48197\n",
      "Epoch 451/5000\n",
      "ecpch:450,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.6145 - val_loss: 187.1462\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 179.48197\n",
      "Epoch 452/5000\n",
      "ecpch:451,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.6248 - val_loss: 186.6724\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 179.48197\n",
      "Epoch 453/5000\n",
      "ecpch:452,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.5767 - val_loss: 187.1466\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 179.48197\n",
      "Epoch 454/5000\n",
      "ecpch:453,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.5512 - val_loss: 186.7100\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 179.48197\n",
      "Epoch 455/5000\n",
      "ecpch:454,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.5814 - val_loss: 187.1384\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 179.48197\n",
      "Epoch 456/5000\n",
      "ecpch:455,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.5843 - val_loss: 186.8025\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 179.48197\n",
      "Epoch 457/5000\n",
      "ecpch:456,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.5480 - val_loss: 187.0367\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 179.48197\n",
      "Epoch 458/5000\n",
      "ecpch:457,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.4544 - val_loss: 186.8355\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 179.48197\n",
      "Epoch 459/5000\n",
      "ecpch:458,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.4496 - val_loss: 187.0850\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 179.48197\n",
      "Epoch 460/5000\n",
      "ecpch:459,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.4656 - val_loss: 186.7043\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 179.48197\n",
      "Epoch 461/5000\n",
      "ecpch:460,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.5454 - val_loss: 187.2063\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 179.48197\n",
      "Epoch 462/5000\n",
      "ecpch:461,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.4845 - val_loss: 186.7023\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 179.48197\n",
      "Epoch 463/5000\n",
      "ecpch:462,learn rate 0.000172\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.4686 - val_loss: 187.1598\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 00463: ReduceLROnPlateau reducing learning rate to 0.00015496818814426662.\n",
      "Epoch 464/5000\n",
      "ecpch:463,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.4308 - val_loss: 186.9119\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 179.48197\n",
      "Epoch 465/5000\n",
      "ecpch:464,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.3432 - val_loss: 186.9732\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 179.48197\n",
      "Epoch 466/5000\n",
      "ecpch:465,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.3048 - val_loss: 187.1405\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 179.48197\n",
      "Epoch 467/5000\n",
      "ecpch:466,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.3049 - val_loss: 186.7882\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 179.48197\n",
      "Epoch 468/5000\n",
      "ecpch:467,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 63.3920 - val_loss: 187.3088\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 179.48197\n",
      "Epoch 469/5000\n",
      "ecpch:468,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.3743 - val_loss: 186.9626\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 179.48197\n",
      "Epoch 470/5000\n",
      "ecpch:469,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.2793 - val_loss: 187.1040\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 179.48197\n",
      "Epoch 471/5000\n",
      "ecpch:470,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.2390 - val_loss: 187.2975\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 179.48197\n",
      "Epoch 472/5000\n",
      "ecpch:471,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.2865 - val_loss: 186.8696\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 179.48197\n",
      "Epoch 473/5000\n",
      "ecpch:472,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.4121 - val_loss: 187.4059\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 179.48197\n",
      "Epoch 474/5000\n",
      "ecpch:473,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.2986 - val_loss: 187.0748\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 179.48197\n",
      "Epoch 475/5000\n",
      "ecpch:474,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.2015 - val_loss: 187.1814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00475: val_loss did not improve from 179.48197\n",
      "Epoch 476/5000\n",
      "ecpch:475,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.2010 - val_loss: 187.3575\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 179.48197\n",
      "Epoch 477/5000\n",
      "ecpch:476,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.3151 - val_loss: 186.9691\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 179.48197\n",
      "Epoch 478/5000\n",
      "ecpch:477,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.3170 - val_loss: 187.3641\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 179.48197\n",
      "Epoch 479/5000\n",
      "ecpch:478,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.1823 - val_loss: 187.0422\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 179.48197\n",
      "Epoch 480/5000\n",
      "ecpch:479,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.2635 - val_loss: 187.1953\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 179.48197\n",
      "Epoch 481/5000\n",
      "ecpch:480,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.2440 - val_loss: 187.4162\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 179.48197\n",
      "Epoch 482/5000\n",
      "ecpch:481,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.1822 - val_loss: 186.8401\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 179.48197\n",
      "Epoch 483/5000\n",
      "ecpch:482,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.4418 - val_loss: 187.2676\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 179.48197\n",
      "Epoch 484/5000\n",
      "ecpch:483,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.1000 - val_loss: 187.5366\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 179.48197\n",
      "Epoch 485/5000\n",
      "ecpch:484,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.2034 - val_loss: 186.8296\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 179.48197\n",
      "Epoch 486/5000\n",
      "ecpch:485,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.4581 - val_loss: 187.3440\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 179.48197\n",
      "Epoch 487/5000\n",
      "ecpch:486,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.0269 - val_loss: 187.7390\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 179.48197\n",
      "Epoch 488/5000\n",
      "ecpch:487,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.3295 - val_loss: 186.8782\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 179.48197\n",
      "Epoch 489/5000\n",
      "ecpch:488,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.4096 - val_loss: 187.3124\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 179.48197\n",
      "Epoch 490/5000\n",
      "ecpch:489,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 63.0484 - val_loss: 187.9139\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 179.48197\n",
      "Epoch 491/5000\n",
      "ecpch:490,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.6001 - val_loss: 187.0174\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 179.48197\n",
      "Epoch 492/5000\n",
      "ecpch:491,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.1745 - val_loss: 187.3030\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 179.48197\n",
      "Epoch 493/5000\n",
      "ecpch:492,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.3815 - val_loss: 187.6448\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 179.48197\n",
      "Epoch 494/5000\n",
      "ecpch:493,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.1207 - val_loss: 186.9883\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 179.48197\n",
      "Epoch 495/5000\n",
      "ecpch:494,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.4517 - val_loss: 187.3874\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 179.48197\n",
      "Epoch 496/5000\n",
      "ecpch:495,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.0409 - val_loss: 187.6880\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 179.48197\n",
      "Epoch 497/5000\n",
      "ecpch:496,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.0791 - val_loss: 186.9493\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 179.48197\n",
      "Epoch 498/5000\n",
      "ecpch:497,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.4450 - val_loss: 187.4784\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 179.48197\n",
      "Epoch 499/5000\n",
      "ecpch:498,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.9065 - val_loss: 187.7247\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 179.48197\n",
      "Epoch 500/5000\n",
      "ecpch:499,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.0426 - val_loss: 186.9875\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 179.48197\n",
      "Epoch 501/5000\n",
      "ecpch:500,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.3668 - val_loss: 187.4955\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 179.48197\n",
      "Epoch 502/5000\n",
      "ecpch:501,learn rate 0.000155\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 62.8611 - val_loss: 187.8027\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 179.48197\n",
      "Epoch 503/5000\n",
      "ecpch:502,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.1040 - val_loss: 186.9791\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 179.48197\n",
      "Epoch 504/5000\n",
      "ecpch:503,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 63.3451 - val_loss: 187.4558\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 179.48197\n",
      "Epoch 505/5000\n",
      "ecpch:504,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.8098 - val_loss: 187.9442\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 179.48197\n",
      "Epoch 506/5000\n",
      "ecpch:505,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.3515 - val_loss: 187.0438\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 179.48197\n",
      "Epoch 507/5000\n",
      "ecpch:506,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.1828 - val_loss: 187.4105\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 179.48197\n",
      "Epoch 508/5000\n",
      "ecpch:507,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 62.8299 - val_loss: 188.0857\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 179.48197\n",
      "Epoch 509/5000\n",
      "ecpch:508,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 63.4516 - val_loss: 187.1607\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 179.48197\n",
      "Epoch 510/5000\n",
      "ecpch:509,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.9746 - val_loss: 187.4279\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 179.48197\n",
      "Epoch 511/5000\n",
      "ecpch:510,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.8632 - val_loss: 188.1025\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 179.48197\n",
      "Epoch 512/5000\n",
      "ecpch:511,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.2742 - val_loss: 187.2259\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 179.48197\n",
      "Epoch 513/5000\n",
      "ecpch:512,learn rate 0.000155\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.9244 - val_loss: 187.4896\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 00513: ReduceLROnPlateau reducing learning rate to 0.0001394713719491847.\n",
      "Epoch 514/5000\n",
      "ecpch:513,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.8452 - val_loss: 188.0317\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 179.48197\n",
      "Epoch 515/5000\n",
      "ecpch:514,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.0273 - val_loss: 187.3299\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 179.48197\n",
      "Epoch 516/5000\n",
      "ecpch:515,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.8622 - val_loss: 187.4281\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 179.48197\n",
      "Epoch 517/5000\n",
      "ecpch:516,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.8759 - val_loss: 188.1200\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 179.48197\n",
      "Epoch 518/5000\n",
      "ecpch:517,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 63.0170 - val_loss: 187.4762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00518: val_loss did not improve from 179.48197\n",
      "Epoch 519/5000\n",
      "ecpch:518,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.8668 - val_loss: 187.3619\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 179.48197\n",
      "Epoch 520/5000\n",
      "ecpch:519,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.8474 - val_loss: 188.1292\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 179.48197\n",
      "Epoch 521/5000\n",
      "ecpch:520,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.9584 - val_loss: 187.6488\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 179.48197\n",
      "Epoch 522/5000\n",
      "ecpch:521,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.6837 - val_loss: 187.4026\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 179.48197\n",
      "Epoch 523/5000\n",
      "ecpch:522,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.7856 - val_loss: 188.0253\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 179.48197\n",
      "Epoch 524/5000\n",
      "ecpch:523,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 62.7547 - val_loss: 187.6786\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 179.48197\n",
      "Epoch 525/5000\n",
      "ecpch:524,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.6191 - val_loss: 187.4782\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 179.48197\n",
      "Epoch 526/5000\n",
      "ecpch:525,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 62.7113 - val_loss: 187.9621\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 179.48197\n",
      "Epoch 527/5000\n",
      "ecpch:526,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 62.6503 - val_loss: 187.6811\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 179.48197\n",
      "Epoch 528/5000\n",
      "ecpch:527,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 62.5883 - val_loss: 187.6164\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 179.48197\n",
      "Epoch 529/5000\n",
      "ecpch:528,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 62.6378 - val_loss: 187.9572\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 179.48197\n",
      "Epoch 530/5000\n",
      "ecpch:529,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.5964 - val_loss: 187.6374\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 179.48197\n",
      "Epoch 531/5000\n",
      "ecpch:530,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 62.5410 - val_loss: 187.7319\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 179.48197\n",
      "Epoch 532/5000\n",
      "ecpch:531,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.5804 - val_loss: 187.8769\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 179.48197\n",
      "Epoch 533/5000\n",
      "ecpch:532,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.5169 - val_loss: 187.6540\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 179.48197\n",
      "Epoch 534/5000\n",
      "ecpch:533,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.4923 - val_loss: 187.8980\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 179.48197\n",
      "Epoch 535/5000\n",
      "ecpch:534,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.5128 - val_loss: 187.7505\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 179.48197\n",
      "Epoch 536/5000\n",
      "ecpch:535,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.4647 - val_loss: 187.8151\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 179.48197\n",
      "Epoch 537/5000\n",
      "ecpch:536,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 62.4297 - val_loss: 187.9003\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 179.48197\n",
      "Epoch 538/5000\n",
      "ecpch:537,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 62.4175 - val_loss: 187.7317\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 179.48197\n",
      "Epoch 539/5000\n",
      "ecpch:538,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.4425 - val_loss: 188.0183\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 179.48197\n",
      "Epoch 540/5000\n",
      "ecpch:539,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.4540 - val_loss: 187.7998\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 179.48197\n",
      "Epoch 541/5000\n",
      "ecpch:540,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.4052 - val_loss: 187.9723\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 179.48197\n",
      "Epoch 542/5000\n",
      "ecpch:541,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.3697 - val_loss: 187.9488\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 179.48197\n",
      "Epoch 543/5000\n",
      "ecpch:542,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.3453 - val_loss: 187.9315\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 179.48197\n",
      "Epoch 544/5000\n",
      "ecpch:543,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.3305 - val_loss: 188.0210\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 179.48197\n",
      "Epoch 545/5000\n",
      "ecpch:544,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.3293 - val_loss: 187.8069\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 179.48197\n",
      "Epoch 546/5000\n",
      "ecpch:545,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.3744 - val_loss: 188.1857\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 179.48197\n",
      "Epoch 547/5000\n",
      "ecpch:546,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 62.4029 - val_loss: 187.7904\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 179.48197\n",
      "Epoch 548/5000\n",
      "ecpch:547,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.3670 - val_loss: 188.0904\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 179.48197\n",
      "Epoch 549/5000\n",
      "ecpch:548,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.3101 - val_loss: 187.9353\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 179.48197\n",
      "Epoch 550/5000\n",
      "ecpch:549,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.3522 - val_loss: 187.9747\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 179.48197\n",
      "Epoch 551/5000\n",
      "ecpch:550,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.3440 - val_loss: 188.0312\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 179.48197\n",
      "Epoch 552/5000\n",
      "ecpch:551,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.2596 - val_loss: 187.8064\n",
      "\n",
      "Epoch 00552: val_loss did not improve from 179.48197\n",
      "Epoch 553/5000\n",
      "ecpch:552,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 62.2863 - val_loss: 188.2239\n",
      "\n",
      "Epoch 00553: val_loss did not improve from 179.48197\n",
      "Epoch 554/5000\n",
      "ecpch:553,learn rate 0.000139\n",
      "64/64 [==============================] - 0s 8ms/step - loss: 62.3521 - val_loss: 187.8120\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 179.48197\n",
      "Epoch 555/5000\n",
      "ecpch:554,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 62.3421 - val_loss: 188.0551\n",
      "\n",
      "Epoch 00555: val_loss did not improve from 179.48197\n",
      "Epoch 556/5000\n",
      "ecpch:555,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.2184 - val_loss: 188.1662\n",
      "\n",
      "Epoch 00556: val_loss did not improve from 179.48197\n",
      "Epoch 557/5000\n",
      "ecpch:556,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 62.2282 - val_loss: 187.7591\n",
      "\n",
      "Epoch 00557: val_loss did not improve from 179.48197\n",
      "Epoch 558/5000\n",
      "ecpch:557,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.3585 - val_loss: 188.3217\n",
      "\n",
      "Epoch 00558: val_loss did not improve from 179.48197\n",
      "Epoch 559/5000\n",
      "ecpch:558,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 62.2656 - val_loss: 188.0021\n",
      "\n",
      "Epoch 00559: val_loss did not improve from 179.48197\n",
      "Epoch 560/5000\n",
      "ecpch:559,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.1752 - val_loss: 188.1147\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 179.48197\n",
      "Epoch 561/5000\n",
      "ecpch:560,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 62.1319 - val_loss: 188.3638\n",
      "\n",
      "Epoch 00561: val_loss did not improve from 179.48197\n",
      "Epoch 562/5000\n",
      "ecpch:561,learn rate 0.000139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 10ms/step - loss: 62.2087 - val_loss: 187.7993\n",
      "\n",
      "Epoch 00562: val_loss did not improve from 179.48197\n",
      "Epoch 563/5000\n",
      "ecpch:562,learn rate 0.000139\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 62.3745 - val_loss: 188.3355\n",
      "\n",
      "Epoch 00563: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 00563: ReduceLROnPlateau reducing learning rate to 0.00012552423868328333.\n",
      "Epoch 564/5000\n",
      "ecpch:563,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 62.1474 - val_loss: 188.2308\n",
      "\n",
      "Epoch 00564: val_loss did not improve from 179.48197\n",
      "Epoch 565/5000\n",
      "ecpch:564,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 62.1073 - val_loss: 187.9941\n",
      "\n",
      "Epoch 00565: val_loss did not improve from 179.48197\n",
      "Epoch 566/5000\n",
      "ecpch:565,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.2420 - val_loss: 188.3285\n",
      "\n",
      "Epoch 00566: val_loss did not improve from 179.48197\n",
      "Epoch 567/5000\n",
      "ecpch:566,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.1134 - val_loss: 188.1714\n",
      "\n",
      "Epoch 00567: val_loss did not improve from 179.48197\n",
      "Epoch 568/5000\n",
      "ecpch:567,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.0472 - val_loss: 188.1207\n",
      "\n",
      "Epoch 00568: val_loss did not improve from 179.48197\n",
      "Epoch 569/5000\n",
      "ecpch:568,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 62.0545 - val_loss: 188.2957\n",
      "\n",
      "Epoch 00569: val_loss did not improve from 179.48197\n",
      "Epoch 570/5000\n",
      "ecpch:569,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 62.0807 - val_loss: 188.0443\n",
      "\n",
      "Epoch 00570: val_loss did not improve from 179.48197\n",
      "Epoch 571/5000\n",
      "ecpch:570,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.0849 - val_loss: 188.2168\n",
      "\n",
      "Epoch 00571: val_loss did not improve from 179.48197\n",
      "Epoch 572/5000\n",
      "ecpch:571,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 62.0285 - val_loss: 188.1608\n",
      "\n",
      "Epoch 00572: val_loss did not improve from 179.48197\n",
      "Epoch 573/5000\n",
      "ecpch:572,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 62.0073 - val_loss: 188.1634\n",
      "\n",
      "Epoch 00573: val_loss did not improve from 179.48197\n",
      "Epoch 574/5000\n",
      "ecpch:573,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.9939 - val_loss: 188.2884\n",
      "\n",
      "Epoch 00574: val_loss did not improve from 179.48197\n",
      "Epoch 575/5000\n",
      "ecpch:574,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 62.0064 - val_loss: 188.0106\n",
      "\n",
      "Epoch 00575: val_loss did not improve from 179.48197\n",
      "Epoch 576/5000\n",
      "ecpch:575,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 62.0633 - val_loss: 188.4256\n",
      "\n",
      "Epoch 00576: val_loss did not improve from 179.48197\n",
      "Epoch 577/5000\n",
      "ecpch:576,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 62.0225 - val_loss: 188.1557\n",
      "\n",
      "Epoch 00577: val_loss did not improve from 179.48197\n",
      "Epoch 578/5000\n",
      "ecpch:577,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.9653 - val_loss: 188.3279\n",
      "\n",
      "Epoch 00578: val_loss did not improve from 179.48197\n",
      "Epoch 579/5000\n",
      "ecpch:578,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 61.9270 - val_loss: 188.2568\n",
      "\n",
      "Epoch 00579: val_loss did not improve from 179.48197\n",
      "Epoch 580/5000\n",
      "ecpch:579,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.9170 - val_loss: 188.3865\n",
      "\n",
      "Epoch 00580: val_loss did not improve from 179.48197\n",
      "Epoch 581/5000\n",
      "ecpch:580,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.9110 - val_loss: 188.1729\n",
      "\n",
      "Epoch 00581: val_loss did not improve from 179.48197\n",
      "Epoch 582/5000\n",
      "ecpch:581,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.9435 - val_loss: 188.5170\n",
      "\n",
      "Epoch 00582: val_loss did not improve from 179.48197\n",
      "Epoch 583/5000\n",
      "ecpch:582,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.9665 - val_loss: 188.1610\n",
      "\n",
      "Epoch 00583: val_loss did not improve from 179.48197\n",
      "Epoch 584/5000\n",
      "ecpch:583,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.9694 - val_loss: 188.4401\n",
      "\n",
      "Epoch 00584: val_loss did not improve from 179.48197\n",
      "Epoch 585/5000\n",
      "ecpch:584,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.8896 - val_loss: 188.3338\n",
      "\n",
      "Epoch 00585: val_loss did not improve from 179.48197\n",
      "Epoch 586/5000\n",
      "ecpch:585,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.8574 - val_loss: 188.4110\n",
      "\n",
      "Epoch 00586: val_loss did not improve from 179.48197\n",
      "Epoch 587/5000\n",
      "ecpch:586,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.8576 - val_loss: 188.3117\n",
      "\n",
      "Epoch 00587: val_loss did not improve from 179.48197\n",
      "Epoch 588/5000\n",
      "ecpch:587,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.8864 - val_loss: 188.4245\n",
      "\n",
      "Epoch 00588: val_loss did not improve from 179.48197\n",
      "Epoch 589/5000\n",
      "ecpch:588,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.8897 - val_loss: 188.3360\n",
      "\n",
      "Epoch 00589: val_loss did not improve from 179.48197\n",
      "Epoch 590/5000\n",
      "ecpch:589,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.8298 - val_loss: 188.4316\n",
      "\n",
      "Epoch 00590: val_loss did not improve from 179.48197\n",
      "Epoch 591/5000\n",
      "ecpch:590,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.7934 - val_loss: 188.2576\n",
      "\n",
      "Epoch 00591: val_loss did not improve from 179.48197\n",
      "Epoch 592/5000\n",
      "ecpch:591,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.8316 - val_loss: 188.6227\n",
      "\n",
      "Epoch 00592: val_loss did not improve from 179.48197\n",
      "Epoch 593/5000\n",
      "ecpch:592,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.9009 - val_loss: 188.2309\n",
      "\n",
      "Epoch 00593: val_loss did not improve from 179.48197\n",
      "Epoch 594/5000\n",
      "ecpch:593,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.8937 - val_loss: 188.4412\n",
      "\n",
      "Epoch 00594: val_loss did not improve from 179.48197\n",
      "Epoch 595/5000\n",
      "ecpch:594,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.7721 - val_loss: 188.5194\n",
      "\n",
      "Epoch 00595: val_loss did not improve from 179.48197\n",
      "Epoch 596/5000\n",
      "ecpch:595,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.7830 - val_loss: 188.1863\n",
      "\n",
      "Epoch 00596: val_loss did not improve from 179.48197\n",
      "Epoch 597/5000\n",
      "ecpch:596,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.8816 - val_loss: 188.6592\n",
      "\n",
      "Epoch 00597: val_loss did not improve from 179.48197\n",
      "Epoch 598/5000\n",
      "ecpch:597,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.8104 - val_loss: 188.3574\n",
      "\n",
      "Epoch 00598: val_loss did not improve from 179.48197\n",
      "Epoch 599/5000\n",
      "ecpch:598,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.7463 - val_loss: 188.5012\n",
      "\n",
      "Epoch 00599: val_loss did not improve from 179.48197\n",
      "Epoch 600/5000\n",
      "ecpch:599,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.7106 - val_loss: 188.6473\n",
      "\n",
      "Epoch 00600: val_loss did not improve from 179.48197\n",
      "Epoch 601/5000\n",
      "ecpch:600,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.8023 - val_loss: 188.2224\n",
      "\n",
      "Epoch 00601: val_loss did not improve from 179.48197\n",
      "Epoch 602/5000\n",
      "ecpch:601,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.8587 - val_loss: 188.6471\n",
      "\n",
      "Epoch 00602: val_loss did not improve from 179.48197\n",
      "Epoch 603/5000\n",
      "ecpch:602,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.6998 - val_loss: 188.4997\n",
      "\n",
      "Epoch 00603: val_loss did not improve from 179.48197\n",
      "Epoch 604/5000\n",
      "ecpch:603,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.6677 - val_loss: 188.4935\n",
      "\n",
      "Epoch 00604: val_loss did not improve from 179.48197\n",
      "Epoch 605/5000\n",
      "ecpch:604,learn rate 0.000126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 10ms/step - loss: 61.6850 - val_loss: 188.6671\n",
      "\n",
      "Epoch 00605: val_loss did not improve from 179.48197\n",
      "Epoch 606/5000\n",
      "ecpch:605,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.7358 - val_loss: 188.3833\n",
      "\n",
      "Epoch 00606: val_loss did not improve from 179.48197\n",
      "Epoch 607/5000\n",
      "ecpch:606,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.6932 - val_loss: 188.7093\n",
      "\n",
      "Epoch 00607: val_loss did not improve from 179.48197\n",
      "Epoch 608/5000\n",
      "ecpch:607,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.6656 - val_loss: 188.5190\n",
      "\n",
      "Epoch 00608: val_loss did not improve from 179.48197\n",
      "Epoch 609/5000\n",
      "ecpch:608,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.7127 - val_loss: 188.6020\n",
      "\n",
      "Epoch 00609: val_loss did not improve from 179.48197\n",
      "Epoch 610/5000\n",
      "ecpch:609,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.6283 - val_loss: 188.6244\n",
      "\n",
      "Epoch 00610: val_loss did not improve from 179.48197\n",
      "Epoch 611/5000\n",
      "ecpch:610,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.5891 - val_loss: 188.4998\n",
      "\n",
      "Epoch 00611: val_loss did not improve from 179.48197\n",
      "Epoch 612/5000\n",
      "ecpch:611,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.5833 - val_loss: 188.7359\n",
      "\n",
      "Epoch 00612: val_loss did not improve from 179.48197\n",
      "Epoch 613/5000\n",
      "ecpch:612,learn rate 0.000126\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.5962 - val_loss: 188.4142\n",
      "\n",
      "Epoch 00613: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 00613: ReduceLROnPlateau reducing learning rate to 0.000112971814814955.\n",
      "Epoch 614/5000\n",
      "ecpch:613,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.6310 - val_loss: 188.7333\n",
      "\n",
      "Epoch 00614: val_loss did not improve from 179.48197\n",
      "Epoch 615/5000\n",
      "ecpch:614,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.5628 - val_loss: 188.6230\n",
      "\n",
      "Epoch 00615: val_loss did not improve from 179.48197\n",
      "Epoch 616/5000\n",
      "ecpch:615,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.5298 - val_loss: 188.6057\n",
      "\n",
      "Epoch 00616: val_loss did not improve from 179.48197\n",
      "Epoch 617/5000\n",
      "ecpch:616,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.5239 - val_loss: 188.7745\n",
      "\n",
      "Epoch 00617: val_loss did not improve from 179.48197\n",
      "Epoch 618/5000\n",
      "ecpch:617,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.5476 - val_loss: 188.4859\n",
      "\n",
      "Epoch 00618: val_loss did not improve from 179.48197\n",
      "Epoch 619/5000\n",
      "ecpch:618,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.5743 - val_loss: 188.8305\n",
      "\n",
      "Epoch 00619: val_loss did not improve from 179.48197\n",
      "Epoch 620/5000\n",
      "ecpch:619,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.5296 - val_loss: 188.6516\n",
      "\n",
      "Epoch 00620: val_loss did not improve from 179.48197\n",
      "Epoch 621/5000\n",
      "ecpch:620,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.5343 - val_loss: 188.7002\n",
      "\n",
      "Epoch 00621: val_loss did not improve from 179.48197\n",
      "Epoch 622/5000\n",
      "ecpch:621,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.4959 - val_loss: 188.7588\n",
      "\n",
      "Epoch 00622: val_loss did not improve from 179.48197\n",
      "Epoch 623/5000\n",
      "ecpch:622,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.4678 - val_loss: 188.6021\n",
      "\n",
      "Epoch 00623: val_loss did not improve from 179.48197\n",
      "Epoch 624/5000\n",
      "ecpch:623,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.4750 - val_loss: 188.8700\n",
      "\n",
      "Epoch 00624: val_loss did not improve from 179.48197\n",
      "Epoch 625/5000\n",
      "ecpch:624,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 61.4706 - val_loss: 188.5989\n",
      "\n",
      "Epoch 00625: val_loss did not improve from 179.48197\n",
      "Epoch 626/5000\n",
      "ecpch:625,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.4623 - val_loss: 188.8729\n",
      "\n",
      "Epoch 00626: val_loss did not improve from 179.48197\n",
      "Epoch 627/5000\n",
      "ecpch:626,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.4384 - val_loss: 188.6274\n",
      "\n",
      "Epoch 00627: val_loss did not improve from 179.48197\n",
      "Epoch 628/5000\n",
      "ecpch:627,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.4424 - val_loss: 188.8424\n",
      "\n",
      "Epoch 00628: val_loss did not improve from 179.48197\n",
      "Epoch 629/5000\n",
      "ecpch:628,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.4351 - val_loss: 188.7113\n",
      "\n",
      "Epoch 00629: val_loss did not improve from 179.48197\n",
      "Epoch 630/5000\n",
      "ecpch:629,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.4146 - val_loss: 188.8199\n",
      "\n",
      "Epoch 00630: val_loss did not improve from 179.48197\n",
      "Epoch 631/5000\n",
      "ecpch:630,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 61.3869 - val_loss: 188.7962\n",
      "\n",
      "Epoch 00631: val_loss did not improve from 179.48197\n",
      "Epoch 632/5000\n",
      "ecpch:631,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.3567 - val_loss: 188.7870\n",
      "\n",
      "Epoch 00632: val_loss did not improve from 179.48197\n",
      "Epoch 633/5000\n",
      "ecpch:632,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.3508 - val_loss: 188.8619\n",
      "\n",
      "Epoch 00633: val_loss did not improve from 179.48197\n",
      "Epoch 634/5000\n",
      "ecpch:633,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.3702 - val_loss: 188.6934\n",
      "\n",
      "Epoch 00634: val_loss did not improve from 179.48197\n",
      "Epoch 635/5000\n",
      "ecpch:634,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.4371 - val_loss: 188.9435\n",
      "\n",
      "Epoch 00635: val_loss did not improve from 179.48197\n",
      "Epoch 636/5000\n",
      "ecpch:635,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.3518 - val_loss: 188.7306\n",
      "\n",
      "Epoch 00636: val_loss did not improve from 179.48197\n",
      "Epoch 637/5000\n",
      "ecpch:636,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.3502 - val_loss: 188.8910\n",
      "\n",
      "Epoch 00637: val_loss did not improve from 179.48197\n",
      "Epoch 638/5000\n",
      "ecpch:637,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.3939 - val_loss: 188.8498\n",
      "\n",
      "Epoch 00638: val_loss did not improve from 179.48197\n",
      "Epoch 639/5000\n",
      "ecpch:638,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.2942 - val_loss: 188.8365\n",
      "\n",
      "Epoch 00639: val_loss did not improve from 179.48197\n",
      "Epoch 640/5000\n",
      "ecpch:639,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.2662 - val_loss: 188.9473\n",
      "\n",
      "Epoch 00640: val_loss did not improve from 179.48197\n",
      "Epoch 641/5000\n",
      "ecpch:640,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.2855 - val_loss: 188.6485\n",
      "\n",
      "Epoch 00641: val_loss did not improve from 179.48197\n",
      "Epoch 642/5000\n",
      "ecpch:641,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.3935 - val_loss: 189.0221\n",
      "\n",
      "Epoch 00642: val_loss did not improve from 179.48197\n",
      "Epoch 643/5000\n",
      "ecpch:642,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.3070 - val_loss: 188.8019\n",
      "\n",
      "Epoch 00643: val_loss did not improve from 179.48197\n",
      "Epoch 644/5000\n",
      "ecpch:643,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.2476 - val_loss: 188.9819\n",
      "\n",
      "Epoch 00644: val_loss did not improve from 179.48197\n",
      "Epoch 645/5000\n",
      "ecpch:644,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.2530 - val_loss: 188.8289\n",
      "\n",
      "Epoch 00645: val_loss did not improve from 179.48197\n",
      "Epoch 646/5000\n",
      "ecpch:645,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.3427 - val_loss: 189.0005\n",
      "\n",
      "Epoch 00646: val_loss did not improve from 179.48197\n",
      "Epoch 647/5000\n",
      "ecpch:646,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.2249 - val_loss: 188.8158\n",
      "\n",
      "Epoch 00647: val_loss did not improve from 179.48197\n",
      "Epoch 648/5000\n",
      "ecpch:647,learn rate 0.000113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 9ms/step - loss: 61.2124 - val_loss: 189.0710\n",
      "\n",
      "Epoch 00648: val_loss did not improve from 179.48197\n",
      "Epoch 649/5000\n",
      "ecpch:648,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.2211 - val_loss: 188.7272\n",
      "\n",
      "Epoch 00649: val_loss did not improve from 179.48197\n",
      "Epoch 650/5000\n",
      "ecpch:649,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.2824 - val_loss: 189.0968\n",
      "\n",
      "Epoch 00650: val_loss did not improve from 179.48197\n",
      "Epoch 651/5000\n",
      "ecpch:650,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.2031 - val_loss: 188.8475\n",
      "\n",
      "Epoch 00651: val_loss did not improve from 179.48197\n",
      "Epoch 652/5000\n",
      "ecpch:651,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.1769 - val_loss: 189.0519\n",
      "\n",
      "Epoch 00652: val_loss did not improve from 179.48197\n",
      "Epoch 653/5000\n",
      "ecpch:652,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.1550 - val_loss: 188.9687\n",
      "\n",
      "Epoch 00653: val_loss did not improve from 179.48197\n",
      "Epoch 654/5000\n",
      "ecpch:653,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.2169 - val_loss: 189.0070\n",
      "\n",
      "Epoch 00654: val_loss did not improve from 179.48197\n",
      "Epoch 655/5000\n",
      "ecpch:654,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.1712 - val_loss: 189.0476\n",
      "\n",
      "Epoch 00655: val_loss did not improve from 179.48197\n",
      "Epoch 656/5000\n",
      "ecpch:655,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.1189 - val_loss: 188.8667\n",
      "\n",
      "Epoch 00656: val_loss did not improve from 179.48197\n",
      "Epoch 657/5000\n",
      "ecpch:656,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.1424 - val_loss: 189.2574\n",
      "\n",
      "Epoch 00657: val_loss did not improve from 179.48197\n",
      "Epoch 658/5000\n",
      "ecpch:657,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.2048 - val_loss: 188.8057\n",
      "\n",
      "Epoch 00658: val_loss did not improve from 179.48197\n",
      "Epoch 659/5000\n",
      "ecpch:658,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.1972 - val_loss: 189.1410\n",
      "\n",
      "Epoch 00659: val_loss did not improve from 179.48197\n",
      "Epoch 660/5000\n",
      "ecpch:659,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.0941 - val_loss: 189.0096\n",
      "\n",
      "Epoch 00660: val_loss did not improve from 179.48197\n",
      "Epoch 661/5000\n",
      "ecpch:660,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.0768 - val_loss: 189.0917\n",
      "\n",
      "Epoch 00661: val_loss did not improve from 179.48197\n",
      "Epoch 662/5000\n",
      "ecpch:661,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.1205 - val_loss: 189.1074\n",
      "\n",
      "Epoch 00662: val_loss did not improve from 179.48197\n",
      "Epoch 663/5000\n",
      "ecpch:662,learn rate 0.000113\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.0746 - val_loss: 188.9724\n",
      "\n",
      "Epoch 00663: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 00663: ReduceLROnPlateau reducing learning rate to 0.0001016746333334595.\n",
      "Epoch 664/5000\n",
      "ecpch:663,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.0729 - val_loss: 189.2239\n",
      "\n",
      "Epoch 00664: val_loss did not improve from 179.48197\n",
      "Epoch 665/5000\n",
      "ecpch:664,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.0646 - val_loss: 188.9381\n",
      "\n",
      "Epoch 00665: val_loss did not improve from 179.48197\n",
      "Epoch 666/5000\n",
      "ecpch:665,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.0499 - val_loss: 189.1394\n",
      "\n",
      "Epoch 00666: val_loss did not improve from 179.48197\n",
      "Epoch 667/5000\n",
      "ecpch:666,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 61.0053 - val_loss: 189.1123\n",
      "\n",
      "Epoch 00667: val_loss did not improve from 179.48197\n",
      "Epoch 668/5000\n",
      "ecpch:667,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 60.9921 - val_loss: 189.0989\n",
      "\n",
      "Epoch 00668: val_loss did not improve from 179.48197\n",
      "Epoch 669/5000\n",
      "ecpch:668,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.0099 - val_loss: 189.1860\n",
      "\n",
      "Epoch 00669: val_loss did not improve from 179.48197\n",
      "Epoch 670/5000\n",
      "ecpch:669,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.9931 - val_loss: 189.0078\n",
      "\n",
      "Epoch 00670: val_loss did not improve from 179.48197\n",
      "Epoch 671/5000\n",
      "ecpch:670,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.0227 - val_loss: 189.2526\n",
      "\n",
      "Epoch 00671: val_loss did not improve from 179.48197\n",
      "Epoch 672/5000\n",
      "ecpch:671,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 60.9802 - val_loss: 189.0492\n",
      "\n",
      "Epoch 00672: val_loss did not improve from 179.48197\n",
      "Epoch 673/5000\n",
      "ecpch:672,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 60.9585 - val_loss: 189.2327\n",
      "\n",
      "Epoch 00673: val_loss did not improve from 179.48197\n",
      "Epoch 674/5000\n",
      "ecpch:673,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.9646 - val_loss: 189.0981\n",
      "\n",
      "Epoch 00674: val_loss did not improve from 179.48197\n",
      "Epoch 675/5000\n",
      "ecpch:674,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.9714 - val_loss: 189.2335\n",
      "\n",
      "Epoch 00675: val_loss did not improve from 179.48197\n",
      "Epoch 676/5000\n",
      "ecpch:675,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 60.9253 - val_loss: 189.1479\n",
      "\n",
      "Epoch 00676: val_loss did not improve from 179.48197\n",
      "Epoch 677/5000\n",
      "ecpch:676,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.8961 - val_loss: 189.2350\n",
      "\n",
      "Epoch 00677: val_loss did not improve from 179.48197\n",
      "Epoch 678/5000\n",
      "ecpch:677,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.9137 - val_loss: 189.1703\n",
      "\n",
      "Epoch 00678: val_loss did not improve from 179.48197\n",
      "Epoch 679/5000\n",
      "ecpch:678,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.9957 - val_loss: 189.2686\n",
      "\n",
      "Epoch 00679: val_loss did not improve from 179.48197\n",
      "Epoch 680/5000\n",
      "ecpch:679,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 60.8805 - val_loss: 189.1160\n",
      "\n",
      "Epoch 00680: val_loss did not improve from 179.48197\n",
      "Epoch 681/5000\n",
      "ecpch:680,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.8857 - val_loss: 189.3447\n",
      "\n",
      "Epoch 00681: val_loss did not improve from 179.48197\n",
      "Epoch 682/5000\n",
      "ecpch:681,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.9481 - val_loss: 189.1019\n",
      "\n",
      "Epoch 00682: val_loss did not improve from 179.48197\n",
      "Epoch 683/5000\n",
      "ecpch:682,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.9026 - val_loss: 189.2991\n",
      "\n",
      "Epoch 00683: val_loss did not improve from 179.48197\n",
      "Epoch 684/5000\n",
      "ecpch:683,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.8406 - val_loss: 189.1316\n",
      "\n",
      "Epoch 00684: val_loss did not improve from 179.48197\n",
      "Epoch 685/5000\n",
      "ecpch:684,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.8534 - val_loss: 189.3772\n",
      "\n",
      "Epoch 00685: val_loss did not improve from 179.48197\n",
      "Epoch 686/5000\n",
      "ecpch:685,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.8862 - val_loss: 189.1757\n",
      "\n",
      "Epoch 00686: val_loss did not improve from 179.48197\n",
      "Epoch 687/5000\n",
      "ecpch:686,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.9097 - val_loss: 189.3013\n",
      "\n",
      "Epoch 00687: val_loss did not improve from 179.48197\n",
      "Epoch 688/5000\n",
      "ecpch:687,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.7910 - val_loss: 189.3331\n",
      "\n",
      "Epoch 00688: val_loss did not improve from 179.48197\n",
      "Epoch 689/5000\n",
      "ecpch:688,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 60.8266 - val_loss: 189.2217\n",
      "\n",
      "Epoch 00689: val_loss did not improve from 179.48197\n",
      "Epoch 690/5000\n",
      "ecpch:689,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.9484 - val_loss: 189.3833\n",
      "\n",
      "Epoch 00690: val_loss did not improve from 179.48197\n",
      "Epoch 691/5000\n",
      "ecpch:690,learn rate 0.000102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 10ms/step - loss: 60.7768 - val_loss: 189.1423\n",
      "\n",
      "Epoch 00691: val_loss did not improve from 179.48197\n",
      "Epoch 692/5000\n",
      "ecpch:691,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 61.0146 - val_loss: 189.3448\n",
      "\n",
      "Epoch 00692: val_loss did not improve from 179.48197\n",
      "Epoch 693/5000\n",
      "ecpch:692,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.7583 - val_loss: 189.5131\n",
      "\n",
      "Epoch 00693: val_loss did not improve from 179.48197\n",
      "Epoch 694/5000\n",
      "ecpch:693,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.8356 - val_loss: 189.0774\n",
      "\n",
      "Epoch 00694: val_loss did not improve from 179.48197\n",
      "Epoch 695/5000\n",
      "ecpch:694,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 61.0009 - val_loss: 189.3749\n",
      "\n",
      "Epoch 00695: val_loss did not improve from 179.48197\n",
      "Epoch 696/5000\n",
      "ecpch:695,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 60.7261 - val_loss: 189.7520\n",
      "\n",
      "Epoch 00696: val_loss did not improve from 179.48197\n",
      "Epoch 697/5000\n",
      "ecpch:696,learn rate 0.000102\n",
      "64/64 [==============================] - 0s 8ms/step - loss: 61.0809 - val_loss: 189.2012\n",
      "\n",
      "Epoch 00697: val_loss did not improve from 179.48197\n",
      "Epoch 698/5000\n",
      "ecpch:697,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 60.7900 - val_loss: 189.3462\n",
      "\n",
      "Epoch 00698: val_loss did not improve from 179.48197\n",
      "Epoch 699/5000\n",
      "ecpch:698,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 60.8743 - val_loss: 189.5673\n",
      "\n",
      "Epoch 00699: val_loss did not improve from 179.48197\n",
      "Epoch 700/5000\n",
      "ecpch:699,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 60.7980 - val_loss: 189.1155\n",
      "\n",
      "Epoch 00700: val_loss did not improve from 179.48197\n",
      "Epoch 701/5000\n",
      "ecpch:700,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 60.8779 - val_loss: 189.3726\n",
      "\n",
      "Epoch 00701: val_loss did not improve from 179.48197\n",
      "Epoch 702/5000\n",
      "ecpch:701,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 60.7845 - val_loss: 189.6148\n",
      "\n",
      "Epoch 00702: val_loss did not improve from 179.48197\n",
      "Epoch 703/5000\n",
      "ecpch:702,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 60.7844 - val_loss: 189.0765\n",
      "\n",
      "Epoch 00703: val_loss did not improve from 179.48197\n",
      "Epoch 704/5000\n",
      "ecpch:703,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.9277 - val_loss: 189.3352\n",
      "\n",
      "Epoch 00704: val_loss did not improve from 179.48197\n",
      "Epoch 705/5000\n",
      "ecpch:704,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.6923 - val_loss: 189.8420\n",
      "\n",
      "Epoch 00705: val_loss did not improve from 179.48197\n",
      "Epoch 706/5000\n",
      "ecpch:705,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 60.9416 - val_loss: 189.2329\n",
      "\n",
      "Epoch 00706: val_loss did not improve from 179.48197\n",
      "Epoch 707/5000\n",
      "ecpch:706,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.7607 - val_loss: 189.2635\n",
      "\n",
      "Epoch 00707: val_loss did not improve from 179.48197\n",
      "Epoch 708/5000\n",
      "ecpch:707,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 60.7157 - val_loss: 189.8880\n",
      "\n",
      "Epoch 00708: val_loss did not improve from 179.48197\n",
      "Epoch 709/5000\n",
      "ecpch:708,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.9349 - val_loss: 189.3459\n",
      "\n",
      "Epoch 00709: val_loss did not improve from 179.48197\n",
      "Epoch 710/5000\n",
      "ecpch:709,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.6288 - val_loss: 189.2420\n",
      "\n",
      "Epoch 00710: val_loss did not improve from 179.48197\n",
      "Epoch 711/5000\n",
      "ecpch:710,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.7045 - val_loss: 189.6841\n",
      "\n",
      "Epoch 00711: val_loss did not improve from 179.48197\n",
      "Epoch 712/5000\n",
      "ecpch:711,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.7249 - val_loss: 189.3610\n",
      "\n",
      "Epoch 00712: val_loss did not improve from 179.48197\n",
      "Epoch 713/5000\n",
      "ecpch:712,learn rate 0.000102\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 60.5813 - val_loss: 189.3339\n",
      "\n",
      "Epoch 00713: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 00713: ReduceLROnPlateau reducing learning rate to 9.150716869044118e-05.\n",
      "Epoch 714/5000\n",
      "ecpch:713,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 60.6381 - val_loss: 189.5925\n",
      "\n",
      "Epoch 00714: val_loss did not improve from 179.48197\n",
      "Epoch 715/5000\n",
      "ecpch:714,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.6184 - val_loss: 189.3939\n",
      "\n",
      "Epoch 00715: val_loss did not improve from 179.48197\n",
      "Epoch 716/5000\n",
      "ecpch:715,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 60.5574 - val_loss: 189.5092\n",
      "\n",
      "Epoch 00716: val_loss did not improve from 179.48197\n",
      "Epoch 717/5000\n",
      "ecpch:716,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 60.6089 - val_loss: 189.4760\n",
      "\n",
      "Epoch 00717: val_loss did not improve from 179.48197\n",
      "Epoch 718/5000\n",
      "ecpch:717,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 60.5423 - val_loss: 189.5818\n",
      "\n",
      "Epoch 00718: val_loss did not improve from 179.48197\n",
      "Epoch 719/5000\n",
      "ecpch:718,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 60.5098 - val_loss: 189.4302\n",
      "\n",
      "Epoch 00719: val_loss did not improve from 179.48197\n",
      "Epoch 720/5000\n",
      "ecpch:719,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 60.5272 - val_loss: 189.6123\n",
      "\n",
      "Epoch 00720: val_loss did not improve from 179.48197\n",
      "Epoch 721/5000\n",
      "ecpch:720,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.5094 - val_loss: 189.4976\n",
      "\n",
      "Epoch 00721: val_loss did not improve from 179.48197\n",
      "Epoch 722/5000\n",
      "ecpch:721,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 60.4856 - val_loss: 189.5974\n",
      "\n",
      "Epoch 00722: val_loss did not improve from 179.48197\n",
      "Epoch 723/5000\n",
      "ecpch:722,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 60.4695 - val_loss: 189.5358\n",
      "\n",
      "Epoch 00723: val_loss did not improve from 179.48197\n",
      "Epoch 724/5000\n",
      "ecpch:723,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.4587 - val_loss: 189.6271\n",
      "\n",
      "Epoch 00724: val_loss did not improve from 179.48197\n",
      "Epoch 725/5000\n",
      "ecpch:724,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.4461 - val_loss: 189.5371\n",
      "\n",
      "Epoch 00725: val_loss did not improve from 179.48197\n",
      "Epoch 726/5000\n",
      "ecpch:725,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.4482 - val_loss: 189.7513\n",
      "\n",
      "Epoch 00726: val_loss did not improve from 179.48197\n",
      "Epoch 727/5000\n",
      "ecpch:726,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.4859 - val_loss: 189.5230\n",
      "\n",
      "Epoch 00727: val_loss did not improve from 179.48197\n",
      "Epoch 728/5000\n",
      "ecpch:727,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.5062 - val_loss: 189.6870\n",
      "\n",
      "Epoch 00728: val_loss did not improve from 179.48197\n",
      "Epoch 729/5000\n",
      "ecpch:728,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.4295 - val_loss: 189.6697\n",
      "\n",
      "Epoch 00729: val_loss did not improve from 179.48197\n",
      "Epoch 730/5000\n",
      "ecpch:729,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.4008 - val_loss: 189.6690\n",
      "\n",
      "Epoch 00730: val_loss did not improve from 179.48197\n",
      "Epoch 731/5000\n",
      "ecpch:730,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.4260 - val_loss: 189.6910\n",
      "\n",
      "Epoch 00731: val_loss did not improve from 179.48197\n",
      "Epoch 732/5000\n",
      "ecpch:731,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.4732 - val_loss: 189.6181\n",
      "\n",
      "Epoch 00732: val_loss did not improve from 179.48197\n",
      "Epoch 733/5000\n",
      "ecpch:732,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.3926 - val_loss: 189.7723\n",
      "\n",
      "Epoch 00733: val_loss did not improve from 179.48197\n",
      "Epoch 734/5000\n",
      "ecpch:733,learn rate 0.000092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 10ms/step - loss: 60.4063 - val_loss: 189.4486\n",
      "\n",
      "Epoch 00734: val_loss did not improve from 179.48197\n",
      "Epoch 735/5000\n",
      "ecpch:734,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 60.4944 - val_loss: 189.6977\n",
      "\n",
      "Epoch 00735: val_loss did not improve from 179.48197\n",
      "Epoch 736/5000\n",
      "ecpch:735,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 60.3699 - val_loss: 189.7659\n",
      "\n",
      "Epoch 00736: val_loss did not improve from 179.48197\n",
      "Epoch 737/5000\n",
      "ecpch:736,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.3695 - val_loss: 189.4119\n",
      "\n",
      "Epoch 00737: val_loss did not improve from 179.48197\n",
      "Epoch 738/5000\n",
      "ecpch:737,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 60.5306 - val_loss: 189.7391\n",
      "\n",
      "Epoch 00738: val_loss did not improve from 179.48197\n",
      "Epoch 739/5000\n",
      "ecpch:738,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.3282 - val_loss: 189.9581\n",
      "\n",
      "Epoch 00739: val_loss did not improve from 179.48197\n",
      "Epoch 740/5000\n",
      "ecpch:739,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.4412 - val_loss: 189.4494\n",
      "\n",
      "Epoch 00740: val_loss did not improve from 179.48197\n",
      "Epoch 741/5000\n",
      "ecpch:740,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.5381 - val_loss: 189.7102\n",
      "\n",
      "Epoch 00741: val_loss did not improve from 179.48197\n",
      "Epoch 742/5000\n",
      "ecpch:741,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.3105 - val_loss: 190.2840\n",
      "\n",
      "Epoch 00742: val_loss did not improve from 179.48197\n",
      "Epoch 743/5000\n",
      "ecpch:742,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.7339 - val_loss: 189.7036\n",
      "\n",
      "Epoch 00743: val_loss did not improve from 179.48197\n",
      "Epoch 744/5000\n",
      "ecpch:743,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.2966 - val_loss: 189.5679\n",
      "\n",
      "Epoch 00744: val_loss did not improve from 179.48197\n",
      "Epoch 745/5000\n",
      "ecpch:744,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 60.4119 - val_loss: 190.0264\n",
      "\n",
      "Epoch 00745: val_loss did not improve from 179.48197\n",
      "Epoch 746/5000\n",
      "ecpch:745,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 60.4327 - val_loss: 189.7481\n",
      "\n",
      "Epoch 00746: val_loss did not improve from 179.48197\n",
      "Epoch 747/5000\n",
      "ecpch:746,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 60.2491 - val_loss: 189.5765\n",
      "\n",
      "Epoch 00747: val_loss did not improve from 179.48197\n",
      "Epoch 748/5000\n",
      "ecpch:747,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.3517 - val_loss: 189.9612\n",
      "\n",
      "Epoch 00748: val_loss did not improve from 179.48197\n",
      "Epoch 749/5000\n",
      "ecpch:748,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.3638 - val_loss: 189.7212\n",
      "\n",
      "Epoch 00749: val_loss did not improve from 179.48197\n",
      "Epoch 750/5000\n",
      "ecpch:749,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.2247 - val_loss: 189.6871\n",
      "\n",
      "Epoch 00750: val_loss did not improve from 179.48197\n",
      "Epoch 751/5000\n",
      "ecpch:750,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.2579 - val_loss: 189.9431\n",
      "\n",
      "Epoch 00751: val_loss did not improve from 179.48197\n",
      "Epoch 752/5000\n",
      "ecpch:751,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.3353 - val_loss: 189.7239\n",
      "\n",
      "Epoch 00752: val_loss did not improve from 179.48197\n",
      "Epoch 753/5000\n",
      "ecpch:752,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.2180 - val_loss: 189.8090\n",
      "\n",
      "Epoch 00753: val_loss did not improve from 179.48197\n",
      "Epoch 754/5000\n",
      "ecpch:753,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.2069 - val_loss: 189.8553\n",
      "\n",
      "Epoch 00754: val_loss did not improve from 179.48197\n",
      "Epoch 755/5000\n",
      "ecpch:754,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.3030 - val_loss: 189.8173\n",
      "\n",
      "Epoch 00755: val_loss did not improve from 179.48197\n",
      "Epoch 756/5000\n",
      "ecpch:755,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.1778 - val_loss: 189.8322\n",
      "\n",
      "Epoch 00756: val_loss did not improve from 179.48197\n",
      "Epoch 757/5000\n",
      "ecpch:756,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.1797 - val_loss: 189.8451\n",
      "\n",
      "Epoch 00757: val_loss did not improve from 179.48197\n",
      "Epoch 758/5000\n",
      "ecpch:757,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.2906 - val_loss: 189.8984\n",
      "\n",
      "Epoch 00758: val_loss did not improve from 179.48197\n",
      "Epoch 759/5000\n",
      "ecpch:758,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.1558 - val_loss: 189.6897\n",
      "\n",
      "Epoch 00759: val_loss did not improve from 179.48197\n",
      "Epoch 760/5000\n",
      "ecpch:759,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.3137 - val_loss: 189.9195\n",
      "\n",
      "Epoch 00760: val_loss did not improve from 179.48197\n",
      "Epoch 761/5000\n",
      "ecpch:760,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.2006 - val_loss: 190.0201\n",
      "\n",
      "Epoch 00761: val_loss did not improve from 179.48197\n",
      "Epoch 762/5000\n",
      "ecpch:761,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.1764 - val_loss: 189.6817\n",
      "\n",
      "Epoch 00762: val_loss did not improve from 179.48197\n",
      "Epoch 763/5000\n",
      "ecpch:762,learn rate 0.000092\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.3360 - val_loss: 189.9285\n",
      "\n",
      "Epoch 00763: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 00763: ReduceLROnPlateau reducing learning rate to 8.235645509557799e-05.\n",
      "Epoch 764/5000\n",
      "ecpch:763,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 60.1021 - val_loss: 190.2006\n",
      "\n",
      "Epoch 00764: val_loss did not improve from 179.48197\n",
      "Epoch 765/5000\n",
      "ecpch:764,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 60.2813 - val_loss: 189.7969\n",
      "\n",
      "Epoch 00765: val_loss did not improve from 179.48197\n",
      "Epoch 766/5000\n",
      "ecpch:765,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.1531 - val_loss: 189.8819\n",
      "\n",
      "Epoch 00766: val_loss did not improve from 179.48197\n",
      "Epoch 767/5000\n",
      "ecpch:766,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.1177 - val_loss: 190.1741\n",
      "\n",
      "Epoch 00767: val_loss did not improve from 179.48197\n",
      "Epoch 768/5000\n",
      "ecpch:767,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.2251 - val_loss: 189.8587\n",
      "\n",
      "Epoch 00768: val_loss did not improve from 179.48197\n",
      "Epoch 769/5000\n",
      "ecpch:768,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.0930 - val_loss: 189.9267\n",
      "\n",
      "Epoch 00769: val_loss did not improve from 179.48197\n",
      "Epoch 770/5000\n",
      "ecpch:769,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.1991 - val_loss: 190.0679\n",
      "\n",
      "Epoch 00770: val_loss did not improve from 179.48197\n",
      "Epoch 771/5000\n",
      "ecpch:770,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.0858 - val_loss: 189.8288\n",
      "\n",
      "Epoch 00771: val_loss did not improve from 179.48197\n",
      "Epoch 772/5000\n",
      "ecpch:771,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.1633 - val_loss: 189.9896\n",
      "\n",
      "Epoch 00772: val_loss did not improve from 179.48197\n",
      "Epoch 773/5000\n",
      "ecpch:772,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.1073 - val_loss: 190.0883\n",
      "\n",
      "Epoch 00773: val_loss did not improve from 179.48197\n",
      "Epoch 774/5000\n",
      "ecpch:773,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.0403 - val_loss: 189.8478\n",
      "\n",
      "Epoch 00774: val_loss did not improve from 179.48197\n",
      "Epoch 775/5000\n",
      "ecpch:774,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.1435 - val_loss: 190.0368\n",
      "\n",
      "Epoch 00775: val_loss did not improve from 179.48197\n",
      "Epoch 776/5000\n",
      "ecpch:775,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 60.0359 - val_loss: 190.1295\n",
      "\n",
      "Epoch 00776: val_loss did not improve from 179.48197\n",
      "Epoch 777/5000\n",
      "ecpch:776,learn rate 0.000082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 9ms/step - loss: 60.0248 - val_loss: 189.8483\n",
      "\n",
      "Epoch 00777: val_loss did not improve from 179.48197\n",
      "Epoch 778/5000\n",
      "ecpch:777,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 60.0876 - val_loss: 190.1036\n",
      "\n",
      "Epoch 00778: val_loss did not improve from 179.48197\n",
      "Epoch 779/5000\n",
      "ecpch:778,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 60.0004 - val_loss: 190.0589\n",
      "\n",
      "Epoch 00779: val_loss did not improve from 179.48197\n",
      "Epoch 780/5000\n",
      "ecpch:779,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.9995 - val_loss: 189.9690\n",
      "\n",
      "Epoch 00780: val_loss did not improve from 179.48197\n",
      "Epoch 781/5000\n",
      "ecpch:780,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.9971 - val_loss: 190.0718\n",
      "\n",
      "Epoch 00781: val_loss did not improve from 179.48197\n",
      "Epoch 782/5000\n",
      "ecpch:781,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.9610 - val_loss: 189.9959\n",
      "\n",
      "Epoch 00782: val_loss did not improve from 179.48197\n",
      "Epoch 783/5000\n",
      "ecpch:782,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.9477 - val_loss: 190.0729\n",
      "\n",
      "Epoch 00783: val_loss did not improve from 179.48197\n",
      "Epoch 784/5000\n",
      "ecpch:783,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.9380 - val_loss: 189.9524\n",
      "\n",
      "Epoch 00784: val_loss did not improve from 179.48197\n",
      "Epoch 785/5000\n",
      "ecpch:784,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.9545 - val_loss: 190.2031\n",
      "\n",
      "Epoch 00785: val_loss did not improve from 179.48197\n",
      "Epoch 786/5000\n",
      "ecpch:785,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.9753 - val_loss: 189.9684\n",
      "\n",
      "Epoch 00786: val_loss did not improve from 179.48197\n",
      "Epoch 787/5000\n",
      "ecpch:786,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.9539 - val_loss: 190.1848\n",
      "\n",
      "Epoch 00787: val_loss did not improve from 179.48197\n",
      "Epoch 788/5000\n",
      "ecpch:787,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.9206 - val_loss: 190.0392\n",
      "\n",
      "Epoch 00788: val_loss did not improve from 179.48197\n",
      "Epoch 789/5000\n",
      "ecpch:788,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 59.9174 - val_loss: 190.2159\n",
      "\n",
      "Epoch 00789: val_loss did not improve from 179.48197\n",
      "Epoch 790/5000\n",
      "ecpch:789,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.9070 - val_loss: 190.0447\n",
      "\n",
      "Epoch 00790: val_loss did not improve from 179.48197\n",
      "Epoch 791/5000\n",
      "ecpch:790,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.9188 - val_loss: 190.2422\n",
      "\n",
      "Epoch 00791: val_loss did not improve from 179.48197\n",
      "Epoch 792/5000\n",
      "ecpch:791,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.9011 - val_loss: 190.0438\n",
      "\n",
      "Epoch 00792: val_loss did not improve from 179.48197\n",
      "Epoch 793/5000\n",
      "ecpch:792,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 59.9010 - val_loss: 190.2204\n",
      "\n",
      "Epoch 00793: val_loss did not improve from 179.48197\n",
      "Epoch 794/5000\n",
      "ecpch:793,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.8669 - val_loss: 190.0844\n",
      "\n",
      "Epoch 00794: val_loss did not improve from 179.48197\n",
      "Epoch 795/5000\n",
      "ecpch:794,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.8912 - val_loss: 190.1919\n",
      "\n",
      "Epoch 00795: val_loss did not improve from 179.48197\n",
      "Epoch 796/5000\n",
      "ecpch:795,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.9071 - val_loss: 190.1574\n",
      "\n",
      "Epoch 00796: val_loss did not improve from 179.48197\n",
      "Epoch 797/5000\n",
      "ecpch:796,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.8571 - val_loss: 190.1628\n",
      "\n",
      "Epoch 00797: val_loss did not improve from 179.48197\n",
      "Epoch 798/5000\n",
      "ecpch:797,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.8201 - val_loss: 190.1835\n",
      "\n",
      "Epoch 00798: val_loss did not improve from 179.48197\n",
      "Epoch 799/5000\n",
      "ecpch:798,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.8117 - val_loss: 190.0853\n",
      "\n",
      "Epoch 00799: val_loss did not improve from 179.48197\n",
      "Epoch 800/5000\n",
      "ecpch:799,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.8271 - val_loss: 190.3049\n",
      "\n",
      "Epoch 00800: val_loss did not improve from 179.48197\n",
      "Epoch 801/5000\n",
      "ecpch:800,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.8402 - val_loss: 190.0459\n",
      "\n",
      "Epoch 00801: val_loss did not improve from 179.48197\n",
      "Epoch 802/5000\n",
      "ecpch:801,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.8601 - val_loss: 190.3286\n",
      "\n",
      "Epoch 00802: val_loss did not improve from 179.48197\n",
      "Epoch 803/5000\n",
      "ecpch:802,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.8114 - val_loss: 190.1504\n",
      "\n",
      "Epoch 00803: val_loss did not improve from 179.48197\n",
      "Epoch 804/5000\n",
      "ecpch:803,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.7909 - val_loss: 190.3252\n",
      "\n",
      "Epoch 00804: val_loss did not improve from 179.48197\n",
      "Epoch 805/5000\n",
      "ecpch:804,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.7866 - val_loss: 190.1512\n",
      "\n",
      "Epoch 00805: val_loss did not improve from 179.48197\n",
      "Epoch 806/5000\n",
      "ecpch:805,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.8243 - val_loss: 190.3264\n",
      "\n",
      "Epoch 00806: val_loss did not improve from 179.48197\n",
      "Epoch 807/5000\n",
      "ecpch:806,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.8028 - val_loss: 190.2017\n",
      "\n",
      "Epoch 00807: val_loss did not improve from 179.48197\n",
      "Epoch 808/5000\n",
      "ecpch:807,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.7843 - val_loss: 190.3059\n",
      "\n",
      "Epoch 00808: val_loss did not improve from 179.48197\n",
      "Epoch 809/5000\n",
      "ecpch:808,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.7509 - val_loss: 190.1617\n",
      "\n",
      "Epoch 00809: val_loss did not improve from 179.48197\n",
      "Epoch 810/5000\n",
      "ecpch:809,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.7790 - val_loss: 190.3248\n",
      "\n",
      "Epoch 00810: val_loss did not improve from 179.48197\n",
      "Epoch 811/5000\n",
      "ecpch:810,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.7678 - val_loss: 190.1440\n",
      "\n",
      "Epoch 00811: val_loss did not improve from 179.48197\n",
      "Epoch 812/5000\n",
      "ecpch:811,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.7637 - val_loss: 190.3139\n",
      "\n",
      "Epoch 00812: val_loss did not improve from 179.48197\n",
      "Epoch 813/5000\n",
      "ecpch:812,learn rate 0.000082\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.7179 - val_loss: 190.1942\n",
      "\n",
      "Epoch 00813: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 00813: ReduceLROnPlateau reducing learning rate to 7.412080958602019e-05.\n",
      "Epoch 814/5000\n",
      "ecpch:813,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.7065 - val_loss: 190.3104\n",
      "\n",
      "Epoch 00814: val_loss did not improve from 179.48197\n",
      "Epoch 815/5000\n",
      "ecpch:814,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.6942 - val_loss: 190.2740\n",
      "\n",
      "Epoch 00815: val_loss did not improve from 179.48197\n",
      "Epoch 816/5000\n",
      "ecpch:815,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.6866 - val_loss: 190.2624\n",
      "\n",
      "Epoch 00816: val_loss did not improve from 179.48197\n",
      "Epoch 817/5000\n",
      "ecpch:816,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.6826 - val_loss: 190.3761\n",
      "\n",
      "Epoch 00817: val_loss did not improve from 179.48197\n",
      "Epoch 818/5000\n",
      "ecpch:817,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.6928 - val_loss: 190.2185\n",
      "\n",
      "Epoch 00818: val_loss did not improve from 179.48197\n",
      "Epoch 819/5000\n",
      "ecpch:818,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.6934 - val_loss: 190.4093\n",
      "\n",
      "Epoch 00819: val_loss did not improve from 179.48197\n",
      "Epoch 820/5000\n",
      "ecpch:819,learn rate 0.000074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 10ms/step - loss: 59.6557 - val_loss: 190.2856\n",
      "\n",
      "Epoch 00820: val_loss did not improve from 179.48197\n",
      "Epoch 821/5000\n",
      "ecpch:820,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.6513 - val_loss: 190.4276\n",
      "\n",
      "Epoch 00821: val_loss did not improve from 179.48197\n",
      "Epoch 822/5000\n",
      "ecpch:821,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.6583 - val_loss: 190.3146\n",
      "\n",
      "Epoch 00822: val_loss did not improve from 179.48197\n",
      "Epoch 823/5000\n",
      "ecpch:822,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.6832 - val_loss: 190.4156\n",
      "\n",
      "Epoch 00823: val_loss did not improve from 179.48197\n",
      "Epoch 824/5000\n",
      "ecpch:823,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.6208 - val_loss: 190.3648\n",
      "\n",
      "Epoch 00824: val_loss did not improve from 179.48197\n",
      "Epoch 825/5000\n",
      "ecpch:824,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.6033 - val_loss: 190.3633\n",
      "\n",
      "Epoch 00825: val_loss did not improve from 179.48197\n",
      "Epoch 826/5000\n",
      "ecpch:825,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.5927 - val_loss: 190.4347\n",
      "\n",
      "Epoch 00826: val_loss did not improve from 179.48197\n",
      "Epoch 827/5000\n",
      "ecpch:826,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.5942 - val_loss: 190.2127\n",
      "\n",
      "Epoch 00827: val_loss did not improve from 179.48197\n",
      "Epoch 828/5000\n",
      "ecpch:827,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.6630 - val_loss: 190.4930\n",
      "\n",
      "Epoch 00828: val_loss did not improve from 179.48197\n",
      "Epoch 829/5000\n",
      "ecpch:828,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.6103 - val_loss: 190.3205\n",
      "\n",
      "Epoch 00829: val_loss did not improve from 179.48197\n",
      "Epoch 830/5000\n",
      "ecpch:829,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.5898 - val_loss: 190.4267\n",
      "\n",
      "Epoch 00830: val_loss did not improve from 179.48197\n",
      "Epoch 831/5000\n",
      "ecpch:830,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.5657 - val_loss: 190.4438\n",
      "\n",
      "Epoch 00831: val_loss did not improve from 179.48197\n",
      "Epoch 832/5000\n",
      "ecpch:831,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 59.5866 - val_loss: 190.3945\n",
      "\n",
      "Epoch 00832: val_loss did not improve from 179.48197\n",
      "Epoch 833/5000\n",
      "ecpch:832,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.6102 - val_loss: 190.5159\n",
      "\n",
      "Epoch 00833: val_loss did not improve from 179.48197\n",
      "Epoch 834/5000\n",
      "ecpch:833,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.5560 - val_loss: 190.3068\n",
      "\n",
      "Epoch 00834: val_loss did not improve from 179.48197\n",
      "Epoch 835/5000\n",
      "ecpch:834,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.5907 - val_loss: 190.5554\n",
      "\n",
      "Epoch 00835: val_loss did not improve from 179.48197\n",
      "Epoch 836/5000\n",
      "ecpch:835,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.5603 - val_loss: 190.3809\n",
      "\n",
      "Epoch 00836: val_loss did not improve from 179.48197\n",
      "Epoch 837/5000\n",
      "ecpch:836,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.5476 - val_loss: 190.4870\n",
      "\n",
      "Epoch 00837: val_loss did not improve from 179.48197\n",
      "Epoch 838/5000\n",
      "ecpch:837,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.5304 - val_loss: 190.4933\n",
      "\n",
      "Epoch 00838: val_loss did not improve from 179.48197\n",
      "Epoch 839/5000\n",
      "ecpch:838,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.5343 - val_loss: 190.3969\n",
      "\n",
      "Epoch 00839: val_loss did not improve from 179.48197\n",
      "Epoch 840/5000\n",
      "ecpch:839,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.5474 - val_loss: 190.5785\n",
      "\n",
      "Epoch 00840: val_loss did not improve from 179.48197\n",
      "Epoch 841/5000\n",
      "ecpch:840,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.5259 - val_loss: 190.3169\n",
      "\n",
      "Epoch 00841: val_loss did not improve from 179.48197\n",
      "Epoch 842/5000\n",
      "ecpch:841,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.5634 - val_loss: 190.4972\n",
      "\n",
      "Epoch 00842: val_loss did not improve from 179.48197\n",
      "Epoch 843/5000\n",
      "ecpch:842,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.5229 - val_loss: 190.6233\n",
      "\n",
      "Epoch 00843: val_loss did not improve from 179.48197\n",
      "Epoch 844/5000\n",
      "ecpch:843,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.5275 - val_loss: 190.2611\n",
      "\n",
      "Epoch 00844: val_loss did not improve from 179.48197\n",
      "Epoch 845/5000\n",
      "ecpch:844,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 59.6180 - val_loss: 190.4728\n",
      "\n",
      "Epoch 00845: val_loss did not improve from 179.48197\n",
      "Epoch 846/5000\n",
      "ecpch:845,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.4741 - val_loss: 190.8444\n",
      "\n",
      "Epoch 00846: val_loss did not improve from 179.48197\n",
      "Epoch 847/5000\n",
      "ecpch:846,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.6983 - val_loss: 190.3909\n",
      "\n",
      "Epoch 00847: val_loss did not improve from 179.48197\n",
      "Epoch 848/5000\n",
      "ecpch:847,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.5164 - val_loss: 190.3115\n",
      "\n",
      "Epoch 00848: val_loss did not improve from 179.48197\n",
      "Epoch 849/5000\n",
      "ecpch:848,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.6077 - val_loss: 190.7471\n",
      "\n",
      "Epoch 00849: val_loss did not improve from 179.48197\n",
      "Epoch 850/5000\n",
      "ecpch:849,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.5653 - val_loss: 190.5343\n",
      "\n",
      "Epoch 00850: val_loss did not improve from 179.48197\n",
      "Epoch 851/5000\n",
      "ecpch:850,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.5252 - val_loss: 190.3029\n",
      "\n",
      "Epoch 00851: val_loss did not improve from 179.48197\n",
      "Epoch 852/5000\n",
      "ecpch:851,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.5617 - val_loss: 190.6940\n",
      "\n",
      "Epoch 00852: val_loss did not improve from 179.48197\n",
      "Epoch 853/5000\n",
      "ecpch:852,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.5142 - val_loss: 190.5872\n",
      "\n",
      "Epoch 00853: val_loss did not improve from 179.48197\n",
      "Epoch 854/5000\n",
      "ecpch:853,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.4412 - val_loss: 190.3405\n",
      "\n",
      "Epoch 00854: val_loss did not improve from 179.48197\n",
      "Epoch 855/5000\n",
      "ecpch:854,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.5124 - val_loss: 190.6613\n",
      "\n",
      "Epoch 00855: val_loss did not improve from 179.48197\n",
      "Epoch 856/5000\n",
      "ecpch:855,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 59.4170 - val_loss: 190.5826\n",
      "\n",
      "Epoch 00856: val_loss did not improve from 179.48197\n",
      "Epoch 857/5000\n",
      "ecpch:856,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.4063 - val_loss: 190.4977\n",
      "\n",
      "Epoch 00857: val_loss did not improve from 179.48197\n",
      "Epoch 858/5000\n",
      "ecpch:857,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.4107 - val_loss: 190.6498\n",
      "\n",
      "Epoch 00858: val_loss did not improve from 179.48197\n",
      "Epoch 859/5000\n",
      "ecpch:858,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.3744 - val_loss: 190.5192\n",
      "\n",
      "Epoch 00859: val_loss did not improve from 179.48197\n",
      "Epoch 860/5000\n",
      "ecpch:859,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.3558 - val_loss: 190.6036\n",
      "\n",
      "Epoch 00860: val_loss did not improve from 179.48197\n",
      "Epoch 861/5000\n",
      "ecpch:860,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.3477 - val_loss: 190.6131\n",
      "\n",
      "Epoch 00861: val_loss did not improve from 179.48197\n",
      "Epoch 862/5000\n",
      "ecpch:861,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.3535 - val_loss: 190.5857\n",
      "\n",
      "Epoch 00862: val_loss did not improve from 179.48197\n",
      "Epoch 863/5000\n",
      "ecpch:862,learn rate 0.000074\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.3620 - val_loss: 190.6954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00863: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 00863: ReduceLROnPlateau reducing learning rate to 6.670872535323724e-05.\n",
      "Epoch 864/5000\n",
      "ecpch:863,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.3439 - val_loss: 190.5561\n",
      "\n",
      "Epoch 00864: val_loss did not improve from 179.48197\n",
      "Epoch 865/5000\n",
      "ecpch:864,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 59.3237 - val_loss: 190.6932\n",
      "\n",
      "Epoch 00865: val_loss did not improve from 179.48197\n",
      "Epoch 866/5000\n",
      "ecpch:865,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.3106 - val_loss: 190.6352\n",
      "\n",
      "Epoch 00866: val_loss did not improve from 179.48197\n",
      "Epoch 867/5000\n",
      "ecpch:866,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.3080 - val_loss: 190.6526\n",
      "\n",
      "Epoch 00867: val_loss did not improve from 179.48197\n",
      "Epoch 868/5000\n",
      "ecpch:867,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.2902 - val_loss: 190.7676\n",
      "\n",
      "Epoch 00868: val_loss did not improve from 179.48197\n",
      "Epoch 869/5000\n",
      "ecpch:868,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.3050 - val_loss: 190.5864\n",
      "\n",
      "Epoch 00869: val_loss did not improve from 179.48197\n",
      "Epoch 870/5000\n",
      "ecpch:869,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.3029 - val_loss: 190.7401\n",
      "\n",
      "Epoch 00870: val_loss did not improve from 179.48197\n",
      "Epoch 871/5000\n",
      "ecpch:870,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.2696 - val_loss: 190.6156\n",
      "\n",
      "Epoch 00871: val_loss did not improve from 179.48197\n",
      "Epoch 872/5000\n",
      "ecpch:871,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.2803 - val_loss: 190.7236\n",
      "\n",
      "Epoch 00872: val_loss did not improve from 179.48197\n",
      "Epoch 873/5000\n",
      "ecpch:872,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.2842 - val_loss: 190.7028\n",
      "\n",
      "Epoch 00873: val_loss did not improve from 179.48197\n",
      "Epoch 874/5000\n",
      "ecpch:873,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.2522 - val_loss: 190.6502\n",
      "\n",
      "Epoch 00874: val_loss did not improve from 179.48197\n",
      "Epoch 875/5000\n",
      "ecpch:874,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.2482 - val_loss: 190.7612\n",
      "\n",
      "Epoch 00875: val_loss did not improve from 179.48197\n",
      "Epoch 876/5000\n",
      "ecpch:875,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.2599 - val_loss: 190.5855\n",
      "\n",
      "Epoch 00876: val_loss did not improve from 179.48197\n",
      "Epoch 877/5000\n",
      "ecpch:876,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.2806 - val_loss: 190.7460\n",
      "\n",
      "Epoch 00877: val_loss did not improve from 179.48197\n",
      "Epoch 878/5000\n",
      "ecpch:877,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.2222 - val_loss: 190.7387\n",
      "\n",
      "Epoch 00878: val_loss did not improve from 179.48197\n",
      "Epoch 879/5000\n",
      "ecpch:878,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.2172 - val_loss: 190.6401\n",
      "\n",
      "Epoch 00879: val_loss did not improve from 179.48197\n",
      "Epoch 880/5000\n",
      "ecpch:879,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.2363 - val_loss: 190.8341\n",
      "\n",
      "Epoch 00880: val_loss did not improve from 179.48197\n",
      "Epoch 881/5000\n",
      "ecpch:880,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.2180 - val_loss: 190.6512\n",
      "\n",
      "Epoch 00881: val_loss did not improve from 179.48197\n",
      "Epoch 882/5000\n",
      "ecpch:881,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.2193 - val_loss: 190.8270\n",
      "\n",
      "Epoch 00882: val_loss did not improve from 179.48197\n",
      "Epoch 883/5000\n",
      "ecpch:882,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.1914 - val_loss: 190.6719\n",
      "\n",
      "Epoch 00883: val_loss did not improve from 179.48197\n",
      "Epoch 884/5000\n",
      "ecpch:883,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.1989 - val_loss: 190.8339\n",
      "\n",
      "Epoch 00884: val_loss did not improve from 179.48197\n",
      "Epoch 885/5000\n",
      "ecpch:884,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.1757 - val_loss: 190.6811\n",
      "\n",
      "Epoch 00885: val_loss did not improve from 179.48197\n",
      "Epoch 886/5000\n",
      "ecpch:885,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.1850 - val_loss: 190.8358\n",
      "\n",
      "Epoch 00886: val_loss did not improve from 179.48197\n",
      "Epoch 887/5000\n",
      "ecpch:886,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.1624 - val_loss: 190.6934\n",
      "\n",
      "Epoch 00887: val_loss did not improve from 179.48197\n",
      "Epoch 888/5000\n",
      "ecpch:887,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.1682 - val_loss: 190.8543\n",
      "\n",
      "Epoch 00888: val_loss did not improve from 179.48197\n",
      "Epoch 889/5000\n",
      "ecpch:888,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.1524 - val_loss: 190.6856\n",
      "\n",
      "Epoch 00889: val_loss did not improve from 179.48197\n",
      "Epoch 890/5000\n",
      "ecpch:889,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.1786 - val_loss: 190.8526\n",
      "\n",
      "Epoch 00890: val_loss did not improve from 179.48197\n",
      "Epoch 891/5000\n",
      "ecpch:890,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.1450 - val_loss: 190.8677\n",
      "\n",
      "Epoch 00891: val_loss did not improve from 179.48197\n",
      "Epoch 892/5000\n",
      "ecpch:891,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.1740 - val_loss: 190.7016\n",
      "\n",
      "Epoch 00892: val_loss did not improve from 179.48197\n",
      "Epoch 893/5000\n",
      "ecpch:892,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.1493 - val_loss: 190.8873\n",
      "\n",
      "Epoch 00893: val_loss did not improve from 179.48197\n",
      "Epoch 894/5000\n",
      "ecpch:893,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.1218 - val_loss: 190.8248\n",
      "\n",
      "Epoch 00894: val_loss did not improve from 179.48197\n",
      "Epoch 895/5000\n",
      "ecpch:894,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.2030 - val_loss: 190.8393\n",
      "\n",
      "Epoch 00895: val_loss did not improve from 179.48197\n",
      "Epoch 896/5000\n",
      "ecpch:895,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.0842 - val_loss: 190.8667\n",
      "\n",
      "Epoch 00896: val_loss did not improve from 179.48197\n",
      "Epoch 897/5000\n",
      "ecpch:896,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 59.1730 - val_loss: 190.8306\n",
      "\n",
      "Epoch 00897: val_loss did not improve from 179.48197\n",
      "Epoch 898/5000\n",
      "ecpch:897,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.1262 - val_loss: 190.9251\n",
      "\n",
      "Epoch 00898: val_loss did not improve from 179.48197\n",
      "Epoch 899/5000\n",
      "ecpch:898,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.0890 - val_loss: 190.7077\n",
      "\n",
      "Epoch 00899: val_loss did not improve from 179.48197\n",
      "Epoch 900/5000\n",
      "ecpch:899,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.2252 - val_loss: 190.8521\n",
      "\n",
      "Epoch 00900: val_loss did not improve from 179.48197\n",
      "Epoch 901/5000\n",
      "ecpch:900,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.0514 - val_loss: 191.1299\n",
      "\n",
      "Epoch 00901: val_loss did not improve from 179.48197\n",
      "Epoch 902/5000\n",
      "ecpch:901,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.2720 - val_loss: 190.8116\n",
      "\n",
      "Epoch 00902: val_loss did not improve from 179.48197\n",
      "Epoch 903/5000\n",
      "ecpch:902,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.0619 - val_loss: 190.8483\n",
      "\n",
      "Epoch 00903: val_loss did not improve from 179.48197\n",
      "Epoch 904/5000\n",
      "ecpch:903,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.1133 - val_loss: 191.0232\n",
      "\n",
      "Epoch 00904: val_loss did not improve from 179.48197\n",
      "Epoch 905/5000\n",
      "ecpch:904,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.1237 - val_loss: 190.7871\n",
      "\n",
      "Epoch 00905: val_loss did not improve from 179.48197\n",
      "Epoch 906/5000\n",
      "ecpch:905,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.0702 - val_loss: 190.9116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00906: val_loss did not improve from 179.48197\n",
      "Epoch 907/5000\n",
      "ecpch:906,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.1470 - val_loss: 190.8940\n",
      "\n",
      "Epoch 00907: val_loss did not improve from 179.48197\n",
      "Epoch 908/5000\n",
      "ecpch:907,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.0006 - val_loss: 190.8136\n",
      "\n",
      "Epoch 00908: val_loss did not improve from 179.48197\n",
      "Epoch 909/5000\n",
      "ecpch:908,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.0921 - val_loss: 190.9867\n",
      "\n",
      "Epoch 00909: val_loss did not improve from 179.48197\n",
      "Epoch 910/5000\n",
      "ecpch:909,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.0521 - val_loss: 190.8163\n",
      "\n",
      "Epoch 00910: val_loss did not improve from 179.48197\n",
      "Epoch 911/5000\n",
      "ecpch:910,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.0015 - val_loss: 190.9323\n",
      "\n",
      "Epoch 00911: val_loss did not improve from 179.48197\n",
      "Epoch 912/5000\n",
      "ecpch:911,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.9947 - val_loss: 190.9243\n",
      "\n",
      "Epoch 00912: val_loss did not improve from 179.48197\n",
      "Epoch 913/5000\n",
      "ecpch:912,learn rate 0.000067\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.9925 - val_loss: 190.8785\n",
      "\n",
      "Epoch 00913: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 00913: ReduceLROnPlateau reducing learning rate to 6.0037850198568775e-05.\n",
      "Epoch 914/5000\n",
      "ecpch:913,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.0006 - val_loss: 190.9932\n",
      "\n",
      "Epoch 00914: val_loss did not improve from 179.48197\n",
      "Epoch 915/5000\n",
      "ecpch:914,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.9735 - val_loss: 190.8180\n",
      "\n",
      "Epoch 00915: val_loss did not improve from 179.48197\n",
      "Epoch 916/5000\n",
      "ecpch:915,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.0122 - val_loss: 190.9656\n",
      "\n",
      "Epoch 00916: val_loss did not improve from 179.48197\n",
      "Epoch 917/5000\n",
      "ecpch:916,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.9703 - val_loss: 191.0604\n",
      "\n",
      "Epoch 00917: val_loss did not improve from 179.48197\n",
      "Epoch 918/5000\n",
      "ecpch:917,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.9717 - val_loss: 190.8180\n",
      "\n",
      "Epoch 00918: val_loss did not improve from 179.48197\n",
      "Epoch 919/5000\n",
      "ecpch:918,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 59.0181 - val_loss: 190.9870\n",
      "\n",
      "Epoch 00919: val_loss did not improve from 179.48197\n",
      "Epoch 920/5000\n",
      "ecpch:919,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.9203 - val_loss: 191.1375\n",
      "\n",
      "Epoch 00920: val_loss did not improve from 179.48197\n",
      "Epoch 921/5000\n",
      "ecpch:920,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.9918 - val_loss: 190.8349\n",
      "\n",
      "Epoch 00921: val_loss did not improve from 179.48197\n",
      "Epoch 922/5000\n",
      "ecpch:921,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.0093 - val_loss: 190.9724\n",
      "\n",
      "Epoch 00922: val_loss did not improve from 179.48197\n",
      "Epoch 923/5000\n",
      "ecpch:922,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.9067 - val_loss: 191.2845\n",
      "\n",
      "Epoch 00923: val_loss did not improve from 179.48197\n",
      "Epoch 924/5000\n",
      "ecpch:923,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 59.1016 - val_loss: 190.9626\n",
      "\n",
      "Epoch 00924: val_loss did not improve from 179.48197\n",
      "Epoch 925/5000\n",
      "ecpch:924,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.8991 - val_loss: 190.8447\n",
      "\n",
      "Epoch 00925: val_loss did not improve from 179.48197\n",
      "Epoch 926/5000\n",
      "ecpch:925,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.9688 - val_loss: 191.1467\n",
      "\n",
      "Epoch 00926: val_loss did not improve from 179.48197\n",
      "Epoch 927/5000\n",
      "ecpch:926,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.9554 - val_loss: 190.9935\n",
      "\n",
      "Epoch 00927: val_loss did not improve from 179.48197\n",
      "Epoch 928/5000\n",
      "ecpch:927,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.9010 - val_loss: 190.8366\n",
      "\n",
      "Epoch 00928: val_loss did not improve from 179.48197\n",
      "Epoch 929/5000\n",
      "ecpch:928,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.9879 - val_loss: 191.0599\n",
      "\n",
      "Epoch 00929: val_loss did not improve from 179.48197\n",
      "Epoch 930/5000\n",
      "ecpch:929,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.8687 - val_loss: 191.0364\n",
      "\n",
      "Epoch 00930: val_loss did not improve from 179.48197\n",
      "Epoch 931/5000\n",
      "ecpch:930,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.9219 - val_loss: 190.9336\n",
      "\n",
      "Epoch 00931: val_loss did not improve from 179.48197\n",
      "Epoch 932/5000\n",
      "ecpch:931,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.9091 - val_loss: 191.1167\n",
      "\n",
      "Epoch 00932: val_loss did not improve from 179.48197\n",
      "Epoch 933/5000\n",
      "ecpch:932,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.8572 - val_loss: 190.9975\n",
      "\n",
      "Epoch 00933: val_loss did not improve from 179.48197\n",
      "Epoch 934/5000\n",
      "ecpch:933,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.9026 - val_loss: 191.0353\n",
      "\n",
      "Epoch 00934: val_loss did not improve from 179.48197\n",
      "Epoch 935/5000\n",
      "ecpch:934,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.8491 - val_loss: 191.2186\n",
      "\n",
      "Epoch 00935: val_loss did not improve from 179.48197\n",
      "Epoch 936/5000\n",
      "ecpch:935,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.8858 - val_loss: 190.9585\n",
      "\n",
      "Epoch 00936: val_loss did not improve from 179.48197\n",
      "Epoch 937/5000\n",
      "ecpch:936,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.8787 - val_loss: 191.0469\n",
      "\n",
      "Epoch 00937: val_loss did not improve from 179.48197\n",
      "Epoch 938/5000\n",
      "ecpch:937,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.8121 - val_loss: 191.2840\n",
      "\n",
      "Epoch 00938: val_loss did not improve from 179.48197\n",
      "Epoch 939/5000\n",
      "ecpch:938,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.9451 - val_loss: 190.9854\n",
      "\n",
      "Epoch 00939: val_loss did not improve from 179.48197\n",
      "Epoch 940/5000\n",
      "ecpch:939,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.8318 - val_loss: 190.9572\n",
      "\n",
      "Epoch 00940: val_loss did not improve from 179.48197\n",
      "Epoch 941/5000\n",
      "ecpch:940,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.8283 - val_loss: 191.2878\n",
      "\n",
      "Epoch 00941: val_loss did not improve from 179.48197\n",
      "Epoch 942/5000\n",
      "ecpch:941,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.9230 - val_loss: 191.0563\n",
      "\n",
      "Epoch 00942: val_loss did not improve from 179.48197\n",
      "Epoch 943/5000\n",
      "ecpch:942,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.7787 - val_loss: 190.8981\n",
      "\n",
      "Epoch 00943: val_loss did not improve from 179.48197\n",
      "Epoch 944/5000\n",
      "ecpch:943,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.8911 - val_loss: 191.1665\n",
      "\n",
      "Epoch 00944: val_loss did not improve from 179.48197\n",
      "Epoch 945/5000\n",
      "ecpch:944,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.7975 - val_loss: 191.1065\n",
      "\n",
      "Epoch 00945: val_loss did not improve from 179.48197\n",
      "Epoch 946/5000\n",
      "ecpch:945,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.7585 - val_loss: 190.9935\n",
      "\n",
      "Epoch 00946: val_loss did not improve from 179.48197\n",
      "Epoch 947/5000\n",
      "ecpch:946,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.8520 - val_loss: 191.1853\n",
      "\n",
      "Epoch 00947: val_loss did not improve from 179.48197\n",
      "Epoch 948/5000\n",
      "ecpch:947,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.7561 - val_loss: 191.0902\n",
      "\n",
      "Epoch 00948: val_loss did not improve from 179.48197\n",
      "Epoch 949/5000\n",
      "ecpch:948,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.7812 - val_loss: 191.1488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00949: val_loss did not improve from 179.48197\n",
      "Epoch 950/5000\n",
      "ecpch:949,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.7951 - val_loss: 191.2299\n",
      "\n",
      "Epoch 00950: val_loss did not improve from 179.48197\n",
      "Epoch 951/5000\n",
      "ecpch:950,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.7457 - val_loss: 191.0096\n",
      "\n",
      "Epoch 00951: val_loss did not improve from 179.48197\n",
      "Epoch 952/5000\n",
      "ecpch:951,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.8700 - val_loss: 191.1585\n",
      "\n",
      "Epoch 00952: val_loss did not improve from 179.48197\n",
      "Epoch 953/5000\n",
      "ecpch:952,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.7108 - val_loss: 191.4248\n",
      "\n",
      "Epoch 00953: val_loss did not improve from 179.48197\n",
      "Epoch 954/5000\n",
      "ecpch:953,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.9271 - val_loss: 191.1285\n",
      "\n",
      "Epoch 00954: val_loss did not improve from 179.48197\n",
      "Epoch 955/5000\n",
      "ecpch:954,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.7091 - val_loss: 191.0798\n",
      "\n",
      "Epoch 00955: val_loss did not improve from 179.48197\n",
      "Epoch 956/5000\n",
      "ecpch:955,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.7771 - val_loss: 191.2820\n",
      "\n",
      "Epoch 00956: val_loss did not improve from 179.48197\n",
      "Epoch 957/5000\n",
      "ecpch:956,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.7578 - val_loss: 191.1322\n",
      "\n",
      "Epoch 00957: val_loss did not improve from 179.48197\n",
      "Epoch 958/5000\n",
      "ecpch:957,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.6957 - val_loss: 191.1968\n",
      "\n",
      "Epoch 00958: val_loss did not improve from 179.48197\n",
      "Epoch 959/5000\n",
      "ecpch:958,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.7980 - val_loss: 191.1899\n",
      "\n",
      "Epoch 00959: val_loss did not improve from 179.48197\n",
      "Epoch 960/5000\n",
      "ecpch:959,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.6599 - val_loss: 191.1696\n",
      "\n",
      "Epoch 00960: val_loss did not improve from 179.48197\n",
      "Epoch 961/5000\n",
      "ecpch:960,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.7748 - val_loss: 191.2857\n",
      "\n",
      "Epoch 00961: val_loss did not improve from 179.48197\n",
      "Epoch 962/5000\n",
      "ecpch:961,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.6776 - val_loss: 191.1248\n",
      "\n",
      "Epoch 00962: val_loss did not improve from 179.48197\n",
      "Epoch 963/5000\n",
      "ecpch:962,learn rate 0.000060\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.6864 - val_loss: 191.2702\n",
      "\n",
      "Epoch 00963: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 00963: ReduceLROnPlateau reducing learning rate to 5.403406648838427e-05.\n",
      "Epoch 964/5000\n",
      "ecpch:963,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 58.6865 - val_loss: 191.2486\n",
      "\n",
      "Epoch 00964: val_loss did not improve from 179.48197\n",
      "Epoch 965/5000\n",
      "ecpch:964,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.6361 - val_loss: 191.1659\n",
      "\n",
      "Epoch 00965: val_loss did not improve from 179.48197\n",
      "Epoch 966/5000\n",
      "ecpch:965,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.6591 - val_loss: 191.2398\n",
      "\n",
      "Epoch 00966: val_loss did not improve from 179.48197\n",
      "Epoch 967/5000\n",
      "ecpch:966,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.6681 - val_loss: 191.3287\n",
      "\n",
      "Epoch 00967: val_loss did not improve from 179.48197\n",
      "Epoch 968/5000\n",
      "ecpch:967,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.6552 - val_loss: 191.0901\n",
      "\n",
      "Epoch 00968: val_loss did not improve from 179.48197\n",
      "Epoch 969/5000\n",
      "ecpch:968,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.7116 - val_loss: 191.2087\n",
      "\n",
      "Epoch 00969: val_loss did not improve from 179.48197\n",
      "Epoch 970/5000\n",
      "ecpch:969,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.6234 - val_loss: 191.4715\n",
      "\n",
      "Epoch 00970: val_loss did not improve from 179.48197\n",
      "Epoch 971/5000\n",
      "ecpch:970,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.7479 - val_loss: 191.2225\n",
      "\n",
      "Epoch 00971: val_loss did not improve from 179.48197\n",
      "Epoch 972/5000\n",
      "ecpch:971,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.6254 - val_loss: 191.1217\n",
      "\n",
      "Epoch 00972: val_loss did not improve from 179.48197\n",
      "Epoch 973/5000\n",
      "ecpch:972,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.6986 - val_loss: 191.3823\n",
      "\n",
      "Epoch 00973: val_loss did not improve from 179.48197\n",
      "Epoch 974/5000\n",
      "ecpch:973,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.6310 - val_loss: 191.3186\n",
      "\n",
      "Epoch 00974: val_loss did not improve from 179.48197\n",
      "Epoch 975/5000\n",
      "ecpch:974,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.6399 - val_loss: 191.1658\n",
      "\n",
      "Epoch 00975: val_loss did not improve from 179.48197\n",
      "Epoch 976/5000\n",
      "ecpch:975,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.6507 - val_loss: 191.3848\n",
      "\n",
      "Epoch 00976: val_loss did not improve from 179.48197\n",
      "Epoch 977/5000\n",
      "ecpch:976,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.6134 - val_loss: 191.3483\n",
      "\n",
      "Epoch 00977: val_loss did not improve from 179.48197\n",
      "Epoch 978/5000\n",
      "ecpch:977,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.6037 - val_loss: 191.2027\n",
      "\n",
      "Epoch 00978: val_loss did not improve from 179.48197\n",
      "Epoch 979/5000\n",
      "ecpch:978,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.6042 - val_loss: 191.3707\n",
      "\n",
      "Epoch 00979: val_loss did not improve from 179.48197\n",
      "Epoch 980/5000\n",
      "ecpch:979,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.5811 - val_loss: 191.3344\n",
      "\n",
      "Epoch 00980: val_loss did not improve from 179.48197\n",
      "Epoch 981/5000\n",
      "ecpch:980,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.5649 - val_loss: 191.2532\n",
      "\n",
      "Epoch 00981: val_loss did not improve from 179.48197\n",
      "Epoch 982/5000\n",
      "ecpch:981,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.5527 - val_loss: 191.3388\n",
      "\n",
      "Epoch 00982: val_loss did not improve from 179.48197\n",
      "Epoch 983/5000\n",
      "ecpch:982,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.5343 - val_loss: 191.2844\n",
      "\n",
      "Epoch 00983: val_loss did not improve from 179.48197\n",
      "Epoch 984/5000\n",
      "ecpch:983,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.5318 - val_loss: 191.3369\n",
      "\n",
      "Epoch 00984: val_loss did not improve from 179.48197\n",
      "Epoch 985/5000\n",
      "ecpch:984,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.5543 - val_loss: 191.3459\n",
      "\n",
      "Epoch 00985: val_loss did not improve from 179.48197\n",
      "Epoch 986/5000\n",
      "ecpch:985,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.5160 - val_loss: 191.2601\n",
      "\n",
      "Epoch 00986: val_loss did not improve from 179.48197\n",
      "Epoch 987/5000\n",
      "ecpch:986,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.5281 - val_loss: 191.4372\n",
      "\n",
      "Epoch 00987: val_loss did not improve from 179.48197\n",
      "Epoch 988/5000\n",
      "ecpch:987,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.5261 - val_loss: 191.3153\n",
      "\n",
      "Epoch 00988: val_loss did not improve from 179.48197\n",
      "Epoch 989/5000\n",
      "ecpch:988,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.5097 - val_loss: 191.3957\n",
      "\n",
      "Epoch 00989: val_loss did not improve from 179.48197\n",
      "Epoch 990/5000\n",
      "ecpch:989,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.5020 - val_loss: 191.3874\n",
      "\n",
      "Epoch 00990: val_loss did not improve from 179.48197\n",
      "Epoch 991/5000\n",
      "ecpch:990,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.4947 - val_loss: 191.3852\n",
      "\n",
      "Epoch 00991: val_loss did not improve from 179.48197\n",
      "Epoch 992/5000\n",
      "ecpch:991,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.4867 - val_loss: 191.4795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00992: val_loss did not improve from 179.48197\n",
      "Epoch 993/5000\n",
      "ecpch:992,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 58.4940 - val_loss: 191.3190\n",
      "\n",
      "Epoch 00993: val_loss did not improve from 179.48197\n",
      "Epoch 994/5000\n",
      "ecpch:993,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.4895 - val_loss: 191.4620\n",
      "\n",
      "Epoch 00994: val_loss did not improve from 179.48197\n",
      "Epoch 995/5000\n",
      "ecpch:994,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.4702 - val_loss: 191.3266\n",
      "\n",
      "Epoch 00995: val_loss did not improve from 179.48197\n",
      "Epoch 996/5000\n",
      "ecpch:995,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.4784 - val_loss: 191.4323\n",
      "\n",
      "Epoch 00996: val_loss did not improve from 179.48197\n",
      "Epoch 997/5000\n",
      "ecpch:996,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.4557 - val_loss: 191.3678\n",
      "\n",
      "Epoch 00997: val_loss did not improve from 179.48197\n",
      "Epoch 998/5000\n",
      "ecpch:997,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.4500 - val_loss: 191.4151\n",
      "\n",
      "Epoch 00998: val_loss did not improve from 179.48197\n",
      "Epoch 999/5000\n",
      "ecpch:998,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.4524 - val_loss: 191.4422\n",
      "\n",
      "Epoch 00999: val_loss did not improve from 179.48197\n",
      "Epoch 1000/5000\n",
      "ecpch:999,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.4425 - val_loss: 191.3437\n",
      "\n",
      "Epoch 01000: val_loss did not improve from 179.48197\n",
      "Epoch 1001/5000\n",
      "ecpch:1000,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.4546 - val_loss: 191.4829\n",
      "\n",
      "Epoch 01001: val_loss did not improve from 179.48197\n",
      "Epoch 1002/5000\n",
      "ecpch:1001,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.4410 - val_loss: 191.4021\n",
      "\n",
      "Epoch 01002: val_loss did not improve from 179.48197\n",
      "Epoch 1003/5000\n",
      "ecpch:1002,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.4323 - val_loss: 191.4935\n",
      "\n",
      "Epoch 01003: val_loss did not improve from 179.48197\n",
      "Epoch 1004/5000\n",
      "ecpch:1003,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.4190 - val_loss: 191.3932\n",
      "\n",
      "Epoch 01004: val_loss did not improve from 179.48197\n",
      "Epoch 1005/5000\n",
      "ecpch:1004,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.4184 - val_loss: 191.5323\n",
      "\n",
      "Epoch 01005: val_loss did not improve from 179.48197\n",
      "Epoch 1006/5000\n",
      "ecpch:1005,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.4156 - val_loss: 191.4060\n",
      "\n",
      "Epoch 01006: val_loss did not improve from 179.48197\n",
      "Epoch 1007/5000\n",
      "ecpch:1006,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.4043 - val_loss: 191.5103\n",
      "\n",
      "Epoch 01007: val_loss did not improve from 179.48197\n",
      "Epoch 1008/5000\n",
      "ecpch:1007,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.3933 - val_loss: 191.4505\n",
      "\n",
      "Epoch 01008: val_loss did not improve from 179.48197\n",
      "Epoch 1009/5000\n",
      "ecpch:1008,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.3954 - val_loss: 191.5070\n",
      "\n",
      "Epoch 01009: val_loss did not improve from 179.48197\n",
      "Epoch 1010/5000\n",
      "ecpch:1009,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.3841 - val_loss: 191.4252\n",
      "\n",
      "Epoch 01010: val_loss did not improve from 179.48197\n",
      "Epoch 1011/5000\n",
      "ecpch:1010,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.3875 - val_loss: 191.5483\n",
      "\n",
      "Epoch 01011: val_loss did not improve from 179.48197\n",
      "Epoch 1012/5000\n",
      "ecpch:1011,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.3827 - val_loss: 191.3625\n",
      "\n",
      "Epoch 01012: val_loss did not improve from 179.48197\n",
      "Epoch 1013/5000\n",
      "ecpch:1012,learn rate 0.000054\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.3979 - val_loss: 191.5261\n",
      "\n",
      "Epoch 01013: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 01013: ReduceLROnPlateau reducing learning rate to 4.863065951212775e-05.\n",
      "Epoch 1014/5000\n",
      "ecpch:1013,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.3689 - val_loss: 191.5185\n",
      "\n",
      "Epoch 01014: val_loss did not improve from 179.48197\n",
      "Epoch 1015/5000\n",
      "ecpch:1014,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.3463 - val_loss: 191.4870\n",
      "\n",
      "Epoch 01015: val_loss did not improve from 179.48197\n",
      "Epoch 1016/5000\n",
      "ecpch:1015,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.3337 - val_loss: 191.5203\n",
      "\n",
      "Epoch 01016: val_loss did not improve from 179.48197\n",
      "Epoch 1017/5000\n",
      "ecpch:1016,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.3238 - val_loss: 191.4931\n",
      "\n",
      "Epoch 01017: val_loss did not improve from 179.48197\n",
      "Epoch 1018/5000\n",
      "ecpch:1017,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.3365 - val_loss: 191.5614\n",
      "\n",
      "Epoch 01018: val_loss did not improve from 179.48197\n",
      "Epoch 1019/5000\n",
      "ecpch:1018,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.3506 - val_loss: 191.4822\n",
      "\n",
      "Epoch 01019: val_loss did not improve from 179.48197\n",
      "Epoch 1020/5000\n",
      "ecpch:1019,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.3229 - val_loss: 191.6006\n",
      "\n",
      "Epoch 01020: val_loss did not improve from 179.48197\n",
      "Epoch 1021/5000\n",
      "ecpch:1020,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.3259 - val_loss: 191.5089\n",
      "\n",
      "Epoch 01021: val_loss did not improve from 179.48197\n",
      "Epoch 1022/5000\n",
      "ecpch:1021,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.3344 - val_loss: 191.5814\n",
      "\n",
      "Epoch 01022: val_loss did not improve from 179.48197\n",
      "Epoch 1023/5000\n",
      "ecpch:1022,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.3046 - val_loss: 191.5353\n",
      "\n",
      "Epoch 01023: val_loss did not improve from 179.48197\n",
      "Epoch 1024/5000\n",
      "ecpch:1023,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.2863 - val_loss: 191.5841\n",
      "\n",
      "Epoch 01024: val_loss did not improve from 179.48197\n",
      "Epoch 1025/5000\n",
      "ecpch:1024,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.2862 - val_loss: 191.4621\n",
      "\n",
      "Epoch 01025: val_loss did not improve from 179.48197\n",
      "Epoch 1026/5000\n",
      "ecpch:1025,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.3194 - val_loss: 191.6062\n",
      "\n",
      "Epoch 01026: val_loss did not improve from 179.48197\n",
      "Epoch 1027/5000\n",
      "ecpch:1026,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.2976 - val_loss: 191.5127\n",
      "\n",
      "Epoch 01027: val_loss did not improve from 179.48197\n",
      "Epoch 1028/5000\n",
      "ecpch:1027,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.2745 - val_loss: 191.5826\n",
      "\n",
      "Epoch 01028: val_loss did not improve from 179.48197\n",
      "Epoch 1029/5000\n",
      "ecpch:1028,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.2604 - val_loss: 191.5419\n",
      "\n",
      "Epoch 01029: val_loss did not improve from 179.48197\n",
      "Epoch 1030/5000\n",
      "ecpch:1029,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.2535 - val_loss: 191.5919\n",
      "\n",
      "Epoch 01030: val_loss did not improve from 179.48197\n",
      "Epoch 1031/5000\n",
      "ecpch:1030,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.2449 - val_loss: 191.5550\n",
      "\n",
      "Epoch 01031: val_loss did not improve from 179.48197\n",
      "Epoch 1032/5000\n",
      "ecpch:1031,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.2443 - val_loss: 191.6632\n",
      "\n",
      "Epoch 01032: val_loss did not improve from 179.48197\n",
      "Epoch 1033/5000\n",
      "ecpch:1032,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.2731 - val_loss: 191.4903\n",
      "\n",
      "Epoch 01033: val_loss did not improve from 179.48197\n",
      "Epoch 1034/5000\n",
      "ecpch:1033,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.2973 - val_loss: 191.6396\n",
      "\n",
      "Epoch 01034: val_loss did not improve from 179.48197\n",
      "Epoch 1035/5000\n",
      "ecpch:1034,learn rate 0.000049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 10ms/step - loss: 58.2304 - val_loss: 191.6317\n",
      "\n",
      "Epoch 01035: val_loss did not improve from 179.48197\n",
      "Epoch 1036/5000\n",
      "ecpch:1035,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.2587 - val_loss: 191.5763\n",
      "\n",
      "Epoch 01036: val_loss did not improve from 179.48197\n",
      "Epoch 1037/5000\n",
      "ecpch:1036,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.2634 - val_loss: 191.6686\n",
      "\n",
      "Epoch 01037: val_loss did not improve from 179.48197\n",
      "Epoch 1038/5000\n",
      "ecpch:1037,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.2153 - val_loss: 191.5447\n",
      "\n",
      "Epoch 01038: val_loss did not improve from 179.48197\n",
      "Epoch 1039/5000\n",
      "ecpch:1038,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.2581 - val_loss: 191.6904\n",
      "\n",
      "Epoch 01039: val_loss did not improve from 179.48197\n",
      "Epoch 1040/5000\n",
      "ecpch:1039,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.2324 - val_loss: 191.6389\n",
      "\n",
      "Epoch 01040: val_loss did not improve from 179.48197\n",
      "Epoch 1041/5000\n",
      "ecpch:1040,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.2115 - val_loss: 191.5916\n",
      "\n",
      "Epoch 01041: val_loss did not improve from 179.48197\n",
      "Epoch 1042/5000\n",
      "ecpch:1041,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.2033 - val_loss: 191.6695\n",
      "\n",
      "Epoch 01042: val_loss did not improve from 179.48197\n",
      "Epoch 1043/5000\n",
      "ecpch:1042,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.1955 - val_loss: 191.4896\n",
      "\n",
      "Epoch 01043: val_loss did not improve from 179.48197\n",
      "Epoch 1044/5000\n",
      "ecpch:1043,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 58.2400 - val_loss: 191.6666\n",
      "\n",
      "Epoch 01044: val_loss did not improve from 179.48197\n",
      "Epoch 1045/5000\n",
      "ecpch:1044,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.1852 - val_loss: 191.6185\n",
      "\n",
      "Epoch 01045: val_loss did not improve from 179.48197\n",
      "Epoch 1046/5000\n",
      "ecpch:1045,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.1725 - val_loss: 191.6298\n",
      "\n",
      "Epoch 01046: val_loss did not improve from 179.48197\n",
      "Epoch 1047/5000\n",
      "ecpch:1046,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.1747 - val_loss: 191.6839\n",
      "\n",
      "Epoch 01047: val_loss did not improve from 179.48197\n",
      "Epoch 1048/5000\n",
      "ecpch:1047,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.2011 - val_loss: 191.5951\n",
      "\n",
      "Epoch 01048: val_loss did not improve from 179.48197\n",
      "Epoch 1049/5000\n",
      "ecpch:1048,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.1740 - val_loss: 191.7374\n",
      "\n",
      "Epoch 01049: val_loss did not improve from 179.48197\n",
      "Epoch 1050/5000\n",
      "ecpch:1049,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.1745 - val_loss: 191.6125\n",
      "\n",
      "Epoch 01050: val_loss did not improve from 179.48197\n",
      "Epoch 1051/5000\n",
      "ecpch:1050,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.2085 - val_loss: 191.7059\n",
      "\n",
      "Epoch 01051: val_loss did not improve from 179.48197\n",
      "Epoch 1052/5000\n",
      "ecpch:1051,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.1352 - val_loss: 191.6775\n",
      "\n",
      "Epoch 01052: val_loss did not improve from 179.48197\n",
      "Epoch 1053/5000\n",
      "ecpch:1052,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.1370 - val_loss: 191.7345\n",
      "\n",
      "Epoch 01053: val_loss did not improve from 179.48197\n",
      "Epoch 1054/5000\n",
      "ecpch:1053,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.1730 - val_loss: 191.6475\n",
      "\n",
      "Epoch 01054: val_loss did not improve from 179.48197\n",
      "Epoch 1055/5000\n",
      "ecpch:1054,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.1405 - val_loss: 191.7693\n",
      "\n",
      "Epoch 01055: val_loss did not improve from 179.48197\n",
      "Epoch 1056/5000\n",
      "ecpch:1055,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.1400 - val_loss: 191.6098\n",
      "\n",
      "Epoch 01056: val_loss did not improve from 179.48197\n",
      "Epoch 1057/5000\n",
      "ecpch:1056,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.1544 - val_loss: 191.7195\n",
      "\n",
      "Epoch 01057: val_loss did not improve from 179.48197\n",
      "Epoch 1058/5000\n",
      "ecpch:1057,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.1183 - val_loss: 191.7789\n",
      "\n",
      "Epoch 01058: val_loss did not improve from 179.48197\n",
      "Epoch 1059/5000\n",
      "ecpch:1058,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 58.1534 - val_loss: 191.5439\n",
      "\n",
      "Epoch 01059: val_loss did not improve from 179.48197\n",
      "Epoch 1060/5000\n",
      "ecpch:1059,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.1799 - val_loss: 191.7307\n",
      "\n",
      "Epoch 01060: val_loss did not improve from 179.48197\n",
      "Epoch 1061/5000\n",
      "ecpch:1060,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.1240 - val_loss: 191.8674\n",
      "\n",
      "Epoch 01061: val_loss did not improve from 179.48197\n",
      "Epoch 1062/5000\n",
      "ecpch:1061,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.2220 - val_loss: 191.6049\n",
      "\n",
      "Epoch 01062: val_loss did not improve from 179.48197\n",
      "Epoch 1063/5000\n",
      "ecpch:1062,learn rate 0.000049\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.1540 - val_loss: 191.6239\n",
      "\n",
      "Epoch 01063: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 01063: ReduceLROnPlateau reducing learning rate to 4.3767593888333066e-05.\n",
      "Epoch 1064/5000\n",
      "ecpch:1063,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.2090 - val_loss: 191.8124\n",
      "\n",
      "Epoch 01064: val_loss did not improve from 179.48197\n",
      "Epoch 1065/5000\n",
      "ecpch:1064,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.1277 - val_loss: 191.7256\n",
      "\n",
      "Epoch 01065: val_loss did not improve from 179.48197\n",
      "Epoch 1066/5000\n",
      "ecpch:1065,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.1962 - val_loss: 191.6551\n",
      "\n",
      "Epoch 01066: val_loss did not improve from 179.48197\n",
      "Epoch 1067/5000\n",
      "ecpch:1066,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.1524 - val_loss: 191.7832\n",
      "\n",
      "Epoch 01067: val_loss did not improve from 179.48197\n",
      "Epoch 1068/5000\n",
      "ecpch:1067,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.1749 - val_loss: 191.8289\n",
      "\n",
      "Epoch 01068: val_loss did not improve from 179.48197\n",
      "Epoch 1069/5000\n",
      "ecpch:1068,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.1478 - val_loss: 191.7006\n",
      "\n",
      "Epoch 01069: val_loss did not improve from 179.48197\n",
      "Epoch 1070/5000\n",
      "ecpch:1069,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.1665 - val_loss: 191.7291\n",
      "\n",
      "Epoch 01070: val_loss did not improve from 179.48197\n",
      "Epoch 1071/5000\n",
      "ecpch:1070,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.1587 - val_loss: 191.8344\n",
      "\n",
      "Epoch 01071: val_loss did not improve from 179.48197\n",
      "Epoch 1072/5000\n",
      "ecpch:1071,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.1002 - val_loss: 191.7305\n",
      "\n",
      "Epoch 01072: val_loss did not improve from 179.48197\n",
      "Epoch 1073/5000\n",
      "ecpch:1072,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.0972 - val_loss: 191.7057\n",
      "\n",
      "Epoch 01073: val_loss did not improve from 179.48197\n",
      "Epoch 1074/5000\n",
      "ecpch:1073,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.0991 - val_loss: 191.8342\n",
      "\n",
      "Epoch 01074: val_loss did not improve from 179.48197\n",
      "Epoch 1075/5000\n",
      "ecpch:1074,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.0938 - val_loss: 191.7256\n",
      "\n",
      "Epoch 01075: val_loss did not improve from 179.48197\n",
      "Epoch 1076/5000\n",
      "ecpch:1075,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.0745 - val_loss: 191.7317\n",
      "\n",
      "Epoch 01076: val_loss did not improve from 179.48197\n",
      "Epoch 1077/5000\n",
      "ecpch:1076,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.0443 - val_loss: 191.8674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01077: val_loss did not improve from 179.48197\n",
      "Epoch 1078/5000\n",
      "ecpch:1077,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.0881 - val_loss: 191.7573\n",
      "\n",
      "Epoch 01078: val_loss did not improve from 179.48197\n",
      "Epoch 1079/5000\n",
      "ecpch:1078,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.0273 - val_loss: 191.7832\n",
      "\n",
      "Epoch 01079: val_loss did not improve from 179.48197\n",
      "Epoch 1080/5000\n",
      "ecpch:1079,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.0732 - val_loss: 191.8571\n",
      "\n",
      "Epoch 01080: val_loss did not improve from 179.48197\n",
      "Epoch 1081/5000\n",
      "ecpch:1080,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 58.0146 - val_loss: 191.7526\n",
      "\n",
      "Epoch 01081: val_loss did not improve from 179.48197\n",
      "Epoch 1082/5000\n",
      "ecpch:1081,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.0725 - val_loss: 191.8184\n",
      "\n",
      "Epoch 01082: val_loss did not improve from 179.48197\n",
      "Epoch 1083/5000\n",
      "ecpch:1082,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.9923 - val_loss: 191.8757\n",
      "\n",
      "Epoch 01083: val_loss did not improve from 179.48197\n",
      "Epoch 1084/5000\n",
      "ecpch:1083,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.0757 - val_loss: 191.7991\n",
      "\n",
      "Epoch 01084: val_loss did not improve from 179.48197\n",
      "Epoch 1085/5000\n",
      "ecpch:1084,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.9845 - val_loss: 191.8477\n",
      "\n",
      "Epoch 01085: val_loss did not improve from 179.48197\n",
      "Epoch 1086/5000\n",
      "ecpch:1085,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.0695 - val_loss: 191.8434\n",
      "\n",
      "Epoch 01086: val_loss did not improve from 179.48197\n",
      "Epoch 1087/5000\n",
      "ecpch:1086,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.9775 - val_loss: 191.8186\n",
      "\n",
      "Epoch 01087: val_loss did not improve from 179.48197\n",
      "Epoch 1088/5000\n",
      "ecpch:1087,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.0916 - val_loss: 191.8432\n",
      "\n",
      "Epoch 01088: val_loss did not improve from 179.48197\n",
      "Epoch 1089/5000\n",
      "ecpch:1088,learn rate 0.000044\n",
      "64/64 [==============================] - 0s 8ms/step - loss: 57.9997 - val_loss: 191.8519\n",
      "\n",
      "Epoch 01089: val_loss did not improve from 179.48197\n",
      "Epoch 1090/5000\n",
      "ecpch:1089,learn rate 0.000044\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 58.1098 - val_loss: 191.8352\n",
      "\n",
      "Epoch 01090: val_loss did not improve from 179.48197\n",
      "Epoch 1091/5000\n",
      "ecpch:1090,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.0672 - val_loss: 191.8605\n",
      "\n",
      "Epoch 01091: val_loss did not improve from 179.48197\n",
      "Epoch 1092/5000\n",
      "ecpch:1091,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.0238 - val_loss: 191.8569\n",
      "\n",
      "Epoch 01092: val_loss did not improve from 179.48197\n",
      "Epoch 1093/5000\n",
      "ecpch:1092,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.0340 - val_loss: 191.8384\n",
      "\n",
      "Epoch 01093: val_loss did not improve from 179.48197\n",
      "Epoch 1094/5000\n",
      "ecpch:1093,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.9892 - val_loss: 191.9298\n",
      "\n",
      "Epoch 01094: val_loss did not improve from 179.48197\n",
      "Epoch 1095/5000\n",
      "ecpch:1094,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.0053 - val_loss: 191.8322\n",
      "\n",
      "Epoch 01095: val_loss did not improve from 179.48197\n",
      "Epoch 1096/5000\n",
      "ecpch:1095,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.9793 - val_loss: 191.8706\n",
      "\n",
      "Epoch 01096: val_loss did not improve from 179.48197\n",
      "Epoch 1097/5000\n",
      "ecpch:1096,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.9417 - val_loss: 191.9377\n",
      "\n",
      "Epoch 01097: val_loss did not improve from 179.48197\n",
      "Epoch 1098/5000\n",
      "ecpch:1097,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.0108 - val_loss: 191.8708\n",
      "\n",
      "Epoch 01098: val_loss did not improve from 179.48197\n",
      "Epoch 1099/5000\n",
      "ecpch:1098,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.9487 - val_loss: 191.8961\n",
      "\n",
      "Epoch 01099: val_loss did not improve from 179.48197\n",
      "Epoch 1100/5000\n",
      "ecpch:1099,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.0145 - val_loss: 191.9422\n",
      "\n",
      "Epoch 01100: val_loss did not improve from 179.48197\n",
      "Epoch 1101/5000\n",
      "ecpch:1100,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.9574 - val_loss: 191.8444\n",
      "\n",
      "Epoch 01101: val_loss did not improve from 179.48197\n",
      "Epoch 1102/5000\n",
      "ecpch:1101,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 58.0259 - val_loss: 191.9017\n",
      "\n",
      "Epoch 01102: val_loss did not improve from 179.48197\n",
      "Epoch 1103/5000\n",
      "ecpch:1102,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 58.0058 - val_loss: 191.9482\n",
      "\n",
      "Epoch 01103: val_loss did not improve from 179.48197\n",
      "Epoch 1104/5000\n",
      "ecpch:1103,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.9392 - val_loss: 191.8414\n",
      "\n",
      "Epoch 01104: val_loss did not improve from 179.48197\n",
      "Epoch 1105/5000\n",
      "ecpch:1104,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.9671 - val_loss: 191.8638\n",
      "\n",
      "Epoch 01105: val_loss did not improve from 179.48197\n",
      "Epoch 1106/5000\n",
      "ecpch:1105,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.9221 - val_loss: 192.0185\n",
      "\n",
      "Epoch 01106: val_loss did not improve from 179.48197\n",
      "Epoch 1107/5000\n",
      "ecpch:1106,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.9681 - val_loss: 191.8416\n",
      "\n",
      "Epoch 01107: val_loss did not improve from 179.48197\n",
      "Epoch 1108/5000\n",
      "ecpch:1107,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.8941 - val_loss: 191.8471\n",
      "\n",
      "Epoch 01108: val_loss did not improve from 179.48197\n",
      "Epoch 1109/5000\n",
      "ecpch:1108,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.9049 - val_loss: 192.0071\n",
      "\n",
      "Epoch 01109: val_loss did not improve from 179.48197\n",
      "Epoch 1110/5000\n",
      "ecpch:1109,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.9013 - val_loss: 191.8752\n",
      "\n",
      "Epoch 01110: val_loss did not improve from 179.48197\n",
      "Epoch 1111/5000\n",
      "ecpch:1110,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.8913 - val_loss: 191.9366\n",
      "\n",
      "Epoch 01111: val_loss did not improve from 179.48197\n",
      "Epoch 1112/5000\n",
      "ecpch:1111,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.8709 - val_loss: 192.0050\n",
      "\n",
      "Epoch 01112: val_loss did not improve from 179.48197\n",
      "Epoch 1113/5000\n",
      "ecpch:1112,learn rate 0.000044\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.8498 - val_loss: 191.8851\n",
      "\n",
      "Epoch 01113: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 01113: ReduceLROnPlateau reducing learning rate to 3.939083580917213e-05.\n",
      "Epoch 1114/5000\n",
      "ecpch:1113,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.8975 - val_loss: 191.9807\n",
      "\n",
      "Epoch 01114: val_loss did not improve from 179.48197\n",
      "Epoch 1115/5000\n",
      "ecpch:1114,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.8225 - val_loss: 192.0714\n",
      "\n",
      "Epoch 01115: val_loss did not improve from 179.48197\n",
      "Epoch 1116/5000\n",
      "ecpch:1115,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.8770 - val_loss: 191.9396\n",
      "\n",
      "Epoch 01116: val_loss did not improve from 179.48197\n",
      "Epoch 1117/5000\n",
      "ecpch:1116,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.8274 - val_loss: 191.9692\n",
      "\n",
      "Epoch 01117: val_loss did not improve from 179.48197\n",
      "Epoch 1118/5000\n",
      "ecpch:1117,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.8339 - val_loss: 192.0655\n",
      "\n",
      "Epoch 01118: val_loss did not improve from 179.48197\n",
      "Epoch 1119/5000\n",
      "ecpch:1118,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.8336 - val_loss: 191.9364\n",
      "\n",
      "Epoch 01119: val_loss did not improve from 179.48197\n",
      "Epoch 1120/5000\n",
      "ecpch:1119,learn rate 0.000039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 9ms/step - loss: 57.8207 - val_loss: 191.9780\n",
      "\n",
      "Epoch 01120: val_loss did not improve from 179.48197\n",
      "Epoch 1121/5000\n",
      "ecpch:1120,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.8158 - val_loss: 192.0574\n",
      "\n",
      "Epoch 01121: val_loss did not improve from 179.48197\n",
      "Epoch 1122/5000\n",
      "ecpch:1121,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.8161 - val_loss: 191.9050\n",
      "\n",
      "Epoch 01122: val_loss did not improve from 179.48197\n",
      "Epoch 1123/5000\n",
      "ecpch:1122,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.8429 - val_loss: 191.9565\n",
      "\n",
      "Epoch 01123: val_loss did not improve from 179.48197\n",
      "Epoch 1124/5000\n",
      "ecpch:1123,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.7864 - val_loss: 192.1187\n",
      "\n",
      "Epoch 01124: val_loss did not improve from 179.48197\n",
      "Epoch 1125/5000\n",
      "ecpch:1124,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.8590 - val_loss: 191.9599\n",
      "\n",
      "Epoch 01125: val_loss did not improve from 179.48197\n",
      "Epoch 1126/5000\n",
      "ecpch:1125,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.7805 - val_loss: 191.9526\n",
      "\n",
      "Epoch 01126: val_loss did not improve from 179.48197\n",
      "Epoch 1127/5000\n",
      "ecpch:1126,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.7828 - val_loss: 192.1017\n",
      "\n",
      "Epoch 01127: val_loss did not improve from 179.48197\n",
      "Epoch 1128/5000\n",
      "ecpch:1127,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.8131 - val_loss: 191.9858\n",
      "\n",
      "Epoch 01128: val_loss did not improve from 179.48197\n",
      "Epoch 1129/5000\n",
      "ecpch:1128,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.7604 - val_loss: 192.0241\n",
      "\n",
      "Epoch 01129: val_loss did not improve from 179.48197\n",
      "Epoch 1130/5000\n",
      "ecpch:1129,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.7534 - val_loss: 192.0507\n",
      "\n",
      "Epoch 01130: val_loss did not improve from 179.48197\n",
      "Epoch 1131/5000\n",
      "ecpch:1130,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.7526 - val_loss: 191.9966\n",
      "\n",
      "Epoch 01131: val_loss did not improve from 179.48197\n",
      "Epoch 1132/5000\n",
      "ecpch:1131,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.7506 - val_loss: 192.0928\n",
      "\n",
      "Epoch 01132: val_loss did not improve from 179.48197\n",
      "Epoch 1133/5000\n",
      "ecpch:1132,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.7514 - val_loss: 191.9775\n",
      "\n",
      "Epoch 01133: val_loss did not improve from 179.48197\n",
      "Epoch 1134/5000\n",
      "ecpch:1133,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.7565 - val_loss: 192.0718\n",
      "\n",
      "Epoch 01134: val_loss did not improve from 179.48197\n",
      "Epoch 1135/5000\n",
      "ecpch:1134,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.7294 - val_loss: 192.0605\n",
      "\n",
      "Epoch 01135: val_loss did not improve from 179.48197\n",
      "Epoch 1136/5000\n",
      "ecpch:1135,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.7245 - val_loss: 192.0362\n",
      "\n",
      "Epoch 01136: val_loss did not improve from 179.48197\n",
      "Epoch 1137/5000\n",
      "ecpch:1136,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.7196 - val_loss: 192.1010\n",
      "\n",
      "Epoch 01137: val_loss did not improve from 179.48197\n",
      "Epoch 1138/5000\n",
      "ecpch:1137,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.7245 - val_loss: 191.9772\n",
      "\n",
      "Epoch 01138: val_loss did not improve from 179.48197\n",
      "Epoch 1139/5000\n",
      "ecpch:1138,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.7443 - val_loss: 192.1173\n",
      "\n",
      "Epoch 01139: val_loss did not improve from 179.48197\n",
      "Epoch 1140/5000\n",
      "ecpch:1139,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.7144 - val_loss: 192.0711\n",
      "\n",
      "Epoch 01140: val_loss did not improve from 179.48197\n",
      "Epoch 1141/5000\n",
      "ecpch:1140,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.7041 - val_loss: 192.0653\n",
      "\n",
      "Epoch 01141: val_loss did not improve from 179.48197\n",
      "Epoch 1142/5000\n",
      "ecpch:1141,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.7035 - val_loss: 192.1437\n",
      "\n",
      "Epoch 01142: val_loss did not improve from 179.48197\n",
      "Epoch 1143/5000\n",
      "ecpch:1142,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.7066 - val_loss: 191.9974\n",
      "\n",
      "Epoch 01143: val_loss did not improve from 179.48197\n",
      "Epoch 1144/5000\n",
      "ecpch:1143,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.7310 - val_loss: 192.1216\n",
      "\n",
      "Epoch 01144: val_loss did not improve from 179.48197\n",
      "Epoch 1145/5000\n",
      "ecpch:1144,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.6836 - val_loss: 192.1510\n",
      "\n",
      "Epoch 01145: val_loss did not improve from 179.48197\n",
      "Epoch 1146/5000\n",
      "ecpch:1145,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.6932 - val_loss: 191.9846\n",
      "\n",
      "Epoch 01146: val_loss did not improve from 179.48197\n",
      "Epoch 1147/5000\n",
      "ecpch:1146,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.7329 - val_loss: 192.1133\n",
      "\n",
      "Epoch 01147: val_loss did not improve from 179.48197\n",
      "Epoch 1148/5000\n",
      "ecpch:1147,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.6679 - val_loss: 192.2331\n",
      "\n",
      "Epoch 01148: val_loss did not improve from 179.48197\n",
      "Epoch 1149/5000\n",
      "ecpch:1148,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.7486 - val_loss: 192.0111\n",
      "\n",
      "Epoch 01149: val_loss did not improve from 179.48197\n",
      "Epoch 1150/5000\n",
      "ecpch:1149,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.6968 - val_loss: 192.0371\n",
      "\n",
      "Epoch 01150: val_loss did not improve from 179.48197\n",
      "Epoch 1151/5000\n",
      "ecpch:1150,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.7125 - val_loss: 192.2184\n",
      "\n",
      "Epoch 01151: val_loss did not improve from 179.48197\n",
      "Epoch 1152/5000\n",
      "ecpch:1151,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.7096 - val_loss: 192.0624\n",
      "\n",
      "Epoch 01152: val_loss did not improve from 179.48197\n",
      "Epoch 1153/5000\n",
      "ecpch:1152,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.6855 - val_loss: 192.0675\n",
      "\n",
      "Epoch 01153: val_loss did not improve from 179.48197\n",
      "Epoch 1154/5000\n",
      "ecpch:1153,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.6667 - val_loss: 192.2059\n",
      "\n",
      "Epoch 01154: val_loss did not improve from 179.48197\n",
      "Epoch 1155/5000\n",
      "ecpch:1154,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.6750 - val_loss: 192.0560\n",
      "\n",
      "Epoch 01155: val_loss did not improve from 179.48197\n",
      "Epoch 1156/5000\n",
      "ecpch:1155,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.6609 - val_loss: 192.1157\n",
      "\n",
      "Epoch 01156: val_loss did not improve from 179.48197\n",
      "Epoch 1157/5000\n",
      "ecpch:1156,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.6465 - val_loss: 192.1966\n",
      "\n",
      "Epoch 01157: val_loss did not improve from 179.48197\n",
      "Epoch 1158/5000\n",
      "ecpch:1157,learn rate 0.000039\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 57.6448 - val_loss: 192.0685\n",
      "\n",
      "Epoch 01158: val_loss did not improve from 179.48197\n",
      "Epoch 1159/5000\n",
      "ecpch:1158,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.6499 - val_loss: 192.1889\n",
      "\n",
      "Epoch 01159: val_loss did not improve from 179.48197\n",
      "Epoch 1160/5000\n",
      "ecpch:1159,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.6357 - val_loss: 192.1605\n",
      "\n",
      "Epoch 01160: val_loss did not improve from 179.48197\n",
      "Epoch 1161/5000\n",
      "ecpch:1160,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.6078 - val_loss: 192.0888\n",
      "\n",
      "Epoch 01161: val_loss did not improve from 179.48197\n",
      "Epoch 1162/5000\n",
      "ecpch:1161,learn rate 0.000039\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.6261 - val_loss: 192.2276\n",
      "\n",
      "Epoch 01162: val_loss did not improve from 179.48197\n",
      "Epoch 1163/5000\n",
      "ecpch:1162,learn rate 0.000039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 9ms/step - loss: 57.6288 - val_loss: 192.1216\n",
      "\n",
      "Epoch 01163: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 01163: ReduceLROnPlateau reducing learning rate to 3.5451750591164455e-05.\n",
      "Epoch 1164/5000\n",
      "ecpch:1163,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.6007 - val_loss: 192.1403\n",
      "\n",
      "Epoch 01164: val_loss did not improve from 179.48197\n",
      "Epoch 1165/5000\n",
      "ecpch:1164,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.6037 - val_loss: 192.2254\n",
      "\n",
      "Epoch 01165: val_loss did not improve from 179.48197\n",
      "Epoch 1166/5000\n",
      "ecpch:1165,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.6213 - val_loss: 192.0947\n",
      "\n",
      "Epoch 01166: val_loss did not improve from 179.48197\n",
      "Epoch 1167/5000\n",
      "ecpch:1166,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.6088 - val_loss: 192.1341\n",
      "\n",
      "Epoch 01167: val_loss did not improve from 179.48197\n",
      "Epoch 1168/5000\n",
      "ecpch:1167,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.6160 - val_loss: 192.2702\n",
      "\n",
      "Epoch 01168: val_loss did not improve from 179.48197\n",
      "Epoch 1169/5000\n",
      "ecpch:1168,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.6248 - val_loss: 192.1187\n",
      "\n",
      "Epoch 01169: val_loss did not improve from 179.48197\n",
      "Epoch 1170/5000\n",
      "ecpch:1169,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.6192 - val_loss: 192.1001\n",
      "\n",
      "Epoch 01170: val_loss did not improve from 179.48197\n",
      "Epoch 1171/5000\n",
      "ecpch:1170,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.5973 - val_loss: 192.2917\n",
      "\n",
      "Epoch 01171: val_loss did not improve from 179.48197\n",
      "Epoch 1172/5000\n",
      "ecpch:1171,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.6173 - val_loss: 192.1959\n",
      "\n",
      "Epoch 01172: val_loss did not improve from 179.48197\n",
      "Epoch 1173/5000\n",
      "ecpch:1172,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.5673 - val_loss: 192.1197\n",
      "\n",
      "Epoch 01173: val_loss did not improve from 179.48197\n",
      "Epoch 1174/5000\n",
      "ecpch:1173,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.5913 - val_loss: 192.2852\n",
      "\n",
      "Epoch 01174: val_loss did not improve from 179.48197\n",
      "Epoch 1175/5000\n",
      "ecpch:1174,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.5781 - val_loss: 192.2249\n",
      "\n",
      "Epoch 01175: val_loss did not improve from 179.48197\n",
      "Epoch 1176/5000\n",
      "ecpch:1175,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.5506 - val_loss: 192.1684\n",
      "\n",
      "Epoch 01176: val_loss did not improve from 179.48197\n",
      "Epoch 1177/5000\n",
      "ecpch:1176,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 57.5541 - val_loss: 192.2840\n",
      "\n",
      "Epoch 01177: val_loss did not improve from 179.48197\n",
      "Epoch 1178/5000\n",
      "ecpch:1177,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.5582 - val_loss: 192.1825\n",
      "\n",
      "Epoch 01178: val_loss did not improve from 179.48197\n",
      "Epoch 1179/5000\n",
      "ecpch:1178,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.5423 - val_loss: 192.1992\n",
      "\n",
      "Epoch 01179: val_loss did not improve from 179.48197\n",
      "Epoch 1180/5000\n",
      "ecpch:1179,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.5288 - val_loss: 192.2802\n",
      "\n",
      "Epoch 01180: val_loss did not improve from 179.48197\n",
      "Epoch 1181/5000\n",
      "ecpch:1180,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.5484 - val_loss: 192.1395\n",
      "\n",
      "Epoch 01181: val_loss did not improve from 179.48197\n",
      "Epoch 1182/5000\n",
      "ecpch:1181,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.5492 - val_loss: 192.2101\n",
      "\n",
      "Epoch 01182: val_loss did not improve from 179.48197\n",
      "Epoch 1183/5000\n",
      "ecpch:1182,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.5159 - val_loss: 192.3228\n",
      "\n",
      "Epoch 01183: val_loss did not improve from 179.48197\n",
      "Epoch 1184/5000\n",
      "ecpch:1183,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.5603 - val_loss: 192.1580\n",
      "\n",
      "Epoch 01184: val_loss did not improve from 179.48197\n",
      "Epoch 1185/5000\n",
      "ecpch:1184,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.5293 - val_loss: 192.1961\n",
      "\n",
      "Epoch 01185: val_loss did not improve from 179.48197\n",
      "Epoch 1186/5000\n",
      "ecpch:1185,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.5288 - val_loss: 192.3545\n",
      "\n",
      "Epoch 01186: val_loss did not improve from 179.48197\n",
      "Epoch 1187/5000\n",
      "ecpch:1186,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.5544 - val_loss: 192.2087\n",
      "\n",
      "Epoch 01187: val_loss did not improve from 179.48197\n",
      "Epoch 1188/5000\n",
      "ecpch:1187,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.5326 - val_loss: 192.1817\n",
      "\n",
      "Epoch 01188: val_loss did not improve from 179.48197\n",
      "Epoch 1189/5000\n",
      "ecpch:1188,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.5304 - val_loss: 192.3673\n",
      "\n",
      "Epoch 01189: val_loss did not improve from 179.48197\n",
      "Epoch 1190/5000\n",
      "ecpch:1189,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.5492 - val_loss: 192.2640\n",
      "\n",
      "Epoch 01190: val_loss did not improve from 179.48197\n",
      "Epoch 1191/5000\n",
      "ecpch:1190,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.5042 - val_loss: 192.1517\n",
      "\n",
      "Epoch 01191: val_loss did not improve from 179.48197\n",
      "Epoch 1192/5000\n",
      "ecpch:1191,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.5496 - val_loss: 192.3205\n",
      "\n",
      "Epoch 01192: val_loss did not improve from 179.48197\n",
      "Epoch 1193/5000\n",
      "ecpch:1192,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.4953 - val_loss: 192.3342\n",
      "\n",
      "Epoch 01193: val_loss did not improve from 179.48197\n",
      "Epoch 1194/5000\n",
      "ecpch:1193,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.5042 - val_loss: 192.1856\n",
      "\n",
      "Epoch 01194: val_loss did not improve from 179.48197\n",
      "Epoch 1195/5000\n",
      "ecpch:1194,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.5061 - val_loss: 192.2629\n",
      "\n",
      "Epoch 01195: val_loss did not improve from 179.48197\n",
      "Epoch 1196/5000\n",
      "ecpch:1195,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.4792 - val_loss: 192.3957\n",
      "\n",
      "Epoch 01196: val_loss did not improve from 179.48197\n",
      "Epoch 1197/5000\n",
      "ecpch:1196,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.5411 - val_loss: 192.2293\n",
      "\n",
      "Epoch 01197: val_loss did not improve from 179.48197\n",
      "Epoch 1198/5000\n",
      "ecpch:1197,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.4677 - val_loss: 192.1816\n",
      "\n",
      "Epoch 01198: val_loss did not improve from 179.48197\n",
      "Epoch 1199/5000\n",
      "ecpch:1198,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.5229 - val_loss: 192.3028\n",
      "\n",
      "Epoch 01199: val_loss did not improve from 179.48197\n",
      "Epoch 1200/5000\n",
      "ecpch:1199,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.4606 - val_loss: 192.2726\n",
      "\n",
      "Epoch 01200: val_loss did not improve from 179.48197\n",
      "Epoch 1201/5000\n",
      "ecpch:1200,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.4969 - val_loss: 192.2652\n",
      "\n",
      "Epoch 01201: val_loss did not improve from 179.48197\n",
      "Epoch 1202/5000\n",
      "ecpch:1201,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.4351 - val_loss: 192.2887\n",
      "\n",
      "Epoch 01202: val_loss did not improve from 179.48197\n",
      "Epoch 1203/5000\n",
      "ecpch:1202,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.4708 - val_loss: 192.3167\n",
      "\n",
      "Epoch 01203: val_loss did not improve from 179.48197\n",
      "Epoch 1204/5000\n",
      "ecpch:1203,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.4313 - val_loss: 192.2730\n",
      "\n",
      "Epoch 01204: val_loss did not improve from 179.48197\n",
      "Epoch 1205/5000\n",
      "ecpch:1204,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.4370 - val_loss: 192.3561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01205: val_loss did not improve from 179.48197\n",
      "Epoch 1206/5000\n",
      "ecpch:1205,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.4460 - val_loss: 192.3166\n",
      "\n",
      "Epoch 01206: val_loss did not improve from 179.48197\n",
      "Epoch 1207/5000\n",
      "ecpch:1206,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.4121 - val_loss: 192.3429\n",
      "\n",
      "Epoch 01207: val_loss did not improve from 179.48197\n",
      "Epoch 1208/5000\n",
      "ecpch:1207,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.4199 - val_loss: 192.3286\n",
      "\n",
      "Epoch 01208: val_loss did not improve from 179.48197\n",
      "Epoch 1209/5000\n",
      "ecpch:1208,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.4391 - val_loss: 192.3955\n",
      "\n",
      "Epoch 01209: val_loss did not improve from 179.48197\n",
      "Epoch 1210/5000\n",
      "ecpch:1209,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.4113 - val_loss: 192.2807\n",
      "\n",
      "Epoch 01210: val_loss did not improve from 179.48197\n",
      "Epoch 1211/5000\n",
      "ecpch:1210,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.4483 - val_loss: 192.3599\n",
      "\n",
      "Epoch 01211: val_loss did not improve from 179.48197\n",
      "Epoch 1212/5000\n",
      "ecpch:1211,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.3968 - val_loss: 192.3557\n",
      "\n",
      "Epoch 01212: val_loss did not improve from 179.48197\n",
      "Epoch 1213/5000\n",
      "ecpch:1212,learn rate 0.000035\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.3879 - val_loss: 192.2913\n",
      "\n",
      "Epoch 01213: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 01213: ReduceLROnPlateau reducing learning rate to 3.1906575532048013e-05.\n",
      "Epoch 1214/5000\n",
      "ecpch:1213,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.4100 - val_loss: 192.3612\n",
      "\n",
      "Epoch 01214: val_loss did not improve from 179.48197\n",
      "Epoch 1215/5000\n",
      "ecpch:1214,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.3862 - val_loss: 192.3175\n",
      "\n",
      "Epoch 01215: val_loss did not improve from 179.48197\n",
      "Epoch 1216/5000\n",
      "ecpch:1215,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.3760 - val_loss: 192.3705\n",
      "\n",
      "Epoch 01216: val_loss did not improve from 179.48197\n",
      "Epoch 1217/5000\n",
      "ecpch:1216,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.3842 - val_loss: 192.3250\n",
      "\n",
      "Epoch 01217: val_loss did not improve from 179.48197\n",
      "Epoch 1218/5000\n",
      "ecpch:1217,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.3762 - val_loss: 192.3758\n",
      "\n",
      "Epoch 01218: val_loss did not improve from 179.48197\n",
      "Epoch 1219/5000\n",
      "ecpch:1218,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.3656 - val_loss: 192.3433\n",
      "\n",
      "Epoch 01219: val_loss did not improve from 179.48197\n",
      "Epoch 1220/5000\n",
      "ecpch:1219,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.3570 - val_loss: 192.3871\n",
      "\n",
      "Epoch 01220: val_loss did not improve from 179.48197\n",
      "Epoch 1221/5000\n",
      "ecpch:1220,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.3626 - val_loss: 192.3378\n",
      "\n",
      "Epoch 01221: val_loss did not improve from 179.48197\n",
      "Epoch 1222/5000\n",
      "ecpch:1221,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.3682 - val_loss: 192.3941\n",
      "\n",
      "Epoch 01222: val_loss did not improve from 179.48197\n",
      "Epoch 1223/5000\n",
      "ecpch:1222,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.3493 - val_loss: 192.3845\n",
      "\n",
      "Epoch 01223: val_loss did not improve from 179.48197\n",
      "Epoch 1224/5000\n",
      "ecpch:1223,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.3390 - val_loss: 192.4137\n",
      "\n",
      "Epoch 01224: val_loss did not improve from 179.48197\n",
      "Epoch 1225/5000\n",
      "ecpch:1224,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.3398 - val_loss: 192.3154\n",
      "\n",
      "Epoch 01225: val_loss did not improve from 179.48197\n",
      "Epoch 1226/5000\n",
      "ecpch:1225,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.3715 - val_loss: 192.4381\n",
      "\n",
      "Epoch 01226: val_loss did not improve from 179.48197\n",
      "Epoch 1227/5000\n",
      "ecpch:1226,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.3395 - val_loss: 192.3819\n",
      "\n",
      "Epoch 01227: val_loss did not improve from 179.48197\n",
      "Epoch 1228/5000\n",
      "ecpch:1227,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.3279 - val_loss: 192.4415\n",
      "\n",
      "Epoch 01228: val_loss did not improve from 179.48197\n",
      "Epoch 1229/5000\n",
      "ecpch:1228,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.3328 - val_loss: 192.3276\n",
      "\n",
      "Epoch 01229: val_loss did not improve from 179.48197\n",
      "Epoch 1230/5000\n",
      "ecpch:1229,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.3550 - val_loss: 192.4252\n",
      "\n",
      "Epoch 01230: val_loss did not improve from 179.48197\n",
      "Epoch 1231/5000\n",
      "ecpch:1230,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.3148 - val_loss: 192.4137\n",
      "\n",
      "Epoch 01231: val_loss did not improve from 179.48197\n",
      "Epoch 1232/5000\n",
      "ecpch:1231,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.3143 - val_loss: 192.4321\n",
      "\n",
      "Epoch 01232: val_loss did not improve from 179.48197\n",
      "Epoch 1233/5000\n",
      "ecpch:1232,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.3272 - val_loss: 192.3631\n",
      "\n",
      "Epoch 01233: val_loss did not improve from 179.48197\n",
      "Epoch 1234/5000\n",
      "ecpch:1233,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.3243 - val_loss: 192.4429\n",
      "\n",
      "Epoch 01234: val_loss did not improve from 179.48197\n",
      "Epoch 1235/5000\n",
      "ecpch:1234,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.3082 - val_loss: 192.3632\n",
      "\n",
      "Epoch 01235: val_loss did not improve from 179.48197\n",
      "Epoch 1236/5000\n",
      "ecpch:1235,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.3137 - val_loss: 192.4428\n",
      "\n",
      "Epoch 01236: val_loss did not improve from 179.48197\n",
      "Epoch 1237/5000\n",
      "ecpch:1236,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.3010 - val_loss: 192.3663\n",
      "\n",
      "Epoch 01237: val_loss did not improve from 179.48197\n",
      "Epoch 1238/5000\n",
      "ecpch:1237,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.3039 - val_loss: 192.4515\n",
      "\n",
      "Epoch 01238: val_loss did not improve from 179.48197\n",
      "Epoch 1239/5000\n",
      "ecpch:1238,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.2950 - val_loss: 192.3801\n",
      "\n",
      "Epoch 01239: val_loss did not improve from 179.48197\n",
      "Epoch 1240/5000\n",
      "ecpch:1239,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.2933 - val_loss: 192.4614\n",
      "\n",
      "Epoch 01240: val_loss did not improve from 179.48197\n",
      "Epoch 1241/5000\n",
      "ecpch:1240,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.2874 - val_loss: 192.4334\n",
      "\n",
      "Epoch 01241: val_loss did not improve from 179.48197\n",
      "Epoch 1242/5000\n",
      "ecpch:1241,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.2770 - val_loss: 192.4211\n",
      "\n",
      "Epoch 01242: val_loss did not improve from 179.48197\n",
      "Epoch 1243/5000\n",
      "ecpch:1242,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.2796 - val_loss: 192.4716\n",
      "\n",
      "Epoch 01243: val_loss did not improve from 179.48197\n",
      "Epoch 1244/5000\n",
      "ecpch:1243,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.2827 - val_loss: 192.4104\n",
      "\n",
      "Epoch 01244: val_loss did not improve from 179.48197\n",
      "Epoch 1245/5000\n",
      "ecpch:1244,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.2662 - val_loss: 192.4898\n",
      "\n",
      "Epoch 01245: val_loss did not improve from 179.48197\n",
      "Epoch 1246/5000\n",
      "ecpch:1245,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.2665 - val_loss: 192.4023\n",
      "\n",
      "Epoch 01246: val_loss did not improve from 179.48197\n",
      "Epoch 1247/5000\n",
      "ecpch:1246,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.2770 - val_loss: 192.4928\n",
      "\n",
      "Epoch 01247: val_loss did not improve from 179.48197\n",
      "Epoch 1248/5000\n",
      "ecpch:1247,learn rate 0.000032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 9ms/step - loss: 57.2660 - val_loss: 192.4661\n",
      "\n",
      "Epoch 01248: val_loss did not improve from 179.48197\n",
      "Epoch 1249/5000\n",
      "ecpch:1248,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.2647 - val_loss: 192.4543\n",
      "\n",
      "Epoch 01249: val_loss did not improve from 179.48197\n",
      "Epoch 1250/5000\n",
      "ecpch:1249,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.2445 - val_loss: 192.5085\n",
      "\n",
      "Epoch 01250: val_loss did not improve from 179.48197\n",
      "Epoch 1251/5000\n",
      "ecpch:1250,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.2480 - val_loss: 192.3807\n",
      "\n",
      "Epoch 01251: val_loss did not improve from 179.48197\n",
      "Epoch 1252/5000\n",
      "ecpch:1251,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.2779 - val_loss: 192.4888\n",
      "\n",
      "Epoch 01252: val_loss did not improve from 179.48197\n",
      "Epoch 1253/5000\n",
      "ecpch:1252,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.2316 - val_loss: 192.4692\n",
      "\n",
      "Epoch 01253: val_loss did not improve from 179.48197\n",
      "Epoch 1254/5000\n",
      "ecpch:1253,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.2221 - val_loss: 192.4838\n",
      "\n",
      "Epoch 01254: val_loss did not improve from 179.48197\n",
      "Epoch 1255/5000\n",
      "ecpch:1254,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.2172 - val_loss: 192.4796\n",
      "\n",
      "Epoch 01255: val_loss did not improve from 179.48197\n",
      "Epoch 1256/5000\n",
      "ecpch:1255,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.2138 - val_loss: 192.5122\n",
      "\n",
      "Epoch 01256: val_loss did not improve from 179.48197\n",
      "Epoch 1257/5000\n",
      "ecpch:1256,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.2274 - val_loss: 192.3958\n",
      "\n",
      "Epoch 01257: val_loss did not improve from 179.48197\n",
      "Epoch 1258/5000\n",
      "ecpch:1257,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.2689 - val_loss: 192.5124\n",
      "\n",
      "Epoch 01258: val_loss did not improve from 179.48197\n",
      "Epoch 1259/5000\n",
      "ecpch:1258,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.2042 - val_loss: 192.5319\n",
      "\n",
      "Epoch 01259: val_loss did not improve from 179.48197\n",
      "Epoch 1260/5000\n",
      "ecpch:1259,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.2602 - val_loss: 192.4477\n",
      "\n",
      "Epoch 01260: val_loss did not improve from 179.48197\n",
      "Epoch 1261/5000\n",
      "ecpch:1260,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.2172 - val_loss: 192.5597\n",
      "\n",
      "Epoch 01261: val_loss did not improve from 179.48197\n",
      "Epoch 1262/5000\n",
      "ecpch:1261,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 57.2479 - val_loss: 192.5005\n",
      "\n",
      "Epoch 01262: val_loss did not improve from 179.48197\n",
      "Epoch 1263/5000\n",
      "ecpch:1262,learn rate 0.000032\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.2058 - val_loss: 192.4758\n",
      "\n",
      "Epoch 01263: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 01263: ReduceLROnPlateau reducing learning rate to 2.8715918961097487e-05.\n",
      "Epoch 1264/5000\n",
      "ecpch:1263,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.1926 - val_loss: 192.5419\n",
      "\n",
      "Epoch 01264: val_loss did not improve from 179.48197\n",
      "Epoch 1265/5000\n",
      "ecpch:1264,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.2092 - val_loss: 192.5263\n",
      "\n",
      "Epoch 01265: val_loss did not improve from 179.48197\n",
      "Epoch 1266/5000\n",
      "ecpch:1265,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.1902 - val_loss: 192.4494\n",
      "\n",
      "Epoch 01266: val_loss did not improve from 179.48197\n",
      "Epoch 1267/5000\n",
      "ecpch:1266,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.2063 - val_loss: 192.5409\n",
      "\n",
      "Epoch 01267: val_loss did not improve from 179.48197\n",
      "Epoch 1268/5000\n",
      "ecpch:1267,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.2072 - val_loss: 192.5467\n",
      "\n",
      "Epoch 01268: val_loss did not improve from 179.48197\n",
      "Epoch 1269/5000\n",
      "ecpch:1268,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.1749 - val_loss: 192.4172\n",
      "\n",
      "Epoch 01269: val_loss did not improve from 179.48197\n",
      "Epoch 1270/5000\n",
      "ecpch:1269,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.2388 - val_loss: 192.5038\n",
      "\n",
      "Epoch 01270: val_loss did not improve from 179.48197\n",
      "Epoch 1271/5000\n",
      "ecpch:1270,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.1697 - val_loss: 192.7062\n",
      "\n",
      "Epoch 01271: val_loss did not improve from 179.48197\n",
      "Epoch 1272/5000\n",
      "ecpch:1271,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.2823 - val_loss: 192.5823\n",
      "\n",
      "Epoch 01272: val_loss did not improve from 179.48197\n",
      "Epoch 1273/5000\n",
      "ecpch:1272,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.1684 - val_loss: 192.3078\n",
      "\n",
      "Epoch 01273: val_loss did not improve from 179.48197\n",
      "Epoch 1274/5000\n",
      "ecpch:1273,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.3473 - val_loss: 192.3501\n",
      "\n",
      "Epoch 01274: val_loss did not improve from 179.48197\n",
      "Epoch 1275/5000\n",
      "ecpch:1274,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.2965 - val_loss: 192.6741\n",
      "\n",
      "Epoch 01275: val_loss did not improve from 179.48197\n",
      "Epoch 1276/5000\n",
      "ecpch:1275,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.2194 - val_loss: 192.6989\n",
      "\n",
      "Epoch 01276: val_loss did not improve from 179.48197\n",
      "Epoch 1277/5000\n",
      "ecpch:1276,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.2461 - val_loss: 192.4407\n",
      "\n",
      "Epoch 01277: val_loss did not improve from 179.48197\n",
      "Epoch 1278/5000\n",
      "ecpch:1277,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.2029 - val_loss: 192.4188\n",
      "\n",
      "Epoch 01278: val_loss did not improve from 179.48197\n",
      "Epoch 1279/5000\n",
      "ecpch:1278,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.2190 - val_loss: 192.6221\n",
      "\n",
      "Epoch 01279: val_loss did not improve from 179.48197\n",
      "Epoch 1280/5000\n",
      "ecpch:1279,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.1674 - val_loss: 192.5922\n",
      "\n",
      "Epoch 01280: val_loss did not improve from 179.48197\n",
      "Epoch 1281/5000\n",
      "ecpch:1280,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.1538 - val_loss: 192.4913\n",
      "\n",
      "Epoch 01281: val_loss did not improve from 179.48197\n",
      "Epoch 1282/5000\n",
      "ecpch:1281,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.1466 - val_loss: 192.5331\n",
      "\n",
      "Epoch 01282: val_loss did not improve from 179.48197\n",
      "Epoch 1283/5000\n",
      "ecpch:1282,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.1342 - val_loss: 192.6274\n",
      "\n",
      "Epoch 01283: val_loss did not improve from 179.48197\n",
      "Epoch 1284/5000\n",
      "ecpch:1283,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.1659 - val_loss: 192.5036\n",
      "\n",
      "Epoch 01284: val_loss did not improve from 179.48197\n",
      "Epoch 1285/5000\n",
      "ecpch:1284,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.1293 - val_loss: 192.5082\n",
      "\n",
      "Epoch 01285: val_loss did not improve from 179.48197\n",
      "Epoch 1286/5000\n",
      "ecpch:1285,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.1648 - val_loss: 192.6220\n",
      "\n",
      "Epoch 01286: val_loss did not improve from 179.48197\n",
      "Epoch 1287/5000\n",
      "ecpch:1286,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.1330 - val_loss: 192.5470\n",
      "\n",
      "Epoch 01287: val_loss did not improve from 179.48197\n",
      "Epoch 1288/5000\n",
      "ecpch:1287,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.1590 - val_loss: 192.5382\n",
      "\n",
      "Epoch 01288: val_loss did not improve from 179.48197\n",
      "Epoch 1289/5000\n",
      "ecpch:1288,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.1103 - val_loss: 192.6444\n",
      "\n",
      "Epoch 01289: val_loss did not improve from 179.48197\n",
      "Epoch 1290/5000\n",
      "ecpch:1289,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.1448 - val_loss: 192.5873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01290: val_loss did not improve from 179.48197\n",
      "Epoch 1291/5000\n",
      "ecpch:1290,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.0963 - val_loss: 192.5808\n",
      "\n",
      "Epoch 01291: val_loss did not improve from 179.48197\n",
      "Epoch 1292/5000\n",
      "ecpch:1291,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.1322 - val_loss: 192.6365\n",
      "\n",
      "Epoch 01292: val_loss did not improve from 179.48197\n",
      "Epoch 1293/5000\n",
      "ecpch:1292,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.0935 - val_loss: 192.6138\n",
      "\n",
      "Epoch 01293: val_loss did not improve from 179.48197\n",
      "Epoch 1294/5000\n",
      "ecpch:1293,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.0930 - val_loss: 192.6335\n",
      "\n",
      "Epoch 01294: val_loss did not improve from 179.48197\n",
      "Epoch 1295/5000\n",
      "ecpch:1294,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.1174 - val_loss: 192.6174\n",
      "\n",
      "Epoch 01295: val_loss did not improve from 179.48197\n",
      "Epoch 1296/5000\n",
      "ecpch:1295,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.0745 - val_loss: 192.6693\n",
      "\n",
      "Epoch 01296: val_loss did not improve from 179.48197\n",
      "Epoch 1297/5000\n",
      "ecpch:1296,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.1150 - val_loss: 192.5942\n",
      "\n",
      "Epoch 01297: val_loss did not improve from 179.48197\n",
      "Epoch 1298/5000\n",
      "ecpch:1297,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.0762 - val_loss: 192.6283\n",
      "\n",
      "Epoch 01298: val_loss did not improve from 179.48197\n",
      "Epoch 1299/5000\n",
      "ecpch:1298,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.0744 - val_loss: 192.6268\n",
      "\n",
      "Epoch 01299: val_loss did not improve from 179.48197\n",
      "Epoch 1300/5000\n",
      "ecpch:1299,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.0993 - val_loss: 192.6207\n",
      "\n",
      "Epoch 01300: val_loss did not improve from 179.48197\n",
      "Epoch 1301/5000\n",
      "ecpch:1300,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.0588 - val_loss: 192.5531\n",
      "\n",
      "Epoch 01301: val_loss did not improve from 179.48197\n",
      "Epoch 1302/5000\n",
      "ecpch:1301,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.1134 - val_loss: 192.6096\n",
      "\n",
      "Epoch 01302: val_loss did not improve from 179.48197\n",
      "Epoch 1303/5000\n",
      "ecpch:1302,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.0473 - val_loss: 192.7097\n",
      "\n",
      "Epoch 01303: val_loss did not improve from 179.48197\n",
      "Epoch 1304/5000\n",
      "ecpch:1303,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.1301 - val_loss: 192.6072\n",
      "\n",
      "Epoch 01304: val_loss did not improve from 179.48197\n",
      "Epoch 1305/5000\n",
      "ecpch:1304,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.0468 - val_loss: 192.6109\n",
      "\n",
      "Epoch 01305: val_loss did not improve from 179.48197\n",
      "Epoch 1306/5000\n",
      "ecpch:1305,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.1347 - val_loss: 192.6684\n",
      "\n",
      "Epoch 01306: val_loss did not improve from 179.48197\n",
      "Epoch 1307/5000\n",
      "ecpch:1306,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.0782 - val_loss: 192.6488\n",
      "\n",
      "Epoch 01307: val_loss did not improve from 179.48197\n",
      "Epoch 1308/5000\n",
      "ecpch:1307,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.1401 - val_loss: 192.6331\n",
      "\n",
      "Epoch 01308: val_loss did not improve from 179.48197\n",
      "Epoch 1309/5000\n",
      "ecpch:1308,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.1229 - val_loss: 192.6697\n",
      "\n",
      "Epoch 01309: val_loss did not improve from 179.48197\n",
      "Epoch 1310/5000\n",
      "ecpch:1309,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.0670 - val_loss: 192.6508\n",
      "\n",
      "Epoch 01310: val_loss did not improve from 179.48197\n",
      "Epoch 1311/5000\n",
      "ecpch:1310,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.0783 - val_loss: 192.6858\n",
      "\n",
      "Epoch 01311: val_loss did not improve from 179.48197\n",
      "Epoch 1312/5000\n",
      "ecpch:1311,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.0540 - val_loss: 192.6741\n",
      "\n",
      "Epoch 01312: val_loss did not improve from 179.48197\n",
      "Epoch 1313/5000\n",
      "ecpch:1312,learn rate 0.000029\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.0398 - val_loss: 192.6689\n",
      "\n",
      "Epoch 01313: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 01313: ReduceLROnPlateau reducing learning rate to 2.5844326410151554e-05.\n",
      "Epoch 1314/5000\n",
      "ecpch:1313,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.0694 - val_loss: 192.6687\n",
      "\n",
      "Epoch 01314: val_loss did not improve from 179.48197\n",
      "Epoch 1315/5000\n",
      "ecpch:1314,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.0357 - val_loss: 192.6644\n",
      "\n",
      "Epoch 01315: val_loss did not improve from 179.48197\n",
      "Epoch 1316/5000\n",
      "ecpch:1315,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.0546 - val_loss: 192.6816\n",
      "\n",
      "Epoch 01316: val_loss did not improve from 179.48197\n",
      "Epoch 1317/5000\n",
      "ecpch:1316,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.0392 - val_loss: 192.6165\n",
      "\n",
      "Epoch 01317: val_loss did not improve from 179.48197\n",
      "Epoch 1318/5000\n",
      "ecpch:1317,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.0508 - val_loss: 192.6267\n",
      "\n",
      "Epoch 01318: val_loss did not improve from 179.48197\n",
      "Epoch 1319/5000\n",
      "ecpch:1318,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.0346 - val_loss: 192.7064\n",
      "\n",
      "Epoch 01319: val_loss did not improve from 179.48197\n",
      "Epoch 1320/5000\n",
      "ecpch:1319,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.0423 - val_loss: 192.6436\n",
      "\n",
      "Epoch 01320: val_loss did not improve from 179.48197\n",
      "Epoch 1321/5000\n",
      "ecpch:1320,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.0314 - val_loss: 192.6588\n",
      "\n",
      "Epoch 01321: val_loss did not improve from 179.48197\n",
      "Epoch 1322/5000\n",
      "ecpch:1321,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.0140 - val_loss: 192.7053\n",
      "\n",
      "Epoch 01322: val_loss did not improve from 179.48197\n",
      "Epoch 1323/5000\n",
      "ecpch:1322,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.0172 - val_loss: 192.6633\n",
      "\n",
      "Epoch 01323: val_loss did not improve from 179.48197\n",
      "Epoch 1324/5000\n",
      "ecpch:1323,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.0075 - val_loss: 192.7086\n",
      "\n",
      "Epoch 01324: val_loss did not improve from 179.48197\n",
      "Epoch 1325/5000\n",
      "ecpch:1324,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.9931 - val_loss: 192.6742\n",
      "\n",
      "Epoch 01325: val_loss did not improve from 179.48197\n",
      "Epoch 1326/5000\n",
      "ecpch:1325,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 57.0016 - val_loss: 192.7109\n",
      "\n",
      "Epoch 01326: val_loss did not improve from 179.48197\n",
      "Epoch 1327/5000\n",
      "ecpch:1326,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.9813 - val_loss: 192.7000\n",
      "\n",
      "Epoch 01327: val_loss did not improve from 179.48197\n",
      "Epoch 1328/5000\n",
      "ecpch:1327,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 57.0001 - val_loss: 192.7307\n",
      "\n",
      "Epoch 01328: val_loss did not improve from 179.48197\n",
      "Epoch 1329/5000\n",
      "ecpch:1328,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.9715 - val_loss: 192.6645\n",
      "\n",
      "Epoch 01329: val_loss did not improve from 179.48197\n",
      "Epoch 1330/5000\n",
      "ecpch:1329,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.0036 - val_loss: 192.7104\n",
      "\n",
      "Epoch 01330: val_loss did not improve from 179.48197\n",
      "Epoch 1331/5000\n",
      "ecpch:1330,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.9603 - val_loss: 192.7790\n",
      "\n",
      "Epoch 01331: val_loss did not improve from 179.48197\n",
      "Epoch 1332/5000\n",
      "ecpch:1331,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.0102 - val_loss: 192.6724\n",
      "\n",
      "Epoch 01332: val_loss did not improve from 179.48197\n",
      "Epoch 1333/5000\n",
      "ecpch:1332,learn rate 0.000026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 11ms/step - loss: 56.9769 - val_loss: 192.6982\n",
      "\n",
      "Epoch 01333: val_loss did not improve from 179.48197\n",
      "Epoch 1334/5000\n",
      "ecpch:1333,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 57.0047 - val_loss: 192.7735\n",
      "\n",
      "Epoch 01334: val_loss did not improve from 179.48197\n",
      "Epoch 1335/5000\n",
      "ecpch:1334,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.9812 - val_loss: 192.7027\n",
      "\n",
      "Epoch 01335: val_loss did not improve from 179.48197\n",
      "Epoch 1336/5000\n",
      "ecpch:1335,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.9984 - val_loss: 192.6971\n",
      "\n",
      "Epoch 01336: val_loss did not improve from 179.48197\n",
      "Epoch 1337/5000\n",
      "ecpch:1336,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.9767 - val_loss: 192.7623\n",
      "\n",
      "Epoch 01337: val_loss did not improve from 179.48197\n",
      "Epoch 1338/5000\n",
      "ecpch:1337,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.9961 - val_loss: 192.7216\n",
      "\n",
      "Epoch 01338: val_loss did not improve from 179.48197\n",
      "Epoch 1339/5000\n",
      "ecpch:1338,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.9719 - val_loss: 192.7038\n",
      "\n",
      "Epoch 01339: val_loss did not improve from 179.48197\n",
      "Epoch 1340/5000\n",
      "ecpch:1339,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.9793 - val_loss: 192.7576\n",
      "\n",
      "Epoch 01340: val_loss did not improve from 179.48197\n",
      "Epoch 1341/5000\n",
      "ecpch:1340,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.9727 - val_loss: 192.7127\n",
      "\n",
      "Epoch 01341: val_loss did not improve from 179.48197\n",
      "Epoch 1342/5000\n",
      "ecpch:1341,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.9559 - val_loss: 192.7373\n",
      "\n",
      "Epoch 01342: val_loss did not improve from 179.48197\n",
      "Epoch 1343/5000\n",
      "ecpch:1342,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.9431 - val_loss: 192.7714\n",
      "\n",
      "Epoch 01343: val_loss did not improve from 179.48197\n",
      "Epoch 1344/5000\n",
      "ecpch:1343,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.9648 - val_loss: 192.7240\n",
      "\n",
      "Epoch 01344: val_loss did not improve from 179.48197\n",
      "Epoch 1345/5000\n",
      "ecpch:1344,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.9466 - val_loss: 192.7732\n",
      "\n",
      "Epoch 01345: val_loss did not improve from 179.48197\n",
      "Epoch 1346/5000\n",
      "ecpch:1345,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.9568 - val_loss: 192.7524\n",
      "\n",
      "Epoch 01346: val_loss did not improve from 179.48197\n",
      "Epoch 1347/5000\n",
      "ecpch:1346,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.9325 - val_loss: 192.7610\n",
      "\n",
      "Epoch 01347: val_loss did not improve from 179.48197\n",
      "Epoch 1348/5000\n",
      "ecpch:1347,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.9483 - val_loss: 192.7668\n",
      "\n",
      "Epoch 01348: val_loss did not improve from 179.48197\n",
      "Epoch 1349/5000\n",
      "ecpch:1348,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.9313 - val_loss: 192.7620\n",
      "\n",
      "Epoch 01349: val_loss did not improve from 179.48197\n",
      "Epoch 1350/5000\n",
      "ecpch:1349,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.9401 - val_loss: 192.7726\n",
      "\n",
      "Epoch 01350: val_loss did not improve from 179.48197\n",
      "Epoch 1351/5000\n",
      "ecpch:1350,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.9226 - val_loss: 192.7470\n",
      "\n",
      "Epoch 01351: val_loss did not improve from 179.48197\n",
      "Epoch 1352/5000\n",
      "ecpch:1351,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.9322 - val_loss: 192.7832\n",
      "\n",
      "Epoch 01352: val_loss did not improve from 179.48197\n",
      "Epoch 1353/5000\n",
      "ecpch:1352,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.9190 - val_loss: 192.7349\n",
      "\n",
      "Epoch 01353: val_loss did not improve from 179.48197\n",
      "Epoch 1354/5000\n",
      "ecpch:1353,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.9232 - val_loss: 192.7520\n",
      "\n",
      "Epoch 01354: val_loss did not improve from 179.48197\n",
      "Epoch 1355/5000\n",
      "ecpch:1354,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.9034 - val_loss: 192.8169\n",
      "\n",
      "Epoch 01355: val_loss did not improve from 179.48197\n",
      "Epoch 1356/5000\n",
      "ecpch:1355,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.9260 - val_loss: 192.7166\n",
      "\n",
      "Epoch 01356: val_loss did not improve from 179.48197\n",
      "Epoch 1357/5000\n",
      "ecpch:1356,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.9236 - val_loss: 192.7664\n",
      "\n",
      "Epoch 01357: val_loss did not improve from 179.48197\n",
      "Epoch 1358/5000\n",
      "ecpch:1357,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.8922 - val_loss: 192.8658\n",
      "\n",
      "Epoch 01358: val_loss did not improve from 179.48197\n",
      "Epoch 1359/5000\n",
      "ecpch:1358,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.9190 - val_loss: 192.7829\n",
      "\n",
      "Epoch 01359: val_loss did not improve from 179.48197\n",
      "Epoch 1360/5000\n",
      "ecpch:1359,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.8778 - val_loss: 192.7453\n",
      "\n",
      "Epoch 01360: val_loss did not improve from 179.48197\n",
      "Epoch 1361/5000\n",
      "ecpch:1360,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.8900 - val_loss: 192.8517\n",
      "\n",
      "Epoch 01361: val_loss did not improve from 179.48197\n",
      "Epoch 1362/5000\n",
      "ecpch:1361,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.8898 - val_loss: 192.8322\n",
      "\n",
      "Epoch 01362: val_loss did not improve from 179.48197\n",
      "Epoch 1363/5000\n",
      "ecpch:1362,learn rate 0.000026\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.8639 - val_loss: 192.7167\n",
      "\n",
      "Epoch 01363: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 01363: ReduceLROnPlateau reducing learning rate to 2.3259894260263535e-05.\n",
      "Epoch 1364/5000\n",
      "ecpch:1363,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.9109 - val_loss: 192.7789\n",
      "\n",
      "Epoch 01364: val_loss did not improve from 179.48197\n",
      "Epoch 1365/5000\n",
      "ecpch:1364,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.8576 - val_loss: 192.9232\n",
      "\n",
      "Epoch 01365: val_loss did not improve from 179.48197\n",
      "Epoch 1366/5000\n",
      "ecpch:1365,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.9222 - val_loss: 192.8491\n",
      "\n",
      "Epoch 01366: val_loss did not improve from 179.48197\n",
      "Epoch 1367/5000\n",
      "ecpch:1366,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.8643 - val_loss: 192.6824\n",
      "\n",
      "Epoch 01367: val_loss did not improve from 179.48197\n",
      "Epoch 1368/5000\n",
      "ecpch:1367,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.9282 - val_loss: 192.7105\n",
      "\n",
      "Epoch 01368: val_loss did not improve from 179.48197\n",
      "Epoch 1369/5000\n",
      "ecpch:1368,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.9055 - val_loss: 192.8878\n",
      "\n",
      "Epoch 01369: val_loss did not improve from 179.48197\n",
      "Epoch 1370/5000\n",
      "ecpch:1369,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.8766 - val_loss: 192.8767\n",
      "\n",
      "Epoch 01370: val_loss did not improve from 179.48197\n",
      "Epoch 1371/5000\n",
      "ecpch:1370,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.8746 - val_loss: 192.7342\n",
      "\n",
      "Epoch 01371: val_loss did not improve from 179.48197\n",
      "Epoch 1372/5000\n",
      "ecpch:1371,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.8724 - val_loss: 192.7479\n",
      "\n",
      "Epoch 01372: val_loss did not improve from 179.48197\n",
      "Epoch 1373/5000\n",
      "ecpch:1372,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.8704 - val_loss: 192.8883\n",
      "\n",
      "Epoch 01373: val_loss did not improve from 179.48197\n",
      "Epoch 1374/5000\n",
      "ecpch:1373,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.8541 - val_loss: 192.8788\n",
      "\n",
      "Epoch 01374: val_loss did not improve from 179.48197\n",
      "Epoch 1375/5000\n",
      "ecpch:1374,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.8554 - val_loss: 192.7713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01375: val_loss did not improve from 179.48197\n",
      "Epoch 1376/5000\n",
      "ecpch:1375,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.8402 - val_loss: 192.7975\n",
      "\n",
      "Epoch 01376: val_loss did not improve from 179.48197\n",
      "Epoch 1377/5000\n",
      "ecpch:1376,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.8434 - val_loss: 192.8930\n",
      "\n",
      "Epoch 01377: val_loss did not improve from 179.48197\n",
      "Epoch 1378/5000\n",
      "ecpch:1377,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.8370 - val_loss: 192.8457\n",
      "\n",
      "Epoch 01378: val_loss did not improve from 179.48197\n",
      "Epoch 1379/5000\n",
      "ecpch:1378,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.8332 - val_loss: 192.8014\n",
      "\n",
      "Epoch 01379: val_loss did not improve from 179.48197\n",
      "Epoch 1380/5000\n",
      "ecpch:1379,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.8228 - val_loss: 192.8628\n",
      "\n",
      "Epoch 01380: val_loss did not improve from 179.48197\n",
      "Epoch 1381/5000\n",
      "ecpch:1380,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.8162 - val_loss: 192.8781\n",
      "\n",
      "Epoch 01381: val_loss did not improve from 179.48197\n",
      "Epoch 1382/5000\n",
      "ecpch:1381,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 56.8086 - val_loss: 192.8428\n",
      "\n",
      "Epoch 01382: val_loss did not improve from 179.48197\n",
      "Epoch 1383/5000\n",
      "ecpch:1382,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.8052 - val_loss: 192.8719\n",
      "\n",
      "Epoch 01383: val_loss did not improve from 179.48197\n",
      "Epoch 1384/5000\n",
      "ecpch:1383,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.8003 - val_loss: 192.8677\n",
      "\n",
      "Epoch 01384: val_loss did not improve from 179.48197\n",
      "Epoch 1385/5000\n",
      "ecpch:1384,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.7895 - val_loss: 192.8392\n",
      "\n",
      "Epoch 01385: val_loss did not improve from 179.48197\n",
      "Epoch 1386/5000\n",
      "ecpch:1385,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.8076 - val_loss: 192.9031\n",
      "\n",
      "Epoch 01386: val_loss did not improve from 179.48197\n",
      "Epoch 1387/5000\n",
      "ecpch:1386,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.7899 - val_loss: 192.8677\n",
      "\n",
      "Epoch 01387: val_loss did not improve from 179.48197\n",
      "Epoch 1388/5000\n",
      "ecpch:1387,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.7902 - val_loss: 192.8684\n",
      "\n",
      "Epoch 01388: val_loss did not improve from 179.48197\n",
      "Epoch 1389/5000\n",
      "ecpch:1388,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.7825 - val_loss: 192.9105\n",
      "\n",
      "Epoch 01389: val_loss did not improve from 179.48197\n",
      "Epoch 1390/5000\n",
      "ecpch:1389,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.7779 - val_loss: 192.8476\n",
      "\n",
      "Epoch 01390: val_loss did not improve from 179.48197\n",
      "Epoch 1391/5000\n",
      "ecpch:1390,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.7818 - val_loss: 192.9166\n",
      "\n",
      "Epoch 01391: val_loss did not improve from 179.48197\n",
      "Epoch 1392/5000\n",
      "ecpch:1391,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.7697 - val_loss: 192.8808\n",
      "\n",
      "Epoch 01392: val_loss did not improve from 179.48197\n",
      "Epoch 1393/5000\n",
      "ecpch:1392,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.7632 - val_loss: 192.9050\n",
      "\n",
      "Epoch 01393: val_loss did not improve from 179.48197\n",
      "Epoch 1394/5000\n",
      "ecpch:1393,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.7630 - val_loss: 192.8575\n",
      "\n",
      "Epoch 01394: val_loss did not improve from 179.48197\n",
      "Epoch 1395/5000\n",
      "ecpch:1394,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.7692 - val_loss: 192.9160\n",
      "\n",
      "Epoch 01395: val_loss did not improve from 179.48197\n",
      "Epoch 1396/5000\n",
      "ecpch:1395,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.7559 - val_loss: 192.8743\n",
      "\n",
      "Epoch 01396: val_loss did not improve from 179.48197\n",
      "Epoch 1397/5000\n",
      "ecpch:1396,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.7533 - val_loss: 192.9138\n",
      "\n",
      "Epoch 01397: val_loss did not improve from 179.48197\n",
      "Epoch 1398/5000\n",
      "ecpch:1397,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.7498 - val_loss: 192.8964\n",
      "\n",
      "Epoch 01398: val_loss did not improve from 179.48197\n",
      "Epoch 1399/5000\n",
      "ecpch:1398,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.7436 - val_loss: 192.9072\n",
      "\n",
      "Epoch 01399: val_loss did not improve from 179.48197\n",
      "Epoch 1400/5000\n",
      "ecpch:1399,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.7396 - val_loss: 192.9364\n",
      "\n",
      "Epoch 01400: val_loss did not improve from 179.48197\n",
      "Epoch 1401/5000\n",
      "ecpch:1400,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.7457 - val_loss: 192.8352\n",
      "\n",
      "Epoch 01401: val_loss did not improve from 179.48197\n",
      "Epoch 1402/5000\n",
      "ecpch:1401,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.7759 - val_loss: 192.9279\n",
      "\n",
      "Epoch 01402: val_loss did not improve from 179.48197\n",
      "Epoch 1403/5000\n",
      "ecpch:1402,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.7308 - val_loss: 192.9606\n",
      "\n",
      "Epoch 01403: val_loss did not improve from 179.48197\n",
      "Epoch 1404/5000\n",
      "ecpch:1403,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.7563 - val_loss: 192.8599\n",
      "\n",
      "Epoch 01404: val_loss did not improve from 179.48197\n",
      "Epoch 1405/5000\n",
      "ecpch:1404,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.7576 - val_loss: 192.9216\n",
      "\n",
      "Epoch 01405: val_loss did not improve from 179.48197\n",
      "Epoch 1406/5000\n",
      "ecpch:1405,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.7325 - val_loss: 193.0178\n",
      "\n",
      "Epoch 01406: val_loss did not improve from 179.48197\n",
      "Epoch 1407/5000\n",
      "ecpch:1406,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.7913 - val_loss: 192.9001\n",
      "\n",
      "Epoch 01407: val_loss did not improve from 179.48197\n",
      "Epoch 1408/5000\n",
      "ecpch:1407,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.7464 - val_loss: 192.8789\n",
      "\n",
      "Epoch 01408: val_loss did not improve from 179.48197\n",
      "Epoch 1409/5000\n",
      "ecpch:1408,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.7656 - val_loss: 192.9554\n",
      "\n",
      "Epoch 01409: val_loss did not improve from 179.48197\n",
      "Epoch 1410/5000\n",
      "ecpch:1409,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.7347 - val_loss: 192.9226\n",
      "\n",
      "Epoch 01410: val_loss did not improve from 179.48197\n",
      "Epoch 1411/5000\n",
      "ecpch:1410,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.7589 - val_loss: 192.9102\n",
      "\n",
      "Epoch 01411: val_loss did not improve from 179.48197\n",
      "Epoch 1412/5000\n",
      "ecpch:1411,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.7323 - val_loss: 192.9587\n",
      "\n",
      "Epoch 01412: val_loss did not improve from 179.48197\n",
      "Epoch 1413/5000\n",
      "ecpch:1412,learn rate 0.000023\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.7653 - val_loss: 192.9220\n",
      "\n",
      "Epoch 01413: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 01413: ReduceLROnPlateau reducing learning rate to 2.0933904670528138e-05.\n",
      "Epoch 1414/5000\n",
      "ecpch:1413,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.7433 - val_loss: 192.9283\n",
      "\n",
      "Epoch 01414: val_loss did not improve from 179.48197\n",
      "Epoch 1415/5000\n",
      "ecpch:1414,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.7300 - val_loss: 192.9516\n",
      "\n",
      "Epoch 01415: val_loss did not improve from 179.48197\n",
      "Epoch 1416/5000\n",
      "ecpch:1415,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.7395 - val_loss: 192.9234\n",
      "\n",
      "Epoch 01416: val_loss did not improve from 179.48197\n",
      "Epoch 1417/5000\n",
      "ecpch:1416,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.7046 - val_loss: 192.9340\n",
      "\n",
      "Epoch 01417: val_loss did not improve from 179.48197\n",
      "Epoch 1418/5000\n",
      "ecpch:1417,learn rate 0.000021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 10ms/step - loss: 56.7194 - val_loss: 192.9620\n",
      "\n",
      "Epoch 01418: val_loss did not improve from 179.48197\n",
      "Epoch 1419/5000\n",
      "ecpch:1418,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.6971 - val_loss: 192.8881\n",
      "\n",
      "Epoch 01419: val_loss did not improve from 179.48197\n",
      "Epoch 1420/5000\n",
      "ecpch:1419,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.7272 - val_loss: 192.9377\n",
      "\n",
      "Epoch 01420: val_loss did not improve from 179.48197\n",
      "Epoch 1421/5000\n",
      "ecpch:1420,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.6859 - val_loss: 193.0161\n",
      "\n",
      "Epoch 01421: val_loss did not improve from 179.48197\n",
      "Epoch 1422/5000\n",
      "ecpch:1421,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.7170 - val_loss: 192.9526\n",
      "\n",
      "Epoch 01422: val_loss did not improve from 179.48197\n",
      "Epoch 1423/5000\n",
      "ecpch:1422,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.6766 - val_loss: 192.9168\n",
      "\n",
      "Epoch 01423: val_loss did not improve from 179.48197\n",
      "Epoch 1424/5000\n",
      "ecpch:1423,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.6954 - val_loss: 192.9930\n",
      "\n",
      "Epoch 01424: val_loss did not improve from 179.48197\n",
      "Epoch 1425/5000\n",
      "ecpch:1424,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 56.6804 - val_loss: 192.9720\n",
      "\n",
      "Epoch 01425: val_loss did not improve from 179.48197\n",
      "Epoch 1426/5000\n",
      "ecpch:1425,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.6723 - val_loss: 192.9521\n",
      "\n",
      "Epoch 01426: val_loss did not improve from 179.48197\n",
      "Epoch 1427/5000\n",
      "ecpch:1426,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.6766 - val_loss: 193.0135\n",
      "\n",
      "Epoch 01427: val_loss did not improve from 179.48197\n",
      "Epoch 1428/5000\n",
      "ecpch:1427,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.6754 - val_loss: 192.9299\n",
      "\n",
      "Epoch 01428: val_loss did not improve from 179.48197\n",
      "Epoch 1429/5000\n",
      "ecpch:1428,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.6839 - val_loss: 192.9678\n",
      "\n",
      "Epoch 01429: val_loss did not improve from 179.48197\n",
      "Epoch 1430/5000\n",
      "ecpch:1429,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.6560 - val_loss: 193.0469\n",
      "\n",
      "Epoch 01430: val_loss did not improve from 179.48197\n",
      "Epoch 1431/5000\n",
      "ecpch:1430,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.6917 - val_loss: 192.9449\n",
      "\n",
      "Epoch 01431: val_loss did not improve from 179.48197\n",
      "Epoch 1432/5000\n",
      "ecpch:1431,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.6615 - val_loss: 192.9545\n",
      "\n",
      "Epoch 01432: val_loss did not improve from 179.48197\n",
      "Epoch 1433/5000\n",
      "ecpch:1432,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.6509 - val_loss: 193.0517\n",
      "\n",
      "Epoch 01433: val_loss did not improve from 179.48197\n",
      "Epoch 1434/5000\n",
      "ecpch:1433,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.6917 - val_loss: 192.9717\n",
      "\n",
      "Epoch 01434: val_loss did not improve from 179.48197\n",
      "Epoch 1435/5000\n",
      "ecpch:1434,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.6400 - val_loss: 192.9130\n",
      "\n",
      "Epoch 01435: val_loss did not improve from 179.48197\n",
      "Epoch 1436/5000\n",
      "ecpch:1435,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.6740 - val_loss: 193.0133\n",
      "\n",
      "Epoch 01436: val_loss did not improve from 179.48197\n",
      "Epoch 1437/5000\n",
      "ecpch:1436,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.6476 - val_loss: 192.9878\n",
      "\n",
      "Epoch 01437: val_loss did not improve from 179.48197\n",
      "Epoch 1438/5000\n",
      "ecpch:1437,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.6329 - val_loss: 192.9209\n",
      "\n",
      "Epoch 01438: val_loss did not improve from 179.48197\n",
      "Epoch 1439/5000\n",
      "ecpch:1438,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.6656 - val_loss: 193.0070\n",
      "\n",
      "Epoch 01439: val_loss did not improve from 179.48197\n",
      "Epoch 1440/5000\n",
      "ecpch:1439,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.6313 - val_loss: 193.0035\n",
      "\n",
      "Epoch 01440: val_loss did not improve from 179.48197\n",
      "Epoch 1441/5000\n",
      "ecpch:1440,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.6342 - val_loss: 192.9912\n",
      "\n",
      "Epoch 01441: val_loss did not improve from 179.48197\n",
      "Epoch 1442/5000\n",
      "ecpch:1441,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.6279 - val_loss: 193.0158\n",
      "\n",
      "Epoch 01442: val_loss did not improve from 179.48197\n",
      "Epoch 1443/5000\n",
      "ecpch:1442,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.6207 - val_loss: 192.9909\n",
      "\n",
      "Epoch 01443: val_loss did not improve from 179.48197\n",
      "Epoch 1444/5000\n",
      "ecpch:1443,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.6168 - val_loss: 193.0214\n",
      "\n",
      "Epoch 01444: val_loss did not improve from 179.48197\n",
      "Epoch 1445/5000\n",
      "ecpch:1444,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.6152 - val_loss: 193.0006\n",
      "\n",
      "Epoch 01445: val_loss did not improve from 179.48197\n",
      "Epoch 1446/5000\n",
      "ecpch:1445,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.6173 - val_loss: 193.0381\n",
      "\n",
      "Epoch 01446: val_loss did not improve from 179.48197\n",
      "Epoch 1447/5000\n",
      "ecpch:1446,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.6200 - val_loss: 192.9992\n",
      "\n",
      "Epoch 01447: val_loss did not improve from 179.48197\n",
      "Epoch 1448/5000\n",
      "ecpch:1447,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.6137 - val_loss: 193.0611\n",
      "\n",
      "Epoch 01448: val_loss did not improve from 179.48197\n",
      "Epoch 1449/5000\n",
      "ecpch:1448,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.6165 - val_loss: 192.9804\n",
      "\n",
      "Epoch 01449: val_loss did not improve from 179.48197\n",
      "Epoch 1450/5000\n",
      "ecpch:1449,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.6238 - val_loss: 193.0385\n",
      "\n",
      "Epoch 01450: val_loss did not improve from 179.48197\n",
      "Epoch 1451/5000\n",
      "ecpch:1450,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.5983 - val_loss: 193.0367\n",
      "\n",
      "Epoch 01451: val_loss did not improve from 179.48197\n",
      "Epoch 1452/5000\n",
      "ecpch:1451,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.5938 - val_loss: 192.9942\n",
      "\n",
      "Epoch 01452: val_loss did not improve from 179.48197\n",
      "Epoch 1453/5000\n",
      "ecpch:1452,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.6095 - val_loss: 193.0611\n",
      "\n",
      "Epoch 01453: val_loss did not improve from 179.48197\n",
      "Epoch 1454/5000\n",
      "ecpch:1453,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.5985 - val_loss: 192.9894\n",
      "\n",
      "Epoch 01454: val_loss did not improve from 179.48197\n",
      "Epoch 1455/5000\n",
      "ecpch:1454,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.6014 - val_loss: 193.0435\n",
      "\n",
      "Epoch 01455: val_loss did not improve from 179.48197\n",
      "Epoch 1456/5000\n",
      "ecpch:1455,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.5851 - val_loss: 193.0339\n",
      "\n",
      "Epoch 01456: val_loss did not improve from 179.48197\n",
      "Epoch 1457/5000\n",
      "ecpch:1456,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.5815 - val_loss: 193.0149\n",
      "\n",
      "Epoch 01457: val_loss did not improve from 179.48197\n",
      "Epoch 1458/5000\n",
      "ecpch:1457,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.5884 - val_loss: 193.0525\n",
      "\n",
      "Epoch 01458: val_loss did not improve from 179.48197\n",
      "Epoch 1459/5000\n",
      "ecpch:1458,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.5848 - val_loss: 192.9984\n",
      "\n",
      "Epoch 01459: val_loss did not improve from 179.48197\n",
      "Epoch 1460/5000\n",
      "ecpch:1459,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.5843 - val_loss: 193.0704\n",
      "\n",
      "Epoch 01460: val_loss did not improve from 179.48197\n",
      "Epoch 1461/5000\n",
      "ecpch:1460,learn rate 0.000021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 10ms/step - loss: 56.5835 - val_loss: 193.0334\n",
      "\n",
      "Epoch 01461: val_loss did not improve from 179.48197\n",
      "Epoch 1462/5000\n",
      "ecpch:1461,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.5782 - val_loss: 193.0538\n",
      "\n",
      "Epoch 01462: val_loss did not improve from 179.48197\n",
      "Epoch 1463/5000\n",
      "ecpch:1462,learn rate 0.000021\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 56.5654 - val_loss: 193.0574\n",
      "\n",
      "Epoch 01463: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 01463: ReduceLROnPlateau reducing learning rate to 1.8840514530893416e-05.\n",
      "Epoch 1464/5000\n",
      "ecpch:1463,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.5600 - val_loss: 193.0506\n",
      "\n",
      "Epoch 01464: val_loss did not improve from 179.48197\n",
      "Epoch 1465/5000\n",
      "ecpch:1464,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.5595 - val_loss: 193.0825\n",
      "\n",
      "Epoch 01465: val_loss did not improve from 179.48197\n",
      "Epoch 1466/5000\n",
      "ecpch:1465,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.5679 - val_loss: 193.0167\n",
      "\n",
      "Epoch 01466: val_loss did not improve from 179.48197\n",
      "Epoch 1467/5000\n",
      "ecpch:1466,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.5724 - val_loss: 193.0695\n",
      "\n",
      "Epoch 01467: val_loss did not improve from 179.48197\n",
      "Epoch 1468/5000\n",
      "ecpch:1467,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 56.5525 - val_loss: 193.0696\n",
      "\n",
      "Epoch 01468: val_loss did not improve from 179.48197\n",
      "Epoch 1469/5000\n",
      "ecpch:1468,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 56.5591 - val_loss: 193.0518\n",
      "\n",
      "Epoch 01469: val_loss did not improve from 179.48197\n",
      "Epoch 1470/5000\n",
      "ecpch:1469,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.5522 - val_loss: 193.0939\n",
      "\n",
      "Epoch 01470: val_loss did not improve from 179.48197\n",
      "Epoch 1471/5000\n",
      "ecpch:1470,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.5517 - val_loss: 193.0129\n",
      "\n",
      "Epoch 01471: val_loss did not improve from 179.48197\n",
      "Epoch 1472/5000\n",
      "ecpch:1471,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.5635 - val_loss: 193.0682\n",
      "\n",
      "Epoch 01472: val_loss did not improve from 179.48197\n",
      "Epoch 1473/5000\n",
      "ecpch:1472,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.5401 - val_loss: 193.1310\n",
      "\n",
      "Epoch 01473: val_loss did not improve from 179.48197\n",
      "Epoch 1474/5000\n",
      "ecpch:1473,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.5787 - val_loss: 193.0359\n",
      "\n",
      "Epoch 01474: val_loss did not improve from 179.48197\n",
      "Epoch 1475/5000\n",
      "ecpch:1474,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.5420 - val_loss: 193.0519\n",
      "\n",
      "Epoch 01475: val_loss did not improve from 179.48197\n",
      "Epoch 1476/5000\n",
      "ecpch:1475,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.5543 - val_loss: 193.1096\n",
      "\n",
      "Epoch 01476: val_loss did not improve from 179.48197\n",
      "Epoch 1477/5000\n",
      "ecpch:1476,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.5454 - val_loss: 193.0257\n",
      "\n",
      "Epoch 01477: val_loss did not improve from 179.48197\n",
      "Epoch 1478/5000\n",
      "ecpch:1477,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.5511 - val_loss: 193.0588\n",
      "\n",
      "Epoch 01478: val_loss did not improve from 179.48197\n",
      "Epoch 1479/5000\n",
      "ecpch:1478,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.5336 - val_loss: 193.1369\n",
      "\n",
      "Epoch 01479: val_loss did not improve from 179.48197\n",
      "Epoch 1480/5000\n",
      "ecpch:1479,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.5589 - val_loss: 193.0548\n",
      "\n",
      "Epoch 01480: val_loss did not improve from 179.48197\n",
      "Epoch 1481/5000\n",
      "ecpch:1480,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.5234 - val_loss: 193.0511\n",
      "\n",
      "Epoch 01481: val_loss did not improve from 179.48197\n",
      "Epoch 1482/5000\n",
      "ecpch:1481,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.5240 - val_loss: 193.1365\n",
      "\n",
      "Epoch 01482: val_loss did not improve from 179.48197\n",
      "Epoch 1483/5000\n",
      "ecpch:1482,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.5429 - val_loss: 193.0609\n",
      "\n",
      "Epoch 01483: val_loss did not improve from 179.48197\n",
      "Epoch 1484/5000\n",
      "ecpch:1483,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.5141 - val_loss: 193.0610\n",
      "\n",
      "Epoch 01484: val_loss did not improve from 179.48197\n",
      "Epoch 1485/5000\n",
      "ecpch:1484,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.5123 - val_loss: 193.1330\n",
      "\n",
      "Epoch 01485: val_loss did not improve from 179.48197\n",
      "Epoch 1486/5000\n",
      "ecpch:1485,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.5348 - val_loss: 193.0663\n",
      "\n",
      "Epoch 01486: val_loss did not improve from 179.48197\n",
      "Epoch 1487/5000\n",
      "ecpch:1486,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 56.5095 - val_loss: 193.0633\n",
      "\n",
      "Epoch 01487: val_loss did not improve from 179.48197\n",
      "Epoch 1488/5000\n",
      "ecpch:1487,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.5208 - val_loss: 193.1241\n",
      "\n",
      "Epoch 01488: val_loss did not improve from 179.48197\n",
      "Epoch 1489/5000\n",
      "ecpch:1488,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.5188 - val_loss: 193.0701\n",
      "\n",
      "Epoch 01489: val_loss did not improve from 179.48197\n",
      "Epoch 1490/5000\n",
      "ecpch:1489,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.5162 - val_loss: 193.0665\n",
      "\n",
      "Epoch 01490: val_loss did not improve from 179.48197\n",
      "Epoch 1491/5000\n",
      "ecpch:1490,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.5138 - val_loss: 193.1479\n",
      "\n",
      "Epoch 01491: val_loss did not improve from 179.48197\n",
      "Epoch 1492/5000\n",
      "ecpch:1491,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.5166 - val_loss: 193.0934\n",
      "\n",
      "Epoch 01492: val_loss did not improve from 179.48197\n",
      "Epoch 1493/5000\n",
      "ecpch:1492,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.5147 - val_loss: 193.0687\n",
      "\n",
      "Epoch 01493: val_loss did not improve from 179.48197\n",
      "Epoch 1494/5000\n",
      "ecpch:1493,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.4971 - val_loss: 193.1846\n",
      "\n",
      "Epoch 01494: val_loss did not improve from 179.48197\n",
      "Epoch 1495/5000\n",
      "ecpch:1494,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.5344 - val_loss: 193.1339\n",
      "\n",
      "Epoch 01495: val_loss did not improve from 179.48197\n",
      "Epoch 1496/5000\n",
      "ecpch:1495,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.4848 - val_loss: 193.0234\n",
      "\n",
      "Epoch 01496: val_loss did not improve from 179.48197\n",
      "Epoch 1497/5000\n",
      "ecpch:1496,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.5621 - val_loss: 193.0639\n",
      "\n",
      "Epoch 01497: val_loss did not improve from 179.48197\n",
      "Epoch 1498/5000\n",
      "ecpch:1497,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.5159 - val_loss: 193.2302\n",
      "\n",
      "Epoch 01498: val_loss did not improve from 179.48197\n",
      "Epoch 1499/5000\n",
      "ecpch:1498,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.5605 - val_loss: 193.2004\n",
      "\n",
      "Epoch 01499: val_loss did not improve from 179.48197\n",
      "Epoch 1500/5000\n",
      "ecpch:1499,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.5439 - val_loss: 193.0420\n",
      "\n",
      "Epoch 01500: val_loss did not improve from 179.48197\n",
      "Epoch 1501/5000\n",
      "ecpch:1500,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.5163 - val_loss: 193.0547\n",
      "\n",
      "Epoch 01501: val_loss did not improve from 179.48197\n",
      "Epoch 1502/5000\n",
      "ecpch:1501,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.5328 - val_loss: 193.1699\n",
      "\n",
      "Epoch 01502: val_loss did not improve from 179.48197\n",
      "Epoch 1503/5000\n",
      "ecpch:1502,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.4864 - val_loss: 193.1546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01503: val_loss did not improve from 179.48197\n",
      "Epoch 1504/5000\n",
      "ecpch:1503,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.4967 - val_loss: 193.0672\n",
      "\n",
      "Epoch 01504: val_loss did not improve from 179.48197\n",
      "Epoch 1505/5000\n",
      "ecpch:1504,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.4860 - val_loss: 193.0970\n",
      "\n",
      "Epoch 01505: val_loss did not improve from 179.48197\n",
      "Epoch 1506/5000\n",
      "ecpch:1505,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.5004 - val_loss: 193.1653\n",
      "\n",
      "Epoch 01506: val_loss did not improve from 179.48197\n",
      "Epoch 1507/5000\n",
      "ecpch:1506,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 56.4798 - val_loss: 193.1334\n",
      "\n",
      "Epoch 01507: val_loss did not improve from 179.48197\n",
      "Epoch 1508/5000\n",
      "ecpch:1507,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.4927 - val_loss: 193.0935\n",
      "\n",
      "Epoch 01508: val_loss did not improve from 179.48197\n",
      "Epoch 1509/5000\n",
      "ecpch:1508,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.4809 - val_loss: 193.1401\n",
      "\n",
      "Epoch 01509: val_loss did not improve from 179.48197\n",
      "Epoch 1510/5000\n",
      "ecpch:1509,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.4891 - val_loss: 193.1733\n",
      "\n",
      "Epoch 01510: val_loss did not improve from 179.48197\n",
      "Epoch 1511/5000\n",
      "ecpch:1510,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.4844 - val_loss: 193.1167\n",
      "\n",
      "Epoch 01511: val_loss did not improve from 179.48197\n",
      "Epoch 1512/5000\n",
      "ecpch:1511,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.4741 - val_loss: 193.1298\n",
      "\n",
      "Epoch 01512: val_loss did not improve from 179.48197\n",
      "Epoch 1513/5000\n",
      "ecpch:1512,learn rate 0.000019\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.4709 - val_loss: 193.1799\n",
      "\n",
      "Epoch 01513: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 01513: ReduceLROnPlateau reducing learning rate to 1.695646242296789e-05.\n",
      "Epoch 1514/5000\n",
      "ecpch:1513,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.4668 - val_loss: 193.1533\n",
      "\n",
      "Epoch 01514: val_loss did not improve from 179.48197\n",
      "Epoch 1515/5000\n",
      "ecpch:1514,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.4594 - val_loss: 193.1187\n",
      "\n",
      "Epoch 01515: val_loss did not improve from 179.48197\n",
      "Epoch 1516/5000\n",
      "ecpch:1515,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.4543 - val_loss: 193.1688\n",
      "\n",
      "Epoch 01516: val_loss did not improve from 179.48197\n",
      "Epoch 1517/5000\n",
      "ecpch:1516,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.4462 - val_loss: 193.1786\n",
      "\n",
      "Epoch 01517: val_loss did not improve from 179.48197\n",
      "Epoch 1518/5000\n",
      "ecpch:1517,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.4434 - val_loss: 193.1350\n",
      "\n",
      "Epoch 01518: val_loss did not improve from 179.48197\n",
      "Epoch 1519/5000\n",
      "ecpch:1518,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.4431 - val_loss: 193.1607\n",
      "\n",
      "Epoch 01519: val_loss did not improve from 179.48197\n",
      "Epoch 1520/5000\n",
      "ecpch:1519,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.4323 - val_loss: 193.2125\n",
      "\n",
      "Epoch 01520: val_loss did not improve from 179.48197\n",
      "Epoch 1521/5000\n",
      "ecpch:1520,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.4393 - val_loss: 193.1378\n",
      "\n",
      "Epoch 01521: val_loss did not improve from 179.48197\n",
      "Epoch 1522/5000\n",
      "ecpch:1521,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.4360 - val_loss: 193.1515\n",
      "\n",
      "Epoch 01522: val_loss did not improve from 179.48197\n",
      "Epoch 1523/5000\n",
      "ecpch:1522,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.4220 - val_loss: 193.2433\n",
      "\n",
      "Epoch 01523: val_loss did not improve from 179.48197\n",
      "Epoch 1524/5000\n",
      "ecpch:1523,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.4532 - val_loss: 193.1806\n",
      "\n",
      "Epoch 01524: val_loss did not improve from 179.48197\n",
      "Epoch 1525/5000\n",
      "ecpch:1524,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.4124 - val_loss: 193.1100\n",
      "\n",
      "Epoch 01525: val_loss did not improve from 179.48197\n",
      "Epoch 1526/5000\n",
      "ecpch:1525,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.4561 - val_loss: 193.1688\n",
      "\n",
      "Epoch 01526: val_loss did not improve from 179.48197\n",
      "Epoch 1527/5000\n",
      "ecpch:1526,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.4109 - val_loss: 193.2707\n",
      "\n",
      "Epoch 01527: val_loss did not improve from 179.48197\n",
      "Epoch 1528/5000\n",
      "ecpch:1527,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.4766 - val_loss: 193.2076\n",
      "\n",
      "Epoch 01528: val_loss did not improve from 179.48197\n",
      "Epoch 1529/5000\n",
      "ecpch:1528,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.4334 - val_loss: 193.0826\n",
      "\n",
      "Epoch 01529: val_loss did not improve from 179.48197\n",
      "Epoch 1530/5000\n",
      "ecpch:1529,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.4744 - val_loss: 193.1009\n",
      "\n",
      "Epoch 01530: val_loss did not improve from 179.48197\n",
      "Epoch 1531/5000\n",
      "ecpch:1530,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 56.4696 - val_loss: 193.2325\n",
      "\n",
      "Epoch 01531: val_loss did not improve from 179.48197\n",
      "Epoch 1532/5000\n",
      "ecpch:1531,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.4235 - val_loss: 193.2164\n",
      "\n",
      "Epoch 01532: val_loss did not improve from 179.48197\n",
      "Epoch 1533/5000\n",
      "ecpch:1532,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.4384 - val_loss: 193.1140\n",
      "\n",
      "Epoch 01533: val_loss did not improve from 179.48197\n",
      "Epoch 1534/5000\n",
      "ecpch:1533,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.4290 - val_loss: 193.1260\n",
      "\n",
      "Epoch 01534: val_loss did not improve from 179.48197\n",
      "Epoch 1535/5000\n",
      "ecpch:1534,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.4360 - val_loss: 193.2178\n",
      "\n",
      "Epoch 01535: val_loss did not improve from 179.48197\n",
      "Epoch 1536/5000\n",
      "ecpch:1535,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.4112 - val_loss: 193.2170\n",
      "\n",
      "Epoch 01536: val_loss did not improve from 179.48197\n",
      "Epoch 1537/5000\n",
      "ecpch:1536,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.4229 - val_loss: 193.1412\n",
      "\n",
      "Epoch 01537: val_loss did not improve from 179.48197\n",
      "Epoch 1538/5000\n",
      "ecpch:1537,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.4253 - val_loss: 193.1606\n",
      "\n",
      "Epoch 01538: val_loss did not improve from 179.48197\n",
      "Epoch 1539/5000\n",
      "ecpch:1538,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.4059 - val_loss: 193.2285\n",
      "\n",
      "Epoch 01539: val_loss did not improve from 179.48197\n",
      "Epoch 1540/5000\n",
      "ecpch:1539,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.4036 - val_loss: 193.2375\n",
      "\n",
      "Epoch 01540: val_loss did not improve from 179.48197\n",
      "Epoch 1541/5000\n",
      "ecpch:1540,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.3985 - val_loss: 193.1495\n",
      "\n",
      "Epoch 01541: val_loss did not improve from 179.48197\n",
      "Epoch 1542/5000\n",
      "ecpch:1541,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.4141 - val_loss: 193.1684\n",
      "\n",
      "Epoch 01542: val_loss did not improve from 179.48197\n",
      "Epoch 1543/5000\n",
      "ecpch:1542,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.3944 - val_loss: 193.2622\n",
      "\n",
      "Epoch 01543: val_loss did not improve from 179.48197\n",
      "Epoch 1544/5000\n",
      "ecpch:1543,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.4014 - val_loss: 193.2535\n",
      "\n",
      "Epoch 01544: val_loss did not improve from 179.48197\n",
      "Epoch 1545/5000\n",
      "ecpch:1544,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.3828 - val_loss: 193.1375\n",
      "\n",
      "Epoch 01545: val_loss did not improve from 179.48197\n",
      "Epoch 1546/5000\n",
      "ecpch:1545,learn rate 0.000017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 9ms/step - loss: 56.4161 - val_loss: 193.1564\n",
      "\n",
      "Epoch 01546: val_loss did not improve from 179.48197\n",
      "Epoch 1547/5000\n",
      "ecpch:1546,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.3930 - val_loss: 193.3026\n",
      "\n",
      "Epoch 01547: val_loss did not improve from 179.48197\n",
      "Epoch 1548/5000\n",
      "ecpch:1547,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 56.4093 - val_loss: 193.2970\n",
      "\n",
      "Epoch 01548: val_loss did not improve from 179.48197\n",
      "Epoch 1549/5000\n",
      "ecpch:1548,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.3950 - val_loss: 193.1480\n",
      "\n",
      "Epoch 01549: val_loss did not improve from 179.48197\n",
      "Epoch 1550/5000\n",
      "ecpch:1549,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.3992 - val_loss: 193.1370\n",
      "\n",
      "Epoch 01550: val_loss did not improve from 179.48197\n",
      "Epoch 1551/5000\n",
      "ecpch:1550,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.3995 - val_loss: 193.2637\n",
      "\n",
      "Epoch 01551: val_loss did not improve from 179.48197\n",
      "Epoch 1552/5000\n",
      "ecpch:1551,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.3701 - val_loss: 193.2744\n",
      "\n",
      "Epoch 01552: val_loss did not improve from 179.48197\n",
      "Epoch 1553/5000\n",
      "ecpch:1552,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.3721 - val_loss: 193.1620\n",
      "\n",
      "Epoch 01553: val_loss did not improve from 179.48197\n",
      "Epoch 1554/5000\n",
      "ecpch:1553,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.3756 - val_loss: 193.1765\n",
      "\n",
      "Epoch 01554: val_loss did not improve from 179.48197\n",
      "Epoch 1555/5000\n",
      "ecpch:1554,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.3689 - val_loss: 193.2773\n",
      "\n",
      "Epoch 01555: val_loss did not improve from 179.48197\n",
      "Epoch 1556/5000\n",
      "ecpch:1555,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.3681 - val_loss: 193.2526\n",
      "\n",
      "Epoch 01556: val_loss did not improve from 179.48197\n",
      "Epoch 1557/5000\n",
      "ecpch:1556,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.3533 - val_loss: 193.1902\n",
      "\n",
      "Epoch 01557: val_loss did not improve from 179.48197\n",
      "Epoch 1558/5000\n",
      "ecpch:1557,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.3596 - val_loss: 193.2057\n",
      "\n",
      "Epoch 01558: val_loss did not improve from 179.48197\n",
      "Epoch 1559/5000\n",
      "ecpch:1558,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.3437 - val_loss: 193.2801\n",
      "\n",
      "Epoch 01559: val_loss did not improve from 179.48197\n",
      "Epoch 1560/5000\n",
      "ecpch:1559,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.3522 - val_loss: 193.2607\n",
      "\n",
      "Epoch 01560: val_loss did not improve from 179.48197\n",
      "Epoch 1561/5000\n",
      "ecpch:1560,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.3385 - val_loss: 193.1984\n",
      "\n",
      "Epoch 01561: val_loss did not improve from 179.48197\n",
      "Epoch 1562/5000\n",
      "ecpch:1561,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.3494 - val_loss: 193.2313\n",
      "\n",
      "Epoch 01562: val_loss did not improve from 179.48197\n",
      "Epoch 1563/5000\n",
      "ecpch:1562,learn rate 0.000017\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.3312 - val_loss: 193.3096\n",
      "\n",
      "Epoch 01563: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 01563: ReduceLROnPlateau reducing learning rate to 1.526081650808919e-05.\n",
      "Epoch 1564/5000\n",
      "ecpch:1563,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.3499 - val_loss: 193.2511\n",
      "\n",
      "Epoch 01564: val_loss did not improve from 179.48197\n",
      "Epoch 1565/5000\n",
      "ecpch:1564,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.3258 - val_loss: 193.2234\n",
      "\n",
      "Epoch 01565: val_loss did not improve from 179.48197\n",
      "Epoch 1566/5000\n",
      "ecpch:1565,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.3350 - val_loss: 193.2823\n",
      "\n",
      "Epoch 01566: val_loss did not improve from 179.48197\n",
      "Epoch 1567/5000\n",
      "ecpch:1566,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.3200 - val_loss: 193.2804\n",
      "\n",
      "Epoch 01567: val_loss did not improve from 179.48197\n",
      "Epoch 1568/5000\n",
      "ecpch:1567,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.3217 - val_loss: 193.2400\n",
      "\n",
      "Epoch 01568: val_loss did not improve from 179.48197\n",
      "Epoch 1569/5000\n",
      "ecpch:1568,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.3240 - val_loss: 193.2709\n",
      "\n",
      "Epoch 01569: val_loss did not improve from 179.48197\n",
      "Epoch 1570/5000\n",
      "ecpch:1569,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.3110 - val_loss: 193.2982\n",
      "\n",
      "Epoch 01570: val_loss did not improve from 179.48197\n",
      "Epoch 1571/5000\n",
      "ecpch:1570,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.3175 - val_loss: 193.2416\n",
      "\n",
      "Epoch 01571: val_loss did not improve from 179.48197\n",
      "Epoch 1572/5000\n",
      "ecpch:1571,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.3165 - val_loss: 193.2588\n",
      "\n",
      "Epoch 01572: val_loss did not improve from 179.48197\n",
      "Epoch 1573/5000\n",
      "ecpch:1572,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.3059 - val_loss: 193.3096\n",
      "\n",
      "Epoch 01573: val_loss did not improve from 179.48197\n",
      "Epoch 1574/5000\n",
      "ecpch:1573,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.3195 - val_loss: 193.2588\n",
      "\n",
      "Epoch 01574: val_loss did not improve from 179.48197\n",
      "Epoch 1575/5000\n",
      "ecpch:1574,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.3022 - val_loss: 193.2614\n",
      "\n",
      "Epoch 01575: val_loss did not improve from 179.48197\n",
      "Epoch 1576/5000\n",
      "ecpch:1575,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.2997 - val_loss: 193.3144\n",
      "\n",
      "Epoch 01576: val_loss did not improve from 179.48197\n",
      "Epoch 1577/5000\n",
      "ecpch:1576,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.3119 - val_loss: 193.2703\n",
      "\n",
      "Epoch 01577: val_loss did not improve from 179.48197\n",
      "Epoch 1578/5000\n",
      "ecpch:1577,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.2927 - val_loss: 193.2554\n",
      "\n",
      "Epoch 01578: val_loss did not improve from 179.48197\n",
      "Epoch 1579/5000\n",
      "ecpch:1578,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.3061 - val_loss: 193.2956\n",
      "\n",
      "Epoch 01579: val_loss did not improve from 179.48197\n",
      "Epoch 1580/5000\n",
      "ecpch:1579,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.2956 - val_loss: 193.2822\n",
      "\n",
      "Epoch 01580: val_loss did not improve from 179.48197\n",
      "Epoch 1581/5000\n",
      "ecpch:1580,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.2864 - val_loss: 193.2678\n",
      "\n",
      "Epoch 01581: val_loss did not improve from 179.48197\n",
      "Epoch 1582/5000\n",
      "ecpch:1581,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.2975 - val_loss: 193.3006\n",
      "\n",
      "Epoch 01582: val_loss did not improve from 179.48197\n",
      "Epoch 1583/5000\n",
      "ecpch:1582,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.2851 - val_loss: 193.2657\n",
      "\n",
      "Epoch 01583: val_loss did not improve from 179.48197\n",
      "Epoch 1584/5000\n",
      "ecpch:1583,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.2932 - val_loss: 193.2934\n",
      "\n",
      "Epoch 01584: val_loss did not improve from 179.48197\n",
      "Epoch 1585/5000\n",
      "ecpch:1584,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.2884 - val_loss: 193.3160\n",
      "\n",
      "Epoch 01585: val_loss did not improve from 179.48197\n",
      "Epoch 1586/5000\n",
      "ecpch:1585,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.2846 - val_loss: 193.2444\n",
      "\n",
      "Epoch 01586: val_loss did not improve from 179.48197\n",
      "Epoch 1587/5000\n",
      "ecpch:1586,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.3063 - val_loss: 193.2709\n",
      "\n",
      "Epoch 01587: val_loss did not improve from 179.48197\n",
      "Epoch 1588/5000\n",
      "ecpch:1587,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.2787 - val_loss: 193.3627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01588: val_loss did not improve from 179.48197\n",
      "Epoch 1589/5000\n",
      "ecpch:1588,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.3258 - val_loss: 193.3283\n",
      "\n",
      "Epoch 01589: val_loss did not improve from 179.48197\n",
      "Epoch 1590/5000\n",
      "ecpch:1589,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.2849 - val_loss: 193.1957\n",
      "\n",
      "Epoch 01590: val_loss did not improve from 179.48197\n",
      "Epoch 1591/5000\n",
      "ecpch:1590,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.3441 - val_loss: 193.2041\n",
      "\n",
      "Epoch 01591: val_loss did not improve from 179.48197\n",
      "Epoch 1592/5000\n",
      "ecpch:1591,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.3372 - val_loss: 193.3382\n",
      "\n",
      "Epoch 01592: val_loss did not improve from 179.48197\n",
      "Epoch 1593/5000\n",
      "ecpch:1592,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.2765 - val_loss: 193.3491\n",
      "\n",
      "Epoch 01593: val_loss did not improve from 179.48197\n",
      "Epoch 1594/5000\n",
      "ecpch:1593,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.2919 - val_loss: 193.2477\n",
      "\n",
      "Epoch 01594: val_loss did not improve from 179.48197\n",
      "Epoch 1595/5000\n",
      "ecpch:1594,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.2848 - val_loss: 193.2625\n",
      "\n",
      "Epoch 01595: val_loss did not improve from 179.48197\n",
      "Epoch 1596/5000\n",
      "ecpch:1595,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.2838 - val_loss: 193.3397\n",
      "\n",
      "Epoch 01596: val_loss did not improve from 179.48197\n",
      "Epoch 1597/5000\n",
      "ecpch:1596,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.2719 - val_loss: 193.3161\n",
      "\n",
      "Epoch 01597: val_loss did not improve from 179.48197\n",
      "Epoch 1598/5000\n",
      "ecpch:1597,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.2618 - val_loss: 193.2770\n",
      "\n",
      "Epoch 01598: val_loss did not improve from 179.48197\n",
      "Epoch 1599/5000\n",
      "ecpch:1598,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.2627 - val_loss: 193.3075\n",
      "\n",
      "Epoch 01599: val_loss did not improve from 179.48197\n",
      "Epoch 1600/5000\n",
      "ecpch:1599,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.2518 - val_loss: 193.3423\n",
      "\n",
      "Epoch 01600: val_loss did not improve from 179.48197\n",
      "Epoch 1601/5000\n",
      "ecpch:1600,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.2688 - val_loss: 193.2900\n",
      "\n",
      "Epoch 01601: val_loss did not improve from 179.48197\n",
      "Epoch 1602/5000\n",
      "ecpch:1601,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.2512 - val_loss: 193.3081\n",
      "\n",
      "Epoch 01602: val_loss did not improve from 179.48197\n",
      "Epoch 1603/5000\n",
      "ecpch:1602,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.2675 - val_loss: 193.3458\n",
      "\n",
      "Epoch 01603: val_loss did not improve from 179.48197\n",
      "Epoch 1604/5000\n",
      "ecpch:1603,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.2478 - val_loss: 193.3085\n",
      "\n",
      "Epoch 01604: val_loss did not improve from 179.48197\n",
      "Epoch 1605/5000\n",
      "ecpch:1604,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.2717 - val_loss: 193.3116\n",
      "\n",
      "Epoch 01605: val_loss did not improve from 179.48197\n",
      "Epoch 1606/5000\n",
      "ecpch:1605,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.2506 - val_loss: 193.3453\n",
      "\n",
      "Epoch 01606: val_loss did not improve from 179.48197\n",
      "Epoch 1607/5000\n",
      "ecpch:1606,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.2771 - val_loss: 193.3403\n",
      "\n",
      "Epoch 01607: val_loss did not improve from 179.48197\n",
      "Epoch 1608/5000\n",
      "ecpch:1607,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.2611 - val_loss: 193.3123\n",
      "\n",
      "Epoch 01608: val_loss did not improve from 179.48197\n",
      "Epoch 1609/5000\n",
      "ecpch:1608,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.2593 - val_loss: 193.3439\n",
      "\n",
      "Epoch 01609: val_loss did not improve from 179.48197\n",
      "Epoch 1610/5000\n",
      "ecpch:1609,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.2593 - val_loss: 193.3584\n",
      "\n",
      "Epoch 01610: val_loss did not improve from 179.48197\n",
      "Epoch 1611/5000\n",
      "ecpch:1610,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.2393 - val_loss: 193.3114\n",
      "\n",
      "Epoch 01611: val_loss did not improve from 179.48197\n",
      "Epoch 1612/5000\n",
      "ecpch:1611,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.2400 - val_loss: 193.3225\n",
      "\n",
      "Epoch 01612: val_loss did not improve from 179.48197\n",
      "Epoch 1613/5000\n",
      "ecpch:1612,learn rate 0.000015\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.2365 - val_loss: 193.3631\n",
      "\n",
      "Epoch 01613: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 01613: ReduceLROnPlateau reducing learning rate to 1.3734735512116459e-05.\n",
      "Epoch 1614/5000\n",
      "ecpch:1613,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.2346 - val_loss: 193.3183\n",
      "\n",
      "Epoch 01614: val_loss did not improve from 179.48197\n",
      "Epoch 1615/5000\n",
      "ecpch:1614,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 56.2307 - val_loss: 193.3029\n",
      "\n",
      "Epoch 01615: val_loss did not improve from 179.48197\n",
      "Epoch 1616/5000\n",
      "ecpch:1615,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 56.2232 - val_loss: 193.3553\n",
      "\n",
      "Epoch 01616: val_loss did not improve from 179.48197\n",
      "Epoch 1617/5000\n",
      "ecpch:1616,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.2336 - val_loss: 193.3287\n",
      "\n",
      "Epoch 01617: val_loss did not improve from 179.48197\n",
      "Epoch 1618/5000\n",
      "ecpch:1617,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.2125 - val_loss: 193.3085\n",
      "\n",
      "Epoch 01618: val_loss did not improve from 179.48197\n",
      "Epoch 1619/5000\n",
      "ecpch:1618,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.2302 - val_loss: 193.3359\n",
      "\n",
      "Epoch 01619: val_loss did not improve from 179.48197\n",
      "Epoch 1620/5000\n",
      "ecpch:1619,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.2073 - val_loss: 193.3717\n",
      "\n",
      "Epoch 01620: val_loss did not improve from 179.48197\n",
      "Epoch 1621/5000\n",
      "ecpch:1620,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.2365 - val_loss: 193.3287\n",
      "\n",
      "Epoch 01621: val_loss did not improve from 179.48197\n",
      "Epoch 1622/5000\n",
      "ecpch:1621,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.2103 - val_loss: 193.3329\n",
      "\n",
      "Epoch 01622: val_loss did not improve from 179.48197\n",
      "Epoch 1623/5000\n",
      "ecpch:1622,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.2333 - val_loss: 193.3716\n",
      "\n",
      "Epoch 01623: val_loss did not improve from 179.48197\n",
      "Epoch 1624/5000\n",
      "ecpch:1623,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.2203 - val_loss: 193.3537\n",
      "\n",
      "Epoch 01624: val_loss did not improve from 179.48197\n",
      "Epoch 1625/5000\n",
      "ecpch:1624,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.2247 - val_loss: 193.3544\n",
      "\n",
      "Epoch 01625: val_loss did not improve from 179.48197\n",
      "Epoch 1626/5000\n",
      "ecpch:1625,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.2232 - val_loss: 193.3632\n",
      "\n",
      "Epoch 01626: val_loss did not improve from 179.48197\n",
      "Epoch 1627/5000\n",
      "ecpch:1626,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.2051 - val_loss: 193.3516\n",
      "\n",
      "Epoch 01627: val_loss did not improve from 179.48197\n",
      "Epoch 1628/5000\n",
      "ecpch:1627,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.2091 - val_loss: 193.3665\n",
      "\n",
      "Epoch 01628: val_loss did not improve from 179.48197\n",
      "Epoch 1629/5000\n",
      "ecpch:1628,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.1997 - val_loss: 193.3673\n",
      "\n",
      "Epoch 01629: val_loss did not improve from 179.48197\n",
      "Epoch 1630/5000\n",
      "ecpch:1629,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.1959 - val_loss: 193.3495\n",
      "\n",
      "Epoch 01630: val_loss did not improve from 179.48197\n",
      "Epoch 1631/5000\n",
      "ecpch:1630,learn rate 0.000014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 10ms/step - loss: 56.2031 - val_loss: 193.3611\n",
      "\n",
      "Epoch 01631: val_loss did not improve from 179.48197\n",
      "Epoch 1632/5000\n",
      "ecpch:1631,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.1881 - val_loss: 193.3871\n",
      "\n",
      "Epoch 01632: val_loss did not improve from 179.48197\n",
      "Epoch 1633/5000\n",
      "ecpch:1632,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.2092 - val_loss: 193.3442\n",
      "\n",
      "Epoch 01633: val_loss did not improve from 179.48197\n",
      "Epoch 1634/5000\n",
      "ecpch:1633,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.1959 - val_loss: 193.3521\n",
      "\n",
      "Epoch 01634: val_loss did not improve from 179.48197\n",
      "Epoch 1635/5000\n",
      "ecpch:1634,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.2052 - val_loss: 193.3883\n",
      "\n",
      "Epoch 01635: val_loss did not improve from 179.48197\n",
      "Epoch 1636/5000\n",
      "ecpch:1635,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.1979 - val_loss: 193.3639\n",
      "\n",
      "Epoch 01636: val_loss did not improve from 179.48197\n",
      "Epoch 1637/5000\n",
      "ecpch:1636,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.1934 - val_loss: 193.3684\n",
      "\n",
      "Epoch 01637: val_loss did not improve from 179.48197\n",
      "Epoch 1638/5000\n",
      "ecpch:1637,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.1899 - val_loss: 193.3839\n",
      "\n",
      "Epoch 01638: val_loss did not improve from 179.48197\n",
      "Epoch 1639/5000\n",
      "ecpch:1638,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.1887 - val_loss: 193.3600\n",
      "\n",
      "Epoch 01639: val_loss did not improve from 179.48197\n",
      "Epoch 1640/5000\n",
      "ecpch:1639,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.1848 - val_loss: 193.3731\n",
      "\n",
      "Epoch 01640: val_loss did not improve from 179.48197\n",
      "Epoch 1641/5000\n",
      "ecpch:1640,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.1794 - val_loss: 193.4074\n",
      "\n",
      "Epoch 01641: val_loss did not improve from 179.48197\n",
      "Epoch 1642/5000\n",
      "ecpch:1641,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.1826 - val_loss: 193.3479\n",
      "\n",
      "Epoch 01642: val_loss did not improve from 179.48197\n",
      "Epoch 1643/5000\n",
      "ecpch:1642,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.1800 - val_loss: 193.3700\n",
      "\n",
      "Epoch 01643: val_loss did not improve from 179.48197\n",
      "Epoch 1644/5000\n",
      "ecpch:1643,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.1736 - val_loss: 193.4190\n",
      "\n",
      "Epoch 01644: val_loss did not improve from 179.48197\n",
      "Epoch 1645/5000\n",
      "ecpch:1644,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.1853 - val_loss: 193.3713\n",
      "\n",
      "Epoch 01645: val_loss did not improve from 179.48197\n",
      "Epoch 1646/5000\n",
      "ecpch:1645,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.1760 - val_loss: 193.3705\n",
      "\n",
      "Epoch 01646: val_loss did not improve from 179.48197\n",
      "Epoch 1647/5000\n",
      "ecpch:1646,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.1656 - val_loss: 193.4198\n",
      "\n",
      "Epoch 01647: val_loss did not improve from 179.48197\n",
      "Epoch 1648/5000\n",
      "ecpch:1647,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.1773 - val_loss: 193.4041\n",
      "\n",
      "Epoch 01648: val_loss did not improve from 179.48197\n",
      "Epoch 1649/5000\n",
      "ecpch:1648,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.1604 - val_loss: 193.3454\n",
      "\n",
      "Epoch 01649: val_loss did not improve from 179.48197\n",
      "Epoch 1650/5000\n",
      "ecpch:1649,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.1809 - val_loss: 193.3762\n",
      "\n",
      "Epoch 01650: val_loss did not improve from 179.48197\n",
      "Epoch 1651/5000\n",
      "ecpch:1650,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.1536 - val_loss: 193.4649\n",
      "\n",
      "Epoch 01651: val_loss did not improve from 179.48197\n",
      "Epoch 1652/5000\n",
      "ecpch:1651,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.1895 - val_loss: 193.4171\n",
      "\n",
      "Epoch 01652: val_loss did not improve from 179.48197\n",
      "Epoch 1653/5000\n",
      "ecpch:1652,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.1513 - val_loss: 193.3024\n",
      "\n",
      "Epoch 01653: val_loss did not improve from 179.48197\n",
      "Epoch 1654/5000\n",
      "ecpch:1653,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.2028 - val_loss: 193.3146\n",
      "\n",
      "Epoch 01654: val_loss did not improve from 179.48197\n",
      "Epoch 1655/5000\n",
      "ecpch:1654,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.1870 - val_loss: 193.4445\n",
      "\n",
      "Epoch 01655: val_loss did not improve from 179.48197\n",
      "Epoch 1656/5000\n",
      "ecpch:1655,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.1634 - val_loss: 193.4555\n",
      "\n",
      "Epoch 01656: val_loss did not improve from 179.48197\n",
      "Epoch 1657/5000\n",
      "ecpch:1656,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.1685 - val_loss: 193.3477\n",
      "\n",
      "Epoch 01657: val_loss did not improve from 179.48197\n",
      "Epoch 1658/5000\n",
      "ecpch:1657,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.1565 - val_loss: 193.3575\n",
      "\n",
      "Epoch 01658: val_loss did not improve from 179.48197\n",
      "Epoch 1659/5000\n",
      "ecpch:1658,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.1605 - val_loss: 193.4317\n",
      "\n",
      "Epoch 01659: val_loss did not improve from 179.48197\n",
      "Epoch 1660/5000\n",
      "ecpch:1659,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.1413 - val_loss: 193.4328\n",
      "\n",
      "Epoch 01660: val_loss did not improve from 179.48197\n",
      "Epoch 1661/5000\n",
      "ecpch:1660,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.1447 - val_loss: 193.3735\n",
      "\n",
      "Epoch 01661: val_loss did not improve from 179.48197\n",
      "Epoch 1662/5000\n",
      "ecpch:1661,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.1367 - val_loss: 193.3963\n",
      "\n",
      "Epoch 01662: val_loss did not improve from 179.48197\n",
      "Epoch 1663/5000\n",
      "ecpch:1662,learn rate 0.000014\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.1310 - val_loss: 193.4522\n",
      "\n",
      "Epoch 01663: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 01663: ReduceLROnPlateau reducing learning rate to 1.236126163348672e-05.\n",
      "Epoch 1664/5000\n",
      "ecpch:1663,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.1396 - val_loss: 193.4158\n",
      "\n",
      "Epoch 01664: val_loss did not improve from 179.48197\n",
      "Epoch 1665/5000\n",
      "ecpch:1664,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.1260 - val_loss: 193.3805\n",
      "\n",
      "Epoch 01665: val_loss did not improve from 179.48197\n",
      "Epoch 1666/5000\n",
      "ecpch:1665,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.1381 - val_loss: 193.4184\n",
      "\n",
      "Epoch 01666: val_loss did not improve from 179.48197\n",
      "Epoch 1667/5000\n",
      "ecpch:1666,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.1199 - val_loss: 193.4534\n",
      "\n",
      "Epoch 01667: val_loss did not improve from 179.48197\n",
      "Epoch 1668/5000\n",
      "ecpch:1667,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.1354 - val_loss: 193.4315\n",
      "\n",
      "Epoch 01668: val_loss did not improve from 179.48197\n",
      "Epoch 1669/5000\n",
      "ecpch:1668,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.1166 - val_loss: 193.4080\n",
      "\n",
      "Epoch 01669: val_loss did not improve from 179.48197\n",
      "Epoch 1670/5000\n",
      "ecpch:1669,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.1326 - val_loss: 193.4280\n",
      "\n",
      "Epoch 01670: val_loss did not improve from 179.48197\n",
      "Epoch 1671/5000\n",
      "ecpch:1670,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.1149 - val_loss: 193.4390\n",
      "\n",
      "Epoch 01671: val_loss did not improve from 179.48197\n",
      "Epoch 1672/5000\n",
      "ecpch:1671,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.1298 - val_loss: 193.4146\n",
      "\n",
      "Epoch 01672: val_loss did not improve from 179.48197\n",
      "Epoch 1673/5000\n",
      "ecpch:1672,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.1194 - val_loss: 193.4249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01673: val_loss did not improve from 179.48197\n",
      "Epoch 1674/5000\n",
      "ecpch:1673,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.1279 - val_loss: 193.4599\n",
      "\n",
      "Epoch 01674: val_loss did not improve from 179.48197\n",
      "Epoch 1675/5000\n",
      "ecpch:1674,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.1265 - val_loss: 193.4273\n",
      "\n",
      "Epoch 01675: val_loss did not improve from 179.48197\n",
      "Epoch 1676/5000\n",
      "ecpch:1675,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.1175 - val_loss: 193.4158\n",
      "\n",
      "Epoch 01676: val_loss did not improve from 179.48197\n",
      "Epoch 1677/5000\n",
      "ecpch:1676,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.1164 - val_loss: 193.4519\n",
      "\n",
      "Epoch 01677: val_loss did not improve from 179.48197\n",
      "Epoch 1678/5000\n",
      "ecpch:1677,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.1141 - val_loss: 193.4298\n",
      "\n",
      "Epoch 01678: val_loss did not improve from 179.48197\n",
      "Epoch 1679/5000\n",
      "ecpch:1678,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.1081 - val_loss: 193.4312\n",
      "\n",
      "Epoch 01679: val_loss did not improve from 179.48197\n",
      "Epoch 1680/5000\n",
      "ecpch:1679,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.1071 - val_loss: 193.4393\n",
      "\n",
      "Epoch 01680: val_loss did not improve from 179.48197\n",
      "Epoch 1681/5000\n",
      "ecpch:1680,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.0992 - val_loss: 193.4352\n",
      "\n",
      "Epoch 01681: val_loss did not improve from 179.48197\n",
      "Epoch 1682/5000\n",
      "ecpch:1681,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.1080 - val_loss: 193.4474\n",
      "\n",
      "Epoch 01682: val_loss did not improve from 179.48197\n",
      "Epoch 1683/5000\n",
      "ecpch:1682,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.0968 - val_loss: 193.4321\n",
      "\n",
      "Epoch 01683: val_loss did not improve from 179.48197\n",
      "Epoch 1684/5000\n",
      "ecpch:1683,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.1089 - val_loss: 193.4458\n",
      "\n",
      "Epoch 01684: val_loss did not improve from 179.48197\n",
      "Epoch 1685/5000\n",
      "ecpch:1684,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.0964 - val_loss: 193.4631\n",
      "\n",
      "Epoch 01685: val_loss did not improve from 179.48197\n",
      "Epoch 1686/5000\n",
      "ecpch:1685,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.1049 - val_loss: 193.4293\n",
      "\n",
      "Epoch 01686: val_loss did not improve from 179.48197\n",
      "Epoch 1687/5000\n",
      "ecpch:1686,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.1005 - val_loss: 193.4453\n",
      "\n",
      "Epoch 01687: val_loss did not improve from 179.48197\n",
      "Epoch 1688/5000\n",
      "ecpch:1687,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.0940 - val_loss: 193.4708\n",
      "\n",
      "Epoch 01688: val_loss did not improve from 179.48197\n",
      "Epoch 1689/5000\n",
      "ecpch:1688,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.0958 - val_loss: 193.4399\n",
      "\n",
      "Epoch 01689: val_loss did not improve from 179.48197\n",
      "Epoch 1690/5000\n",
      "ecpch:1689,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.0876 - val_loss: 193.4577\n",
      "\n",
      "Epoch 01690: val_loss did not improve from 179.48197\n",
      "Epoch 1691/5000\n",
      "ecpch:1690,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.0820 - val_loss: 193.4665\n",
      "\n",
      "Epoch 01691: val_loss did not improve from 179.48197\n",
      "Epoch 1692/5000\n",
      "ecpch:1691,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.0841 - val_loss: 193.4345\n",
      "\n",
      "Epoch 01692: val_loss did not improve from 179.48197\n",
      "Epoch 1693/5000\n",
      "ecpch:1692,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 56.0820 - val_loss: 193.4582\n",
      "\n",
      "Epoch 01693: val_loss did not improve from 179.48197\n",
      "Epoch 1694/5000\n",
      "ecpch:1693,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.0772 - val_loss: 193.4793\n",
      "\n",
      "Epoch 01694: val_loss did not improve from 179.48197\n",
      "Epoch 1695/5000\n",
      "ecpch:1694,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.0783 - val_loss: 193.4208\n",
      "\n",
      "Epoch 01695: val_loss did not improve from 179.48197\n",
      "Epoch 1696/5000\n",
      "ecpch:1695,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 56.0866 - val_loss: 193.4400\n",
      "\n",
      "Epoch 01696: val_loss did not improve from 179.48197\n",
      "Epoch 1697/5000\n",
      "ecpch:1696,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.0723 - val_loss: 193.5054\n",
      "\n",
      "Epoch 01697: val_loss did not improve from 179.48197\n",
      "Epoch 1698/5000\n",
      "ecpch:1697,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.0947 - val_loss: 193.4713\n",
      "\n",
      "Epoch 01698: val_loss did not improve from 179.48197\n",
      "Epoch 1699/5000\n",
      "ecpch:1698,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.0692 - val_loss: 193.4156\n",
      "\n",
      "Epoch 01699: val_loss did not improve from 179.48197\n",
      "Epoch 1700/5000\n",
      "ecpch:1699,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.0869 - val_loss: 193.4546\n",
      "\n",
      "Epoch 01700: val_loss did not improve from 179.48197\n",
      "Epoch 1701/5000\n",
      "ecpch:1700,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 56.0685 - val_loss: 193.5233\n",
      "\n",
      "Epoch 01701: val_loss did not improve from 179.48197\n",
      "Epoch 1702/5000\n",
      "ecpch:1701,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.0973 - val_loss: 193.4830\n",
      "\n",
      "Epoch 01702: val_loss did not improve from 179.48197\n",
      "Epoch 1703/5000\n",
      "ecpch:1702,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.0750 - val_loss: 193.3977\n",
      "\n",
      "Epoch 01703: val_loss did not improve from 179.48197\n",
      "Epoch 1704/5000\n",
      "ecpch:1703,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.0943 - val_loss: 193.4244\n",
      "\n",
      "Epoch 01704: val_loss did not improve from 179.48197\n",
      "Epoch 1705/5000\n",
      "ecpch:1704,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.0889 - val_loss: 193.5101\n",
      "\n",
      "Epoch 01705: val_loss did not improve from 179.48197\n",
      "Epoch 1706/5000\n",
      "ecpch:1705,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.0748 - val_loss: 193.5012\n",
      "\n",
      "Epoch 01706: val_loss did not improve from 179.48197\n",
      "Epoch 1707/5000\n",
      "ecpch:1706,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.0722 - val_loss: 193.4063\n",
      "\n",
      "Epoch 01707: val_loss did not improve from 179.48197\n",
      "Epoch 1708/5000\n",
      "ecpch:1707,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.0773 - val_loss: 193.4269\n",
      "\n",
      "Epoch 01708: val_loss did not improve from 179.48197\n",
      "Epoch 1709/5000\n",
      "ecpch:1708,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.0763 - val_loss: 193.5041\n",
      "\n",
      "Epoch 01709: val_loss did not improve from 179.48197\n",
      "Epoch 1710/5000\n",
      "ecpch:1709,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.0599 - val_loss: 193.5116\n",
      "\n",
      "Epoch 01710: val_loss did not improve from 179.48197\n",
      "Epoch 1711/5000\n",
      "ecpch:1710,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.0584 - val_loss: 193.4205\n",
      "\n",
      "Epoch 01711: val_loss did not improve from 179.48197\n",
      "Epoch 1712/5000\n",
      "ecpch:1711,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.0720 - val_loss: 193.4206\n",
      "\n",
      "Epoch 01712: val_loss did not improve from 179.48197\n",
      "Epoch 1713/5000\n",
      "ecpch:1712,learn rate 0.000012\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.0658 - val_loss: 193.5065\n",
      "\n",
      "Epoch 01713: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 01713: ReduceLROnPlateau reducing learning rate to 1.1125135551992571e-05.\n",
      "Epoch 1714/5000\n",
      "ecpch:1713,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.0525 - val_loss: 193.5418\n",
      "\n",
      "Epoch 01714: val_loss did not improve from 179.48197\n",
      "Epoch 1715/5000\n",
      "ecpch:1714,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.0686 - val_loss: 193.4652\n",
      "\n",
      "Epoch 01715: val_loss did not improve from 179.48197\n",
      "Epoch 1716/5000\n",
      "ecpch:1715,learn rate 0.000011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 11ms/step - loss: 56.0472 - val_loss: 193.4347\n",
      "\n",
      "Epoch 01716: val_loss did not improve from 179.48197\n",
      "Epoch 1717/5000\n",
      "ecpch:1716,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.0508 - val_loss: 193.4765\n",
      "\n",
      "Epoch 01717: val_loss did not improve from 179.48197\n",
      "Epoch 1718/5000\n",
      "ecpch:1717,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.0442 - val_loss: 193.5341\n",
      "\n",
      "Epoch 01718: val_loss did not improve from 179.48197\n",
      "Epoch 1719/5000\n",
      "ecpch:1718,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.0520 - val_loss: 193.4856\n",
      "\n",
      "Epoch 01719: val_loss did not improve from 179.48197\n",
      "Epoch 1720/5000\n",
      "ecpch:1719,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.0366 - val_loss: 193.4422\n",
      "\n",
      "Epoch 01720: val_loss did not improve from 179.48197\n",
      "Epoch 1721/5000\n",
      "ecpch:1720,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.0419 - val_loss: 193.4766\n",
      "\n",
      "Epoch 01721: val_loss did not improve from 179.48197\n",
      "Epoch 1722/5000\n",
      "ecpch:1721,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.0354 - val_loss: 193.5359\n",
      "\n",
      "Epoch 01722: val_loss did not improve from 179.48197\n",
      "Epoch 1723/5000\n",
      "ecpch:1722,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.0398 - val_loss: 193.5012\n",
      "\n",
      "Epoch 01723: val_loss did not improve from 179.48197\n",
      "Epoch 1724/5000\n",
      "ecpch:1723,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.0279 - val_loss: 193.4585\n",
      "\n",
      "Epoch 01724: val_loss did not improve from 179.48197\n",
      "Epoch 1725/5000\n",
      "ecpch:1724,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.0321 - val_loss: 193.4930\n",
      "\n",
      "Epoch 01725: val_loss did not improve from 179.48197\n",
      "Epoch 1726/5000\n",
      "ecpch:1725,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.0243 - val_loss: 193.5324\n",
      "\n",
      "Epoch 01726: val_loss did not improve from 179.48197\n",
      "Epoch 1727/5000\n",
      "ecpch:1726,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 56.0263 - val_loss: 193.4931\n",
      "\n",
      "Epoch 01727: val_loss did not improve from 179.48197\n",
      "Epoch 1728/5000\n",
      "ecpch:1727,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.0215 - val_loss: 193.4931\n",
      "\n",
      "Epoch 01728: val_loss did not improve from 179.48197\n",
      "Epoch 1729/5000\n",
      "ecpch:1728,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.0168 - val_loss: 193.5318\n",
      "\n",
      "Epoch 01729: val_loss did not improve from 179.48197\n",
      "Epoch 1730/5000\n",
      "ecpch:1729,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.0174 - val_loss: 193.5103\n",
      "\n",
      "Epoch 01730: val_loss did not improve from 179.48197\n",
      "Epoch 1731/5000\n",
      "ecpch:1730,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.0130 - val_loss: 193.5130\n",
      "\n",
      "Epoch 01731: val_loss did not improve from 179.48197\n",
      "Epoch 1732/5000\n",
      "ecpch:1731,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.0067 - val_loss: 193.5241\n",
      "\n",
      "Epoch 01732: val_loss did not improve from 179.48197\n",
      "Epoch 1733/5000\n",
      "ecpch:1732,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.0112 - val_loss: 193.5001\n",
      "\n",
      "Epoch 01733: val_loss did not improve from 179.48197\n",
      "Epoch 1734/5000\n",
      "ecpch:1733,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 56.0064 - val_loss: 193.5249\n",
      "\n",
      "Epoch 01734: val_loss did not improve from 179.48197\n",
      "Epoch 1735/5000\n",
      "ecpch:1734,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.0027 - val_loss: 193.5188\n",
      "\n",
      "Epoch 01735: val_loss did not improve from 179.48197\n",
      "Epoch 1736/5000\n",
      "ecpch:1735,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 56.0008 - val_loss: 193.5301\n",
      "\n",
      "Epoch 01736: val_loss did not improve from 179.48197\n",
      "Epoch 1737/5000\n",
      "ecpch:1736,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.9980 - val_loss: 193.5116\n",
      "\n",
      "Epoch 01737: val_loss did not improve from 179.48197\n",
      "Epoch 1738/5000\n",
      "ecpch:1737,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.9990 - val_loss: 193.5267\n",
      "\n",
      "Epoch 01738: val_loss did not improve from 179.48197\n",
      "Epoch 1739/5000\n",
      "ecpch:1738,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.9953 - val_loss: 193.5107\n",
      "\n",
      "Epoch 01739: val_loss did not improve from 179.48197\n",
      "Epoch 1740/5000\n",
      "ecpch:1739,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9946 - val_loss: 193.5312\n",
      "\n",
      "Epoch 01740: val_loss did not improve from 179.48197\n",
      "Epoch 1741/5000\n",
      "ecpch:1740,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9930 - val_loss: 193.5152\n",
      "\n",
      "Epoch 01741: val_loss did not improve from 179.48197\n",
      "Epoch 1742/5000\n",
      "ecpch:1741,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9902 - val_loss: 193.5330\n",
      "\n",
      "Epoch 01742: val_loss did not improve from 179.48197\n",
      "Epoch 1743/5000\n",
      "ecpch:1742,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9877 - val_loss: 193.5097\n",
      "\n",
      "Epoch 01743: val_loss did not improve from 179.48197\n",
      "Epoch 1744/5000\n",
      "ecpch:1743,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9890 - val_loss: 193.5420\n",
      "\n",
      "Epoch 01744: val_loss did not improve from 179.48197\n",
      "Epoch 1745/5000\n",
      "ecpch:1744,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9895 - val_loss: 193.5076\n",
      "\n",
      "Epoch 01745: val_loss did not improve from 179.48197\n",
      "Epoch 1746/5000\n",
      "ecpch:1745,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9886 - val_loss: 193.5366\n",
      "\n",
      "Epoch 01746: val_loss did not improve from 179.48197\n",
      "Epoch 1747/5000\n",
      "ecpch:1746,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9798 - val_loss: 193.5369\n",
      "\n",
      "Epoch 01747: val_loss did not improve from 179.48197\n",
      "Epoch 1748/5000\n",
      "ecpch:1747,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.9802 - val_loss: 193.5039\n",
      "\n",
      "Epoch 01748: val_loss did not improve from 179.48197\n",
      "Epoch 1749/5000\n",
      "ecpch:1748,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.9878 - val_loss: 193.5459\n",
      "\n",
      "Epoch 01749: val_loss did not improve from 179.48197\n",
      "Epoch 1750/5000\n",
      "ecpch:1749,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.9797 - val_loss: 193.5280\n",
      "\n",
      "Epoch 01750: val_loss did not improve from 179.48197\n",
      "Epoch 1751/5000\n",
      "ecpch:1750,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9782 - val_loss: 193.5372\n",
      "\n",
      "Epoch 01751: val_loss did not improve from 179.48197\n",
      "Epoch 1752/5000\n",
      "ecpch:1751,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.9746 - val_loss: 193.5420\n",
      "\n",
      "Epoch 01752: val_loss did not improve from 179.48197\n",
      "Epoch 1753/5000\n",
      "ecpch:1752,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.9707 - val_loss: 193.5437\n",
      "\n",
      "Epoch 01753: val_loss did not improve from 179.48197\n",
      "Epoch 1754/5000\n",
      "ecpch:1753,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9684 - val_loss: 193.5287\n",
      "\n",
      "Epoch 01754: val_loss did not improve from 179.48197\n",
      "Epoch 1755/5000\n",
      "ecpch:1754,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9692 - val_loss: 193.5635\n",
      "\n",
      "Epoch 01755: val_loss did not improve from 179.48197\n",
      "Epoch 1756/5000\n",
      "ecpch:1755,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9748 - val_loss: 193.5215\n",
      "\n",
      "Epoch 01756: val_loss did not improve from 179.48197\n",
      "Epoch 1757/5000\n",
      "ecpch:1756,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9719 - val_loss: 193.5536\n",
      "\n",
      "Epoch 01757: val_loss did not improve from 179.48197\n",
      "Epoch 1758/5000\n",
      "ecpch:1757,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9632 - val_loss: 193.5495\n",
      "\n",
      "Epoch 01758: val_loss did not improve from 179.48197\n",
      "Epoch 1759/5000\n",
      "ecpch:1758,learn rate 0.000011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 9ms/step - loss: 55.9683 - val_loss: 193.5409\n",
      "\n",
      "Epoch 01759: val_loss did not improve from 179.48197\n",
      "Epoch 1760/5000\n",
      "ecpch:1759,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9660 - val_loss: 193.5702\n",
      "\n",
      "Epoch 01760: val_loss did not improve from 179.48197\n",
      "Epoch 1761/5000\n",
      "ecpch:1760,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9613 - val_loss: 193.5273\n",
      "\n",
      "Epoch 01761: val_loss did not improve from 179.48197\n",
      "Epoch 1762/5000\n",
      "ecpch:1761,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9680 - val_loss: 193.5586\n",
      "\n",
      "Epoch 01762: val_loss did not improve from 179.48197\n",
      "Epoch 1763/5000\n",
      "ecpch:1762,learn rate 0.000011\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.9565 - val_loss: 193.5601\n",
      "\n",
      "Epoch 01763: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 01763: ReduceLROnPlateau reducing learning rate to 1.0012622078647837e-05.\n",
      "Epoch 1764/5000\n",
      "ecpch:1763,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.9555 - val_loss: 193.5292\n",
      "\n",
      "Epoch 01764: val_loss did not improve from 179.48197\n",
      "Epoch 1765/5000\n",
      "ecpch:1764,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.9575 - val_loss: 193.5620\n",
      "\n",
      "Epoch 01765: val_loss did not improve from 179.48197\n",
      "Epoch 1766/5000\n",
      "ecpch:1765,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9515 - val_loss: 193.5711\n",
      "\n",
      "Epoch 01766: val_loss did not improve from 179.48197\n",
      "Epoch 1767/5000\n",
      "ecpch:1766,learn rate 0.000010\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 55.9539 - val_loss: 193.5177\n",
      "\n",
      "Epoch 01767: val_loss did not improve from 179.48197\n",
      "Epoch 1768/5000\n",
      "ecpch:1767,learn rate 0.000010\n",
      "64/64 [==============================] - 0s 8ms/step - loss: 55.9615 - val_loss: 193.5421\n",
      "\n",
      "Epoch 01768: val_loss did not improve from 179.48197\n",
      "Epoch 1769/5000\n",
      "ecpch:1768,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9476 - val_loss: 193.5973\n",
      "\n",
      "Epoch 01769: val_loss did not improve from 179.48197\n",
      "Epoch 1770/5000\n",
      "ecpch:1769,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.9718 - val_loss: 193.5600\n",
      "\n",
      "Epoch 01770: val_loss did not improve from 179.48197\n",
      "Epoch 1771/5000\n",
      "ecpch:1770,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.9439 - val_loss: 193.4978\n",
      "\n",
      "Epoch 01771: val_loss did not improve from 179.48197\n",
      "Epoch 1772/5000\n",
      "ecpch:1771,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.9777 - val_loss: 193.5204\n",
      "\n",
      "Epoch 01772: val_loss did not improve from 179.48197\n",
      "Epoch 1773/5000\n",
      "ecpch:1772,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9595 - val_loss: 193.5998\n",
      "\n",
      "Epoch 01773: val_loss did not improve from 179.48197\n",
      "Epoch 1774/5000\n",
      "ecpch:1773,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9722 - val_loss: 193.5930\n",
      "\n",
      "Epoch 01774: val_loss did not improve from 179.48197\n",
      "Epoch 1775/5000\n",
      "ecpch:1774,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9664 - val_loss: 193.5143\n",
      "\n",
      "Epoch 01775: val_loss did not improve from 179.48197\n",
      "Epoch 1776/5000\n",
      "ecpch:1775,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9585 - val_loss: 193.5126\n",
      "\n",
      "Epoch 01776: val_loss did not improve from 179.48197\n",
      "Epoch 1777/5000\n",
      "ecpch:1776,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9638 - val_loss: 193.5795\n",
      "\n",
      "Epoch 01777: val_loss did not improve from 179.48197\n",
      "Epoch 1778/5000\n",
      "ecpch:1777,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9394 - val_loss: 193.5826\n",
      "\n",
      "Epoch 01778: val_loss did not improve from 179.48197\n",
      "Epoch 1779/5000\n",
      "ecpch:1778,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9413 - val_loss: 193.5331\n",
      "\n",
      "Epoch 01779: val_loss did not improve from 179.48197\n",
      "Epoch 1780/5000\n",
      "ecpch:1779,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9464 - val_loss: 193.5493\n",
      "\n",
      "Epoch 01780: val_loss did not improve from 179.48197\n",
      "Epoch 1781/5000\n",
      "ecpch:1780,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.9442 - val_loss: 193.5871\n",
      "\n",
      "Epoch 01781: val_loss did not improve from 179.48197\n",
      "Epoch 1782/5000\n",
      "ecpch:1781,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9378 - val_loss: 193.5597\n",
      "\n",
      "Epoch 01782: val_loss did not improve from 179.48197\n",
      "Epoch 1783/5000\n",
      "ecpch:1782,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9350 - val_loss: 193.5589\n",
      "\n",
      "Epoch 01783: val_loss did not improve from 179.48197\n",
      "Epoch 1784/5000\n",
      "ecpch:1783,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 55.9275 - val_loss: 193.5816\n",
      "\n",
      "Epoch 01784: val_loss did not improve from 179.48197\n",
      "Epoch 1785/5000\n",
      "ecpch:1784,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9274 - val_loss: 193.5795\n",
      "\n",
      "Epoch 01785: val_loss did not improve from 179.48197\n",
      "Epoch 1786/5000\n",
      "ecpch:1785,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9264 - val_loss: 193.5667\n",
      "\n",
      "Epoch 01786: val_loss did not improve from 179.48197\n",
      "Epoch 1787/5000\n",
      "ecpch:1786,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9210 - val_loss: 193.5887\n",
      "\n",
      "Epoch 01787: val_loss did not improve from 179.48197\n",
      "Epoch 1788/5000\n",
      "ecpch:1787,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9294 - val_loss: 193.5701\n",
      "\n",
      "Epoch 01788: val_loss did not improve from 179.48197\n",
      "Epoch 1789/5000\n",
      "ecpch:1788,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9170 - val_loss: 193.5904\n",
      "\n",
      "Epoch 01789: val_loss did not improve from 179.48197\n",
      "Epoch 1790/5000\n",
      "ecpch:1789,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9217 - val_loss: 193.5752\n",
      "\n",
      "Epoch 01790: val_loss did not improve from 179.48197\n",
      "Epoch 1791/5000\n",
      "ecpch:1790,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9190 - val_loss: 193.5891\n",
      "\n",
      "Epoch 01791: val_loss did not improve from 179.48197\n",
      "Epoch 1792/5000\n",
      "ecpch:1791,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.9113 - val_loss: 193.5764\n",
      "\n",
      "Epoch 01792: val_loss did not improve from 179.48197\n",
      "Epoch 1793/5000\n",
      "ecpch:1792,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.9159 - val_loss: 193.6005\n",
      "\n",
      "Epoch 01793: val_loss did not improve from 179.48197\n",
      "Epoch 1794/5000\n",
      "ecpch:1793,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.9153 - val_loss: 193.5707\n",
      "\n",
      "Epoch 01794: val_loss did not improve from 179.48197\n",
      "Epoch 1795/5000\n",
      "ecpch:1794,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.9088 - val_loss: 193.5953\n",
      "\n",
      "Epoch 01795: val_loss did not improve from 179.48197\n",
      "Epoch 1796/5000\n",
      "ecpch:1795,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.9072 - val_loss: 193.5926\n",
      "\n",
      "Epoch 01796: val_loss did not improve from 179.48197\n",
      "Epoch 1797/5000\n",
      "ecpch:1796,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.9079 - val_loss: 193.5882\n",
      "\n",
      "Epoch 01797: val_loss did not improve from 179.48197\n",
      "Epoch 1798/5000\n",
      "ecpch:1797,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.9064 - val_loss: 193.6063\n",
      "\n",
      "Epoch 01798: val_loss did not improve from 179.48197\n",
      "Epoch 1799/5000\n",
      "ecpch:1798,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.9059 - val_loss: 193.5690\n",
      "\n",
      "Epoch 01799: val_loss did not improve from 179.48197\n",
      "Epoch 1800/5000\n",
      "ecpch:1799,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.9078 - val_loss: 193.5958\n",
      "\n",
      "Epoch 01800: val_loss did not improve from 179.48197\n",
      "Epoch 1801/5000\n",
      "ecpch:1800,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 55.8991 - val_loss: 193.5945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01801: val_loss did not improve from 179.48197\n",
      "Epoch 1802/5000\n",
      "ecpch:1801,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8970 - val_loss: 193.5809\n",
      "\n",
      "Epoch 01802: val_loss did not improve from 179.48197\n",
      "Epoch 1803/5000\n",
      "ecpch:1802,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8988 - val_loss: 193.6164\n",
      "\n",
      "Epoch 01803: val_loss did not improve from 179.48197\n",
      "Epoch 1804/5000\n",
      "ecpch:1803,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.9040 - val_loss: 193.5908\n",
      "\n",
      "Epoch 01804: val_loss did not improve from 179.48197\n",
      "Epoch 1805/5000\n",
      "ecpch:1804,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8932 - val_loss: 193.6009\n",
      "\n",
      "Epoch 01805: val_loss did not improve from 179.48197\n",
      "Epoch 1806/5000\n",
      "ecpch:1805,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8901 - val_loss: 193.5868\n",
      "\n",
      "Epoch 01806: val_loss did not improve from 179.48197\n",
      "Epoch 1807/5000\n",
      "ecpch:1806,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8931 - val_loss: 193.6134\n",
      "\n",
      "Epoch 01807: val_loss did not improve from 179.48197\n",
      "Epoch 1808/5000\n",
      "ecpch:1807,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8936 - val_loss: 193.5885\n",
      "\n",
      "Epoch 01808: val_loss did not improve from 179.48197\n",
      "Epoch 1809/5000\n",
      "ecpch:1808,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8906 - val_loss: 193.6147\n",
      "\n",
      "Epoch 01809: val_loss did not improve from 179.48197\n",
      "Epoch 1810/5000\n",
      "ecpch:1809,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8897 - val_loss: 193.5840\n",
      "\n",
      "Epoch 01810: val_loss did not improve from 179.48197\n",
      "Epoch 1811/5000\n",
      "ecpch:1810,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8913 - val_loss: 193.6097\n",
      "\n",
      "Epoch 01811: val_loss did not improve from 179.48197\n",
      "Epoch 1812/5000\n",
      "ecpch:1811,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8846 - val_loss: 193.5984\n",
      "\n",
      "Epoch 01812: val_loss did not improve from 179.48197\n",
      "Epoch 1813/5000\n",
      "ecpch:1812,learn rate 0.000010\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8823 - val_loss: 193.6145\n",
      "\n",
      "Epoch 01813: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 01813: ReduceLROnPlateau reducing learning rate to 9.01135954336496e-06.\n",
      "Epoch 1814/5000\n",
      "ecpch:1813,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8833 - val_loss: 193.5912\n",
      "\n",
      "Epoch 01814: val_loss did not improve from 179.48197\n",
      "Epoch 1815/5000\n",
      "ecpch:1814,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8828 - val_loss: 193.6143\n",
      "\n",
      "Epoch 01815: val_loss did not improve from 179.48197\n",
      "Epoch 1816/5000\n",
      "ecpch:1815,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8777 - val_loss: 193.5983\n",
      "\n",
      "Epoch 01816: val_loss did not improve from 179.48197\n",
      "Epoch 1817/5000\n",
      "ecpch:1816,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.8789 - val_loss: 193.6101\n",
      "\n",
      "Epoch 01817: val_loss did not improve from 179.48197\n",
      "Epoch 1818/5000\n",
      "ecpch:1817,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8806 - val_loss: 193.6237\n",
      "\n",
      "Epoch 01818: val_loss did not improve from 179.48197\n",
      "Epoch 1819/5000\n",
      "ecpch:1818,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8750 - val_loss: 193.5755\n",
      "\n",
      "Epoch 01819: val_loss did not improve from 179.48197\n",
      "Epoch 1820/5000\n",
      "ecpch:1819,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8902 - val_loss: 193.5984\n",
      "\n",
      "Epoch 01820: val_loss did not improve from 179.48197\n",
      "Epoch 1821/5000\n",
      "ecpch:1820,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8750 - val_loss: 193.6594\n",
      "\n",
      "Epoch 01821: val_loss did not improve from 179.48197\n",
      "Epoch 1822/5000\n",
      "ecpch:1821,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.9060 - val_loss: 193.6509\n",
      "\n",
      "Epoch 01822: val_loss did not improve from 179.48197\n",
      "Epoch 1823/5000\n",
      "ecpch:1822,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8884 - val_loss: 193.5620\n",
      "\n",
      "Epoch 01823: val_loss did not improve from 179.48197\n",
      "Epoch 1824/5000\n",
      "ecpch:1823,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8995 - val_loss: 193.5502\n",
      "\n",
      "Epoch 01824: val_loss did not improve from 179.48197\n",
      "Epoch 1825/5000\n",
      "ecpch:1824,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.9048 - val_loss: 193.6228\n",
      "\n",
      "Epoch 01825: val_loss did not improve from 179.48197\n",
      "Epoch 1826/5000\n",
      "ecpch:1825,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8641 - val_loss: 193.6673\n",
      "\n",
      "Epoch 01826: val_loss did not improve from 179.48197\n",
      "Epoch 1827/5000\n",
      "ecpch:1826,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8904 - val_loss: 193.6248\n",
      "\n",
      "Epoch 01827: val_loss did not improve from 179.48197\n",
      "Epoch 1828/5000\n",
      "ecpch:1827,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8636 - val_loss: 193.5796\n",
      "\n",
      "Epoch 01828: val_loss did not improve from 179.48197\n",
      "Epoch 1829/5000\n",
      "ecpch:1828,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8803 - val_loss: 193.6106\n",
      "\n",
      "Epoch 01829: val_loss did not improve from 179.48197\n",
      "Epoch 1830/5000\n",
      "ecpch:1829,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8631 - val_loss: 193.6659\n",
      "\n",
      "Epoch 01830: val_loss did not improve from 179.48197\n",
      "Epoch 1831/5000\n",
      "ecpch:1830,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8907 - val_loss: 193.6518\n",
      "\n",
      "Epoch 01831: val_loss did not improve from 179.48197\n",
      "Epoch 1832/5000\n",
      "ecpch:1831,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8773 - val_loss: 193.5877\n",
      "\n",
      "Epoch 01832: val_loss did not improve from 179.48197\n",
      "Epoch 1833/5000\n",
      "ecpch:1832,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8765 - val_loss: 193.5811\n",
      "\n",
      "Epoch 01833: val_loss did not improve from 179.48197\n",
      "Epoch 1834/5000\n",
      "ecpch:1833,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8802 - val_loss: 193.6401\n",
      "\n",
      "Epoch 01834: val_loss did not improve from 179.48197\n",
      "Epoch 1835/5000\n",
      "ecpch:1834,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8569 - val_loss: 193.6478\n",
      "\n",
      "Epoch 01835: val_loss did not improve from 179.48197\n",
      "Epoch 1836/5000\n",
      "ecpch:1835,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8622 - val_loss: 193.6148\n",
      "\n",
      "Epoch 01836: val_loss did not improve from 179.48197\n",
      "Epoch 1837/5000\n",
      "ecpch:1836,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8558 - val_loss: 193.6149\n",
      "\n",
      "Epoch 01837: val_loss did not improve from 179.48197\n",
      "Epoch 1838/5000\n",
      "ecpch:1837,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8497 - val_loss: 193.6547\n",
      "\n",
      "Epoch 01838: val_loss did not improve from 179.48197\n",
      "Epoch 1839/5000\n",
      "ecpch:1838,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8566 - val_loss: 193.6246\n",
      "\n",
      "Epoch 01839: val_loss did not improve from 179.48197\n",
      "Epoch 1840/5000\n",
      "ecpch:1839,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8481 - val_loss: 193.6183\n",
      "\n",
      "Epoch 01840: val_loss did not improve from 179.48197\n",
      "Epoch 1841/5000\n",
      "ecpch:1840,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8531 - val_loss: 193.6424\n",
      "\n",
      "Epoch 01841: val_loss did not improve from 179.48197\n",
      "Epoch 1842/5000\n",
      "ecpch:1841,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8449 - val_loss: 193.6285\n",
      "\n",
      "Epoch 01842: val_loss did not improve from 179.48197\n",
      "Epoch 1843/5000\n",
      "ecpch:1842,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8502 - val_loss: 193.6263\n",
      "\n",
      "Epoch 01843: val_loss did not improve from 179.48197\n",
      "Epoch 1844/5000\n",
      "ecpch:1843,learn rate 0.000009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8420 - val_loss: 193.6504\n",
      "\n",
      "Epoch 01844: val_loss did not improve from 179.48197\n",
      "Epoch 1845/5000\n",
      "ecpch:1844,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8401 - val_loss: 193.6289\n",
      "\n",
      "Epoch 01845: val_loss did not improve from 179.48197\n",
      "Epoch 1846/5000\n",
      "ecpch:1845,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8478 - val_loss: 193.6399\n",
      "\n",
      "Epoch 01846: val_loss did not improve from 179.48197\n",
      "Epoch 1847/5000\n",
      "ecpch:1846,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8358 - val_loss: 193.6599\n",
      "\n",
      "Epoch 01847: val_loss did not improve from 179.48197\n",
      "Epoch 1848/5000\n",
      "ecpch:1847,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8509 - val_loss: 193.6442\n",
      "\n",
      "Epoch 01848: val_loss did not improve from 179.48197\n",
      "Epoch 1849/5000\n",
      "ecpch:1848,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8327 - val_loss: 193.6383\n",
      "\n",
      "Epoch 01849: val_loss did not improve from 179.48197\n",
      "Epoch 1850/5000\n",
      "ecpch:1849,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.8362 - val_loss: 193.6619\n",
      "\n",
      "Epoch 01850: val_loss did not improve from 179.48197\n",
      "Epoch 1851/5000\n",
      "ecpch:1850,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8369 - val_loss: 193.6328\n",
      "\n",
      "Epoch 01851: val_loss did not improve from 179.48197\n",
      "Epoch 1852/5000\n",
      "ecpch:1851,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.8308 - val_loss: 193.6664\n",
      "\n",
      "Epoch 01852: val_loss did not improve from 179.48197\n",
      "Epoch 1853/5000\n",
      "ecpch:1852,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.8376 - val_loss: 193.6456\n",
      "\n",
      "Epoch 01853: val_loss did not improve from 179.48197\n",
      "Epoch 1854/5000\n",
      "ecpch:1853,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8275 - val_loss: 193.6247\n",
      "\n",
      "Epoch 01854: val_loss did not improve from 179.48197\n",
      "Epoch 1855/5000\n",
      "ecpch:1854,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.8332 - val_loss: 193.6593\n",
      "\n",
      "Epoch 01855: val_loss did not improve from 179.48197\n",
      "Epoch 1856/5000\n",
      "ecpch:1855,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8307 - val_loss: 193.6679\n",
      "\n",
      "Epoch 01856: val_loss did not improve from 179.48197\n",
      "Epoch 1857/5000\n",
      "ecpch:1856,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8280 - val_loss: 193.6183\n",
      "\n",
      "Epoch 01857: val_loss did not improve from 179.48197\n",
      "Epoch 1858/5000\n",
      "ecpch:1857,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.8402 - val_loss: 193.6261\n",
      "\n",
      "Epoch 01858: val_loss did not improve from 179.48197\n",
      "Epoch 1859/5000\n",
      "ecpch:1858,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8326 - val_loss: 193.6872\n",
      "\n",
      "Epoch 01859: val_loss did not improve from 179.48197\n",
      "Epoch 1860/5000\n",
      "ecpch:1859,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8362 - val_loss: 193.6592\n",
      "\n",
      "Epoch 01860: val_loss did not improve from 179.48197\n",
      "Epoch 1861/5000\n",
      "ecpch:1860,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8213 - val_loss: 193.6167\n",
      "\n",
      "Epoch 01861: val_loss did not improve from 179.48197\n",
      "Epoch 1862/5000\n",
      "ecpch:1861,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8353 - val_loss: 193.6349\n",
      "\n",
      "Epoch 01862: val_loss did not improve from 179.48197\n",
      "Epoch 1863/5000\n",
      "ecpch:1862,learn rate 0.000009\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8197 - val_loss: 193.6985\n",
      "\n",
      "Epoch 01863: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 01863: ReduceLROnPlateau reducing learning rate to 8.110223916446557e-06.\n",
      "Epoch 1864/5000\n",
      "ecpch:1863,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8410 - val_loss: 193.6792\n",
      "\n",
      "Epoch 01864: val_loss did not improve from 179.48197\n",
      "Epoch 1865/5000\n",
      "ecpch:1864,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8227 - val_loss: 193.6016\n",
      "\n",
      "Epoch 01865: val_loss did not improve from 179.48197\n",
      "Epoch 1866/5000\n",
      "ecpch:1865,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.8434 - val_loss: 193.6017\n",
      "\n",
      "Epoch 01866: val_loss did not improve from 179.48197\n",
      "Epoch 1867/5000\n",
      "ecpch:1866,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8471 - val_loss: 193.6604\n",
      "\n",
      "Epoch 01867: val_loss did not improve from 179.48197\n",
      "Epoch 1868/5000\n",
      "ecpch:1867,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8085 - val_loss: 193.7142\n",
      "\n",
      "Epoch 01868: val_loss did not improve from 179.48197\n",
      "Epoch 1869/5000\n",
      "ecpch:1868,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8361 - val_loss: 193.6789\n",
      "\n",
      "Epoch 01869: val_loss did not improve from 179.48197\n",
      "Epoch 1870/5000\n",
      "ecpch:1869,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8104 - val_loss: 193.6214\n",
      "\n",
      "Epoch 01870: val_loss did not improve from 179.48197\n",
      "Epoch 1871/5000\n",
      "ecpch:1870,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8318 - val_loss: 193.6192\n",
      "\n",
      "Epoch 01871: val_loss did not improve from 179.48197\n",
      "Epoch 1872/5000\n",
      "ecpch:1871,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8257 - val_loss: 193.6958\n",
      "\n",
      "Epoch 01872: val_loss did not improve from 179.48197\n",
      "Epoch 1873/5000\n",
      "ecpch:1872,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8116 - val_loss: 193.7048\n",
      "\n",
      "Epoch 01873: val_loss did not improve from 179.48197\n",
      "Epoch 1874/5000\n",
      "ecpch:1873,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.8128 - val_loss: 193.6406\n",
      "\n",
      "Epoch 01874: val_loss did not improve from 179.48197\n",
      "Epoch 1875/5000\n",
      "ecpch:1874,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.8129 - val_loss: 193.6480\n",
      "\n",
      "Epoch 01875: val_loss did not improve from 179.48197\n",
      "Epoch 1876/5000\n",
      "ecpch:1875,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8109 - val_loss: 193.6973\n",
      "\n",
      "Epoch 01876: val_loss did not improve from 179.48197\n",
      "Epoch 1877/5000\n",
      "ecpch:1876,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8061 - val_loss: 193.6877\n",
      "\n",
      "Epoch 01877: val_loss did not improve from 179.48197\n",
      "Epoch 1878/5000\n",
      "ecpch:1877,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8010 - val_loss: 193.6448\n",
      "\n",
      "Epoch 01878: val_loss did not improve from 179.48197\n",
      "Epoch 1879/5000\n",
      "ecpch:1878,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8042 - val_loss: 193.6525\n",
      "\n",
      "Epoch 01879: val_loss did not improve from 179.48197\n",
      "Epoch 1880/5000\n",
      "ecpch:1879,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7997 - val_loss: 193.6922\n",
      "\n",
      "Epoch 01880: val_loss did not improve from 179.48197\n",
      "Epoch 1881/5000\n",
      "ecpch:1880,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8010 - val_loss: 193.6872\n",
      "\n",
      "Epoch 01881: val_loss did not improve from 179.48197\n",
      "Epoch 1882/5000\n",
      "ecpch:1881,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7913 - val_loss: 193.6537\n",
      "\n",
      "Epoch 01882: val_loss did not improve from 179.48197\n",
      "Epoch 1883/5000\n",
      "ecpch:1882,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7998 - val_loss: 193.6739\n",
      "\n",
      "Epoch 01883: val_loss did not improve from 179.48197\n",
      "Epoch 1884/5000\n",
      "ecpch:1883,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7896 - val_loss: 193.7048\n",
      "\n",
      "Epoch 01884: val_loss did not improve from 179.48197\n",
      "Epoch 1885/5000\n",
      "ecpch:1884,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.8020 - val_loss: 193.6837\n",
      "\n",
      "Epoch 01885: val_loss did not improve from 179.48197\n",
      "Epoch 1886/5000\n",
      "ecpch:1885,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7859 - val_loss: 193.6474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01886: val_loss did not improve from 179.48197\n",
      "Epoch 1887/5000\n",
      "ecpch:1886,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7957 - val_loss: 193.6819\n",
      "\n",
      "Epoch 01887: val_loss did not improve from 179.48197\n",
      "Epoch 1888/5000\n",
      "ecpch:1887,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7825 - val_loss: 193.7125\n",
      "\n",
      "Epoch 01888: val_loss did not improve from 179.48197\n",
      "Epoch 1889/5000\n",
      "ecpch:1888,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.7944 - val_loss: 193.6775\n",
      "\n",
      "Epoch 01889: val_loss did not improve from 179.48197\n",
      "Epoch 1890/5000\n",
      "ecpch:1889,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7813 - val_loss: 193.6793\n",
      "\n",
      "Epoch 01890: val_loss did not improve from 179.48197\n",
      "Epoch 1891/5000\n",
      "ecpch:1890,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.7813 - val_loss: 193.7095\n",
      "\n",
      "Epoch 01891: val_loss did not improve from 179.48197\n",
      "Epoch 1892/5000\n",
      "ecpch:1891,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7881 - val_loss: 193.6919\n",
      "\n",
      "Epoch 01892: val_loss did not improve from 179.48197\n",
      "Epoch 1893/5000\n",
      "ecpch:1892,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.7764 - val_loss: 193.6642\n",
      "\n",
      "Epoch 01893: val_loss did not improve from 179.48197\n",
      "Epoch 1894/5000\n",
      "ecpch:1893,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.7886 - val_loss: 193.6986\n",
      "\n",
      "Epoch 01894: val_loss did not improve from 179.48197\n",
      "Epoch 1895/5000\n",
      "ecpch:1894,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.7737 - val_loss: 193.7056\n",
      "\n",
      "Epoch 01895: val_loss did not improve from 179.48197\n",
      "Epoch 1896/5000\n",
      "ecpch:1895,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7754 - val_loss: 193.6718\n",
      "\n",
      "Epoch 01896: val_loss did not improve from 179.48197\n",
      "Epoch 1897/5000\n",
      "ecpch:1896,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.7800 - val_loss: 193.6871\n",
      "\n",
      "Epoch 01897: val_loss did not improve from 179.48197\n",
      "Epoch 1898/5000\n",
      "ecpch:1897,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.7706 - val_loss: 193.7309\n",
      "\n",
      "Epoch 01898: val_loss did not improve from 179.48197\n",
      "Epoch 1899/5000\n",
      "ecpch:1898,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7876 - val_loss: 193.6947\n",
      "\n",
      "Epoch 01899: val_loss did not improve from 179.48197\n",
      "Epoch 1900/5000\n",
      "ecpch:1899,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7689 - val_loss: 193.6781\n",
      "\n",
      "Epoch 01900: val_loss did not improve from 179.48197\n",
      "Epoch 1901/5000\n",
      "ecpch:1900,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.7848 - val_loss: 193.6912\n",
      "\n",
      "Epoch 01901: val_loss did not improve from 179.48197\n",
      "Epoch 1902/5000\n",
      "ecpch:1901,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.7686 - val_loss: 193.7158\n",
      "\n",
      "Epoch 01902: val_loss did not improve from 179.48197\n",
      "Epoch 1903/5000\n",
      "ecpch:1902,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7932 - val_loss: 193.7011\n",
      "\n",
      "Epoch 01903: val_loss did not improve from 179.48197\n",
      "Epoch 1904/5000\n",
      "ecpch:1903,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.7834 - val_loss: 193.6870\n",
      "\n",
      "Epoch 01904: val_loss did not improve from 179.48197\n",
      "Epoch 1905/5000\n",
      "ecpch:1904,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7758 - val_loss: 193.6913\n",
      "\n",
      "Epoch 01905: val_loss did not improve from 179.48197\n",
      "Epoch 1906/5000\n",
      "ecpch:1905,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7780 - val_loss: 193.7075\n",
      "\n",
      "Epoch 01906: val_loss did not improve from 179.48197\n",
      "Epoch 1907/5000\n",
      "ecpch:1906,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7655 - val_loss: 193.6978\n",
      "\n",
      "Epoch 01907: val_loss did not improve from 179.48197\n",
      "Epoch 1908/5000\n",
      "ecpch:1907,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7662 - val_loss: 193.6992\n",
      "\n",
      "Epoch 01908: val_loss did not improve from 179.48197\n",
      "Epoch 1909/5000\n",
      "ecpch:1908,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7660 - val_loss: 193.7029\n",
      "\n",
      "Epoch 01909: val_loss did not improve from 179.48197\n",
      "Epoch 1910/5000\n",
      "ecpch:1909,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7592 - val_loss: 193.6948\n",
      "\n",
      "Epoch 01910: val_loss did not improve from 179.48197\n",
      "Epoch 1911/5000\n",
      "ecpch:1910,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7712 - val_loss: 193.7047\n",
      "\n",
      "Epoch 01911: val_loss did not improve from 179.48197\n",
      "Epoch 1912/5000\n",
      "ecpch:1911,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7600 - val_loss: 193.7030\n",
      "\n",
      "Epoch 01912: val_loss did not improve from 179.48197\n",
      "Epoch 1913/5000\n",
      "ecpch:1912,learn rate 0.000008\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7739 - val_loss: 193.6956\n",
      "\n",
      "Epoch 01913: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 01913: ReduceLROnPlateau reducing learning rate to 7.299201934074518e-06.\n",
      "Epoch 1914/5000\n",
      "ecpch:1913,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7700 - val_loss: 193.6997\n",
      "\n",
      "Epoch 01914: val_loss did not improve from 179.48197\n",
      "Epoch 1915/5000\n",
      "ecpch:1914,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7547 - val_loss: 193.7336\n",
      "\n",
      "Epoch 01915: val_loss did not improve from 179.48197\n",
      "Epoch 1916/5000\n",
      "ecpch:1915,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.7668 - val_loss: 193.7142\n",
      "\n",
      "Epoch 01916: val_loss did not improve from 179.48197\n",
      "Epoch 1917/5000\n",
      "ecpch:1916,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7493 - val_loss: 193.6834\n",
      "\n",
      "Epoch 01917: val_loss did not improve from 179.48197\n",
      "Epoch 1918/5000\n",
      "ecpch:1917,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7634 - val_loss: 193.7037\n",
      "\n",
      "Epoch 01918: val_loss did not improve from 179.48197\n",
      "Epoch 1919/5000\n",
      "ecpch:1918,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7490 - val_loss: 193.7463\n",
      "\n",
      "Epoch 01919: val_loss did not improve from 179.48197\n",
      "Epoch 1920/5000\n",
      "ecpch:1919,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7704 - val_loss: 193.7365\n",
      "\n",
      "Epoch 01920: val_loss did not improve from 179.48197\n",
      "Epoch 1921/5000\n",
      "ecpch:1920,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7556 - val_loss: 193.6720\n",
      "\n",
      "Epoch 01921: val_loss did not improve from 179.48197\n",
      "Epoch 1922/5000\n",
      "ecpch:1921,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7687 - val_loss: 193.6652\n",
      "\n",
      "Epoch 01922: val_loss did not improve from 179.48197\n",
      "Epoch 1923/5000\n",
      "ecpch:1922,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7713 - val_loss: 193.7211\n",
      "\n",
      "Epoch 01923: val_loss did not improve from 179.48197\n",
      "Epoch 1924/5000\n",
      "ecpch:1923,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7424 - val_loss: 193.7558\n",
      "\n",
      "Epoch 01924: val_loss did not improve from 179.48197\n",
      "Epoch 1925/5000\n",
      "ecpch:1924,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7644 - val_loss: 193.7203\n",
      "\n",
      "Epoch 01925: val_loss did not improve from 179.48197\n",
      "Epoch 1926/5000\n",
      "ecpch:1925,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7424 - val_loss: 193.6917\n",
      "\n",
      "Epoch 01926: val_loss did not improve from 179.48197\n",
      "Epoch 1927/5000\n",
      "ecpch:1926,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7504 - val_loss: 193.7014\n",
      "\n",
      "Epoch 01927: val_loss did not improve from 179.48197\n",
      "Epoch 1928/5000\n",
      "ecpch:1927,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7404 - val_loss: 193.7421\n",
      "\n",
      "Epoch 01928: val_loss did not improve from 179.48197\n",
      "Epoch 1929/5000\n",
      "ecpch:1928,learn rate 0.000007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7522 - val_loss: 193.7252\n",
      "\n",
      "Epoch 01929: val_loss did not improve from 179.48197\n",
      "Epoch 1930/5000\n",
      "ecpch:1929,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7430 - val_loss: 193.7040\n",
      "\n",
      "Epoch 01930: val_loss did not improve from 179.48197\n",
      "Epoch 1931/5000\n",
      "ecpch:1930,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7426 - val_loss: 193.7180\n",
      "\n",
      "Epoch 01931: val_loss did not improve from 179.48197\n",
      "Epoch 1932/5000\n",
      "ecpch:1931,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7381 - val_loss: 193.7496\n",
      "\n",
      "Epoch 01932: val_loss did not improve from 179.48197\n",
      "Epoch 1933/5000\n",
      "ecpch:1932,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7433 - val_loss: 193.7264\n",
      "\n",
      "Epoch 01933: val_loss did not improve from 179.48197\n",
      "Epoch 1934/5000\n",
      "ecpch:1933,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.7377 - val_loss: 193.7110\n",
      "\n",
      "Epoch 01934: val_loss did not improve from 179.48197\n",
      "Epoch 1935/5000\n",
      "ecpch:1934,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.7373 - val_loss: 193.7262\n",
      "\n",
      "Epoch 01935: val_loss did not improve from 179.48197\n",
      "Epoch 1936/5000\n",
      "ecpch:1935,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.7351 - val_loss: 193.7308\n",
      "\n",
      "Epoch 01936: val_loss did not improve from 179.48197\n",
      "Epoch 1937/5000\n",
      "ecpch:1936,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7327 - val_loss: 193.7224\n",
      "\n",
      "Epoch 01937: val_loss did not improve from 179.48197\n",
      "Epoch 1938/5000\n",
      "ecpch:1937,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7309 - val_loss: 193.7330\n",
      "\n",
      "Epoch 01938: val_loss did not improve from 179.48197\n",
      "Epoch 1939/5000\n",
      "ecpch:1938,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7321 - val_loss: 193.7279\n",
      "\n",
      "Epoch 01939: val_loss did not improve from 179.48197\n",
      "Epoch 1940/5000\n",
      "ecpch:1939,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7272 - val_loss: 193.7294\n",
      "\n",
      "Epoch 01940: val_loss did not improve from 179.48197\n",
      "Epoch 1941/5000\n",
      "ecpch:1940,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7318 - val_loss: 193.7564\n",
      "\n",
      "Epoch 01941: val_loss did not improve from 179.48197\n",
      "Epoch 1942/5000\n",
      "ecpch:1941,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 55.7322 - val_loss: 193.7221\n",
      "\n",
      "Epoch 01942: val_loss did not improve from 179.48197\n",
      "Epoch 1943/5000\n",
      "ecpch:1942,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7245 - val_loss: 193.7174\n",
      "\n",
      "Epoch 01943: val_loss did not improve from 179.48197\n",
      "Epoch 1944/5000\n",
      "ecpch:1943,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7242 - val_loss: 193.7420\n",
      "\n",
      "Epoch 01944: val_loss did not improve from 179.48197\n",
      "Epoch 1945/5000\n",
      "ecpch:1944,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7218 - val_loss: 193.7334\n",
      "\n",
      "Epoch 01945: val_loss did not improve from 179.48197\n",
      "Epoch 1946/5000\n",
      "ecpch:1945,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7165 - val_loss: 193.7343\n",
      "\n",
      "Epoch 01946: val_loss did not improve from 179.48197\n",
      "Epoch 1947/5000\n",
      "ecpch:1946,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7224 - val_loss: 193.7310\n",
      "\n",
      "Epoch 01947: val_loss did not improve from 179.48197\n",
      "Epoch 1948/5000\n",
      "ecpch:1947,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7136 - val_loss: 193.7371\n",
      "\n",
      "Epoch 01948: val_loss did not improve from 179.48197\n",
      "Epoch 1949/5000\n",
      "ecpch:1948,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7187 - val_loss: 193.7419\n",
      "\n",
      "Epoch 01949: val_loss did not improve from 179.48197\n",
      "Epoch 1950/5000\n",
      "ecpch:1949,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 55.7115 - val_loss: 193.7178\n",
      "\n",
      "Epoch 01950: val_loss did not improve from 179.48197\n",
      "Epoch 1951/5000\n",
      "ecpch:1950,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7193 - val_loss: 193.7358\n",
      "\n",
      "Epoch 01951: val_loss did not improve from 179.48197\n",
      "Epoch 1952/5000\n",
      "ecpch:1951,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.7080 - val_loss: 193.7634\n",
      "\n",
      "Epoch 01952: val_loss did not improve from 179.48197\n",
      "Epoch 1953/5000\n",
      "ecpch:1952,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7193 - val_loss: 193.7329\n",
      "\n",
      "Epoch 01953: val_loss did not improve from 179.48197\n",
      "Epoch 1954/5000\n",
      "ecpch:1953,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7073 - val_loss: 193.7357\n",
      "\n",
      "Epoch 01954: val_loss did not improve from 179.48197\n",
      "Epoch 1955/5000\n",
      "ecpch:1954,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7152 - val_loss: 193.7509\n",
      "\n",
      "Epoch 01955: val_loss did not improve from 179.48197\n",
      "Epoch 1956/5000\n",
      "ecpch:1955,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7056 - val_loss: 193.7368\n",
      "\n",
      "Epoch 01956: val_loss did not improve from 179.48197\n",
      "Epoch 1957/5000\n",
      "ecpch:1956,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7194 - val_loss: 193.7458\n",
      "\n",
      "Epoch 01957: val_loss did not improve from 179.48197\n",
      "Epoch 1958/5000\n",
      "ecpch:1957,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7062 - val_loss: 193.7729\n",
      "\n",
      "Epoch 01958: val_loss did not improve from 179.48197\n",
      "Epoch 1959/5000\n",
      "ecpch:1958,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.7274 - val_loss: 193.7590\n",
      "\n",
      "Epoch 01959: val_loss did not improve from 179.48197\n",
      "Epoch 1960/5000\n",
      "ecpch:1959,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7208 - val_loss: 193.7270\n",
      "\n",
      "Epoch 01960: val_loss did not improve from 179.48197\n",
      "Epoch 1961/5000\n",
      "ecpch:1960,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7118 - val_loss: 193.7343\n",
      "\n",
      "Epoch 01961: val_loss did not improve from 179.48197\n",
      "Epoch 1962/5000\n",
      "ecpch:1961,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7139 - val_loss: 193.7686\n",
      "\n",
      "Epoch 01962: val_loss did not improve from 179.48197\n",
      "Epoch 1963/5000\n",
      "ecpch:1962,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7062 - val_loss: 193.7526\n",
      "\n",
      "Epoch 01963: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 01963: ReduceLROnPlateau reducing learning rate to 6.569281822521589e-06.\n",
      "Epoch 1964/5000\n",
      "ecpch:1963,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7081 - val_loss: 193.7357\n",
      "\n",
      "Epoch 01964: val_loss did not improve from 179.48197\n",
      "Epoch 1965/5000\n",
      "ecpch:1964,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6998 - val_loss: 193.7638\n",
      "\n",
      "Epoch 01965: val_loss did not improve from 179.48197\n",
      "Epoch 1966/5000\n",
      "ecpch:1965,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7031 - val_loss: 193.7674\n",
      "\n",
      "Epoch 01966: val_loss did not improve from 179.48197\n",
      "Epoch 1967/5000\n",
      "ecpch:1966,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6959 - val_loss: 193.7356\n",
      "\n",
      "Epoch 01967: val_loss did not improve from 179.48197\n",
      "Epoch 1968/5000\n",
      "ecpch:1967,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.7066 - val_loss: 193.7329\n",
      "\n",
      "Epoch 01968: val_loss did not improve from 179.48197\n",
      "Epoch 1969/5000\n",
      "ecpch:1968,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.7017 - val_loss: 193.7583\n",
      "\n",
      "Epoch 01969: val_loss did not improve from 179.48197\n",
      "Epoch 1970/5000\n",
      "ecpch:1969,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6969 - val_loss: 193.7682\n",
      "\n",
      "Epoch 01970: val_loss did not improve from 179.48197\n",
      "Epoch 1971/5000\n",
      "ecpch:1970,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6955 - val_loss: 193.7395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01971: val_loss did not improve from 179.48197\n",
      "Epoch 1972/5000\n",
      "ecpch:1971,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6948 - val_loss: 193.7419\n",
      "\n",
      "Epoch 01972: val_loss did not improve from 179.48197\n",
      "Epoch 1973/5000\n",
      "ecpch:1972,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.6946 - val_loss: 193.7651\n",
      "\n",
      "Epoch 01973: val_loss did not improve from 179.48197\n",
      "Epoch 1974/5000\n",
      "ecpch:1973,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.6898 - val_loss: 193.7476\n",
      "\n",
      "Epoch 01974: val_loss did not improve from 179.48197\n",
      "Epoch 1975/5000\n",
      "ecpch:1974,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6911 - val_loss: 193.7531\n",
      "\n",
      "Epoch 01975: val_loss did not improve from 179.48197\n",
      "Epoch 1976/5000\n",
      "ecpch:1975,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6876 - val_loss: 193.7673\n",
      "\n",
      "Epoch 01976: val_loss did not improve from 179.48197\n",
      "Epoch 1977/5000\n",
      "ecpch:1976,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.6871 - val_loss: 193.7541\n",
      "\n",
      "Epoch 01977: val_loss did not improve from 179.48197\n",
      "Epoch 1978/5000\n",
      "ecpch:1977,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6867 - val_loss: 193.7708\n",
      "\n",
      "Epoch 01978: val_loss did not improve from 179.48197\n",
      "Epoch 1979/5000\n",
      "ecpch:1978,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.6802 - val_loss: 193.7686\n",
      "\n",
      "Epoch 01979: val_loss did not improve from 179.48197\n",
      "Epoch 1980/5000\n",
      "ecpch:1979,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6851 - val_loss: 193.7623\n",
      "\n",
      "Epoch 01980: val_loss did not improve from 179.48197\n",
      "Epoch 1981/5000\n",
      "ecpch:1980,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6793 - val_loss: 193.7748\n",
      "\n",
      "Epoch 01981: val_loss did not improve from 179.48197\n",
      "Epoch 1982/5000\n",
      "ecpch:1981,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6853 - val_loss: 193.7742\n",
      "\n",
      "Epoch 01982: val_loss did not improve from 179.48197\n",
      "Epoch 1983/5000\n",
      "ecpch:1982,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6754 - val_loss: 193.7618\n",
      "\n",
      "Epoch 01983: val_loss did not improve from 179.48197\n",
      "Epoch 1984/5000\n",
      "ecpch:1983,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6854 - val_loss: 193.7742\n",
      "\n",
      "Epoch 01984: val_loss did not improve from 179.48197\n",
      "Epoch 1985/5000\n",
      "ecpch:1984,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6761 - val_loss: 193.7593\n",
      "\n",
      "Epoch 01985: val_loss did not improve from 179.48197\n",
      "Epoch 1986/5000\n",
      "ecpch:1985,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6891 - val_loss: 193.7738\n",
      "\n",
      "Epoch 01986: val_loss did not improve from 179.48197\n",
      "Epoch 1987/5000\n",
      "ecpch:1986,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6848 - val_loss: 193.7760\n",
      "\n",
      "Epoch 01987: val_loss did not improve from 179.48197\n",
      "Epoch 1988/5000\n",
      "ecpch:1987,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6762 - val_loss: 193.7701\n",
      "\n",
      "Epoch 01988: val_loss did not improve from 179.48197\n",
      "Epoch 1989/5000\n",
      "ecpch:1988,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6783 - val_loss: 193.7696\n",
      "\n",
      "Epoch 01989: val_loss did not improve from 179.48197\n",
      "Epoch 1990/5000\n",
      "ecpch:1989,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6728 - val_loss: 193.7874\n",
      "\n",
      "Epoch 01990: val_loss did not improve from 179.48197\n",
      "Epoch 1991/5000\n",
      "ecpch:1990,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6760 - val_loss: 193.7610\n",
      "\n",
      "Epoch 01991: val_loss did not improve from 179.48197\n",
      "Epoch 1992/5000\n",
      "ecpch:1991,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6719 - val_loss: 193.7694\n",
      "\n",
      "Epoch 01992: val_loss did not improve from 179.48197\n",
      "Epoch 1993/5000\n",
      "ecpch:1992,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6699 - val_loss: 193.7928\n",
      "\n",
      "Epoch 01993: val_loss did not improve from 179.48197\n",
      "Epoch 1994/5000\n",
      "ecpch:1993,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6740 - val_loss: 193.7669\n",
      "\n",
      "Epoch 01994: val_loss did not improve from 179.48197\n",
      "Epoch 1995/5000\n",
      "ecpch:1994,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6680 - val_loss: 193.7801\n",
      "\n",
      "Epoch 01995: val_loss did not improve from 179.48197\n",
      "Epoch 1996/5000\n",
      "ecpch:1995,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6676 - val_loss: 193.7860\n",
      "\n",
      "Epoch 01996: val_loss did not improve from 179.48197\n",
      "Epoch 1997/5000\n",
      "ecpch:1996,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.6668 - val_loss: 193.7748\n",
      "\n",
      "Epoch 01997: val_loss did not improve from 179.48197\n",
      "Epoch 1998/5000\n",
      "ecpch:1997,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.6686 - val_loss: 193.7725\n",
      "\n",
      "Epoch 01998: val_loss did not improve from 179.48197\n",
      "Epoch 1999/5000\n",
      "ecpch:1998,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.6611 - val_loss: 193.7928\n",
      "\n",
      "Epoch 01999: val_loss did not improve from 179.48197\n",
      "Epoch 2000/5000\n",
      "ecpch:1999,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6740 - val_loss: 193.7819\n",
      "\n",
      "Epoch 02000: val_loss did not improve from 179.48197\n",
      "Epoch 2001/5000\n",
      "ecpch:2000,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6635 - val_loss: 193.7507\n",
      "\n",
      "Epoch 02001: val_loss did not improve from 179.48197\n",
      "Epoch 2002/5000\n",
      "ecpch:2001,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6770 - val_loss: 193.7660\n",
      "\n",
      "Epoch 02002: val_loss did not improve from 179.48197\n",
      "Epoch 2003/5000\n",
      "ecpch:2002,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6728 - val_loss: 193.7998\n",
      "\n",
      "Epoch 02003: val_loss did not improve from 179.48197\n",
      "Epoch 2004/5000\n",
      "ecpch:2003,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6658 - val_loss: 193.7894\n",
      "\n",
      "Epoch 02004: val_loss did not improve from 179.48197\n",
      "Epoch 2005/5000\n",
      "ecpch:2004,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6721 - val_loss: 193.7661\n",
      "\n",
      "Epoch 02005: val_loss did not improve from 179.48197\n",
      "Epoch 2006/5000\n",
      "ecpch:2005,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6617 - val_loss: 193.7733\n",
      "\n",
      "Epoch 02006: val_loss did not improve from 179.48197\n",
      "Epoch 2007/5000\n",
      "ecpch:2006,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6659 - val_loss: 193.8070\n",
      "\n",
      "Epoch 02007: val_loss did not improve from 179.48197\n",
      "Epoch 2008/5000\n",
      "ecpch:2007,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6699 - val_loss: 193.7918\n",
      "\n",
      "Epoch 02008: val_loss did not improve from 179.48197\n",
      "Epoch 2009/5000\n",
      "ecpch:2008,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6519 - val_loss: 193.7527\n",
      "\n",
      "Epoch 02009: val_loss did not improve from 179.48197\n",
      "Epoch 2010/5000\n",
      "ecpch:2009,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6642 - val_loss: 193.7700\n",
      "\n",
      "Epoch 02010: val_loss did not improve from 179.48197\n",
      "Epoch 2011/5000\n",
      "ecpch:2010,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.6504 - val_loss: 193.8108\n",
      "\n",
      "Epoch 02011: val_loss did not improve from 179.48197\n",
      "Epoch 2012/5000\n",
      "ecpch:2011,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6687 - val_loss: 193.8076\n",
      "\n",
      "Epoch 02012: val_loss did not improve from 179.48197\n",
      "Epoch 2013/5000\n",
      "ecpch:2012,learn rate 0.000007\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6553 - val_loss: 193.7496\n",
      "\n",
      "Epoch 02013: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 02013: ReduceLROnPlateau reducing learning rate to 5.912353844905738e-06.\n",
      "Epoch 2014/5000\n",
      "ecpch:2013,learn rate 0.000006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6678 - val_loss: 193.7450\n",
      "\n",
      "Epoch 02014: val_loss did not improve from 179.48197\n",
      "Epoch 2015/5000\n",
      "ecpch:2014,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6699 - val_loss: 193.7896\n",
      "\n",
      "Epoch 02015: val_loss did not improve from 179.48197\n",
      "Epoch 2016/5000\n",
      "ecpch:2015,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6429 - val_loss: 193.8224\n",
      "\n",
      "Epoch 02016: val_loss did not improve from 179.48197\n",
      "Epoch 2017/5000\n",
      "ecpch:2016,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6670 - val_loss: 193.8091\n",
      "\n",
      "Epoch 02017: val_loss did not improve from 179.48197\n",
      "Epoch 2018/5000\n",
      "ecpch:2017,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6514 - val_loss: 193.7492\n",
      "\n",
      "Epoch 02018: val_loss did not improve from 179.48197\n",
      "Epoch 2019/5000\n",
      "ecpch:2018,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6612 - val_loss: 193.7456\n",
      "\n",
      "Epoch 02019: val_loss did not improve from 179.48197\n",
      "Epoch 2020/5000\n",
      "ecpch:2019,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6687 - val_loss: 193.7851\n",
      "\n",
      "Epoch 02020: val_loss did not improve from 179.48197\n",
      "Epoch 2021/5000\n",
      "ecpch:2020,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6422 - val_loss: 193.8379\n",
      "\n",
      "Epoch 02021: val_loss did not improve from 179.48197\n",
      "Epoch 2022/5000\n",
      "ecpch:2021,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6692 - val_loss: 193.8299\n",
      "\n",
      "Epoch 02022: val_loss did not improve from 179.48197\n",
      "Epoch 2023/5000\n",
      "ecpch:2022,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6662 - val_loss: 193.7725\n",
      "\n",
      "Epoch 02023: val_loss did not improve from 179.48197\n",
      "Epoch 2024/5000\n",
      "ecpch:2023,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6479 - val_loss: 193.7567\n",
      "\n",
      "Epoch 02024: val_loss did not improve from 179.48197\n",
      "Epoch 2025/5000\n",
      "ecpch:2024,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.6622 - val_loss: 193.7760\n",
      "\n",
      "Epoch 02025: val_loss did not improve from 179.48197\n",
      "Epoch 2026/5000\n",
      "ecpch:2025,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6573 - val_loss: 193.8170\n",
      "\n",
      "Epoch 02026: val_loss did not improve from 179.48197\n",
      "Epoch 2027/5000\n",
      "ecpch:2026,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.6401 - val_loss: 193.8165\n",
      "\n",
      "Epoch 02027: val_loss did not improve from 179.48197\n",
      "Epoch 2028/5000\n",
      "ecpch:2027,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.6474 - val_loss: 193.8020\n",
      "\n",
      "Epoch 02028: val_loss did not improve from 179.48197\n",
      "Epoch 2029/5000\n",
      "ecpch:2028,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.6418 - val_loss: 193.7894\n",
      "\n",
      "Epoch 02029: val_loss did not improve from 179.48197\n",
      "Epoch 2030/5000\n",
      "ecpch:2029,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.6369 - val_loss: 193.8019\n",
      "\n",
      "Epoch 02030: val_loss did not improve from 179.48197\n",
      "Epoch 2031/5000\n",
      "ecpch:2030,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6397 - val_loss: 193.8094\n",
      "\n",
      "Epoch 02031: val_loss did not improve from 179.48197\n",
      "Epoch 2032/5000\n",
      "ecpch:2031,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.6291 - val_loss: 193.7995\n",
      "\n",
      "Epoch 02032: val_loss did not improve from 179.48197\n",
      "Epoch 2033/5000\n",
      "ecpch:2032,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.6372 - val_loss: 193.7978\n",
      "\n",
      "Epoch 02033: val_loss did not improve from 179.48197\n",
      "Epoch 2034/5000\n",
      "ecpch:2033,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6268 - val_loss: 193.8211\n",
      "\n",
      "Epoch 02034: val_loss did not improve from 179.48197\n",
      "Epoch 2035/5000\n",
      "ecpch:2034,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.6387 - val_loss: 193.8126\n",
      "\n",
      "Epoch 02035: val_loss did not improve from 179.48197\n",
      "Epoch 2036/5000\n",
      "ecpch:2035,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.6304 - val_loss: 193.7893\n",
      "\n",
      "Epoch 02036: val_loss did not improve from 179.48197\n",
      "Epoch 2037/5000\n",
      "ecpch:2036,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.6382 - val_loss: 193.7993\n",
      "\n",
      "Epoch 02037: val_loss did not improve from 179.48197\n",
      "Epoch 2038/5000\n",
      "ecpch:2037,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6355 - val_loss: 193.8361\n",
      "\n",
      "Epoch 02038: val_loss did not improve from 179.48197\n",
      "Epoch 2039/5000\n",
      "ecpch:2038,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6306 - val_loss: 193.8219\n",
      "\n",
      "Epoch 02039: val_loss did not improve from 179.48197\n",
      "Epoch 2040/5000\n",
      "ecpch:2039,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6357 - val_loss: 193.7965\n",
      "\n",
      "Epoch 02040: val_loss did not improve from 179.48197\n",
      "Epoch 2041/5000\n",
      "ecpch:2040,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.6303 - val_loss: 193.7958\n",
      "\n",
      "Epoch 02041: val_loss did not improve from 179.48197\n",
      "Epoch 2042/5000\n",
      "ecpch:2041,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.6275 - val_loss: 193.8292\n",
      "\n",
      "Epoch 02042: val_loss did not improve from 179.48197\n",
      "Epoch 2043/5000\n",
      "ecpch:2042,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.6296 - val_loss: 193.8290\n",
      "\n",
      "Epoch 02043: val_loss did not improve from 179.48197\n",
      "Epoch 2044/5000\n",
      "ecpch:2043,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6211 - val_loss: 193.7814\n",
      "\n",
      "Epoch 02044: val_loss did not improve from 179.48197\n",
      "Epoch 2045/5000\n",
      "ecpch:2044,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6273 - val_loss: 193.7911\n",
      "\n",
      "Epoch 02045: val_loss did not improve from 179.48197\n",
      "Epoch 2046/5000\n",
      "ecpch:2045,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6226 - val_loss: 193.8354\n",
      "\n",
      "Epoch 02046: val_loss did not improve from 179.48197\n",
      "Epoch 2047/5000\n",
      "ecpch:2046,learn rate 0.000006\n",
      "64/64 [==============================] - 0s 8ms/step - loss: 55.6235 - val_loss: 193.8248\n",
      "\n",
      "Epoch 02047: val_loss did not improve from 179.48197\n",
      "Epoch 2048/5000\n",
      "ecpch:2047,learn rate 0.000006\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 55.6189 - val_loss: 193.7859\n",
      "\n",
      "Epoch 02048: val_loss did not improve from 179.48197\n",
      "Epoch 2049/5000\n",
      "ecpch:2048,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6241 - val_loss: 193.7878\n",
      "\n",
      "Epoch 02049: val_loss did not improve from 179.48197\n",
      "Epoch 2050/5000\n",
      "ecpch:2049,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6222 - val_loss: 193.8246\n",
      "\n",
      "Epoch 02050: val_loss did not improve from 179.48197\n",
      "Epoch 2051/5000\n",
      "ecpch:2050,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6142 - val_loss: 193.8365\n",
      "\n",
      "Epoch 02051: val_loss did not improve from 179.48197\n",
      "Epoch 2052/5000\n",
      "ecpch:2051,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.6186 - val_loss: 193.7884\n",
      "\n",
      "Epoch 02052: val_loss did not improve from 179.48197\n",
      "Epoch 2053/5000\n",
      "ecpch:2052,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6137 - val_loss: 193.7952\n",
      "\n",
      "Epoch 02053: val_loss did not improve from 179.48197\n",
      "Epoch 2054/5000\n",
      "ecpch:2053,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6196 - val_loss: 193.8199\n",
      "\n",
      "Epoch 02054: val_loss did not improve from 179.48197\n",
      "Epoch 2055/5000\n",
      "ecpch:2054,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6076 - val_loss: 193.8398\n",
      "\n",
      "Epoch 02055: val_loss did not improve from 179.48197\n",
      "Epoch 2056/5000\n",
      "ecpch:2055,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6162 - val_loss: 193.8135\n",
      "\n",
      "Epoch 02056: val_loss did not improve from 179.48197\n",
      "Epoch 2057/5000\n",
      "ecpch:2056,learn rate 0.000006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 10ms/step - loss: 55.6089 - val_loss: 193.8031\n",
      "\n",
      "Epoch 02057: val_loss did not improve from 179.48197\n",
      "Epoch 2058/5000\n",
      "ecpch:2057,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.6133 - val_loss: 193.8170\n",
      "\n",
      "Epoch 02058: val_loss did not improve from 179.48197\n",
      "Epoch 2059/5000\n",
      "ecpch:2058,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.6055 - val_loss: 193.8413\n",
      "\n",
      "Epoch 02059: val_loss did not improve from 179.48197\n",
      "Epoch 2060/5000\n",
      "ecpch:2059,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6119 - val_loss: 193.8252\n",
      "\n",
      "Epoch 02060: val_loss did not improve from 179.48197\n",
      "Epoch 2061/5000\n",
      "ecpch:2060,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6057 - val_loss: 193.8121\n",
      "\n",
      "Epoch 02061: val_loss did not improve from 179.48197\n",
      "Epoch 2062/5000\n",
      "ecpch:2061,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.6079 - val_loss: 193.8242\n",
      "\n",
      "Epoch 02062: val_loss did not improve from 179.48197\n",
      "Epoch 2063/5000\n",
      "ecpch:2062,learn rate 0.000006\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6044 - val_loss: 193.8337\n",
      "\n",
      "Epoch 02063: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 02063: ReduceLROnPlateau reducing learning rate to 5.32111862412421e-06.\n",
      "Epoch 2064/5000\n",
      "ecpch:2063,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.6022 - val_loss: 193.8336\n",
      "\n",
      "Epoch 02064: val_loss did not improve from 179.48197\n",
      "Epoch 2065/5000\n",
      "ecpch:2064,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.6004 - val_loss: 193.8295\n",
      "\n",
      "Epoch 02065: val_loss did not improve from 179.48197\n",
      "Epoch 2066/5000\n",
      "ecpch:2065,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5995 - val_loss: 193.8271\n",
      "\n",
      "Epoch 02066: val_loss did not improve from 179.48197\n",
      "Epoch 2067/5000\n",
      "ecpch:2066,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.6000 - val_loss: 193.8373\n",
      "\n",
      "Epoch 02067: val_loss did not improve from 179.48197\n",
      "Epoch 2068/5000\n",
      "ecpch:2067,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5944 - val_loss: 193.8426\n",
      "\n",
      "Epoch 02068: val_loss did not improve from 179.48197\n",
      "Epoch 2069/5000\n",
      "ecpch:2068,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5975 - val_loss: 193.8230\n",
      "\n",
      "Epoch 02069: val_loss did not improve from 179.48197\n",
      "Epoch 2070/5000\n",
      "ecpch:2069,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5933 - val_loss: 193.8304\n",
      "\n",
      "Epoch 02070: val_loss did not improve from 179.48197\n",
      "Epoch 2071/5000\n",
      "ecpch:2070,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5942 - val_loss: 193.8434\n",
      "\n",
      "Epoch 02071: val_loss did not improve from 179.48197\n",
      "Epoch 2072/5000\n",
      "ecpch:2071,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5918 - val_loss: 193.8311\n",
      "\n",
      "Epoch 02072: val_loss did not improve from 179.48197\n",
      "Epoch 2073/5000\n",
      "ecpch:2072,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5912 - val_loss: 193.8295\n",
      "\n",
      "Epoch 02073: val_loss did not improve from 179.48197\n",
      "Epoch 2074/5000\n",
      "ecpch:2073,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5899 - val_loss: 193.8362\n",
      "\n",
      "Epoch 02074: val_loss did not improve from 179.48197\n",
      "Epoch 2075/5000\n",
      "ecpch:2074,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5875 - val_loss: 193.8389\n",
      "\n",
      "Epoch 02075: val_loss did not improve from 179.48197\n",
      "Epoch 2076/5000\n",
      "ecpch:2075,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5888 - val_loss: 193.8389\n",
      "\n",
      "Epoch 02076: val_loss did not improve from 179.48197\n",
      "Epoch 2077/5000\n",
      "ecpch:2076,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5848 - val_loss: 193.8362\n",
      "\n",
      "Epoch 02077: val_loss did not improve from 179.48197\n",
      "Epoch 2078/5000\n",
      "ecpch:2077,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5869 - val_loss: 193.8430\n",
      "\n",
      "Epoch 02078: val_loss did not improve from 179.48197\n",
      "Epoch 2079/5000\n",
      "ecpch:2078,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5851 - val_loss: 193.8228\n",
      "\n",
      "Epoch 02079: val_loss did not improve from 179.48197\n",
      "Epoch 2080/5000\n",
      "ecpch:2079,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5857 - val_loss: 193.8458\n",
      "\n",
      "Epoch 02080: val_loss did not improve from 179.48197\n",
      "Epoch 2081/5000\n",
      "ecpch:2080,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5851 - val_loss: 193.8423\n",
      "\n",
      "Epoch 02081: val_loss did not improve from 179.48197\n",
      "Epoch 2082/5000\n",
      "ecpch:2081,learn rate 0.000005\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 55.5811 - val_loss: 193.8351\n",
      "\n",
      "Epoch 02082: val_loss did not improve from 179.48197\n",
      "Epoch 2083/5000\n",
      "ecpch:2082,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5837 - val_loss: 193.8460\n",
      "\n",
      "Epoch 02083: val_loss did not improve from 179.48197\n",
      "Epoch 2084/5000\n",
      "ecpch:2083,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5810 - val_loss: 193.8421\n",
      "\n",
      "Epoch 02084: val_loss did not improve from 179.48197\n",
      "Epoch 2085/5000\n",
      "ecpch:2084,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5781 - val_loss: 193.8388\n",
      "\n",
      "Epoch 02085: val_loss did not improve from 179.48197\n",
      "Epoch 2086/5000\n",
      "ecpch:2085,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5815 - val_loss: 193.8542\n",
      "\n",
      "Epoch 02086: val_loss did not improve from 179.48197\n",
      "Epoch 2087/5000\n",
      "ecpch:2086,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5782 - val_loss: 193.8409\n",
      "\n",
      "Epoch 02087: val_loss did not improve from 179.48197\n",
      "Epoch 2088/5000\n",
      "ecpch:2087,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5761 - val_loss: 193.8510\n",
      "\n",
      "Epoch 02088: val_loss did not improve from 179.48197\n",
      "Epoch 2089/5000\n",
      "ecpch:2088,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5763 - val_loss: 193.8383\n",
      "\n",
      "Epoch 02089: val_loss did not improve from 179.48197\n",
      "Epoch 2090/5000\n",
      "ecpch:2089,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5755 - val_loss: 193.8455\n",
      "\n",
      "Epoch 02090: val_loss did not improve from 179.48197\n",
      "Epoch 2091/5000\n",
      "ecpch:2090,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5734 - val_loss: 193.8467\n",
      "\n",
      "Epoch 02091: val_loss did not improve from 179.48197\n",
      "Epoch 2092/5000\n",
      "ecpch:2091,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5751 - val_loss: 193.8555\n",
      "\n",
      "Epoch 02092: val_loss did not improve from 179.48197\n",
      "Epoch 2093/5000\n",
      "ecpch:2092,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5729 - val_loss: 193.8404\n",
      "\n",
      "Epoch 02093: val_loss did not improve from 179.48197\n",
      "Epoch 2094/5000\n",
      "ecpch:2093,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5734 - val_loss: 193.8540\n",
      "\n",
      "Epoch 02094: val_loss did not improve from 179.48197\n",
      "Epoch 2095/5000\n",
      "ecpch:2094,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5696 - val_loss: 193.8436\n",
      "\n",
      "Epoch 02095: val_loss did not improve from 179.48197\n",
      "Epoch 2096/5000\n",
      "ecpch:2095,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5680 - val_loss: 193.8509\n",
      "\n",
      "Epoch 02096: val_loss did not improve from 179.48197\n",
      "Epoch 2097/5000\n",
      "ecpch:2096,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5680 - val_loss: 193.8399\n",
      "\n",
      "Epoch 02097: val_loss did not improve from 179.48197\n",
      "Epoch 2098/5000\n",
      "ecpch:2097,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5726 - val_loss: 193.8537\n",
      "\n",
      "Epoch 02098: val_loss did not improve from 179.48197\n",
      "Epoch 2099/5000\n",
      "ecpch:2098,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5657 - val_loss: 193.8567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 02099: val_loss did not improve from 179.48197\n",
      "Epoch 2100/5000\n",
      "ecpch:2099,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5679 - val_loss: 193.8326\n",
      "\n",
      "Epoch 02100: val_loss did not improve from 179.48197\n",
      "Epoch 2101/5000\n",
      "ecpch:2100,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5728 - val_loss: 193.8380\n",
      "\n",
      "Epoch 02101: val_loss did not improve from 179.48197\n",
      "Epoch 2102/5000\n",
      "ecpch:2101,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5663 - val_loss: 193.8773\n",
      "\n",
      "Epoch 02102: val_loss did not improve from 179.48197\n",
      "Epoch 2103/5000\n",
      "ecpch:2102,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5767 - val_loss: 193.8646\n",
      "\n",
      "Epoch 02103: val_loss did not improve from 179.48197\n",
      "Epoch 2104/5000\n",
      "ecpch:2103,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5652 - val_loss: 193.8187\n",
      "\n",
      "Epoch 02104: val_loss did not improve from 179.48197\n",
      "Epoch 2105/5000\n",
      "ecpch:2104,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5831 - val_loss: 193.8173\n",
      "\n",
      "Epoch 02105: val_loss did not improve from 179.48197\n",
      "Epoch 2106/5000\n",
      "ecpch:2105,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5810 - val_loss: 193.8668\n",
      "\n",
      "Epoch 02106: val_loss did not improve from 179.48197\n",
      "Epoch 2107/5000\n",
      "ecpch:2106,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5621 - val_loss: 193.8699\n",
      "\n",
      "Epoch 02107: val_loss did not improve from 179.48197\n",
      "Epoch 2108/5000\n",
      "ecpch:2107,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5663 - val_loss: 193.8350\n",
      "\n",
      "Epoch 02108: val_loss did not improve from 179.48197\n",
      "Epoch 2109/5000\n",
      "ecpch:2108,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5646 - val_loss: 193.8438\n",
      "\n",
      "Epoch 02109: val_loss did not improve from 179.48197\n",
      "Epoch 2110/5000\n",
      "ecpch:2109,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5631 - val_loss: 193.8744\n",
      "\n",
      "Epoch 02110: val_loss did not improve from 179.48197\n",
      "Epoch 2111/5000\n",
      "ecpch:2110,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5620 - val_loss: 193.8643\n",
      "\n",
      "Epoch 02111: val_loss did not improve from 179.48197\n",
      "Epoch 2112/5000\n",
      "ecpch:2111,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5587 - val_loss: 193.8396\n",
      "\n",
      "Epoch 02112: val_loss did not improve from 179.48197\n",
      "Epoch 2113/5000\n",
      "ecpch:2112,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 55.5624 - val_loss: 193.8462\n",
      "\n",
      "Epoch 02113: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 02113: ReduceLROnPlateau reducing learning rate to 4.7890069254208354e-06.\n",
      "Epoch 2114/5000\n",
      "ecpch:2113,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5577 - val_loss: 193.8782\n",
      "\n",
      "Epoch 02114: val_loss did not improve from 179.48197\n",
      "Epoch 2115/5000\n",
      "ecpch:2114,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5598 - val_loss: 193.8704\n",
      "\n",
      "Epoch 02115: val_loss did not improve from 179.48197\n",
      "Epoch 2116/5000\n",
      "ecpch:2115,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5563 - val_loss: 193.8528\n",
      "\n",
      "Epoch 02116: val_loss did not improve from 179.48197\n",
      "Epoch 2117/5000\n",
      "ecpch:2116,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5546 - val_loss: 193.8613\n",
      "\n",
      "Epoch 02117: val_loss did not improve from 179.48197\n",
      "Epoch 2118/5000\n",
      "ecpch:2117,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5511 - val_loss: 193.8761\n",
      "\n",
      "Epoch 02118: val_loss did not improve from 179.48197\n",
      "Epoch 2119/5000\n",
      "ecpch:2118,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5550 - val_loss: 193.8637\n",
      "\n",
      "Epoch 02119: val_loss did not improve from 179.48197\n",
      "Epoch 2120/5000\n",
      "ecpch:2119,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5504 - val_loss: 193.8657\n",
      "\n",
      "Epoch 02120: val_loss did not improve from 179.48197\n",
      "Epoch 2121/5000\n",
      "ecpch:2120,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5557 - val_loss: 193.8622\n",
      "\n",
      "Epoch 02121: val_loss did not improve from 179.48197\n",
      "Epoch 2122/5000\n",
      "ecpch:2121,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5506 - val_loss: 193.8601\n",
      "\n",
      "Epoch 02122: val_loss did not improve from 179.48197\n",
      "Epoch 2123/5000\n",
      "ecpch:2122,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5576 - val_loss: 193.8623\n",
      "\n",
      "Epoch 02123: val_loss did not improve from 179.48197\n",
      "Epoch 2124/5000\n",
      "ecpch:2123,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5547 - val_loss: 193.8722\n",
      "\n",
      "Epoch 02124: val_loss did not improve from 179.48197\n",
      "Epoch 2125/5000\n",
      "ecpch:2124,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5494 - val_loss: 193.8612\n",
      "\n",
      "Epoch 02125: val_loss did not improve from 179.48197\n",
      "Epoch 2126/5000\n",
      "ecpch:2125,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 55.5498 - val_loss: 193.8674\n",
      "\n",
      "Epoch 02126: val_loss did not improve from 179.48197\n",
      "Epoch 2127/5000\n",
      "ecpch:2126,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5457 - val_loss: 193.8822\n",
      "\n",
      "Epoch 02127: val_loss did not improve from 179.48197\n",
      "Epoch 2128/5000\n",
      "ecpch:2127,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5491 - val_loss: 193.8660\n",
      "\n",
      "Epoch 02128: val_loss did not improve from 179.48197\n",
      "Epoch 2129/5000\n",
      "ecpch:2128,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5426 - val_loss: 193.8602\n",
      "\n",
      "Epoch 02129: val_loss did not improve from 179.48197\n",
      "Epoch 2130/5000\n",
      "ecpch:2129,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5421 - val_loss: 193.8785\n",
      "\n",
      "Epoch 02130: val_loss did not improve from 179.48197\n",
      "Epoch 2131/5000\n",
      "ecpch:2130,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5438 - val_loss: 193.8616\n",
      "\n",
      "Epoch 02131: val_loss did not improve from 179.48197\n",
      "Epoch 2132/5000\n",
      "ecpch:2131,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5389 - val_loss: 193.8713\n",
      "\n",
      "Epoch 02132: val_loss did not improve from 179.48197\n",
      "Epoch 2133/5000\n",
      "ecpch:2132,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5402 - val_loss: 193.8776\n",
      "\n",
      "Epoch 02133: val_loss did not improve from 179.48197\n",
      "Epoch 2134/5000\n",
      "ecpch:2133,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5394 - val_loss: 193.8667\n",
      "\n",
      "Epoch 02134: val_loss did not improve from 179.48197\n",
      "Epoch 2135/5000\n",
      "ecpch:2134,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5392 - val_loss: 193.8829\n",
      "\n",
      "Epoch 02135: val_loss did not improve from 179.48197\n",
      "Epoch 2136/5000\n",
      "ecpch:2135,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5400 - val_loss: 193.8708\n",
      "\n",
      "Epoch 02136: val_loss did not improve from 179.48197\n",
      "Epoch 2137/5000\n",
      "ecpch:2136,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5348 - val_loss: 193.8798\n",
      "\n",
      "Epoch 02137: val_loss did not improve from 179.48197\n",
      "Epoch 2138/5000\n",
      "ecpch:2137,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5352 - val_loss: 193.8708\n",
      "\n",
      "Epoch 02138: val_loss did not improve from 179.48197\n",
      "Epoch 2139/5000\n",
      "ecpch:2138,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5357 - val_loss: 193.8755\n",
      "\n",
      "Epoch 02139: val_loss did not improve from 179.48197\n",
      "Epoch 2140/5000\n",
      "ecpch:2139,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5325 - val_loss: 193.8879\n",
      "\n",
      "Epoch 02140: val_loss did not improve from 179.48197\n",
      "Epoch 2141/5000\n",
      "ecpch:2140,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5331 - val_loss: 193.8623\n",
      "\n",
      "Epoch 02141: val_loss did not improve from 179.48197\n",
      "Epoch 2142/5000\n",
      "ecpch:2141,learn rate 0.000005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5366 - val_loss: 193.8798\n",
      "\n",
      "Epoch 02142: val_loss did not improve from 179.48197\n",
      "Epoch 2143/5000\n",
      "ecpch:2142,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5305 - val_loss: 193.8917\n",
      "\n",
      "Epoch 02143: val_loss did not improve from 179.48197\n",
      "Epoch 2144/5000\n",
      "ecpch:2143,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 55.5387 - val_loss: 193.8765\n",
      "\n",
      "Epoch 02144: val_loss did not improve from 179.48197\n",
      "Epoch 2145/5000\n",
      "ecpch:2144,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5310 - val_loss: 193.8763\n",
      "\n",
      "Epoch 02145: val_loss did not improve from 179.48197\n",
      "Epoch 2146/5000\n",
      "ecpch:2145,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5352 - val_loss: 193.8811\n",
      "\n",
      "Epoch 02146: val_loss did not improve from 179.48197\n",
      "Epoch 2147/5000\n",
      "ecpch:2146,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5303 - val_loss: 193.8760\n",
      "\n",
      "Epoch 02147: val_loss did not improve from 179.48197\n",
      "Epoch 2148/5000\n",
      "ecpch:2147,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5377 - val_loss: 193.8825\n",
      "\n",
      "Epoch 02148: val_loss did not improve from 179.48197\n",
      "Epoch 2149/5000\n",
      "ecpch:2148,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5317 - val_loss: 193.8867\n",
      "\n",
      "Epoch 02149: val_loss did not improve from 179.48197\n",
      "Epoch 2150/5000\n",
      "ecpch:2149,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5358 - val_loss: 193.8791\n",
      "\n",
      "Epoch 02150: val_loss did not improve from 179.48197\n",
      "Epoch 2151/5000\n",
      "ecpch:2150,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5335 - val_loss: 193.8658\n",
      "\n",
      "Epoch 02151: val_loss did not improve from 179.48197\n",
      "Epoch 2152/5000\n",
      "ecpch:2151,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5306 - val_loss: 193.8932\n",
      "\n",
      "Epoch 02152: val_loss did not improve from 179.48197\n",
      "Epoch 2153/5000\n",
      "ecpch:2152,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5316 - val_loss: 193.8887\n",
      "\n",
      "Epoch 02153: val_loss did not improve from 179.48197\n",
      "Epoch 2154/5000\n",
      "ecpch:2153,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5243 - val_loss: 193.8635\n",
      "\n",
      "Epoch 02154: val_loss did not improve from 179.48197\n",
      "Epoch 2155/5000\n",
      "ecpch:2154,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5301 - val_loss: 193.8768\n",
      "\n",
      "Epoch 02155: val_loss did not improve from 179.48197\n",
      "Epoch 2156/5000\n",
      "ecpch:2155,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5230 - val_loss: 193.9069\n",
      "\n",
      "Epoch 02156: val_loss did not improve from 179.48197\n",
      "Epoch 2157/5000\n",
      "ecpch:2156,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5357 - val_loss: 193.8973\n",
      "\n",
      "Epoch 02157: val_loss did not improve from 179.48197\n",
      "Epoch 2158/5000\n",
      "ecpch:2157,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5269 - val_loss: 193.8469\n",
      "\n",
      "Epoch 02158: val_loss did not improve from 179.48197\n",
      "Epoch 2159/5000\n",
      "ecpch:2158,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5343 - val_loss: 193.8452\n",
      "\n",
      "Epoch 02159: val_loss did not improve from 179.48197\n",
      "Epoch 2160/5000\n",
      "ecpch:2159,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5362 - val_loss: 193.8859\n",
      "\n",
      "Epoch 02160: val_loss did not improve from 179.48197\n",
      "Epoch 2161/5000\n",
      "ecpch:2160,learn rate 0.000005\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 55.5185 - val_loss: 193.9087\n",
      "\n",
      "Epoch 02161: val_loss did not improve from 179.48197\n",
      "Epoch 2162/5000\n",
      "ecpch:2161,learn rate 0.000005\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 55.5309 - val_loss: 193.8814\n",
      "\n",
      "Epoch 02162: val_loss did not improve from 179.48197\n",
      "Epoch 2163/5000\n",
      "ecpch:2162,learn rate 0.000005\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 55.5167 - val_loss: 193.8572\n",
      "\n",
      "Epoch 02163: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 02163: ReduceLROnPlateau reducing learning rate to 4.310106396587799e-06.\n",
      "Epoch 2164/5000\n",
      "ecpch:2163,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5276 - val_loss: 193.8673\n",
      "\n",
      "Epoch 02164: val_loss did not improve from 179.48197\n",
      "Epoch 2165/5000\n",
      "ecpch:2164,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5208 - val_loss: 193.9063\n",
      "\n",
      "Epoch 02165: val_loss did not improve from 179.48197\n",
      "Epoch 2166/5000\n",
      "ecpch:2165,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5198 - val_loss: 193.9022\n",
      "\n",
      "Epoch 02166: val_loss did not improve from 179.48197\n",
      "Epoch 2167/5000\n",
      "ecpch:2166,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5179 - val_loss: 193.8729\n",
      "\n",
      "Epoch 02167: val_loss did not improve from 179.48197\n",
      "Epoch 2168/5000\n",
      "ecpch:2167,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5182 - val_loss: 193.8722\n",
      "\n",
      "Epoch 02168: val_loss did not improve from 179.48197\n",
      "Epoch 2169/5000\n",
      "ecpch:2168,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5183 - val_loss: 193.9020\n",
      "\n",
      "Epoch 02169: val_loss did not improve from 179.48197\n",
      "Epoch 2170/5000\n",
      "ecpch:2169,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5122 - val_loss: 193.9081\n",
      "\n",
      "Epoch 02170: val_loss did not improve from 179.48197\n",
      "Epoch 2171/5000\n",
      "ecpch:2170,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5151 - val_loss: 193.8859\n",
      "\n",
      "Epoch 02171: val_loss did not improve from 179.48197\n",
      "Epoch 2172/5000\n",
      "ecpch:2171,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5117 - val_loss: 193.8857\n",
      "\n",
      "Epoch 02172: val_loss did not improve from 179.48197\n",
      "Epoch 2173/5000\n",
      "ecpch:2172,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5127 - val_loss: 193.8964\n",
      "\n",
      "Epoch 02173: val_loss did not improve from 179.48197\n",
      "Epoch 2174/5000\n",
      "ecpch:2173,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5081 - val_loss: 193.9062\n",
      "\n",
      "Epoch 02174: val_loss did not improve from 179.48197\n",
      "Epoch 2175/5000\n",
      "ecpch:2174,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5114 - val_loss: 193.8891\n",
      "\n",
      "Epoch 02175: val_loss did not improve from 179.48197\n",
      "Epoch 2176/5000\n",
      "ecpch:2175,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5068 - val_loss: 193.8957\n",
      "\n",
      "Epoch 02176: val_loss did not improve from 179.48197\n",
      "Epoch 2177/5000\n",
      "ecpch:2176,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5102 - val_loss: 193.9000\n",
      "\n",
      "Epoch 02177: val_loss did not improve from 179.48197\n",
      "Epoch 2178/5000\n",
      "ecpch:2177,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5041 - val_loss: 193.8965\n",
      "\n",
      "Epoch 02178: val_loss did not improve from 179.48197\n",
      "Epoch 2179/5000\n",
      "ecpch:2178,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5077 - val_loss: 193.9001\n",
      "\n",
      "Epoch 02179: val_loss did not improve from 179.48197\n",
      "Epoch 2180/5000\n",
      "ecpch:2179,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5022 - val_loss: 193.9024\n",
      "\n",
      "Epoch 02180: val_loss did not improve from 179.48197\n",
      "Epoch 2181/5000\n",
      "ecpch:2180,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5061 - val_loss: 193.8971\n",
      "\n",
      "Epoch 02181: val_loss did not improve from 179.48197\n",
      "Epoch 2182/5000\n",
      "ecpch:2181,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5029 - val_loss: 193.9014\n",
      "\n",
      "Epoch 02182: val_loss did not improve from 179.48197\n",
      "Epoch 2183/5000\n",
      "ecpch:2182,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5005 - val_loss: 193.8981\n",
      "\n",
      "Epoch 02183: val_loss did not improve from 179.48197\n",
      "Epoch 2184/5000\n",
      "ecpch:2183,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5013 - val_loss: 193.8996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 02184: val_loss did not improve from 179.48197\n",
      "Epoch 2185/5000\n",
      "ecpch:2184,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.5000 - val_loss: 193.9076\n",
      "\n",
      "Epoch 02185: val_loss did not improve from 179.48197\n",
      "Epoch 2186/5000\n",
      "ecpch:2185,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4998 - val_loss: 193.9056\n",
      "\n",
      "Epoch 02186: val_loss did not improve from 179.48197\n",
      "Epoch 2187/5000\n",
      "ecpch:2186,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4991 - val_loss: 193.8989\n",
      "\n",
      "Epoch 02187: val_loss did not improve from 179.48197\n",
      "Epoch 2188/5000\n",
      "ecpch:2187,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4966 - val_loss: 193.9172\n",
      "\n",
      "Epoch 02188: val_loss did not improve from 179.48197\n",
      "Epoch 2189/5000\n",
      "ecpch:2188,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.5025 - val_loss: 193.9050\n",
      "\n",
      "Epoch 02189: val_loss did not improve from 179.48197\n",
      "Epoch 2190/5000\n",
      "ecpch:2189,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4950 - val_loss: 193.8994\n",
      "\n",
      "Epoch 02190: val_loss did not improve from 179.48197\n",
      "Epoch 2191/5000\n",
      "ecpch:2190,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 55.4981 - val_loss: 193.9111\n",
      "\n",
      "Epoch 02191: val_loss did not improve from 179.48197\n",
      "Epoch 2192/5000\n",
      "ecpch:2191,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4940 - val_loss: 193.9037\n",
      "\n",
      "Epoch 02192: val_loss did not improve from 179.48197\n",
      "Epoch 2193/5000\n",
      "ecpch:2192,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4938 - val_loss: 193.9072\n",
      "\n",
      "Epoch 02193: val_loss did not improve from 179.48197\n",
      "Epoch 2194/5000\n",
      "ecpch:2193,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4957 - val_loss: 193.9112\n",
      "\n",
      "Epoch 02194: val_loss did not improve from 179.48197\n",
      "Epoch 2195/5000\n",
      "ecpch:2194,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4910 - val_loss: 193.9119\n",
      "\n",
      "Epoch 02195: val_loss did not improve from 179.48197\n",
      "Epoch 2196/5000\n",
      "ecpch:2195,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4932 - val_loss: 193.8985\n",
      "\n",
      "Epoch 02196: val_loss did not improve from 179.48197\n",
      "Epoch 2197/5000\n",
      "ecpch:2196,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4940 - val_loss: 193.9065\n",
      "\n",
      "Epoch 02197: val_loss did not improve from 179.48197\n",
      "Epoch 2198/5000\n",
      "ecpch:2197,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4892 - val_loss: 193.9167\n",
      "\n",
      "Epoch 02198: val_loss did not improve from 179.48197\n",
      "Epoch 2199/5000\n",
      "ecpch:2198,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4928 - val_loss: 193.9035\n",
      "\n",
      "Epoch 02199: val_loss did not improve from 179.48197\n",
      "Epoch 2200/5000\n",
      "ecpch:2199,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4887 - val_loss: 193.9132\n",
      "\n",
      "Epoch 02200: val_loss did not improve from 179.48197\n",
      "Epoch 2201/5000\n",
      "ecpch:2200,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4921 - val_loss: 193.9041\n",
      "\n",
      "Epoch 02201: val_loss did not improve from 179.48197\n",
      "Epoch 2202/5000\n",
      "ecpch:2201,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4871 - val_loss: 193.9106\n",
      "\n",
      "Epoch 02202: val_loss did not improve from 179.48197\n",
      "Epoch 2203/5000\n",
      "ecpch:2202,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4857 - val_loss: 193.9172\n",
      "\n",
      "Epoch 02203: val_loss did not improve from 179.48197\n",
      "Epoch 2204/5000\n",
      "ecpch:2203,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4862 - val_loss: 193.9040\n",
      "\n",
      "Epoch 02204: val_loss did not improve from 179.48197\n",
      "Epoch 2205/5000\n",
      "ecpch:2204,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4864 - val_loss: 193.9152\n",
      "\n",
      "Epoch 02205: val_loss did not improve from 179.48197\n",
      "Epoch 2206/5000\n",
      "ecpch:2205,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4856 - val_loss: 193.9078\n",
      "\n",
      "Epoch 02206: val_loss did not improve from 179.48197\n",
      "Epoch 2207/5000\n",
      "ecpch:2206,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4841 - val_loss: 193.9175\n",
      "\n",
      "Epoch 02207: val_loss did not improve from 179.48197\n",
      "Epoch 2208/5000\n",
      "ecpch:2207,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4822 - val_loss: 193.9139\n",
      "\n",
      "Epoch 02208: val_loss did not improve from 179.48197\n",
      "Epoch 2209/5000\n",
      "ecpch:2208,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4822 - val_loss: 193.9129\n",
      "\n",
      "Epoch 02209: val_loss did not improve from 179.48197\n",
      "Epoch 2210/5000\n",
      "ecpch:2209,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4817 - val_loss: 193.9190\n",
      "\n",
      "Epoch 02210: val_loss did not improve from 179.48197\n",
      "Epoch 2211/5000\n",
      "ecpch:2210,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4826 - val_loss: 193.9054\n",
      "\n",
      "Epoch 02211: val_loss did not improve from 179.48197\n",
      "Epoch 2212/5000\n",
      "ecpch:2211,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4805 - val_loss: 193.9137\n",
      "\n",
      "Epoch 02212: val_loss did not improve from 179.48197\n",
      "Epoch 2213/5000\n",
      "ecpch:2212,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4793 - val_loss: 193.9090\n",
      "\n",
      "Epoch 02213: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 02213: ReduceLROnPlateau reducing learning rate to 3.879095675074495e-06.\n",
      "Epoch 2214/5000\n",
      "ecpch:2213,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 55.4798 - val_loss: 193.9178\n",
      "\n",
      "Epoch 02214: val_loss did not improve from 179.48197\n",
      "Epoch 2215/5000\n",
      "ecpch:2214,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 55.4779 - val_loss: 193.9149\n",
      "\n",
      "Epoch 02215: val_loss did not improve from 179.48197\n",
      "Epoch 2216/5000\n",
      "ecpch:2215,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4782 - val_loss: 193.9237\n",
      "\n",
      "Epoch 02216: val_loss did not improve from 179.48197\n",
      "Epoch 2217/5000\n",
      "ecpch:2216,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4765 - val_loss: 193.9121\n",
      "\n",
      "Epoch 02217: val_loss did not improve from 179.48197\n",
      "Epoch 2218/5000\n",
      "ecpch:2217,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4758 - val_loss: 193.9239\n",
      "\n",
      "Epoch 02218: val_loss did not improve from 179.48197\n",
      "Epoch 2219/5000\n",
      "ecpch:2218,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4742 - val_loss: 193.9111\n",
      "\n",
      "Epoch 02219: val_loss did not improve from 179.48197\n",
      "Epoch 2220/5000\n",
      "ecpch:2219,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4745 - val_loss: 193.9270\n",
      "\n",
      "Epoch 02220: val_loss did not improve from 179.48197\n",
      "Epoch 2221/5000\n",
      "ecpch:2220,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4740 - val_loss: 193.9164\n",
      "\n",
      "Epoch 02221: val_loss did not improve from 179.48197\n",
      "Epoch 2222/5000\n",
      "ecpch:2221,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 55.4738 - val_loss: 193.9258\n",
      "\n",
      "Epoch 02222: val_loss did not improve from 179.48197\n",
      "Epoch 2223/5000\n",
      "ecpch:2222,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4720 - val_loss: 193.9250\n",
      "\n",
      "Epoch 02223: val_loss did not improve from 179.48197\n",
      "Epoch 2224/5000\n",
      "ecpch:2223,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4706 - val_loss: 193.9242\n",
      "\n",
      "Epoch 02224: val_loss did not improve from 179.48197\n",
      "Epoch 2225/5000\n",
      "ecpch:2224,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4699 - val_loss: 193.9190\n",
      "\n",
      "Epoch 02225: val_loss did not improve from 179.48197\n",
      "Epoch 2226/5000\n",
      "ecpch:2225,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4694 - val_loss: 193.9273\n",
      "\n",
      "Epoch 02226: val_loss did not improve from 179.48197\n",
      "Epoch 2227/5000\n",
      "ecpch:2226,learn rate 0.000004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4699 - val_loss: 193.9150\n",
      "\n",
      "Epoch 02227: val_loss did not improve from 179.48197\n",
      "Epoch 2228/5000\n",
      "ecpch:2227,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4720 - val_loss: 193.9291\n",
      "\n",
      "Epoch 02228: val_loss did not improve from 179.48197\n",
      "Epoch 2229/5000\n",
      "ecpch:2228,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 55.4683 - val_loss: 193.9238\n",
      "\n",
      "Epoch 02229: val_loss did not improve from 179.48197\n",
      "Epoch 2230/5000\n",
      "ecpch:2229,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4703 - val_loss: 193.9212\n",
      "\n",
      "Epoch 02230: val_loss did not improve from 179.48197\n",
      "Epoch 2231/5000\n",
      "ecpch:2230,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4666 - val_loss: 193.9348\n",
      "\n",
      "Epoch 02231: val_loss did not improve from 179.48197\n",
      "Epoch 2232/5000\n",
      "ecpch:2231,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4692 - val_loss: 193.9165\n",
      "\n",
      "Epoch 02232: val_loss did not improve from 179.48197\n",
      "Epoch 2233/5000\n",
      "ecpch:2232,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4675 - val_loss: 193.9239\n",
      "\n",
      "Epoch 02233: val_loss did not improve from 179.48197\n",
      "Epoch 2234/5000\n",
      "ecpch:2233,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4641 - val_loss: 193.9229\n",
      "\n",
      "Epoch 02234: val_loss did not improve from 179.48197\n",
      "Epoch 2235/5000\n",
      "ecpch:2234,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4640 - val_loss: 193.9334\n",
      "\n",
      "Epoch 02235: val_loss did not improve from 179.48197\n",
      "Epoch 2236/5000\n",
      "ecpch:2235,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4650 - val_loss: 193.9172\n",
      "\n",
      "Epoch 02236: val_loss did not improve from 179.48197\n",
      "Epoch 2237/5000\n",
      "ecpch:2236,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4650 - val_loss: 193.9295\n",
      "\n",
      "Epoch 02237: val_loss did not improve from 179.48197\n",
      "Epoch 2238/5000\n",
      "ecpch:2237,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4617 - val_loss: 193.9330\n",
      "\n",
      "Epoch 02238: val_loss did not improve from 179.48197\n",
      "Epoch 2239/5000\n",
      "ecpch:2238,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4647 - val_loss: 193.9260\n",
      "\n",
      "Epoch 02239: val_loss did not improve from 179.48197\n",
      "Epoch 2240/5000\n",
      "ecpch:2239,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4604 - val_loss: 193.9255\n",
      "\n",
      "Epoch 02240: val_loss did not improve from 179.48197\n",
      "Epoch 2241/5000\n",
      "ecpch:2240,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4629 - val_loss: 193.9257\n",
      "\n",
      "Epoch 02241: val_loss did not improve from 179.48197\n",
      "Epoch 2242/5000\n",
      "ecpch:2241,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4616 - val_loss: 193.9325\n",
      "\n",
      "Epoch 02242: val_loss did not improve from 179.48197\n",
      "Epoch 2243/5000\n",
      "ecpch:2242,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4592 - val_loss: 193.9186\n",
      "\n",
      "Epoch 02243: val_loss did not improve from 179.48197\n",
      "Epoch 2244/5000\n",
      "ecpch:2243,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 55.4636 - val_loss: 193.9278\n",
      "\n",
      "Epoch 02244: val_loss did not improve from 179.48197\n",
      "Epoch 2245/5000\n",
      "ecpch:2244,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4570 - val_loss: 193.9472\n",
      "\n",
      "Epoch 02245: val_loss did not improve from 179.48197\n",
      "Epoch 2246/5000\n",
      "ecpch:2245,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4659 - val_loss: 193.9315\n",
      "\n",
      "Epoch 02246: val_loss did not improve from 179.48197\n",
      "Epoch 2247/5000\n",
      "ecpch:2246,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4554 - val_loss: 193.9097\n",
      "\n",
      "Epoch 02247: val_loss did not improve from 179.48197\n",
      "Epoch 2248/5000\n",
      "ecpch:2247,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4669 - val_loss: 193.9253\n",
      "\n",
      "Epoch 02248: val_loss did not improve from 179.48197\n",
      "Epoch 2249/5000\n",
      "ecpch:2248,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4593 - val_loss: 193.9627\n",
      "\n",
      "Epoch 02249: val_loss did not improve from 179.48197\n",
      "Epoch 2250/5000\n",
      "ecpch:2249,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4692 - val_loss: 193.9545\n",
      "\n",
      "Epoch 02250: val_loss did not improve from 179.48197\n",
      "Epoch 2251/5000\n",
      "ecpch:2250,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4663 - val_loss: 193.9160\n",
      "\n",
      "Epoch 02251: val_loss did not improve from 179.48197\n",
      "Epoch 2252/5000\n",
      "ecpch:2251,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4598 - val_loss: 193.9166\n",
      "\n",
      "Epoch 02252: val_loss did not improve from 179.48197\n",
      "Epoch 2253/5000\n",
      "ecpch:2252,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4621 - val_loss: 193.9446\n",
      "\n",
      "Epoch 02253: val_loss did not improve from 179.48197\n",
      "Epoch 2254/5000\n",
      "ecpch:2253,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4538 - val_loss: 193.9419\n",
      "\n",
      "Epoch 02254: val_loss did not improve from 179.48197\n",
      "Epoch 2255/5000\n",
      "ecpch:2254,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4553 - val_loss: 193.9160\n",
      "\n",
      "Epoch 02255: val_loss did not improve from 179.48197\n",
      "Epoch 2256/5000\n",
      "ecpch:2255,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 55.4581 - val_loss: 193.9264\n",
      "\n",
      "Epoch 02256: val_loss did not improve from 179.48197\n",
      "Epoch 2257/5000\n",
      "ecpch:2256,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4537 - val_loss: 193.9494\n",
      "\n",
      "Epoch 02257: val_loss did not improve from 179.48197\n",
      "Epoch 2258/5000\n",
      "ecpch:2257,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4554 - val_loss: 193.9415\n",
      "\n",
      "Epoch 02258: val_loss did not improve from 179.48197\n",
      "Epoch 2259/5000\n",
      "ecpch:2258,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4493 - val_loss: 193.9190\n",
      "\n",
      "Epoch 02259: val_loss did not improve from 179.48197\n",
      "Epoch 2260/5000\n",
      "ecpch:2259,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4557 - val_loss: 193.9262\n",
      "\n",
      "Epoch 02260: val_loss did not improve from 179.48197\n",
      "Epoch 2261/5000\n",
      "ecpch:2260,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4497 - val_loss: 193.9565\n",
      "\n",
      "Epoch 02261: val_loss did not improve from 179.48197\n",
      "Epoch 2262/5000\n",
      "ecpch:2261,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4572 - val_loss: 193.9494\n",
      "\n",
      "Epoch 02262: val_loss did not improve from 179.48197\n",
      "Epoch 2263/5000\n",
      "ecpch:2262,learn rate 0.000004\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4517 - val_loss: 193.9177\n",
      "\n",
      "Epoch 02263: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 02263: ReduceLROnPlateau reducing learning rate to 3.491186271276092e-06.\n",
      "Epoch 2264/5000\n",
      "ecpch:2263,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4528 - val_loss: 193.9211\n",
      "\n",
      "Epoch 02264: val_loss did not improve from 179.48197\n",
      "Epoch 2265/5000\n",
      "ecpch:2264,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4527 - val_loss: 193.9460\n",
      "\n",
      "Epoch 02265: val_loss did not improve from 179.48197\n",
      "Epoch 2266/5000\n",
      "ecpch:2265,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4455 - val_loss: 193.9519\n",
      "\n",
      "Epoch 02266: val_loss did not improve from 179.48197\n",
      "Epoch 2267/5000\n",
      "ecpch:2266,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4479 - val_loss: 193.9347\n",
      "\n",
      "Epoch 02267: val_loss did not improve from 179.48197\n",
      "Epoch 2268/5000\n",
      "ecpch:2267,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4439 - val_loss: 193.9423\n",
      "\n",
      "Epoch 02268: val_loss did not improve from 179.48197\n",
      "Epoch 2269/5000\n",
      "ecpch:2268,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4486 - val_loss: 193.9478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 02269: val_loss did not improve from 179.48197\n",
      "Epoch 2270/5000\n",
      "ecpch:2269,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4431 - val_loss: 193.9343\n",
      "\n",
      "Epoch 02270: val_loss did not improve from 179.48197\n",
      "Epoch 2271/5000\n",
      "ecpch:2270,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4480 - val_loss: 193.9386\n",
      "\n",
      "Epoch 02271: val_loss did not improve from 179.48197\n",
      "Epoch 2272/5000\n",
      "ecpch:2271,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4423 - val_loss: 193.9552\n",
      "\n",
      "Epoch 02272: val_loss did not improve from 179.48197\n",
      "Epoch 2273/5000\n",
      "ecpch:2272,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4512 - val_loss: 193.9530\n",
      "\n",
      "Epoch 02273: val_loss did not improve from 179.48197\n",
      "Epoch 2274/5000\n",
      "ecpch:2273,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4480 - val_loss: 193.9342\n",
      "\n",
      "Epoch 02274: val_loss did not improve from 179.48197\n",
      "Epoch 2275/5000\n",
      "ecpch:2274,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4446 - val_loss: 193.9389\n",
      "\n",
      "Epoch 02275: val_loss did not improve from 179.48197\n",
      "Epoch 2276/5000\n",
      "ecpch:2275,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4453 - val_loss: 193.9543\n",
      "\n",
      "Epoch 02276: val_loss did not improve from 179.48197\n",
      "Epoch 2277/5000\n",
      "ecpch:2276,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4431 - val_loss: 193.9465\n",
      "\n",
      "Epoch 02277: val_loss did not improve from 179.48197\n",
      "Epoch 2278/5000\n",
      "ecpch:2277,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4439 - val_loss: 193.9341\n",
      "\n",
      "Epoch 02278: val_loss did not improve from 179.48197\n",
      "Epoch 2279/5000\n",
      "ecpch:2278,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4434 - val_loss: 193.9404\n",
      "\n",
      "Epoch 02279: val_loss did not improve from 179.48197\n",
      "Epoch 2280/5000\n",
      "ecpch:2279,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4401 - val_loss: 193.9631\n",
      "\n",
      "Epoch 02280: val_loss did not improve from 179.48197\n",
      "Epoch 2281/5000\n",
      "ecpch:2280,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4430 - val_loss: 193.9636\n",
      "\n",
      "Epoch 02281: val_loss did not improve from 179.48197\n",
      "Epoch 2282/5000\n",
      "ecpch:2281,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4399 - val_loss: 193.9341\n",
      "\n",
      "Epoch 02282: val_loss did not improve from 179.48197\n",
      "Epoch 2283/5000\n",
      "ecpch:2282,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 55.4398 - val_loss: 193.9315\n",
      "\n",
      "Epoch 02283: val_loss did not improve from 179.48197\n",
      "Epoch 2284/5000\n",
      "ecpch:2283,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4384 - val_loss: 193.9527\n",
      "\n",
      "Epoch 02284: val_loss did not improve from 179.48197\n",
      "Epoch 2285/5000\n",
      "ecpch:2284,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4382 - val_loss: 193.9559\n",
      "\n",
      "Epoch 02285: val_loss did not improve from 179.48197\n",
      "Epoch 2286/5000\n",
      "ecpch:2285,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4365 - val_loss: 193.9398\n",
      "\n",
      "Epoch 02286: val_loss did not improve from 179.48197\n",
      "Epoch 2287/5000\n",
      "ecpch:2286,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4338 - val_loss: 193.9461\n",
      "\n",
      "Epoch 02287: val_loss did not improve from 179.48197\n",
      "Epoch 2288/5000\n",
      "ecpch:2287,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4333 - val_loss: 193.9539\n",
      "\n",
      "Epoch 02288: val_loss did not improve from 179.48197\n",
      "Epoch 2289/5000\n",
      "ecpch:2288,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4337 - val_loss: 193.9538\n",
      "\n",
      "Epoch 02289: val_loss did not improve from 179.48197\n",
      "Epoch 2290/5000\n",
      "ecpch:2289,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4310 - val_loss: 193.9448\n",
      "\n",
      "Epoch 02290: val_loss did not improve from 179.48197\n",
      "Epoch 2291/5000\n",
      "ecpch:2290,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4342 - val_loss: 193.9485\n",
      "\n",
      "Epoch 02291: val_loss did not improve from 179.48197\n",
      "Epoch 2292/5000\n",
      "ecpch:2291,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4295 - val_loss: 193.9609\n",
      "\n",
      "Epoch 02292: val_loss did not improve from 179.48197\n",
      "Epoch 2293/5000\n",
      "ecpch:2292,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4342 - val_loss: 193.9506\n",
      "\n",
      "Epoch 02293: val_loss did not improve from 179.48197\n",
      "Epoch 2294/5000\n",
      "ecpch:2293,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 55.4274 - val_loss: 193.9387\n",
      "\n",
      "Epoch 02294: val_loss did not improve from 179.48197\n",
      "Epoch 2295/5000\n",
      "ecpch:2294,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4362 - val_loss: 193.9466\n",
      "\n",
      "Epoch 02295: val_loss did not improve from 179.48197\n",
      "Epoch 2296/5000\n",
      "ecpch:2295,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4305 - val_loss: 193.9671\n",
      "\n",
      "Epoch 02296: val_loss did not improve from 179.48197\n",
      "Epoch 2297/5000\n",
      "ecpch:2296,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4359 - val_loss: 193.9679\n",
      "\n",
      "Epoch 02297: val_loss did not improve from 179.48197\n",
      "Epoch 2298/5000\n",
      "ecpch:2297,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4341 - val_loss: 193.9462\n",
      "\n",
      "Epoch 02298: val_loss did not improve from 179.48197\n",
      "Epoch 2299/5000\n",
      "ecpch:2298,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4294 - val_loss: 193.9431\n",
      "\n",
      "Epoch 02299: val_loss did not improve from 179.48197\n",
      "Epoch 2300/5000\n",
      "ecpch:2299,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4304 - val_loss: 193.9592\n",
      "\n",
      "Epoch 02300: val_loss did not improve from 179.48197\n",
      "Epoch 2301/5000\n",
      "ecpch:2300,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4267 - val_loss: 193.9653\n",
      "\n",
      "Epoch 02301: val_loss did not improve from 179.48197\n",
      "Epoch 2302/5000\n",
      "ecpch:2301,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4256 - val_loss: 193.9490\n",
      "\n",
      "Epoch 02302: val_loss did not improve from 179.48197\n",
      "Epoch 2303/5000\n",
      "ecpch:2302,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4270 - val_loss: 193.9533\n",
      "\n",
      "Epoch 02303: val_loss did not improve from 179.48197\n",
      "Epoch 2304/5000\n",
      "ecpch:2303,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4229 - val_loss: 193.9714\n",
      "\n",
      "Epoch 02304: val_loss did not improve from 179.48197\n",
      "Epoch 2305/5000\n",
      "ecpch:2304,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4277 - val_loss: 193.9539\n",
      "\n",
      "Epoch 02305: val_loss did not improve from 179.48197\n",
      "Epoch 2306/5000\n",
      "ecpch:2305,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4222 - val_loss: 193.9459\n",
      "\n",
      "Epoch 02306: val_loss did not improve from 179.48197\n",
      "Epoch 2307/5000\n",
      "ecpch:2306,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4281 - val_loss: 193.9474\n",
      "\n",
      "Epoch 02307: val_loss did not improve from 179.48197\n",
      "Epoch 2308/5000\n",
      "ecpch:2307,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4242 - val_loss: 193.9690\n",
      "\n",
      "Epoch 02308: val_loss did not improve from 179.48197\n",
      "Epoch 2309/5000\n",
      "ecpch:2308,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4256 - val_loss: 193.9691\n",
      "\n",
      "Epoch 02309: val_loss did not improve from 179.48197\n",
      "Epoch 2310/5000\n",
      "ecpch:2309,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4236 - val_loss: 193.9562\n",
      "\n",
      "Epoch 02310: val_loss did not improve from 179.48197\n",
      "Epoch 2311/5000\n",
      "ecpch:2310,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4230 - val_loss: 193.9392\n",
      "\n",
      "Epoch 02311: val_loss did not improve from 179.48197\n",
      "Epoch 2312/5000\n",
      "ecpch:2311,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4223 - val_loss: 193.9657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 02312: val_loss did not improve from 179.48197\n",
      "Epoch 2313/5000\n",
      "ecpch:2312,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4203 - val_loss: 193.9766\n",
      "\n",
      "Epoch 02313: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 02313: ReduceLROnPlateau reducing learning rate to 3.142067726003006e-06.\n",
      "Epoch 2314/5000\n",
      "ecpch:2313,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4239 - val_loss: 193.9596\n",
      "\n",
      "Epoch 02314: val_loss did not improve from 179.48197\n",
      "Epoch 2315/5000\n",
      "ecpch:2314,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4161 - val_loss: 193.9446\n",
      "\n",
      "Epoch 02315: val_loss did not improve from 179.48197\n",
      "Epoch 2316/5000\n",
      "ecpch:2315,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4210 - val_loss: 193.9558\n",
      "\n",
      "Epoch 02316: val_loss did not improve from 179.48197\n",
      "Epoch 2317/5000\n",
      "ecpch:2316,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4152 - val_loss: 193.9756\n",
      "\n",
      "Epoch 02317: val_loss did not improve from 179.48197\n",
      "Epoch 2318/5000\n",
      "ecpch:2317,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4177 - val_loss: 193.9652\n",
      "\n",
      "Epoch 02318: val_loss did not improve from 179.48197\n",
      "Epoch 2319/5000\n",
      "ecpch:2318,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4147 - val_loss: 193.9566\n",
      "\n",
      "Epoch 02319: val_loss did not improve from 179.48197\n",
      "Epoch 2320/5000\n",
      "ecpch:2319,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4143 - val_loss: 193.9559\n",
      "\n",
      "Epoch 02320: val_loss did not improve from 179.48197\n",
      "Epoch 2321/5000\n",
      "ecpch:2320,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4128 - val_loss: 193.9731\n",
      "\n",
      "Epoch 02321: val_loss did not improve from 179.48197\n",
      "Epoch 2322/5000\n",
      "ecpch:2321,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4131 - val_loss: 193.9675\n",
      "\n",
      "Epoch 02322: val_loss did not improve from 179.48197\n",
      "Epoch 2323/5000\n",
      "ecpch:2322,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4111 - val_loss: 193.9636\n",
      "\n",
      "Epoch 02323: val_loss did not improve from 179.48197\n",
      "Epoch 2324/5000\n",
      "ecpch:2323,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4115 - val_loss: 193.9723\n",
      "\n",
      "Epoch 02324: val_loss did not improve from 179.48197\n",
      "Epoch 2325/5000\n",
      "ecpch:2324,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4095 - val_loss: 193.9766\n",
      "\n",
      "Epoch 02325: val_loss did not improve from 179.48197\n",
      "Epoch 2326/5000\n",
      "ecpch:2325,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4103 - val_loss: 193.9653\n",
      "\n",
      "Epoch 02326: val_loss did not improve from 179.48197\n",
      "Epoch 2327/5000\n",
      "ecpch:2326,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4086 - val_loss: 193.9724\n",
      "\n",
      "Epoch 02327: val_loss did not improve from 179.48197\n",
      "Epoch 2328/5000\n",
      "ecpch:2327,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4076 - val_loss: 193.9722\n",
      "\n",
      "Epoch 02328: val_loss did not improve from 179.48197\n",
      "Epoch 2329/5000\n",
      "ecpch:2328,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4086 - val_loss: 193.9646\n",
      "\n",
      "Epoch 02329: val_loss did not improve from 179.48197\n",
      "Epoch 2330/5000\n",
      "ecpch:2329,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4062 - val_loss: 193.9704\n",
      "\n",
      "Epoch 02330: val_loss did not improve from 179.48197\n",
      "Epoch 2331/5000\n",
      "ecpch:2330,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4065 - val_loss: 193.9782\n",
      "\n",
      "Epoch 02331: val_loss did not improve from 179.48197\n",
      "Epoch 2332/5000\n",
      "ecpch:2331,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4071 - val_loss: 193.9710\n",
      "\n",
      "Epoch 02332: val_loss did not improve from 179.48197\n",
      "Epoch 2333/5000\n",
      "ecpch:2332,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4043 - val_loss: 193.9725\n",
      "\n",
      "Epoch 02333: val_loss did not improve from 179.48197\n",
      "Epoch 2334/5000\n",
      "ecpch:2333,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4063 - val_loss: 193.9738\n",
      "\n",
      "Epoch 02334: val_loss did not improve from 179.48197\n",
      "Epoch 2335/5000\n",
      "ecpch:2334,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4043 - val_loss: 193.9680\n",
      "\n",
      "Epoch 02335: val_loss did not improve from 179.48197\n",
      "Epoch 2336/5000\n",
      "ecpch:2335,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4034 - val_loss: 193.9752\n",
      "\n",
      "Epoch 02336: val_loss did not improve from 179.48197\n",
      "Epoch 2337/5000\n",
      "ecpch:2336,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4048 - val_loss: 193.9757\n",
      "\n",
      "Epoch 02337: val_loss did not improve from 179.48197\n",
      "Epoch 2338/5000\n",
      "ecpch:2337,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4024 - val_loss: 193.9656\n",
      "\n",
      "Epoch 02338: val_loss did not improve from 179.48197\n",
      "Epoch 2339/5000\n",
      "ecpch:2338,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4066 - val_loss: 193.9712\n",
      "\n",
      "Epoch 02339: val_loss did not improve from 179.48197\n",
      "Epoch 2340/5000\n",
      "ecpch:2339,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4025 - val_loss: 193.9883\n",
      "\n",
      "Epoch 02340: val_loss did not improve from 179.48197\n",
      "Epoch 2341/5000\n",
      "ecpch:2340,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4073 - val_loss: 193.9783\n",
      "\n",
      "Epoch 02341: val_loss did not improve from 179.48197\n",
      "Epoch 2342/5000\n",
      "ecpch:2341,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.4006 - val_loss: 193.9588\n",
      "\n",
      "Epoch 02342: val_loss did not improve from 179.48197\n",
      "Epoch 2343/5000\n",
      "ecpch:2342,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4104 - val_loss: 193.9576\n",
      "\n",
      "Epoch 02343: val_loss did not improve from 179.48197\n",
      "Epoch 2344/5000\n",
      "ecpch:2343,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4070 - val_loss: 193.9879\n",
      "\n",
      "Epoch 02344: val_loss did not improve from 179.48197\n",
      "Epoch 2345/5000\n",
      "ecpch:2344,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4023 - val_loss: 193.9831\n",
      "\n",
      "Epoch 02345: val_loss did not improve from 179.48197\n",
      "Epoch 2346/5000\n",
      "ecpch:2345,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4028 - val_loss: 193.9693\n",
      "\n",
      "Epoch 02346: val_loss did not improve from 179.48197\n",
      "Epoch 2347/5000\n",
      "ecpch:2346,learn rate 0.000003\n",
      "64/64 [==============================] - 0s 8ms/step - loss: 55.4012 - val_loss: 193.9692\n",
      "\n",
      "Epoch 02347: val_loss did not improve from 179.48197\n",
      "Epoch 2348/5000\n",
      "ecpch:2347,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.4013 - val_loss: 193.9832\n",
      "\n",
      "Epoch 02348: val_loss did not improve from 179.48197\n",
      "Epoch 2349/5000\n",
      "ecpch:2348,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3989 - val_loss: 193.9745\n",
      "\n",
      "Epoch 02349: val_loss did not improve from 179.48197\n",
      "Epoch 2350/5000\n",
      "ecpch:2349,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3984 - val_loss: 193.9778\n",
      "\n",
      "Epoch 02350: val_loss did not improve from 179.48197\n",
      "Epoch 2351/5000\n",
      "ecpch:2350,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3960 - val_loss: 193.9824\n",
      "\n",
      "Epoch 02351: val_loss did not improve from 179.48197\n",
      "Epoch 2352/5000\n",
      "ecpch:2351,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3948 - val_loss: 193.9739\n",
      "\n",
      "Epoch 02352: val_loss did not improve from 179.48197\n",
      "Epoch 2353/5000\n",
      "ecpch:2352,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3969 - val_loss: 193.9783\n",
      "\n",
      "Epoch 02353: val_loss did not improve from 179.48197\n",
      "Epoch 2354/5000\n",
      "ecpch:2353,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3932 - val_loss: 193.9747\n",
      "\n",
      "Epoch 02354: val_loss did not improve from 179.48197\n",
      "Epoch 2355/5000\n",
      "ecpch:2354,learn rate 0.000003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3965 - val_loss: 193.9768\n",
      "\n",
      "Epoch 02355: val_loss did not improve from 179.48197\n",
      "Epoch 2356/5000\n",
      "ecpch:2355,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3918 - val_loss: 193.9930\n",
      "\n",
      "Epoch 02356: val_loss did not improve from 179.48197\n",
      "Epoch 2357/5000\n",
      "ecpch:2356,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3957 - val_loss: 193.9756\n",
      "\n",
      "Epoch 02357: val_loss did not improve from 179.48197\n",
      "Epoch 2358/5000\n",
      "ecpch:2357,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3907 - val_loss: 193.9808\n",
      "\n",
      "Epoch 02358: val_loss did not improve from 179.48197\n",
      "Epoch 2359/5000\n",
      "ecpch:2358,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3907 - val_loss: 193.9901\n",
      "\n",
      "Epoch 02359: val_loss did not improve from 179.48197\n",
      "Epoch 2360/5000\n",
      "ecpch:2359,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3935 - val_loss: 193.9824\n",
      "\n",
      "Epoch 02360: val_loss did not improve from 179.48197\n",
      "Epoch 2361/5000\n",
      "ecpch:2360,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3889 - val_loss: 193.9819\n",
      "\n",
      "Epoch 02361: val_loss did not improve from 179.48197\n",
      "Epoch 2362/5000\n",
      "ecpch:2361,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3922 - val_loss: 193.9871\n",
      "\n",
      "Epoch 02362: val_loss did not improve from 179.48197\n",
      "Epoch 2363/5000\n",
      "ecpch:2362,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3886 - val_loss: 193.9736\n",
      "\n",
      "Epoch 02363: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 02363: ReduceLROnPlateau reducing learning rate to 2.8278609534027055e-06.\n",
      "Epoch 2364/5000\n",
      "ecpch:2363,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3904 - val_loss: 193.9838\n",
      "\n",
      "Epoch 02364: val_loss did not improve from 179.48197\n",
      "Epoch 2365/5000\n",
      "ecpch:2364,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3889 - val_loss: 193.9917\n",
      "\n",
      "Epoch 02365: val_loss did not improve from 179.48197\n",
      "Epoch 2366/5000\n",
      "ecpch:2365,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3863 - val_loss: 193.9739\n",
      "\n",
      "Epoch 02366: val_loss did not improve from 179.48197\n",
      "Epoch 2367/5000\n",
      "ecpch:2366,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3891 - val_loss: 193.9848\n",
      "\n",
      "Epoch 02367: val_loss did not improve from 179.48197\n",
      "Epoch 2368/5000\n",
      "ecpch:2367,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3859 - val_loss: 193.9991\n",
      "\n",
      "Epoch 02368: val_loss did not improve from 179.48197\n",
      "Epoch 2369/5000\n",
      "ecpch:2368,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3878 - val_loss: 193.9817\n",
      "\n",
      "Epoch 02369: val_loss did not improve from 179.48197\n",
      "Epoch 2370/5000\n",
      "ecpch:2369,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3867 - val_loss: 193.9807\n",
      "\n",
      "Epoch 02370: val_loss did not improve from 179.48197\n",
      "Epoch 2371/5000\n",
      "ecpch:2370,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3839 - val_loss: 193.9890\n",
      "\n",
      "Epoch 02371: val_loss did not improve from 179.48197\n",
      "Epoch 2372/5000\n",
      "ecpch:2371,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3876 - val_loss: 193.9874\n",
      "\n",
      "Epoch 02372: val_loss did not improve from 179.48197\n",
      "Epoch 2373/5000\n",
      "ecpch:2372,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3829 - val_loss: 193.9835\n",
      "\n",
      "Epoch 02373: val_loss did not improve from 179.48197\n",
      "Epoch 2374/5000\n",
      "ecpch:2373,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3832 - val_loss: 193.9892\n",
      "\n",
      "Epoch 02374: val_loss did not improve from 179.48197\n",
      "Epoch 2375/5000\n",
      "ecpch:2374,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 55.3838 - val_loss: 193.9849\n",
      "\n",
      "Epoch 02375: val_loss did not improve from 179.48197\n",
      "Epoch 2376/5000\n",
      "ecpch:2375,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3823 - val_loss: 193.9837\n",
      "\n",
      "Epoch 02376: val_loss did not improve from 179.48197\n",
      "Epoch 2377/5000\n",
      "ecpch:2376,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3815 - val_loss: 193.9936\n",
      "\n",
      "Epoch 02377: val_loss did not improve from 179.48197\n",
      "Epoch 2378/5000\n",
      "ecpch:2377,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3826 - val_loss: 193.9875\n",
      "\n",
      "Epoch 02378: val_loss did not improve from 179.48197\n",
      "Epoch 2379/5000\n",
      "ecpch:2378,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3801 - val_loss: 193.9862\n",
      "\n",
      "Epoch 02379: val_loss did not improve from 179.48197\n",
      "Epoch 2380/5000\n",
      "ecpch:2379,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3792 - val_loss: 193.9904\n",
      "\n",
      "Epoch 02380: val_loss did not improve from 179.48197\n",
      "Epoch 2381/5000\n",
      "ecpch:2380,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3793 - val_loss: 193.9890\n",
      "\n",
      "Epoch 02381: val_loss did not improve from 179.48197\n",
      "Epoch 2382/5000\n",
      "ecpch:2381,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3803 - val_loss: 193.9960\n",
      "\n",
      "Epoch 02382: val_loss did not improve from 179.48197\n",
      "Epoch 2383/5000\n",
      "ecpch:2382,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3780 - val_loss: 193.9811\n",
      "\n",
      "Epoch 02383: val_loss did not improve from 179.48197\n",
      "Epoch 2384/5000\n",
      "ecpch:2383,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3804 - val_loss: 193.9925\n",
      "\n",
      "Epoch 02384: val_loss did not improve from 179.48197\n",
      "Epoch 2385/5000\n",
      "ecpch:2384,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 55.3767 - val_loss: 193.9907\n",
      "\n",
      "Epoch 02385: val_loss did not improve from 179.48197\n",
      "Epoch 2386/5000\n",
      "ecpch:2385,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3763 - val_loss: 193.9890\n",
      "\n",
      "Epoch 02386: val_loss did not improve from 179.48197\n",
      "Epoch 2387/5000\n",
      "ecpch:2386,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3776 - val_loss: 193.9943\n",
      "\n",
      "Epoch 02387: val_loss did not improve from 179.48197\n",
      "Epoch 2388/5000\n",
      "ecpch:2387,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3772 - val_loss: 193.9918\n",
      "\n",
      "Epoch 02388: val_loss did not improve from 179.48197\n",
      "Epoch 2389/5000\n",
      "ecpch:2388,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3746 - val_loss: 193.9943\n",
      "\n",
      "Epoch 02389: val_loss did not improve from 179.48197\n",
      "Epoch 2390/5000\n",
      "ecpch:2389,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3744 - val_loss: 193.9981\n",
      "\n",
      "Epoch 02390: val_loss did not improve from 179.48197\n",
      "Epoch 2391/5000\n",
      "ecpch:2390,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3768 - val_loss: 193.9953\n",
      "\n",
      "Epoch 02391: val_loss did not improve from 179.48197\n",
      "Epoch 2392/5000\n",
      "ecpch:2391,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3738 - val_loss: 193.9919\n",
      "\n",
      "Epoch 02392: val_loss did not improve from 179.48197\n",
      "Epoch 2393/5000\n",
      "ecpch:2392,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3729 - val_loss: 193.9956\n",
      "\n",
      "Epoch 02393: val_loss did not improve from 179.48197\n",
      "Epoch 2394/5000\n",
      "ecpch:2393,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3743 - val_loss: 193.9995\n",
      "\n",
      "Epoch 02394: val_loss did not improve from 179.48197\n",
      "Epoch 2395/5000\n",
      "ecpch:2394,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3718 - val_loss: 193.9987\n",
      "\n",
      "Epoch 02395: val_loss did not improve from 179.48197\n",
      "Epoch 2396/5000\n",
      "ecpch:2395,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3711 - val_loss: 193.9955\n",
      "\n",
      "Epoch 02396: val_loss did not improve from 179.48197\n",
      "Epoch 2397/5000\n",
      "ecpch:2396,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3717 - val_loss: 193.9972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 02397: val_loss did not improve from 179.48197\n",
      "Epoch 2398/5000\n",
      "ecpch:2397,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3736 - val_loss: 193.9949\n",
      "\n",
      "Epoch 02398: val_loss did not improve from 179.48197\n",
      "Epoch 2399/5000\n",
      "ecpch:2398,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3691 - val_loss: 193.9976\n",
      "\n",
      "Epoch 02399: val_loss did not improve from 179.48197\n",
      "Epoch 2400/5000\n",
      "ecpch:2399,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3695 - val_loss: 194.0031\n",
      "\n",
      "Epoch 02400: val_loss did not improve from 179.48197\n",
      "Epoch 2401/5000\n",
      "ecpch:2400,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3731 - val_loss: 193.9950\n",
      "\n",
      "Epoch 02401: val_loss did not improve from 179.48197\n",
      "Epoch 2402/5000\n",
      "ecpch:2401,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3682 - val_loss: 193.9937\n",
      "\n",
      "Epoch 02402: val_loss did not improve from 179.48197\n",
      "Epoch 2403/5000\n",
      "ecpch:2402,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3720 - val_loss: 194.0007\n",
      "\n",
      "Epoch 02403: val_loss did not improve from 179.48197\n",
      "Epoch 2404/5000\n",
      "ecpch:2403,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3687 - val_loss: 193.9956\n",
      "\n",
      "Epoch 02404: val_loss did not improve from 179.48197\n",
      "Epoch 2405/5000\n",
      "ecpch:2404,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3698 - val_loss: 193.9976\n",
      "\n",
      "Epoch 02405: val_loss did not improve from 179.48197\n",
      "Epoch 2406/5000\n",
      "ecpch:2405,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3668 - val_loss: 194.0092\n",
      "\n",
      "Epoch 02406: val_loss did not improve from 179.48197\n",
      "Epoch 2407/5000\n",
      "ecpch:2406,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3713 - val_loss: 194.0007\n",
      "\n",
      "Epoch 02407: val_loss did not improve from 179.48197\n",
      "Epoch 2408/5000\n",
      "ecpch:2407,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3662 - val_loss: 193.9841\n",
      "\n",
      "Epoch 02408: val_loss did not improve from 179.48197\n",
      "Epoch 2409/5000\n",
      "ecpch:2408,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3743 - val_loss: 193.9905\n",
      "\n",
      "Epoch 02409: val_loss did not improve from 179.48197\n",
      "Epoch 2410/5000\n",
      "ecpch:2409,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3702 - val_loss: 194.0097\n",
      "\n",
      "Epoch 02410: val_loss did not improve from 179.48197\n",
      "Epoch 2411/5000\n",
      "ecpch:2410,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3721 - val_loss: 194.0106\n",
      "\n",
      "Epoch 02411: val_loss did not improve from 179.48197\n",
      "Epoch 2412/5000\n",
      "ecpch:2411,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3717 - val_loss: 193.9895\n",
      "\n",
      "Epoch 02412: val_loss did not improve from 179.48197\n",
      "Epoch 2413/5000\n",
      "ecpch:2412,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3674 - val_loss: 193.9933\n",
      "\n",
      "Epoch 02413: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 02413: ReduceLROnPlateau reducing learning rate to 2.545074858062435e-06.\n",
      "Epoch 2414/5000\n",
      "ecpch:2413,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3680 - val_loss: 194.0058\n",
      "\n",
      "Epoch 02414: val_loss did not improve from 179.48197\n",
      "Epoch 2415/5000\n",
      "ecpch:2414,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3644 - val_loss: 194.0040\n",
      "\n",
      "Epoch 02415: val_loss did not improve from 179.48197\n",
      "Epoch 2416/5000\n",
      "ecpch:2415,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3649 - val_loss: 193.9877\n",
      "\n",
      "Epoch 02416: val_loss did not improve from 179.48197\n",
      "Epoch 2417/5000\n",
      "ecpch:2416,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 55.3628 - val_loss: 194.0037\n",
      "\n",
      "Epoch 02417: val_loss did not improve from 179.48197\n",
      "Epoch 2418/5000\n",
      "ecpch:2417,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3632 - val_loss: 194.0067\n",
      "\n",
      "Epoch 02418: val_loss did not improve from 179.48197\n",
      "Epoch 2419/5000\n",
      "ecpch:2418,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3611 - val_loss: 193.9968\n",
      "\n",
      "Epoch 02419: val_loss did not improve from 179.48197\n",
      "Epoch 2420/5000\n",
      "ecpch:2419,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3641 - val_loss: 193.9962\n",
      "\n",
      "Epoch 02420: val_loss did not improve from 179.48197\n",
      "Epoch 2421/5000\n",
      "ecpch:2420,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3612 - val_loss: 194.0098\n",
      "\n",
      "Epoch 02421: val_loss did not improve from 179.48197\n",
      "Epoch 2422/5000\n",
      "ecpch:2421,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3637 - val_loss: 194.0055\n",
      "\n",
      "Epoch 02422: val_loss did not improve from 179.48197\n",
      "Epoch 2423/5000\n",
      "ecpch:2422,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3597 - val_loss: 193.9907\n",
      "\n",
      "Epoch 02423: val_loss did not improve from 179.48197\n",
      "Epoch 2424/5000\n",
      "ecpch:2423,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3656 - val_loss: 193.9902\n",
      "\n",
      "Epoch 02424: val_loss did not improve from 179.48197\n",
      "Epoch 2425/5000\n",
      "ecpch:2424,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3639 - val_loss: 194.0144\n",
      "\n",
      "Epoch 02425: val_loss did not improve from 179.48197\n",
      "Epoch 2426/5000\n",
      "ecpch:2425,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3601 - val_loss: 194.0139\n",
      "\n",
      "Epoch 02426: val_loss did not improve from 179.48197\n",
      "Epoch 2427/5000\n",
      "ecpch:2426,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3594 - val_loss: 193.9968\n",
      "\n",
      "Epoch 02427: val_loss did not improve from 179.48197\n",
      "Epoch 2428/5000\n",
      "ecpch:2427,learn rate 0.000003\n",
      "64/64 [==============================] - 0s 8ms/step - loss: 55.3614 - val_loss: 193.9936\n",
      "\n",
      "Epoch 02428: val_loss did not improve from 179.48197\n",
      "Epoch 2429/5000\n",
      "ecpch:2428,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3602 - val_loss: 194.0160\n",
      "\n",
      "Epoch 02429: val_loss did not improve from 179.48197\n",
      "Epoch 2430/5000\n",
      "ecpch:2429,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3594 - val_loss: 194.0154\n",
      "\n",
      "Epoch 02430: val_loss did not improve from 179.48197\n",
      "Epoch 2431/5000\n",
      "ecpch:2430,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3571 - val_loss: 193.9952\n",
      "\n",
      "Epoch 02431: val_loss did not improve from 179.48197\n",
      "Epoch 2432/5000\n",
      "ecpch:2431,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3606 - val_loss: 193.9909\n",
      "\n",
      "Epoch 02432: val_loss did not improve from 179.48197\n",
      "Epoch 2433/5000\n",
      "ecpch:2432,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3594 - val_loss: 194.0138\n",
      "\n",
      "Epoch 02433: val_loss did not improve from 179.48197\n",
      "Epoch 2434/5000\n",
      "ecpch:2433,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3561 - val_loss: 194.0111\n",
      "\n",
      "Epoch 02434: val_loss did not improve from 179.48197\n",
      "Epoch 2435/5000\n",
      "ecpch:2434,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3553 - val_loss: 194.0046\n",
      "\n",
      "Epoch 02435: val_loss did not improve from 179.48197\n",
      "Epoch 2436/5000\n",
      "ecpch:2435,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3567 - val_loss: 193.9987\n",
      "\n",
      "Epoch 02436: val_loss did not improve from 179.48197\n",
      "Epoch 2437/5000\n",
      "ecpch:2436,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3551 - val_loss: 194.0181\n",
      "\n",
      "Epoch 02437: val_loss did not improve from 179.48197\n",
      "Epoch 2438/5000\n",
      "ecpch:2437,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3553 - val_loss: 194.0150\n",
      "\n",
      "Epoch 02438: val_loss did not improve from 179.48197\n",
      "Epoch 2439/5000\n",
      "ecpch:2438,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3530 - val_loss: 193.9992\n",
      "\n",
      "Epoch 02439: val_loss did not improve from 179.48197\n",
      "Epoch 2440/5000\n",
      "ecpch:2439,learn rate 0.000003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3532 - val_loss: 194.0009\n",
      "\n",
      "Epoch 02440: val_loss did not improve from 179.48197\n",
      "Epoch 2441/5000\n",
      "ecpch:2440,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3528 - val_loss: 194.0168\n",
      "\n",
      "Epoch 02441: val_loss did not improve from 179.48197\n",
      "Epoch 2442/5000\n",
      "ecpch:2441,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3514 - val_loss: 194.0198\n",
      "\n",
      "Epoch 02442: val_loss did not improve from 179.48197\n",
      "Epoch 2443/5000\n",
      "ecpch:2442,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3519 - val_loss: 194.0124\n",
      "\n",
      "Epoch 02443: val_loss did not improve from 179.48197\n",
      "Epoch 2444/5000\n",
      "ecpch:2443,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3511 - val_loss: 194.0033\n",
      "\n",
      "Epoch 02444: val_loss did not improve from 179.48197\n",
      "Epoch 2445/5000\n",
      "ecpch:2444,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3497 - val_loss: 194.0108\n",
      "\n",
      "Epoch 02445: val_loss did not improve from 179.48197\n",
      "Epoch 2446/5000\n",
      "ecpch:2445,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3501 - val_loss: 194.0176\n",
      "\n",
      "Epoch 02446: val_loss did not improve from 179.48197\n",
      "Epoch 2447/5000\n",
      "ecpch:2446,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3486 - val_loss: 194.0026\n",
      "\n",
      "Epoch 02447: val_loss did not improve from 179.48197\n",
      "Epoch 2448/5000\n",
      "ecpch:2447,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3493 - val_loss: 194.0119\n",
      "\n",
      "Epoch 02448: val_loss did not improve from 179.48197\n",
      "Epoch 2449/5000\n",
      "ecpch:2448,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3478 - val_loss: 194.0170\n",
      "\n",
      "Epoch 02449: val_loss did not improve from 179.48197\n",
      "Epoch 2450/5000\n",
      "ecpch:2449,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3488 - val_loss: 194.0096\n",
      "\n",
      "Epoch 02450: val_loss did not improve from 179.48197\n",
      "Epoch 2451/5000\n",
      "ecpch:2450,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3472 - val_loss: 194.0136\n",
      "\n",
      "Epoch 02451: val_loss did not improve from 179.48197\n",
      "Epoch 2452/5000\n",
      "ecpch:2451,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3474 - val_loss: 194.0234\n",
      "\n",
      "Epoch 02452: val_loss did not improve from 179.48197\n",
      "Epoch 2453/5000\n",
      "ecpch:2452,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3469 - val_loss: 194.0130\n",
      "\n",
      "Epoch 02453: val_loss did not improve from 179.48197\n",
      "Epoch 2454/5000\n",
      "ecpch:2453,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3456 - val_loss: 194.0145\n",
      "\n",
      "Epoch 02454: val_loss did not improve from 179.48197\n",
      "Epoch 2455/5000\n",
      "ecpch:2454,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3467 - val_loss: 194.0234\n",
      "\n",
      "Epoch 02455: val_loss did not improve from 179.48197\n",
      "Epoch 2456/5000\n",
      "ecpch:2455,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3443 - val_loss: 194.0166\n",
      "\n",
      "Epoch 02456: val_loss did not improve from 179.48197\n",
      "Epoch 2457/5000\n",
      "ecpch:2456,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3449 - val_loss: 194.0185\n",
      "\n",
      "Epoch 02457: val_loss did not improve from 179.48197\n",
      "Epoch 2458/5000\n",
      "ecpch:2457,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3429 - val_loss: 194.0102\n",
      "\n",
      "Epoch 02458: val_loss did not improve from 179.48197\n",
      "Epoch 2459/5000\n",
      "ecpch:2458,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3418 - val_loss: 194.0188\n",
      "\n",
      "Epoch 02459: val_loss did not improve from 179.48197\n",
      "Epoch 2460/5000\n",
      "ecpch:2459,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3433 - val_loss: 194.0151\n",
      "\n",
      "Epoch 02460: val_loss did not improve from 179.48197\n",
      "Epoch 2461/5000\n",
      "ecpch:2460,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3419 - val_loss: 194.0174\n",
      "\n",
      "Epoch 02461: val_loss did not improve from 179.48197\n",
      "Epoch 2462/5000\n",
      "ecpch:2461,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3410 - val_loss: 194.0153\n",
      "\n",
      "Epoch 02462: val_loss did not improve from 179.48197\n",
      "Epoch 2463/5000\n",
      "ecpch:2462,learn rate 0.000003\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3413 - val_loss: 194.0176\n",
      "\n",
      "Epoch 02463: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 02463: ReduceLROnPlateau reducing learning rate to 2.290567454110715e-06.\n",
      "Epoch 2464/5000\n",
      "ecpch:2463,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3405 - val_loss: 194.0177\n",
      "\n",
      "Epoch 02464: val_loss did not improve from 179.48197\n",
      "Epoch 2465/5000\n",
      "ecpch:2464,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3392 - val_loss: 194.0148\n",
      "\n",
      "Epoch 02465: val_loss did not improve from 179.48197\n",
      "Epoch 2466/5000\n",
      "ecpch:2465,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3387 - val_loss: 194.0200\n",
      "\n",
      "Epoch 02466: val_loss did not improve from 179.48197\n",
      "Epoch 2467/5000\n",
      "ecpch:2466,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3393 - val_loss: 194.0174\n",
      "\n",
      "Epoch 02467: val_loss did not improve from 179.48197\n",
      "Epoch 2468/5000\n",
      "ecpch:2467,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3381 - val_loss: 194.0186\n",
      "\n",
      "Epoch 02468: val_loss did not improve from 179.48197\n",
      "Epoch 2469/5000\n",
      "ecpch:2468,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3373 - val_loss: 194.0269\n",
      "\n",
      "Epoch 02469: val_loss did not improve from 179.48197\n",
      "Epoch 2470/5000\n",
      "ecpch:2469,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3372 - val_loss: 194.0204\n",
      "\n",
      "Epoch 02470: val_loss did not improve from 179.48197\n",
      "Epoch 2471/5000\n",
      "ecpch:2470,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3378 - val_loss: 194.0233\n",
      "\n",
      "Epoch 02471: val_loss did not improve from 179.48197\n",
      "Epoch 2472/5000\n",
      "ecpch:2471,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3365 - val_loss: 194.0186\n",
      "\n",
      "Epoch 02472: val_loss did not improve from 179.48197\n",
      "Epoch 2473/5000\n",
      "ecpch:2472,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3359 - val_loss: 194.0255\n",
      "\n",
      "Epoch 02473: val_loss did not improve from 179.48197\n",
      "Epoch 2474/5000\n",
      "ecpch:2473,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3352 - val_loss: 194.0206\n",
      "\n",
      "Epoch 02474: val_loss did not improve from 179.48197\n",
      "Epoch 2475/5000\n",
      "ecpch:2474,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3358 - val_loss: 194.0251\n",
      "\n",
      "Epoch 02475: val_loss did not improve from 179.48197\n",
      "Epoch 2476/5000\n",
      "ecpch:2475,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3368 - val_loss: 194.0222\n",
      "\n",
      "Epoch 02476: val_loss did not improve from 179.48197\n",
      "Epoch 2477/5000\n",
      "ecpch:2476,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3337 - val_loss: 194.0193\n",
      "\n",
      "Epoch 02477: val_loss did not improve from 179.48197\n",
      "Epoch 2478/5000\n",
      "ecpch:2477,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3350 - val_loss: 194.0283\n",
      "\n",
      "Epoch 02478: val_loss did not improve from 179.48197\n",
      "Epoch 2479/5000\n",
      "ecpch:2478,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3360 - val_loss: 194.0244\n",
      "\n",
      "Epoch 02479: val_loss did not improve from 179.48197\n",
      "Epoch 2480/5000\n",
      "ecpch:2479,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3327 - val_loss: 194.0125\n",
      "\n",
      "Epoch 02480: val_loss did not improve from 179.48197\n",
      "Epoch 2481/5000\n",
      "ecpch:2480,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3371 - val_loss: 194.0269\n",
      "\n",
      "Epoch 02481: val_loss did not improve from 179.48197\n",
      "Epoch 2482/5000\n",
      "ecpch:2481,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3323 - val_loss: 194.0296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 02482: val_loss did not improve from 179.48197\n",
      "Epoch 2483/5000\n",
      "ecpch:2482,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3394 - val_loss: 194.0234\n",
      "\n",
      "Epoch 02483: val_loss did not improve from 179.48197\n",
      "Epoch 2484/5000\n",
      "ecpch:2483,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3368 - val_loss: 194.0193\n",
      "\n",
      "Epoch 02484: val_loss did not improve from 179.48197\n",
      "Epoch 2485/5000\n",
      "ecpch:2484,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3346 - val_loss: 194.0285\n",
      "\n",
      "Epoch 02485: val_loss did not improve from 179.48197\n",
      "Epoch 2486/5000\n",
      "ecpch:2485,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3349 - val_loss: 194.0271\n",
      "\n",
      "Epoch 02486: val_loss did not improve from 179.48197\n",
      "Epoch 2487/5000\n",
      "ecpch:2486,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3330 - val_loss: 194.0182\n",
      "\n",
      "Epoch 02487: val_loss did not improve from 179.48197\n",
      "Epoch 2488/5000\n",
      "ecpch:2487,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3325 - val_loss: 194.0121\n",
      "\n",
      "Epoch 02488: val_loss did not improve from 179.48197\n",
      "Epoch 2489/5000\n",
      "ecpch:2488,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3314 - val_loss: 194.0265\n",
      "\n",
      "Epoch 02489: val_loss did not improve from 179.48197\n",
      "Epoch 2490/5000\n",
      "ecpch:2489,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3310 - val_loss: 194.0286\n",
      "\n",
      "Epoch 02490: val_loss did not improve from 179.48197\n",
      "Epoch 2491/5000\n",
      "ecpch:2490,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3302 - val_loss: 194.0216\n",
      "\n",
      "Epoch 02491: val_loss did not improve from 179.48197\n",
      "Epoch 2492/5000\n",
      "ecpch:2491,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3284 - val_loss: 194.0250\n",
      "\n",
      "Epoch 02492: val_loss did not improve from 179.48197\n",
      "Epoch 2493/5000\n",
      "ecpch:2492,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3322 - val_loss: 194.0279\n",
      "\n",
      "Epoch 02493: val_loss did not improve from 179.48197\n",
      "Epoch 2494/5000\n",
      "ecpch:2493,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3270 - val_loss: 194.0206\n",
      "\n",
      "Epoch 02494: val_loss did not improve from 179.48197\n",
      "Epoch 2495/5000\n",
      "ecpch:2494,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3331 - val_loss: 194.0199\n",
      "\n",
      "Epoch 02495: val_loss did not improve from 179.48197\n",
      "Epoch 2496/5000\n",
      "ecpch:2495,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3296 - val_loss: 194.0312\n",
      "\n",
      "Epoch 02496: val_loss did not improve from 179.48197\n",
      "Epoch 2497/5000\n",
      "ecpch:2496,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3323 - val_loss: 194.0302\n",
      "\n",
      "Epoch 02497: val_loss did not improve from 179.48197\n",
      "Epoch 2498/5000\n",
      "ecpch:2497,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3315 - val_loss: 194.0246\n",
      "\n",
      "Epoch 02498: val_loss did not improve from 179.48197\n",
      "Epoch 2499/5000\n",
      "ecpch:2498,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3282 - val_loss: 194.0312\n",
      "\n",
      "Epoch 02499: val_loss did not improve from 179.48197\n",
      "Epoch 2500/5000\n",
      "ecpch:2499,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3299 - val_loss: 194.0393\n",
      "\n",
      "Epoch 02500: val_loss did not improve from 179.48197\n",
      "Epoch 2501/5000\n",
      "ecpch:2500,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3267 - val_loss: 194.0248\n",
      "\n",
      "Epoch 02501: val_loss did not improve from 179.48197\n",
      "Epoch 2502/5000\n",
      "ecpch:2501,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3282 - val_loss: 194.0247\n",
      "\n",
      "Epoch 02502: val_loss did not improve from 179.48197\n",
      "Epoch 2503/5000\n",
      "ecpch:2502,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3245 - val_loss: 194.0337\n",
      "\n",
      "Epoch 02503: val_loss did not improve from 179.48197\n",
      "Epoch 2504/5000\n",
      "ecpch:2503,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3309 - val_loss: 194.0350\n",
      "\n",
      "Epoch 02504: val_loss did not improve from 179.48197\n",
      "Epoch 2505/5000\n",
      "ecpch:2504,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3287 - val_loss: 194.0224\n",
      "\n",
      "Epoch 02505: val_loss did not improve from 179.48197\n",
      "Epoch 2506/5000\n",
      "ecpch:2505,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3253 - val_loss: 194.0247\n",
      "\n",
      "Epoch 02506: val_loss did not improve from 179.48197\n",
      "Epoch 2507/5000\n",
      "ecpch:2506,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3255 - val_loss: 194.0334\n",
      "\n",
      "Epoch 02507: val_loss did not improve from 179.48197\n",
      "Epoch 2508/5000\n",
      "ecpch:2507,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3248 - val_loss: 194.0324\n",
      "\n",
      "Epoch 02508: val_loss did not improve from 179.48197\n",
      "Epoch 2509/5000\n",
      "ecpch:2508,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3238 - val_loss: 194.0191\n",
      "\n",
      "Epoch 02509: val_loss did not improve from 179.48197\n",
      "Epoch 2510/5000\n",
      "ecpch:2509,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3240 - val_loss: 194.0256\n",
      "\n",
      "Epoch 02510: val_loss did not improve from 179.48197\n",
      "Epoch 2511/5000\n",
      "ecpch:2510,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3214 - val_loss: 194.0365\n",
      "\n",
      "Epoch 02511: val_loss did not improve from 179.48197\n",
      "Epoch 2512/5000\n",
      "ecpch:2511,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3245 - val_loss: 194.0334\n",
      "\n",
      "Epoch 02512: val_loss did not improve from 179.48197\n",
      "Epoch 2513/5000\n",
      "ecpch:2512,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3224 - val_loss: 194.0239\n",
      "\n",
      "Epoch 02513: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 02513: ReduceLROnPlateau reducing learning rate to 2.0615106677723817e-06.\n",
      "Epoch 2514/5000\n",
      "ecpch:2513,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3225 - val_loss: 194.0319\n",
      "\n",
      "Epoch 02514: val_loss did not improve from 179.48197\n",
      "Epoch 2515/5000\n",
      "ecpch:2514,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3209 - val_loss: 194.0311\n",
      "\n",
      "Epoch 02515: val_loss did not improve from 179.48197\n",
      "Epoch 2516/5000\n",
      "ecpch:2515,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3212 - val_loss: 194.0386\n",
      "\n",
      "Epoch 02516: val_loss did not improve from 179.48197\n",
      "Epoch 2517/5000\n",
      "ecpch:2516,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3211 - val_loss: 194.0323\n",
      "\n",
      "Epoch 02517: val_loss did not improve from 179.48197\n",
      "Epoch 2518/5000\n",
      "ecpch:2517,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3186 - val_loss: 194.0285\n",
      "\n",
      "Epoch 02518: val_loss did not improve from 179.48197\n",
      "Epoch 2519/5000\n",
      "ecpch:2518,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3187 - val_loss: 194.0399\n",
      "\n",
      "Epoch 02519: val_loss did not improve from 179.48197\n",
      "Epoch 2520/5000\n",
      "ecpch:2519,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3188 - val_loss: 194.0345\n",
      "\n",
      "Epoch 02520: val_loss did not improve from 179.48197\n",
      "Epoch 2521/5000\n",
      "ecpch:2520,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3175 - val_loss: 194.0299\n",
      "\n",
      "Epoch 02521: val_loss did not improve from 179.48197\n",
      "Epoch 2522/5000\n",
      "ecpch:2521,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3183 - val_loss: 194.0360\n",
      "\n",
      "Epoch 02522: val_loss did not improve from 179.48197\n",
      "Epoch 2523/5000\n",
      "ecpch:2522,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3156 - val_loss: 194.0391\n",
      "\n",
      "Epoch 02523: val_loss did not improve from 179.48197\n",
      "Epoch 2524/5000\n",
      "ecpch:2523,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3170 - val_loss: 194.0356\n",
      "\n",
      "Epoch 02524: val_loss did not improve from 179.48197\n",
      "Epoch 2525/5000\n",
      "ecpch:2524,learn rate 0.000002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3147 - val_loss: 194.0358\n",
      "\n",
      "Epoch 02525: val_loss did not improve from 179.48197\n",
      "Epoch 2526/5000\n",
      "ecpch:2525,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3174 - val_loss: 194.0403\n",
      "\n",
      "Epoch 02526: val_loss did not improve from 179.48197\n",
      "Epoch 2527/5000\n",
      "ecpch:2526,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3141 - val_loss: 194.0371\n",
      "\n",
      "Epoch 02527: val_loss did not improve from 179.48197\n",
      "Epoch 2528/5000\n",
      "ecpch:2527,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3174 - val_loss: 194.0387\n",
      "\n",
      "Epoch 02528: val_loss did not improve from 179.48197\n",
      "Epoch 2529/5000\n",
      "ecpch:2528,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3146 - val_loss: 194.0368\n",
      "\n",
      "Epoch 02529: val_loss did not improve from 179.48197\n",
      "Epoch 2530/5000\n",
      "ecpch:2529,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3171 - val_loss: 194.0404\n",
      "\n",
      "Epoch 02530: val_loss did not improve from 179.48197\n",
      "Epoch 2531/5000\n",
      "ecpch:2530,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3159 - val_loss: 194.0432\n",
      "\n",
      "Epoch 02531: val_loss did not improve from 179.48197\n",
      "Epoch 2532/5000\n",
      "ecpch:2531,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3142 - val_loss: 194.0362\n",
      "\n",
      "Epoch 02532: val_loss did not improve from 179.48197\n",
      "Epoch 2533/5000\n",
      "ecpch:2532,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3147 - val_loss: 194.0366\n",
      "\n",
      "Epoch 02533: val_loss did not improve from 179.48197\n",
      "Epoch 2534/5000\n",
      "ecpch:2533,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3127 - val_loss: 194.0315\n",
      "\n",
      "Epoch 02534: val_loss did not improve from 179.48197\n",
      "Epoch 2535/5000\n",
      "ecpch:2534,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3122 - val_loss: 194.0399\n",
      "\n",
      "Epoch 02535: val_loss did not improve from 179.48197\n",
      "Epoch 2536/5000\n",
      "ecpch:2535,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3136 - val_loss: 194.0433\n",
      "\n",
      "Epoch 02536: val_loss did not improve from 179.48197\n",
      "Epoch 2537/5000\n",
      "ecpch:2536,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3119 - val_loss: 194.0401\n",
      "\n",
      "Epoch 02537: val_loss did not improve from 179.48197\n",
      "Epoch 2538/5000\n",
      "ecpch:2537,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3130 - val_loss: 194.0411\n",
      "\n",
      "Epoch 02538: val_loss did not improve from 179.48197\n",
      "Epoch 2539/5000\n",
      "ecpch:2538,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3119 - val_loss: 194.0373\n",
      "\n",
      "Epoch 02539: val_loss did not improve from 179.48197\n",
      "Epoch 2540/5000\n",
      "ecpch:2539,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3123 - val_loss: 194.0398\n",
      "\n",
      "Epoch 02540: val_loss did not improve from 179.48197\n",
      "Epoch 2541/5000\n",
      "ecpch:2540,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3120 - val_loss: 194.0480\n",
      "\n",
      "Epoch 02541: val_loss did not improve from 179.48197\n",
      "Epoch 2542/5000\n",
      "ecpch:2541,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3105 - val_loss: 194.0380\n",
      "\n",
      "Epoch 02542: val_loss did not improve from 179.48197\n",
      "Epoch 2543/5000\n",
      "ecpch:2542,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3112 - val_loss: 194.0424\n",
      "\n",
      "Epoch 02543: val_loss did not improve from 179.48197\n",
      "Epoch 2544/5000\n",
      "ecpch:2543,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3084 - val_loss: 194.0444\n",
      "\n",
      "Epoch 02544: val_loss did not improve from 179.48197\n",
      "Epoch 2545/5000\n",
      "ecpch:2544,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3102 - val_loss: 194.0394\n",
      "\n",
      "Epoch 02545: val_loss did not improve from 179.48197\n",
      "Epoch 2546/5000\n",
      "ecpch:2545,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3069 - val_loss: 194.0330\n",
      "\n",
      "Epoch 02546: val_loss did not improve from 179.48197\n",
      "Epoch 2547/5000\n",
      "ecpch:2546,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3110 - val_loss: 194.0371\n",
      "\n",
      "Epoch 02547: val_loss did not improve from 179.48197\n",
      "Epoch 2548/5000\n",
      "ecpch:2547,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3066 - val_loss: 194.0525\n",
      "\n",
      "Epoch 02548: val_loss did not improve from 179.48197\n",
      "Epoch 2549/5000\n",
      "ecpch:2548,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3128 - val_loss: 194.0452\n",
      "\n",
      "Epoch 02549: val_loss did not improve from 179.48197\n",
      "Epoch 2550/5000\n",
      "ecpch:2549,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3095 - val_loss: 194.0270\n",
      "\n",
      "Epoch 02550: val_loss did not improve from 179.48197\n",
      "Epoch 2551/5000\n",
      "ecpch:2550,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3096 - val_loss: 194.0245\n",
      "\n",
      "Epoch 02551: val_loss did not improve from 179.48197\n",
      "Epoch 2552/5000\n",
      "ecpch:2551,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3104 - val_loss: 194.0489\n",
      "\n",
      "Epoch 02552: val_loss did not improve from 179.48197\n",
      "Epoch 2553/5000\n",
      "ecpch:2552,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3050 - val_loss: 194.0484\n",
      "\n",
      "Epoch 02553: val_loss did not improve from 179.48197\n",
      "Epoch 2554/5000\n",
      "ecpch:2553,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3056 - val_loss: 194.0341\n",
      "\n",
      "Epoch 02554: val_loss did not improve from 179.48197\n",
      "Epoch 2555/5000\n",
      "ecpch:2554,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3050 - val_loss: 194.0391\n",
      "\n",
      "Epoch 02555: val_loss did not improve from 179.48197\n",
      "Epoch 2556/5000\n",
      "ecpch:2555,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3039 - val_loss: 194.0474\n",
      "\n",
      "Epoch 02556: val_loss did not improve from 179.48197\n",
      "Epoch 2557/5000\n",
      "ecpch:2556,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3052 - val_loss: 194.0440\n",
      "\n",
      "Epoch 02557: val_loss did not improve from 179.48197\n",
      "Epoch 2558/5000\n",
      "ecpch:2557,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3041 - val_loss: 194.0402\n",
      "\n",
      "Epoch 02558: val_loss did not improve from 179.48197\n",
      "Epoch 2559/5000\n",
      "ecpch:2558,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3036 - val_loss: 194.0482\n",
      "\n",
      "Epoch 02559: val_loss did not improve from 179.48197\n",
      "Epoch 2560/5000\n",
      "ecpch:2559,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3028 - val_loss: 194.0479\n",
      "\n",
      "Epoch 02560: val_loss did not improve from 179.48197\n",
      "Epoch 2561/5000\n",
      "ecpch:2560,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3024 - val_loss: 194.0400\n",
      "\n",
      "Epoch 02561: val_loss did not improve from 179.48197\n",
      "Epoch 2562/5000\n",
      "ecpch:2561,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3012 - val_loss: 194.0479\n",
      "\n",
      "Epoch 02562: val_loss did not improve from 179.48197\n",
      "Epoch 2563/5000\n",
      "ecpch:2562,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3016 - val_loss: 194.0516\n",
      "\n",
      "Epoch 02563: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 02563: ReduceLROnPlateau reducing learning rate to 1.855359641922405e-06.\n",
      "Epoch 2564/5000\n",
      "ecpch:2563,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3005 - val_loss: 194.0431\n",
      "\n",
      "Epoch 02564: val_loss did not improve from 179.48197\n",
      "Epoch 2565/5000\n",
      "ecpch:2564,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.3005 - val_loss: 194.0461\n",
      "\n",
      "Epoch 02565: val_loss did not improve from 179.48197\n",
      "Epoch 2566/5000\n",
      "ecpch:2565,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2995 - val_loss: 194.0532\n",
      "\n",
      "Epoch 02566: val_loss did not improve from 179.48197\n",
      "Epoch 2567/5000\n",
      "ecpch:2566,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3013 - val_loss: 194.0439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 02567: val_loss did not improve from 179.48197\n",
      "Epoch 2568/5000\n",
      "ecpch:2567,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2990 - val_loss: 194.0364\n",
      "\n",
      "Epoch 02568: val_loss did not improve from 179.48197\n",
      "Epoch 2569/5000\n",
      "ecpch:2568,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.3002 - val_loss: 194.0456\n",
      "\n",
      "Epoch 02569: val_loss did not improve from 179.48197\n",
      "Epoch 2570/5000\n",
      "ecpch:2569,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2981 - val_loss: 194.0510\n",
      "\n",
      "Epoch 02570: val_loss did not improve from 179.48197\n",
      "Epoch 2571/5000\n",
      "ecpch:2570,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2982 - val_loss: 194.0405\n",
      "\n",
      "Epoch 02571: val_loss did not improve from 179.48197\n",
      "Epoch 2572/5000\n",
      "ecpch:2571,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2979 - val_loss: 194.0506\n",
      "\n",
      "Epoch 02572: val_loss did not improve from 179.48197\n",
      "Epoch 2573/5000\n",
      "ecpch:2572,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2972 - val_loss: 194.0461\n",
      "\n",
      "Epoch 02573: val_loss did not improve from 179.48197\n",
      "Epoch 2574/5000\n",
      "ecpch:2573,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2964 - val_loss: 194.0470\n",
      "\n",
      "Epoch 02574: val_loss did not improve from 179.48197\n",
      "Epoch 2575/5000\n",
      "ecpch:2574,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2959 - val_loss: 194.0492\n",
      "\n",
      "Epoch 02575: val_loss did not improve from 179.48197\n",
      "Epoch 2576/5000\n",
      "ecpch:2575,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2956 - val_loss: 194.0433\n",
      "\n",
      "Epoch 02576: val_loss did not improve from 179.48197\n",
      "Epoch 2577/5000\n",
      "ecpch:2576,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2955 - val_loss: 194.0521\n",
      "\n",
      "Epoch 02577: val_loss did not improve from 179.48197\n",
      "Epoch 2578/5000\n",
      "ecpch:2577,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2956 - val_loss: 194.0511\n",
      "\n",
      "Epoch 02578: val_loss did not improve from 179.48197\n",
      "Epoch 2579/5000\n",
      "ecpch:2578,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2949 - val_loss: 194.0531\n",
      "\n",
      "Epoch 02579: val_loss did not improve from 179.48197\n",
      "Epoch 2580/5000\n",
      "ecpch:2579,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2940 - val_loss: 194.0504\n",
      "\n",
      "Epoch 02580: val_loss did not improve from 179.48197\n",
      "Epoch 2581/5000\n",
      "ecpch:2580,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2943 - val_loss: 194.0453\n",
      "\n",
      "Epoch 02581: val_loss did not improve from 179.48197\n",
      "Epoch 2582/5000\n",
      "ecpch:2581,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2944 - val_loss: 194.0578\n",
      "\n",
      "Epoch 02582: val_loss did not improve from 179.48197\n",
      "Epoch 2583/5000\n",
      "ecpch:2582,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2931 - val_loss: 194.0524\n",
      "\n",
      "Epoch 02583: val_loss did not improve from 179.48197\n",
      "Epoch 2584/5000\n",
      "ecpch:2583,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2928 - val_loss: 194.0515\n",
      "\n",
      "Epoch 02584: val_loss did not improve from 179.48197\n",
      "Epoch 2585/5000\n",
      "ecpch:2584,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2929 - val_loss: 194.0470\n",
      "\n",
      "Epoch 02585: val_loss did not improve from 179.48197\n",
      "Epoch 2586/5000\n",
      "ecpch:2585,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2919 - val_loss: 194.0484\n",
      "\n",
      "Epoch 02586: val_loss did not improve from 179.48197\n",
      "Epoch 2587/5000\n",
      "ecpch:2586,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2915 - val_loss: 194.0506\n",
      "\n",
      "Epoch 02587: val_loss did not improve from 179.48197\n",
      "Epoch 2588/5000\n",
      "ecpch:2587,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2922 - val_loss: 194.0524\n",
      "\n",
      "Epoch 02588: val_loss did not improve from 179.48197\n",
      "Epoch 2589/5000\n",
      "ecpch:2588,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2925 - val_loss: 194.0542\n",
      "\n",
      "Epoch 02589: val_loss did not improve from 179.48197\n",
      "Epoch 2590/5000\n",
      "ecpch:2589,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2908 - val_loss: 194.0478\n",
      "\n",
      "Epoch 02590: val_loss did not improve from 179.48197\n",
      "Epoch 2591/5000\n",
      "ecpch:2590,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2912 - val_loss: 194.0541\n",
      "\n",
      "Epoch 02591: val_loss did not improve from 179.48197\n",
      "Epoch 2592/5000\n",
      "ecpch:2591,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2901 - val_loss: 194.0537\n",
      "\n",
      "Epoch 02592: val_loss did not improve from 179.48197\n",
      "Epoch 2593/5000\n",
      "ecpch:2592,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2895 - val_loss: 194.0598\n",
      "\n",
      "Epoch 02593: val_loss did not improve from 179.48197\n",
      "Epoch 2594/5000\n",
      "ecpch:2593,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2907 - val_loss: 194.0503\n",
      "\n",
      "Epoch 02594: val_loss did not improve from 179.48197\n",
      "Epoch 2595/5000\n",
      "ecpch:2594,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2902 - val_loss: 194.0513\n",
      "\n",
      "Epoch 02595: val_loss did not improve from 179.48197\n",
      "Epoch 2596/5000\n",
      "ecpch:2595,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2883 - val_loss: 194.0648\n",
      "\n",
      "Epoch 02596: val_loss did not improve from 179.48197\n",
      "Epoch 2597/5000\n",
      "ecpch:2596,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2908 - val_loss: 194.0508\n",
      "\n",
      "Epoch 02597: val_loss did not improve from 179.48197\n",
      "Epoch 2598/5000\n",
      "ecpch:2597,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2887 - val_loss: 194.0488\n",
      "\n",
      "Epoch 02598: val_loss did not improve from 179.48197\n",
      "Epoch 2599/5000\n",
      "ecpch:2598,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2887 - val_loss: 194.0661\n",
      "\n",
      "Epoch 02599: val_loss did not improve from 179.48197\n",
      "Epoch 2600/5000\n",
      "ecpch:2599,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2900 - val_loss: 194.0543\n",
      "\n",
      "Epoch 02600: val_loss did not improve from 179.48197\n",
      "Epoch 2601/5000\n",
      "ecpch:2600,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2881 - val_loss: 194.0443\n",
      "\n",
      "Epoch 02601: val_loss did not improve from 179.48197\n",
      "Epoch 2602/5000\n",
      "ecpch:2601,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2921 - val_loss: 194.0525\n",
      "\n",
      "Epoch 02602: val_loss did not improve from 179.48197\n",
      "Epoch 2603/5000\n",
      "ecpch:2602,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2903 - val_loss: 194.0641\n",
      "\n",
      "Epoch 02603: val_loss did not improve from 179.48197\n",
      "Epoch 2604/5000\n",
      "ecpch:2603,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2898 - val_loss: 194.0589\n",
      "\n",
      "Epoch 02604: val_loss did not improve from 179.48197\n",
      "Epoch 2605/5000\n",
      "ecpch:2604,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2909 - val_loss: 194.0548\n",
      "\n",
      "Epoch 02605: val_loss did not improve from 179.48197\n",
      "Epoch 2606/5000\n",
      "ecpch:2605,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2870 - val_loss: 194.0521\n",
      "\n",
      "Epoch 02606: val_loss did not improve from 179.48197\n",
      "Epoch 2607/5000\n",
      "ecpch:2606,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2883 - val_loss: 194.0601\n",
      "\n",
      "Epoch 02607: val_loss did not improve from 179.48197\n",
      "Epoch 2608/5000\n",
      "ecpch:2607,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2874 - val_loss: 194.0568\n",
      "\n",
      "Epoch 02608: val_loss did not improve from 179.48197\n",
      "Epoch 2609/5000\n",
      "ecpch:2608,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2875 - val_loss: 194.0485\n",
      "\n",
      "Epoch 02609: val_loss did not improve from 179.48197\n",
      "Epoch 2610/5000\n",
      "ecpch:2609,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2859 - val_loss: 194.0530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 02610: val_loss did not improve from 179.48197\n",
      "Epoch 2611/5000\n",
      "ecpch:2610,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2872 - val_loss: 194.0654\n",
      "\n",
      "Epoch 02611: val_loss did not improve from 179.48197\n",
      "Epoch 2612/5000\n",
      "ecpch:2611,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2860 - val_loss: 194.0600\n",
      "\n",
      "Epoch 02612: val_loss did not improve from 179.48197\n",
      "Epoch 2613/5000\n",
      "ecpch:2612,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2856 - val_loss: 194.0543\n",
      "\n",
      "Epoch 02613: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 02613: ReduceLROnPlateau reducing learning rate to 1.6698236777301645e-06.\n",
      "Epoch 2614/5000\n",
      "ecpch:2613,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2847 - val_loss: 194.0575\n",
      "\n",
      "Epoch 02614: val_loss did not improve from 179.48197\n",
      "Epoch 2615/5000\n",
      "ecpch:2614,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2842 - val_loss: 194.0629\n",
      "\n",
      "Epoch 02615: val_loss did not improve from 179.48197\n",
      "Epoch 2616/5000\n",
      "ecpch:2615,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2839 - val_loss: 194.0580\n",
      "\n",
      "Epoch 02616: val_loss did not improve from 179.48197\n",
      "Epoch 2617/5000\n",
      "ecpch:2616,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2835 - val_loss: 194.0548\n",
      "\n",
      "Epoch 02617: val_loss did not improve from 179.48197\n",
      "Epoch 2618/5000\n",
      "ecpch:2617,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2830 - val_loss: 194.0605\n",
      "\n",
      "Epoch 02618: val_loss did not improve from 179.48197\n",
      "Epoch 2619/5000\n",
      "ecpch:2618,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2828 - val_loss: 194.0571\n",
      "\n",
      "Epoch 02619: val_loss did not improve from 179.48197\n",
      "Epoch 2620/5000\n",
      "ecpch:2619,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2819 - val_loss: 194.0603\n",
      "\n",
      "Epoch 02620: val_loss did not improve from 179.48197\n",
      "Epoch 2621/5000\n",
      "ecpch:2620,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2819 - val_loss: 194.0590\n",
      "\n",
      "Epoch 02621: val_loss did not improve from 179.48197\n",
      "Epoch 2622/5000\n",
      "ecpch:2621,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2812 - val_loss: 194.0561\n",
      "\n",
      "Epoch 02622: val_loss did not improve from 179.48197\n",
      "Epoch 2623/5000\n",
      "ecpch:2622,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2812 - val_loss: 194.0582\n",
      "\n",
      "Epoch 02623: val_loss did not improve from 179.48197\n",
      "Epoch 2624/5000\n",
      "ecpch:2623,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2798 - val_loss: 194.0570\n",
      "\n",
      "Epoch 02624: val_loss did not improve from 179.48197\n",
      "Epoch 2625/5000\n",
      "ecpch:2624,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2817 - val_loss: 194.0563\n",
      "\n",
      "Epoch 02625: val_loss did not improve from 179.48197\n",
      "Epoch 2626/5000\n",
      "ecpch:2625,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2800 - val_loss: 194.0584\n",
      "\n",
      "Epoch 02626: val_loss did not improve from 179.48197\n",
      "Epoch 2627/5000\n",
      "ecpch:2626,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2807 - val_loss: 194.0648\n",
      "\n",
      "Epoch 02627: val_loss did not improve from 179.48197\n",
      "Epoch 2628/5000\n",
      "ecpch:2627,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2805 - val_loss: 194.0623\n",
      "\n",
      "Epoch 02628: val_loss did not improve from 179.48197\n",
      "Epoch 2629/5000\n",
      "ecpch:2628,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2793 - val_loss: 194.0558\n",
      "\n",
      "Epoch 02629: val_loss did not improve from 179.48197\n",
      "Epoch 2630/5000\n",
      "ecpch:2629,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2787 - val_loss: 194.0616\n",
      "\n",
      "Epoch 02630: val_loss did not improve from 179.48197\n",
      "Epoch 2631/5000\n",
      "ecpch:2630,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2790 - val_loss: 194.0672\n",
      "\n",
      "Epoch 02631: val_loss did not improve from 179.48197\n",
      "Epoch 2632/5000\n",
      "ecpch:2631,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2780 - val_loss: 194.0571\n",
      "\n",
      "Epoch 02632: val_loss did not improve from 179.48197\n",
      "Epoch 2633/5000\n",
      "ecpch:2632,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2787 - val_loss: 194.0601\n",
      "\n",
      "Epoch 02633: val_loss did not improve from 179.48197\n",
      "Epoch 2634/5000\n",
      "ecpch:2633,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2773 - val_loss: 194.0622\n",
      "\n",
      "Epoch 02634: val_loss did not improve from 179.48197\n",
      "Epoch 2635/5000\n",
      "ecpch:2634,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2791 - val_loss: 194.0625\n",
      "\n",
      "Epoch 02635: val_loss did not improve from 179.48197\n",
      "Epoch 2636/5000\n",
      "ecpch:2635,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2772 - val_loss: 194.0602\n",
      "\n",
      "Epoch 02636: val_loss did not improve from 179.48197\n",
      "Epoch 2637/5000\n",
      "ecpch:2636,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 55.2775 - val_loss: 194.0690\n",
      "\n",
      "Epoch 02637: val_loss did not improve from 179.48197\n",
      "Epoch 2638/5000\n",
      "ecpch:2637,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2766 - val_loss: 194.0618\n",
      "\n",
      "Epoch 02638: val_loss did not improve from 179.48197\n",
      "Epoch 2639/5000\n",
      "ecpch:2638,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2766 - val_loss: 194.0634\n",
      "\n",
      "Epoch 02639: val_loss did not improve from 179.48197\n",
      "Epoch 2640/5000\n",
      "ecpch:2639,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2761 - val_loss: 194.0621\n",
      "\n",
      "Epoch 02640: val_loss did not improve from 179.48197\n",
      "Epoch 2641/5000\n",
      "ecpch:2640,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2755 - val_loss: 194.0601\n",
      "\n",
      "Epoch 02641: val_loss did not improve from 179.48197\n",
      "Epoch 2642/5000\n",
      "ecpch:2641,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2764 - val_loss: 194.0657\n",
      "\n",
      "Epoch 02642: val_loss did not improve from 179.48197\n",
      "Epoch 2643/5000\n",
      "ecpch:2642,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2738 - val_loss: 194.0795\n",
      "\n",
      "Epoch 02643: val_loss did not improve from 179.48197\n",
      "Epoch 2644/5000\n",
      "ecpch:2643,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2782 - val_loss: 194.0700\n",
      "\n",
      "Epoch 02644: val_loss did not improve from 179.48197\n",
      "Epoch 2645/5000\n",
      "ecpch:2644,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2747 - val_loss: 194.0591\n",
      "\n",
      "Epoch 02645: val_loss did not improve from 179.48197\n",
      "Epoch 2646/5000\n",
      "ecpch:2645,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2775 - val_loss: 194.0509\n",
      "\n",
      "Epoch 02646: val_loss did not improve from 179.48197\n",
      "Epoch 2647/5000\n",
      "ecpch:2646,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2772 - val_loss: 194.0667\n",
      "\n",
      "Epoch 02647: val_loss did not improve from 179.48197\n",
      "Epoch 2648/5000\n",
      "ecpch:2647,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2723 - val_loss: 194.0665\n",
      "\n",
      "Epoch 02648: val_loss did not improve from 179.48197\n",
      "Epoch 2649/5000\n",
      "ecpch:2648,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2728 - val_loss: 194.0602\n",
      "\n",
      "Epoch 02649: val_loss did not improve from 179.48197\n",
      "Epoch 2650/5000\n",
      "ecpch:2649,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2735 - val_loss: 194.0565\n",
      "\n",
      "Epoch 02650: val_loss did not improve from 179.48197\n",
      "Epoch 2651/5000\n",
      "ecpch:2650,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2724 - val_loss: 194.0671\n",
      "\n",
      "Epoch 02651: val_loss did not improve from 179.48197\n",
      "Epoch 2652/5000\n",
      "ecpch:2651,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2733 - val_loss: 194.0718\n",
      "\n",
      "Epoch 02652: val_loss did not improve from 179.48197\n",
      "Epoch 2653/5000\n",
      "ecpch:2652,learn rate 0.000002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2708 - val_loss: 194.0616\n",
      "\n",
      "Epoch 02653: val_loss did not improve from 179.48197\n",
      "Epoch 2654/5000\n",
      "ecpch:2653,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2727 - val_loss: 194.0628\n",
      "\n",
      "Epoch 02654: val_loss did not improve from 179.48197\n",
      "Epoch 2655/5000\n",
      "ecpch:2654,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2708 - val_loss: 194.0744\n",
      "\n",
      "Epoch 02655: val_loss did not improve from 179.48197\n",
      "Epoch 2656/5000\n",
      "ecpch:2655,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2726 - val_loss: 194.0733\n",
      "\n",
      "Epoch 02656: val_loss did not improve from 179.48197\n",
      "Epoch 2657/5000\n",
      "ecpch:2656,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2702 - val_loss: 194.0528\n",
      "\n",
      "Epoch 02657: val_loss did not improve from 179.48197\n",
      "Epoch 2658/5000\n",
      "ecpch:2657,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2736 - val_loss: 194.0572\n",
      "\n",
      "Epoch 02658: val_loss did not improve from 179.48197\n",
      "Epoch 2659/5000\n",
      "ecpch:2658,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2729 - val_loss: 194.0718\n",
      "\n",
      "Epoch 02659: val_loss did not improve from 179.48197\n",
      "Epoch 2660/5000\n",
      "ecpch:2659,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2692 - val_loss: 194.0750\n",
      "\n",
      "Epoch 02660: val_loss did not improve from 179.48197\n",
      "Epoch 2661/5000\n",
      "ecpch:2660,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2702 - val_loss: 194.0661\n",
      "\n",
      "Epoch 02661: val_loss did not improve from 179.48197\n",
      "Epoch 2662/5000\n",
      "ecpch:2661,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2687 - val_loss: 194.0655\n",
      "\n",
      "Epoch 02662: val_loss did not improve from 179.48197\n",
      "Epoch 2663/5000\n",
      "ecpch:2662,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2687 - val_loss: 194.0716\n",
      "\n",
      "Epoch 02663: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 02663: ReduceLROnPlateau reducing learning rate to 1.5028412690298864e-06.\n",
      "Epoch 2664/5000\n",
      "ecpch:2663,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2679 - val_loss: 194.0775\n",
      "\n",
      "Epoch 02664: val_loss did not improve from 179.48197\n",
      "Epoch 2665/5000\n",
      "ecpch:2664,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2678 - val_loss: 194.0644\n",
      "\n",
      "Epoch 02665: val_loss did not improve from 179.48197\n",
      "Epoch 2666/5000\n",
      "ecpch:2665,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2670 - val_loss: 194.0607\n",
      "\n",
      "Epoch 02666: val_loss did not improve from 179.48197\n",
      "Epoch 2667/5000\n",
      "ecpch:2666,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2667 - val_loss: 194.0767\n",
      "\n",
      "Epoch 02667: val_loss did not improve from 179.48197\n",
      "Epoch 2668/5000\n",
      "ecpch:2667,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2665 - val_loss: 194.0716\n",
      "\n",
      "Epoch 02668: val_loss did not improve from 179.48197\n",
      "Epoch 2669/5000\n",
      "ecpch:2668,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2667 - val_loss: 194.0629\n",
      "\n",
      "Epoch 02669: val_loss did not improve from 179.48197\n",
      "Epoch 2670/5000\n",
      "ecpch:2669,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2656 - val_loss: 194.0700\n",
      "\n",
      "Epoch 02670: val_loss did not improve from 179.48197\n",
      "Epoch 2671/5000\n",
      "ecpch:2670,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2655 - val_loss: 194.0739\n",
      "\n",
      "Epoch 02671: val_loss did not improve from 179.48197\n",
      "Epoch 2672/5000\n",
      "ecpch:2671,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2653 - val_loss: 194.0740\n",
      "\n",
      "Epoch 02672: val_loss did not improve from 179.48197\n",
      "Epoch 2673/5000\n",
      "ecpch:2672,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2641 - val_loss: 194.0655\n",
      "\n",
      "Epoch 02673: val_loss did not improve from 179.48197\n",
      "Epoch 2674/5000\n",
      "ecpch:2673,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2653 - val_loss: 194.0708\n",
      "\n",
      "Epoch 02674: val_loss did not improve from 179.48197\n",
      "Epoch 2675/5000\n",
      "ecpch:2674,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2635 - val_loss: 194.0855\n",
      "\n",
      "Epoch 02675: val_loss did not improve from 179.48197\n",
      "Epoch 2676/5000\n",
      "ecpch:2675,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2659 - val_loss: 194.0707\n",
      "\n",
      "Epoch 02676: val_loss did not improve from 179.48197\n",
      "Epoch 2677/5000\n",
      "ecpch:2676,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2626 - val_loss: 194.0639\n",
      "\n",
      "Epoch 02677: val_loss did not improve from 179.48197\n",
      "Epoch 2678/5000\n",
      "ecpch:2677,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2661 - val_loss: 194.0693\n",
      "\n",
      "Epoch 02678: val_loss did not improve from 179.48197\n",
      "Epoch 2679/5000\n",
      "ecpch:2678,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2637 - val_loss: 194.0811\n",
      "\n",
      "Epoch 02679: val_loss did not improve from 179.48197\n",
      "Epoch 2680/5000\n",
      "ecpch:2679,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2663 - val_loss: 194.0807\n",
      "\n",
      "Epoch 02680: val_loss did not improve from 179.48197\n",
      "Epoch 2681/5000\n",
      "ecpch:2680,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2652 - val_loss: 194.0654\n",
      "\n",
      "Epoch 02681: val_loss did not improve from 179.48197\n",
      "Epoch 2682/5000\n",
      "ecpch:2681,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2635 - val_loss: 194.0591\n",
      "\n",
      "Epoch 02682: val_loss did not improve from 179.48197\n",
      "Epoch 2683/5000\n",
      "ecpch:2682,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2640 - val_loss: 194.0764\n",
      "\n",
      "Epoch 02683: val_loss did not improve from 179.48197\n",
      "Epoch 2684/5000\n",
      "ecpch:2683,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2616 - val_loss: 194.0759\n",
      "\n",
      "Epoch 02684: val_loss did not improve from 179.48197\n",
      "Epoch 2685/5000\n",
      "ecpch:2684,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2612 - val_loss: 194.0678\n",
      "\n",
      "Epoch 02685: val_loss did not improve from 179.48197\n",
      "Epoch 2686/5000\n",
      "ecpch:2685,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2626 - val_loss: 194.0725\n",
      "\n",
      "Epoch 02686: val_loss did not improve from 179.48197\n",
      "Epoch 2687/5000\n",
      "ecpch:2686,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2608 - val_loss: 194.0741\n",
      "\n",
      "Epoch 02687: val_loss did not improve from 179.48197\n",
      "Epoch 2688/5000\n",
      "ecpch:2687,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2622 - val_loss: 194.0740\n",
      "\n",
      "Epoch 02688: val_loss did not improve from 179.48197\n",
      "Epoch 2689/5000\n",
      "ecpch:2688,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2601 - val_loss: 194.0695\n",
      "\n",
      "Epoch 02689: val_loss did not improve from 179.48197\n",
      "Epoch 2690/5000\n",
      "ecpch:2689,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2615 - val_loss: 194.0691\n",
      "\n",
      "Epoch 02690: val_loss did not improve from 179.48197\n",
      "Epoch 2691/5000\n",
      "ecpch:2690,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2600 - val_loss: 194.0794\n",
      "\n",
      "Epoch 02691: val_loss did not improve from 179.48197\n",
      "Epoch 2692/5000\n",
      "ecpch:2691,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2607 - val_loss: 194.0811\n",
      "\n",
      "Epoch 02692: val_loss did not improve from 179.48197\n",
      "Epoch 2693/5000\n",
      "ecpch:2692,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2588 - val_loss: 194.0668\n",
      "\n",
      "Epoch 02693: val_loss did not improve from 179.48197\n",
      "Epoch 2694/5000\n",
      "ecpch:2693,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2598 - val_loss: 194.0736\n",
      "\n",
      "Epoch 02694: val_loss did not improve from 179.48197\n",
      "Epoch 2695/5000\n",
      "ecpch:2694,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2587 - val_loss: 194.0807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 02695: val_loss did not improve from 179.48197\n",
      "Epoch 2696/5000\n",
      "ecpch:2695,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2593 - val_loss: 194.0786\n",
      "\n",
      "Epoch 02696: val_loss did not improve from 179.48197\n",
      "Epoch 2697/5000\n",
      "ecpch:2696,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2576 - val_loss: 194.0730\n",
      "\n",
      "Epoch 02697: val_loss did not improve from 179.48197\n",
      "Epoch 2698/5000\n",
      "ecpch:2697,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2589 - val_loss: 194.0677\n",
      "\n",
      "Epoch 02698: val_loss did not improve from 179.48197\n",
      "Epoch 2699/5000\n",
      "ecpch:2698,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2569 - val_loss: 194.0722\n",
      "\n",
      "Epoch 02699: val_loss did not improve from 179.48197\n",
      "Epoch 2700/5000\n",
      "ecpch:2699,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2588 - val_loss: 194.0837\n",
      "\n",
      "Epoch 02700: val_loss did not improve from 179.48197\n",
      "Epoch 2701/5000\n",
      "ecpch:2700,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2566 - val_loss: 194.0719\n",
      "\n",
      "Epoch 02701: val_loss did not improve from 179.48197\n",
      "Epoch 2702/5000\n",
      "ecpch:2701,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2592 - val_loss: 194.0713\n",
      "\n",
      "Epoch 02702: val_loss did not improve from 179.48197\n",
      "Epoch 2703/5000\n",
      "ecpch:2702,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2577 - val_loss: 194.0822\n",
      "\n",
      "Epoch 02703: val_loss did not improve from 179.48197\n",
      "Epoch 2704/5000\n",
      "ecpch:2703,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2577 - val_loss: 194.0835\n",
      "\n",
      "Epoch 02704: val_loss did not improve from 179.48197\n",
      "Epoch 2705/5000\n",
      "ecpch:2704,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2576 - val_loss: 194.0733\n",
      "\n",
      "Epoch 02705: val_loss did not improve from 179.48197\n",
      "Epoch 2706/5000\n",
      "ecpch:2705,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2564 - val_loss: 194.0720\n",
      "\n",
      "Epoch 02706: val_loss did not improve from 179.48197\n",
      "Epoch 2707/5000\n",
      "ecpch:2706,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2569 - val_loss: 194.0849\n",
      "\n",
      "Epoch 02707: val_loss did not improve from 179.48197\n",
      "Epoch 2708/5000\n",
      "ecpch:2707,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2549 - val_loss: 194.0836\n",
      "\n",
      "Epoch 02708: val_loss did not improve from 179.48197\n",
      "Epoch 2709/5000\n",
      "ecpch:2708,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2558 - val_loss: 194.0768\n",
      "\n",
      "Epoch 02709: val_loss did not improve from 179.48197\n",
      "Epoch 2710/5000\n",
      "ecpch:2709,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2546 - val_loss: 194.0737\n",
      "\n",
      "Epoch 02710: val_loss did not improve from 179.48197\n",
      "Epoch 2711/5000\n",
      "ecpch:2710,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2555 - val_loss: 194.0787\n",
      "\n",
      "Epoch 02711: val_loss did not improve from 179.48197\n",
      "Epoch 2712/5000\n",
      "ecpch:2711,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2531 - val_loss: 194.0856\n",
      "\n",
      "Epoch 02712: val_loss did not improve from 179.48197\n",
      "Epoch 2713/5000\n",
      "ecpch:2712,learn rate 0.000002\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2544 - val_loss: 194.0793\n",
      "\n",
      "Epoch 02713: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 02713: ReduceLROnPlateau reducing learning rate to 1.3525571830541595e-06.\n",
      "Epoch 2714/5000\n",
      "ecpch:2713,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2526 - val_loss: 194.0750\n",
      "\n",
      "Epoch 02714: val_loss did not improve from 179.48197\n",
      "Epoch 2715/5000\n",
      "ecpch:2714,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2528 - val_loss: 194.0808\n",
      "\n",
      "Epoch 02715: val_loss did not improve from 179.48197\n",
      "Epoch 2716/5000\n",
      "ecpch:2715,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2517 - val_loss: 194.0811\n",
      "\n",
      "Epoch 02716: val_loss did not improve from 179.48197\n",
      "Epoch 2717/5000\n",
      "ecpch:2716,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2527 - val_loss: 194.0777\n",
      "\n",
      "Epoch 02717: val_loss did not improve from 179.48197\n",
      "Epoch 2718/5000\n",
      "ecpch:2717,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2515 - val_loss: 194.0758\n",
      "\n",
      "Epoch 02718: val_loss did not improve from 179.48197\n",
      "Epoch 2719/5000\n",
      "ecpch:2718,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2517 - val_loss: 194.0890\n",
      "\n",
      "Epoch 02719: val_loss did not improve from 179.48197\n",
      "Epoch 2720/5000\n",
      "ecpch:2719,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2511 - val_loss: 194.0781\n",
      "\n",
      "Epoch 02720: val_loss did not improve from 179.48197\n",
      "Epoch 2721/5000\n",
      "ecpch:2720,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2505 - val_loss: 194.0768\n",
      "\n",
      "Epoch 02721: val_loss did not improve from 179.48197\n",
      "Epoch 2722/5000\n",
      "ecpch:2721,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2510 - val_loss: 194.0820\n",
      "\n",
      "Epoch 02722: val_loss did not improve from 179.48197\n",
      "Epoch 2723/5000\n",
      "ecpch:2722,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2497 - val_loss: 194.0859\n",
      "\n",
      "Epoch 02723: val_loss did not improve from 179.48197\n",
      "Epoch 2724/5000\n",
      "ecpch:2723,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2507 - val_loss: 194.0848\n",
      "\n",
      "Epoch 02724: val_loss did not improve from 179.48197\n",
      "Epoch 2725/5000\n",
      "ecpch:2724,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 55.2493 - val_loss: 194.0782\n",
      "\n",
      "Epoch 02725: val_loss did not improve from 179.48197\n",
      "Epoch 2726/5000\n",
      "ecpch:2725,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2490 - val_loss: 194.0825\n",
      "\n",
      "Epoch 02726: val_loss did not improve from 179.48197\n",
      "Epoch 2727/5000\n",
      "ecpch:2726,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2495 - val_loss: 194.0829\n",
      "\n",
      "Epoch 02727: val_loss did not improve from 179.48197\n",
      "Epoch 2728/5000\n",
      "ecpch:2727,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2484 - val_loss: 194.0806\n",
      "\n",
      "Epoch 02728: val_loss did not improve from 179.48197\n",
      "Epoch 2729/5000\n",
      "ecpch:2728,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2486 - val_loss: 194.0802\n",
      "\n",
      "Epoch 02729: val_loss did not improve from 179.48197\n",
      "Epoch 2730/5000\n",
      "ecpch:2729,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2488 - val_loss: 194.0887\n",
      "\n",
      "Epoch 02730: val_loss did not improve from 179.48197\n",
      "Epoch 2731/5000\n",
      "ecpch:2730,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2481 - val_loss: 194.0804\n",
      "\n",
      "Epoch 02731: val_loss did not improve from 179.48197\n",
      "Epoch 2732/5000\n",
      "ecpch:2731,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2487 - val_loss: 194.0774\n",
      "\n",
      "Epoch 02732: val_loss did not improve from 179.48197\n",
      "Epoch 2733/5000\n",
      "ecpch:2732,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2481 - val_loss: 194.0856\n",
      "\n",
      "Epoch 02733: val_loss did not improve from 179.48197\n",
      "Epoch 2734/5000\n",
      "ecpch:2733,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2480 - val_loss: 194.0857\n",
      "\n",
      "Epoch 02734: val_loss did not improve from 179.48197\n",
      "Epoch 2735/5000\n",
      "ecpch:2734,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2466 - val_loss: 194.0824\n",
      "\n",
      "Epoch 02735: val_loss did not improve from 179.48197\n",
      "Epoch 2736/5000\n",
      "ecpch:2735,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2475 - val_loss: 194.0845\n",
      "\n",
      "Epoch 02736: val_loss did not improve from 179.48197\n",
      "Epoch 2737/5000\n",
      "ecpch:2736,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2460 - val_loss: 194.0835\n",
      "\n",
      "Epoch 02737: val_loss did not improve from 179.48197\n",
      "Epoch 2738/5000\n",
      "ecpch:2737,learn rate 0.000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2469 - val_loss: 194.0834\n",
      "\n",
      "Epoch 02738: val_loss did not improve from 179.48197\n",
      "Epoch 2739/5000\n",
      "ecpch:2738,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2455 - val_loss: 194.0863\n",
      "\n",
      "Epoch 02739: val_loss did not improve from 179.48197\n",
      "Epoch 2740/5000\n",
      "ecpch:2739,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2454 - val_loss: 194.0844\n",
      "\n",
      "Epoch 02740: val_loss did not improve from 179.48197\n",
      "Epoch 2741/5000\n",
      "ecpch:2740,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2460 - val_loss: 194.0837\n",
      "\n",
      "Epoch 02741: val_loss did not improve from 179.48197\n",
      "Epoch 2742/5000\n",
      "ecpch:2741,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2443 - val_loss: 194.0845\n",
      "\n",
      "Epoch 02742: val_loss did not improve from 179.48197\n",
      "Epoch 2743/5000\n",
      "ecpch:2742,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2453 - val_loss: 194.0855\n",
      "\n",
      "Epoch 02743: val_loss did not improve from 179.48197\n",
      "Epoch 2744/5000\n",
      "ecpch:2743,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2444 - val_loss: 194.0818\n",
      "\n",
      "Epoch 02744: val_loss did not improve from 179.48197\n",
      "Epoch 2745/5000\n",
      "ecpch:2744,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2441 - val_loss: 194.0769\n",
      "\n",
      "Epoch 02745: val_loss did not improve from 179.48197\n",
      "Epoch 2746/5000\n",
      "ecpch:2745,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2446 - val_loss: 194.0859\n",
      "\n",
      "Epoch 02746: val_loss did not improve from 179.48197\n",
      "Epoch 2747/5000\n",
      "ecpch:2746,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2431 - val_loss: 194.0875\n",
      "\n",
      "Epoch 02747: val_loss did not improve from 179.48197\n",
      "Epoch 2748/5000\n",
      "ecpch:2747,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2445 - val_loss: 194.0838\n",
      "\n",
      "Epoch 02748: val_loss did not improve from 179.48197\n",
      "Epoch 2749/5000\n",
      "ecpch:2748,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2428 - val_loss: 194.0803\n",
      "\n",
      "Epoch 02749: val_loss did not improve from 179.48197\n",
      "Epoch 2750/5000\n",
      "ecpch:2749,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2434 - val_loss: 194.0871\n",
      "\n",
      "Epoch 02750: val_loss did not improve from 179.48197\n",
      "Epoch 2751/5000\n",
      "ecpch:2750,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2433 - val_loss: 194.0821\n",
      "\n",
      "Epoch 02751: val_loss did not improve from 179.48197\n",
      "Epoch 2752/5000\n",
      "ecpch:2751,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2418 - val_loss: 194.0869\n",
      "\n",
      "Epoch 02752: val_loss did not improve from 179.48197\n",
      "Epoch 2753/5000\n",
      "ecpch:2752,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2440 - val_loss: 194.0861\n",
      "\n",
      "Epoch 02753: val_loss did not improve from 179.48197\n",
      "Epoch 2754/5000\n",
      "ecpch:2753,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2411 - val_loss: 194.0859\n",
      "\n",
      "Epoch 02754: val_loss did not improve from 179.48197\n",
      "Epoch 2755/5000\n",
      "ecpch:2754,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2423 - val_loss: 194.0806\n",
      "\n",
      "Epoch 02755: val_loss did not improve from 179.48197\n",
      "Epoch 2756/5000\n",
      "ecpch:2755,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2421 - val_loss: 194.0885\n",
      "\n",
      "Epoch 02756: val_loss did not improve from 179.48197\n",
      "Epoch 2757/5000\n",
      "ecpch:2756,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2404 - val_loss: 194.0871\n",
      "\n",
      "Epoch 02757: val_loss did not improve from 179.48197\n",
      "Epoch 2758/5000\n",
      "ecpch:2757,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2418 - val_loss: 194.0839\n",
      "\n",
      "Epoch 02758: val_loss did not improve from 179.48197\n",
      "Epoch 2759/5000\n",
      "ecpch:2758,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2403 - val_loss: 194.0878\n",
      "\n",
      "Epoch 02759: val_loss did not improve from 179.48197\n",
      "Epoch 2760/5000\n",
      "ecpch:2759,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2398 - val_loss: 194.0909\n",
      "\n",
      "Epoch 02760: val_loss did not improve from 179.48197\n",
      "Epoch 2761/5000\n",
      "ecpch:2760,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2395 - val_loss: 194.0886\n",
      "\n",
      "Epoch 02761: val_loss did not improve from 179.48197\n",
      "Epoch 2762/5000\n",
      "ecpch:2761,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2394 - val_loss: 194.0859\n",
      "\n",
      "Epoch 02762: val_loss did not improve from 179.48197\n",
      "Epoch 2763/5000\n",
      "ecpch:2762,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2394 - val_loss: 194.0852\n",
      "\n",
      "Epoch 02763: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 02763: ReduceLROnPlateau reducing learning rate to 1.2173014852123742e-06.\n",
      "Epoch 2764/5000\n",
      "ecpch:2763,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2389 - val_loss: 194.0866\n",
      "\n",
      "Epoch 02764: val_loss did not improve from 179.48197\n",
      "Epoch 2765/5000\n",
      "ecpch:2764,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2396 - val_loss: 194.0920\n",
      "\n",
      "Epoch 02765: val_loss did not improve from 179.48197\n",
      "Epoch 2766/5000\n",
      "ecpch:2765,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2384 - val_loss: 194.0939\n",
      "\n",
      "Epoch 02766: val_loss did not improve from 179.48197\n",
      "Epoch 2767/5000\n",
      "ecpch:2766,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2384 - val_loss: 194.0838\n",
      "\n",
      "Epoch 02767: val_loss did not improve from 179.48197\n",
      "Epoch 2768/5000\n",
      "ecpch:2767,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 55.2387 - val_loss: 194.0881\n",
      "\n",
      "Epoch 02768: val_loss did not improve from 179.48197\n",
      "Epoch 2769/5000\n",
      "ecpch:2768,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2380 - val_loss: 194.0931\n",
      "\n",
      "Epoch 02769: val_loss did not improve from 179.48197\n",
      "Epoch 2770/5000\n",
      "ecpch:2769,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2381 - val_loss: 194.0917\n",
      "\n",
      "Epoch 02770: val_loss did not improve from 179.48197\n",
      "Epoch 2771/5000\n",
      "ecpch:2770,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2371 - val_loss: 194.0870\n",
      "\n",
      "Epoch 02771: val_loss did not improve from 179.48197\n",
      "Epoch 2772/5000\n",
      "ecpch:2771,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2385 - val_loss: 194.0908\n",
      "\n",
      "Epoch 02772: val_loss did not improve from 179.48197\n",
      "Epoch 2773/5000\n",
      "ecpch:2772,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2364 - val_loss: 194.0901\n",
      "\n",
      "Epoch 02773: val_loss did not improve from 179.48197\n",
      "Epoch 2774/5000\n",
      "ecpch:2773,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2368 - val_loss: 194.0900\n",
      "\n",
      "Epoch 02774: val_loss did not improve from 179.48197\n",
      "Epoch 2775/5000\n",
      "ecpch:2774,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2378 - val_loss: 194.0873\n",
      "\n",
      "Epoch 02775: val_loss did not improve from 179.48197\n",
      "Epoch 2776/5000\n",
      "ecpch:2775,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2359 - val_loss: 194.0938\n",
      "\n",
      "Epoch 02776: val_loss did not improve from 179.48197\n",
      "Epoch 2777/5000\n",
      "ecpch:2776,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2396 - val_loss: 194.0913\n",
      "\n",
      "Epoch 02777: val_loss did not improve from 179.48197\n",
      "Epoch 2778/5000\n",
      "ecpch:2777,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2371 - val_loss: 194.0861\n",
      "\n",
      "Epoch 02778: val_loss did not improve from 179.48197\n",
      "Epoch 2779/5000\n",
      "ecpch:2778,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2391 - val_loss: 194.0891\n",
      "\n",
      "Epoch 02779: val_loss did not improve from 179.48197\n",
      "Epoch 2780/5000\n",
      "ecpch:2779,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2397 - val_loss: 194.0934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 02780: val_loss did not improve from 179.48197\n",
      "Epoch 2781/5000\n",
      "ecpch:2780,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2348 - val_loss: 194.0971\n",
      "\n",
      "Epoch 02781: val_loss did not improve from 179.48197\n",
      "Epoch 2782/5000\n",
      "ecpch:2781,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2378 - val_loss: 194.0945\n",
      "\n",
      "Epoch 02782: val_loss did not improve from 179.48197\n",
      "Epoch 2783/5000\n",
      "ecpch:2782,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2357 - val_loss: 194.0881\n",
      "\n",
      "Epoch 02783: val_loss did not improve from 179.48197\n",
      "Epoch 2784/5000\n",
      "ecpch:2783,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2371 - val_loss: 194.0943\n",
      "\n",
      "Epoch 02784: val_loss did not improve from 179.48197\n",
      "Epoch 2785/5000\n",
      "ecpch:2784,learn rate 0.000001\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 55.2371 - val_loss: 194.0956\n",
      "\n",
      "Epoch 02785: val_loss did not improve from 179.48197\n",
      "Epoch 2786/5000\n",
      "ecpch:2785,learn rate 0.000001\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 55.2347 - val_loss: 194.0868\n",
      "\n",
      "Epoch 02786: val_loss did not improve from 179.48197\n",
      "Epoch 2787/5000\n",
      "ecpch:2786,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2368 - val_loss: 194.0893\n",
      "\n",
      "Epoch 02787: val_loss did not improve from 179.48197\n",
      "Epoch 2788/5000\n",
      "ecpch:2787,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2342 - val_loss: 194.0918\n",
      "\n",
      "Epoch 02788: val_loss did not improve from 179.48197\n",
      "Epoch 2789/5000\n",
      "ecpch:2788,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2370 - val_loss: 194.0962\n",
      "\n",
      "Epoch 02789: val_loss did not improve from 179.48197\n",
      "Epoch 2790/5000\n",
      "ecpch:2789,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2363 - val_loss: 194.0940\n",
      "\n",
      "Epoch 02790: val_loss did not improve from 179.48197\n",
      "Epoch 2791/5000\n",
      "ecpch:2790,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2331 - val_loss: 194.0893\n",
      "\n",
      "Epoch 02791: val_loss did not improve from 179.48197\n",
      "Epoch 2792/5000\n",
      "ecpch:2791,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2341 - val_loss: 194.0896\n",
      "\n",
      "Epoch 02792: val_loss did not improve from 179.48197\n",
      "Epoch 2793/5000\n",
      "ecpch:2792,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 55.2330 - val_loss: 194.0998\n",
      "\n",
      "Epoch 02793: val_loss did not improve from 179.48197\n",
      "Epoch 2794/5000\n",
      "ecpch:2793,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2336 - val_loss: 194.0929\n",
      "\n",
      "Epoch 02794: val_loss did not improve from 179.48197\n",
      "Epoch 2795/5000\n",
      "ecpch:2794,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2317 - val_loss: 194.0902\n",
      "\n",
      "Epoch 02795: val_loss did not improve from 179.48197\n",
      "Epoch 2796/5000\n",
      "ecpch:2795,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2321 - val_loss: 194.0954\n",
      "\n",
      "Epoch 02796: val_loss did not improve from 179.48197\n",
      "Epoch 2797/5000\n",
      "ecpch:2796,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2315 - val_loss: 194.0912\n",
      "\n",
      "Epoch 02797: val_loss did not improve from 179.48197\n",
      "Epoch 2798/5000\n",
      "ecpch:2797,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2311 - val_loss: 194.0907\n",
      "\n",
      "Epoch 02798: val_loss did not improve from 179.48197\n",
      "Epoch 2799/5000\n",
      "ecpch:2798,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 55.2322 - val_loss: 194.0948\n",
      "\n",
      "Epoch 02799: val_loss did not improve from 179.48197\n",
      "Epoch 2800/5000\n",
      "ecpch:2799,learn rate 0.000001\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 55.2303 - val_loss: 194.0995\n",
      "\n",
      "Epoch 02800: val_loss did not improve from 179.48197\n",
      "Epoch 2801/5000\n",
      "ecpch:2800,learn rate 0.000001\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 55.2328 - val_loss: 194.0958\n",
      "\n",
      "Epoch 02801: val_loss did not improve from 179.48197\n",
      "Epoch 2802/5000\n",
      "ecpch:2801,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2304 - val_loss: 194.0943\n",
      "\n",
      "Epoch 02802: val_loss did not improve from 179.48197\n",
      "Epoch 2803/5000\n",
      "ecpch:2802,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2332 - val_loss: 194.0909\n",
      "\n",
      "Epoch 02803: val_loss did not improve from 179.48197\n",
      "Epoch 2804/5000\n",
      "ecpch:2803,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2328 - val_loss: 194.0981\n",
      "\n",
      "Epoch 02804: val_loss did not improve from 179.48197\n",
      "Epoch 2805/5000\n",
      "ecpch:2804,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2297 - val_loss: 194.0969\n",
      "\n",
      "Epoch 02805: val_loss did not improve from 179.48197\n",
      "Epoch 2806/5000\n",
      "ecpch:2805,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2299 - val_loss: 194.0903\n",
      "\n",
      "Epoch 02806: val_loss did not improve from 179.48197\n",
      "Epoch 2807/5000\n",
      "ecpch:2806,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2304 - val_loss: 194.0934\n",
      "\n",
      "Epoch 02807: val_loss did not improve from 179.48197\n",
      "Epoch 2808/5000\n",
      "ecpch:2807,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2292 - val_loss: 194.1018\n",
      "\n",
      "Epoch 02808: val_loss did not improve from 179.48197\n",
      "Epoch 2809/5000\n",
      "ecpch:2808,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2309 - val_loss: 194.0996\n",
      "\n",
      "Epoch 02809: val_loss did not improve from 179.48197\n",
      "Epoch 2810/5000\n",
      "ecpch:2809,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2290 - val_loss: 194.0893\n",
      "\n",
      "Epoch 02810: val_loss did not improve from 179.48197\n",
      "Epoch 2811/5000\n",
      "ecpch:2810,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 55.2310 - val_loss: 194.0851\n",
      "\n",
      "Epoch 02811: val_loss did not improve from 179.48197\n",
      "Epoch 2812/5000\n",
      "ecpch:2811,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2308 - val_loss: 194.1008\n",
      "\n",
      "Epoch 02812: val_loss did not improve from 179.48197\n",
      "Epoch 2813/5000\n",
      "ecpch:2812,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2276 - val_loss: 194.0967\n",
      "\n",
      "Epoch 02813: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 02813: ReduceLROnPlateau reducing learning rate to 1.0955713264593215e-06.\n",
      "Epoch 2814/5000\n",
      "ecpch:2813,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2293 - val_loss: 194.0994\n",
      "\n",
      "Epoch 02814: val_loss did not improve from 179.48197\n",
      "Epoch 2815/5000\n",
      "ecpch:2814,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2273 - val_loss: 194.0886\n",
      "\n",
      "Epoch 02815: val_loss did not improve from 179.48197\n",
      "Epoch 2816/5000\n",
      "ecpch:2815,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2293 - val_loss: 194.0929\n",
      "\n",
      "Epoch 02816: val_loss did not improve from 179.48197\n",
      "Epoch 2817/5000\n",
      "ecpch:2816,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2274 - val_loss: 194.1038\n",
      "\n",
      "Epoch 02817: val_loss did not improve from 179.48197\n",
      "Epoch 2818/5000\n",
      "ecpch:2817,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2283 - val_loss: 194.1022\n",
      "\n",
      "Epoch 02818: val_loss did not improve from 179.48197\n",
      "Epoch 2819/5000\n",
      "ecpch:2818,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2281 - val_loss: 194.0972\n",
      "\n",
      "Epoch 02819: val_loss did not improve from 179.48197\n",
      "Epoch 2820/5000\n",
      "ecpch:2819,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2263 - val_loss: 194.1018\n",
      "\n",
      "Epoch 02820: val_loss did not improve from 179.48197\n",
      "Epoch 2821/5000\n",
      "ecpch:2820,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2270 - val_loss: 194.0963\n",
      "\n",
      "Epoch 02821: val_loss did not improve from 179.48197\n",
      "Epoch 2822/5000\n",
      "ecpch:2821,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2256 - val_loss: 194.0995\n",
      "\n",
      "Epoch 02822: val_loss did not improve from 179.48197\n",
      "Epoch 2823/5000\n",
      "ecpch:2822,learn rate 0.000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2262 - val_loss: 194.0970\n",
      "\n",
      "Epoch 02823: val_loss did not improve from 179.48197\n",
      "Epoch 2824/5000\n",
      "ecpch:2823,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2248 - val_loss: 194.0913\n",
      "\n",
      "Epoch 02824: val_loss did not improve from 179.48197\n",
      "Epoch 2825/5000\n",
      "ecpch:2824,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2253 - val_loss: 194.0994\n",
      "\n",
      "Epoch 02825: val_loss did not improve from 179.48197\n",
      "Epoch 2826/5000\n",
      "ecpch:2825,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2241 - val_loss: 194.1061\n",
      "\n",
      "Epoch 02826: val_loss did not improve from 179.48197\n",
      "Epoch 2827/5000\n",
      "ecpch:2826,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2252 - val_loss: 194.0980\n",
      "\n",
      "Epoch 02827: val_loss did not improve from 179.48197\n",
      "Epoch 2828/5000\n",
      "ecpch:2827,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2241 - val_loss: 194.1000\n",
      "\n",
      "Epoch 02828: val_loss did not improve from 179.48197\n",
      "Epoch 2829/5000\n",
      "ecpch:2828,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2239 - val_loss: 194.1077\n",
      "\n",
      "Epoch 02829: val_loss did not improve from 179.48197\n",
      "Epoch 2830/5000\n",
      "ecpch:2829,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2240 - val_loss: 194.1026\n",
      "\n",
      "Epoch 02830: val_loss did not improve from 179.48197\n",
      "Epoch 2831/5000\n",
      "ecpch:2830,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2230 - val_loss: 194.0974\n",
      "\n",
      "Epoch 02831: val_loss did not improve from 179.48197\n",
      "Epoch 2832/5000\n",
      "ecpch:2831,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2238 - val_loss: 194.1014\n",
      "\n",
      "Epoch 02832: val_loss did not improve from 179.48197\n",
      "Epoch 2833/5000\n",
      "ecpch:2832,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2225 - val_loss: 194.1003\n",
      "\n",
      "Epoch 02833: val_loss did not improve from 179.48197\n",
      "Epoch 2834/5000\n",
      "ecpch:2833,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2234 - val_loss: 194.1001\n",
      "\n",
      "Epoch 02834: val_loss did not improve from 179.48197\n",
      "Epoch 2835/5000\n",
      "ecpch:2834,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2220 - val_loss: 194.0953\n",
      "\n",
      "Epoch 02835: val_loss did not improve from 179.48197\n",
      "Epoch 2836/5000\n",
      "ecpch:2835,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2221 - val_loss: 194.1050\n",
      "\n",
      "Epoch 02836: val_loss did not improve from 179.48197\n",
      "Epoch 2837/5000\n",
      "ecpch:2836,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2228 - val_loss: 194.1030\n",
      "\n",
      "Epoch 02837: val_loss did not improve from 179.48197\n",
      "Epoch 2838/5000\n",
      "ecpch:2837,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2216 - val_loss: 194.0934\n",
      "\n",
      "Epoch 02838: val_loss did not improve from 179.48197\n",
      "Epoch 2839/5000\n",
      "ecpch:2838,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2239 - val_loss: 194.1008\n",
      "\n",
      "Epoch 02839: val_loss did not improve from 179.48197\n",
      "Epoch 2840/5000\n",
      "ecpch:2839,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2217 - val_loss: 194.1046\n",
      "\n",
      "Epoch 02840: val_loss did not improve from 179.48197\n",
      "Epoch 2841/5000\n",
      "ecpch:2840,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2235 - val_loss: 194.1029\n",
      "\n",
      "Epoch 02841: val_loss did not improve from 179.48197\n",
      "Epoch 2842/5000\n",
      "ecpch:2841,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2219 - val_loss: 194.0901\n",
      "\n",
      "Epoch 02842: val_loss did not improve from 179.48197\n",
      "Epoch 2843/5000\n",
      "ecpch:2842,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2236 - val_loss: 194.0955\n",
      "\n",
      "Epoch 02843: val_loss did not improve from 179.48197\n",
      "Epoch 2844/5000\n",
      "ecpch:2843,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2239 - val_loss: 194.1041\n",
      "\n",
      "Epoch 02844: val_loss did not improve from 179.48197\n",
      "Epoch 2845/5000\n",
      "ecpch:2844,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2202 - val_loss: 194.1076\n",
      "\n",
      "Epoch 02845: val_loss did not improve from 179.48197\n",
      "Epoch 2846/5000\n",
      "ecpch:2845,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2225 - val_loss: 194.1022\n",
      "\n",
      "Epoch 02846: val_loss did not improve from 179.48197\n",
      "Epoch 2847/5000\n",
      "ecpch:2846,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2200 - val_loss: 194.0980\n",
      "\n",
      "Epoch 02847: val_loss did not improve from 179.48197\n",
      "Epoch 2848/5000\n",
      "ecpch:2847,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2215 - val_loss: 194.0964\n",
      "\n",
      "Epoch 02848: val_loss did not improve from 179.48197\n",
      "Epoch 2849/5000\n",
      "ecpch:2848,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2195 - val_loss: 194.1089\n",
      "\n",
      "Epoch 02849: val_loss did not improve from 179.48197\n",
      "Epoch 2850/5000\n",
      "ecpch:2849,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2218 - val_loss: 194.1065\n",
      "\n",
      "Epoch 02850: val_loss did not improve from 179.48197\n",
      "Epoch 2851/5000\n",
      "ecpch:2850,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2204 - val_loss: 194.1003\n",
      "\n",
      "Epoch 02851: val_loss did not improve from 179.48197\n",
      "Epoch 2852/5000\n",
      "ecpch:2851,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2207 - val_loss: 194.0988\n",
      "\n",
      "Epoch 02852: val_loss did not improve from 179.48197\n",
      "Epoch 2853/5000\n",
      "ecpch:2852,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2205 - val_loss: 194.1054\n",
      "\n",
      "Epoch 02853: val_loss did not improve from 179.48197\n",
      "Epoch 2854/5000\n",
      "ecpch:2853,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2191 - val_loss: 194.1074\n",
      "\n",
      "Epoch 02854: val_loss did not improve from 179.48197\n",
      "Epoch 2855/5000\n",
      "ecpch:2854,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2187 - val_loss: 194.0998\n",
      "\n",
      "Epoch 02855: val_loss did not improve from 179.48197\n",
      "Epoch 2856/5000\n",
      "ecpch:2855,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2193 - val_loss: 194.0966\n",
      "\n",
      "Epoch 02856: val_loss did not improve from 179.48197\n",
      "Epoch 2857/5000\n",
      "ecpch:2856,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2184 - val_loss: 194.1050\n",
      "\n",
      "Epoch 02857: val_loss did not improve from 179.48197\n",
      "Epoch 2858/5000\n",
      "ecpch:2857,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2196 - val_loss: 194.1046\n",
      "\n",
      "Epoch 02858: val_loss did not improve from 179.48197\n",
      "Epoch 2859/5000\n",
      "ecpch:2858,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2187 - val_loss: 194.0946\n",
      "\n",
      "Epoch 02859: val_loss did not improve from 179.48197\n",
      "Epoch 2860/5000\n",
      "ecpch:2859,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2186 - val_loss: 194.1035\n",
      "\n",
      "Epoch 02860: val_loss did not improve from 179.48197\n",
      "Epoch 2861/5000\n",
      "ecpch:2860,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2182 - val_loss: 194.1055\n",
      "\n",
      "Epoch 02861: val_loss did not improve from 179.48197\n",
      "Epoch 2862/5000\n",
      "ecpch:2861,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2184 - val_loss: 194.1062\n",
      "\n",
      "Epoch 02862: val_loss did not improve from 179.48197\n",
      "Epoch 2863/5000\n",
      "ecpch:2862,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2187 - val_loss: 194.1032\n",
      "\n",
      "Epoch 02863: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 02863: ReduceLROnPlateau reducing learning rate to 9.860141631179432e-07.\n",
      "Epoch 2864/5000\n",
      "ecpch:2863,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2166 - val_loss: 194.0997\n",
      "\n",
      "Epoch 02864: val_loss did not improve from 179.48197\n",
      "Epoch 2865/5000\n",
      "ecpch:2864,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2180 - val_loss: 194.0939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 02865: val_loss did not improve from 179.48197\n",
      "Epoch 2866/5000\n",
      "ecpch:2865,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2165 - val_loss: 194.1014\n",
      "\n",
      "Epoch 02866: val_loss did not improve from 179.48197\n",
      "Epoch 2867/5000\n",
      "ecpch:2866,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2162 - val_loss: 194.1107\n",
      "\n",
      "Epoch 02867: val_loss did not improve from 179.48197\n",
      "Epoch 2868/5000\n",
      "ecpch:2867,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2165 - val_loss: 194.1008\n",
      "\n",
      "Epoch 02868: val_loss did not improve from 179.48197\n",
      "Epoch 2869/5000\n",
      "ecpch:2868,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2158 - val_loss: 194.1041\n",
      "\n",
      "Epoch 02869: val_loss did not improve from 179.48197\n",
      "Epoch 2870/5000\n",
      "ecpch:2869,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2162 - val_loss: 194.1028\n",
      "\n",
      "Epoch 02870: val_loss did not improve from 179.48197\n",
      "Epoch 2871/5000\n",
      "ecpch:2870,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2144 - val_loss: 194.1069\n",
      "\n",
      "Epoch 02871: val_loss did not improve from 179.48197\n",
      "Epoch 2872/5000\n",
      "ecpch:2871,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 55.2165 - val_loss: 194.1115\n",
      "\n",
      "Epoch 02872: val_loss did not improve from 179.48197\n",
      "Epoch 2873/5000\n",
      "ecpch:2872,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2141 - val_loss: 194.0970\n",
      "\n",
      "Epoch 02873: val_loss did not improve from 179.48197\n",
      "Epoch 2874/5000\n",
      "ecpch:2873,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2162 - val_loss: 194.1053\n",
      "\n",
      "Epoch 02874: val_loss did not improve from 179.48197\n",
      "Epoch 2875/5000\n",
      "ecpch:2874,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2151 - val_loss: 194.1064\n",
      "\n",
      "Epoch 02875: val_loss did not improve from 179.48197\n",
      "Epoch 2876/5000\n",
      "ecpch:2875,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2156 - val_loss: 194.1101\n",
      "\n",
      "Epoch 02876: val_loss did not improve from 179.48197\n",
      "Epoch 2877/5000\n",
      "ecpch:2876,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2149 - val_loss: 194.1014\n",
      "\n",
      "Epoch 02877: val_loss did not improve from 179.48197\n",
      "Epoch 2878/5000\n",
      "ecpch:2877,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2145 - val_loss: 194.1034\n",
      "\n",
      "Epoch 02878: val_loss did not improve from 179.48197\n",
      "Epoch 2879/5000\n",
      "ecpch:2878,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2147 - val_loss: 194.1038\n",
      "\n",
      "Epoch 02879: val_loss did not improve from 179.48197\n",
      "Epoch 2880/5000\n",
      "ecpch:2879,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2132 - val_loss: 194.1111\n",
      "\n",
      "Epoch 02880: val_loss did not improve from 179.48197\n",
      "Epoch 2881/5000\n",
      "ecpch:2880,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2132 - val_loss: 194.1003\n",
      "\n",
      "Epoch 02881: val_loss did not improve from 179.48197\n",
      "Epoch 2882/5000\n",
      "ecpch:2881,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2130 - val_loss: 194.1045\n",
      "\n",
      "Epoch 02882: val_loss did not improve from 179.48197\n",
      "Epoch 2883/5000\n",
      "ecpch:2882,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2124 - val_loss: 194.1106\n",
      "\n",
      "Epoch 02883: val_loss did not improve from 179.48197\n",
      "Epoch 2884/5000\n",
      "ecpch:2883,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2131 - val_loss: 194.1046\n",
      "\n",
      "Epoch 02884: val_loss did not improve from 179.48197\n",
      "Epoch 2885/5000\n",
      "ecpch:2884,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2118 - val_loss: 194.1007\n",
      "\n",
      "Epoch 02885: val_loss did not improve from 179.48197\n",
      "Epoch 2886/5000\n",
      "ecpch:2885,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2138 - val_loss: 194.1008\n",
      "\n",
      "Epoch 02886: val_loss did not improve from 179.48197\n",
      "Epoch 2887/5000\n",
      "ecpch:2886,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2129 - val_loss: 194.1081\n",
      "\n",
      "Epoch 02887: val_loss did not improve from 179.48197\n",
      "Epoch 2888/5000\n",
      "ecpch:2887,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2124 - val_loss: 194.1058\n",
      "\n",
      "Epoch 02888: val_loss did not improve from 179.48197\n",
      "Epoch 2889/5000\n",
      "ecpch:2888,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2120 - val_loss: 194.1063\n",
      "\n",
      "Epoch 02889: val_loss did not improve from 179.48197\n",
      "Epoch 2890/5000\n",
      "ecpch:2889,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2121 - val_loss: 194.1056\n",
      "\n",
      "Epoch 02890: val_loss did not improve from 179.48197\n",
      "Epoch 2891/5000\n",
      "ecpch:2890,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2119 - val_loss: 194.1103\n",
      "\n",
      "Epoch 02891: val_loss did not improve from 179.48197\n",
      "Epoch 2892/5000\n",
      "ecpch:2891,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2110 - val_loss: 194.1122\n",
      "\n",
      "Epoch 02892: val_loss did not improve from 179.48197\n",
      "Epoch 2893/5000\n",
      "ecpch:2892,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2113 - val_loss: 194.1028\n",
      "\n",
      "Epoch 02893: val_loss did not improve from 179.48197\n",
      "Epoch 2894/5000\n",
      "ecpch:2893,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2107 - val_loss: 194.1032\n",
      "\n",
      "Epoch 02894: val_loss did not improve from 179.48197\n",
      "Epoch 2895/5000\n",
      "ecpch:2894,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2109 - val_loss: 194.1058\n",
      "\n",
      "Epoch 02895: val_loss did not improve from 179.48197\n",
      "Epoch 2896/5000\n",
      "ecpch:2895,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2099 - val_loss: 194.1073\n",
      "\n",
      "Epoch 02896: val_loss did not improve from 179.48197\n",
      "Epoch 2897/5000\n",
      "ecpch:2896,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2100 - val_loss: 194.1039\n",
      "\n",
      "Epoch 02897: val_loss did not improve from 179.48197\n",
      "Epoch 2898/5000\n",
      "ecpch:2897,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2101 - val_loss: 194.1143\n",
      "\n",
      "Epoch 02898: val_loss did not improve from 179.48197\n",
      "Epoch 2899/5000\n",
      "ecpch:2898,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2097 - val_loss: 194.1085\n",
      "\n",
      "Epoch 02899: val_loss did not improve from 179.48197\n",
      "Epoch 2900/5000\n",
      "ecpch:2899,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2094 - val_loss: 194.1077\n",
      "\n",
      "Epoch 02900: val_loss did not improve from 179.48197\n",
      "Epoch 2901/5000\n",
      "ecpch:2900,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2086 - val_loss: 194.1029\n",
      "\n",
      "Epoch 02901: val_loss did not improve from 179.48197\n",
      "Epoch 2902/5000\n",
      "ecpch:2901,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2090 - val_loss: 194.1103\n",
      "\n",
      "Epoch 02902: val_loss did not improve from 179.48197\n",
      "Epoch 2903/5000\n",
      "ecpch:2902,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2078 - val_loss: 194.1146\n",
      "\n",
      "Epoch 02903: val_loss did not improve from 179.48197\n",
      "Epoch 2904/5000\n",
      "ecpch:2903,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2087 - val_loss: 194.1037\n",
      "\n",
      "Epoch 02904: val_loss did not improve from 179.48197\n",
      "Epoch 2905/5000\n",
      "ecpch:2904,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2076 - val_loss: 194.1066\n",
      "\n",
      "Epoch 02905: val_loss did not improve from 179.48197\n",
      "Epoch 2906/5000\n",
      "ecpch:2905,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2073 - val_loss: 194.1177\n",
      "\n",
      "Epoch 02906: val_loss did not improve from 179.48197\n",
      "Epoch 2907/5000\n",
      "ecpch:2906,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2082 - val_loss: 194.1069\n",
      "\n",
      "Epoch 02907: val_loss did not improve from 179.48197\n",
      "Epoch 2908/5000\n",
      "ecpch:2907,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2068 - val_loss: 194.1128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 02908: val_loss did not improve from 179.48197\n",
      "Epoch 2909/5000\n",
      "ecpch:2908,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 55.2089 - val_loss: 194.1116\n",
      "\n",
      "Epoch 02909: val_loss did not improve from 179.48197\n",
      "Epoch 2910/5000\n",
      "ecpch:2909,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 55.2073 - val_loss: 194.1083\n",
      "\n",
      "Epoch 02910: val_loss did not improve from 179.48197\n",
      "Epoch 2911/5000\n",
      "ecpch:2910,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2088 - val_loss: 194.1116\n",
      "\n",
      "Epoch 02911: val_loss did not improve from 179.48197\n",
      "Epoch 2912/5000\n",
      "ecpch:2911,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2083 - val_loss: 194.1127\n",
      "\n",
      "Epoch 02912: val_loss did not improve from 179.48197\n",
      "Epoch 2913/5000\n",
      "ecpch:2912,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2067 - val_loss: 194.1139\n",
      "\n",
      "Epoch 02913: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 02913: ReduceLROnPlateau reducing learning rate to 8.874127161107026e-07.\n",
      "Epoch 2914/5000\n",
      "ecpch:2913,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2072 - val_loss: 194.1137\n",
      "\n",
      "Epoch 02914: val_loss did not improve from 179.48197\n",
      "Epoch 2915/5000\n",
      "ecpch:2914,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2059 - val_loss: 194.1140\n",
      "\n",
      "Epoch 02915: val_loss did not improve from 179.48197\n",
      "Epoch 2916/5000\n",
      "ecpch:2915,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2062 - val_loss: 194.1133\n",
      "\n",
      "Epoch 02916: val_loss did not improve from 179.48197\n",
      "Epoch 2917/5000\n",
      "ecpch:2916,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2056 - val_loss: 194.1068\n",
      "\n",
      "Epoch 02917: val_loss did not improve from 179.48197\n",
      "Epoch 2918/5000\n",
      "ecpch:2917,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2056 - val_loss: 194.1109\n",
      "\n",
      "Epoch 02918: val_loss did not improve from 179.48197\n",
      "Epoch 2919/5000\n",
      "ecpch:2918,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2054 - val_loss: 194.1120\n",
      "\n",
      "Epoch 02919: val_loss did not improve from 179.48197\n",
      "Epoch 2920/5000\n",
      "ecpch:2919,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2047 - val_loss: 194.1051\n",
      "\n",
      "Epoch 02920: val_loss did not improve from 179.48197\n",
      "Epoch 2921/5000\n",
      "ecpch:2920,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2051 - val_loss: 194.1140\n",
      "\n",
      "Epoch 02921: val_loss did not improve from 179.48197\n",
      "Epoch 2922/5000\n",
      "ecpch:2921,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2042 - val_loss: 194.1083\n",
      "\n",
      "Epoch 02922: val_loss did not improve from 179.48197\n",
      "Epoch 2923/5000\n",
      "ecpch:2922,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2053 - val_loss: 194.1147\n",
      "\n",
      "Epoch 02923: val_loss did not improve from 179.48197\n",
      "Epoch 2924/5000\n",
      "ecpch:2923,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2038 - val_loss: 194.1163\n",
      "\n",
      "Epoch 02924: val_loss did not improve from 179.48197\n",
      "Epoch 2925/5000\n",
      "ecpch:2924,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2046 - val_loss: 194.1142\n",
      "\n",
      "Epoch 02925: val_loss did not improve from 179.48197\n",
      "Epoch 2926/5000\n",
      "ecpch:2925,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2033 - val_loss: 194.1095\n",
      "\n",
      "Epoch 02926: val_loss did not improve from 179.48197\n",
      "Epoch 2927/5000\n",
      "ecpch:2926,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2050 - val_loss: 194.1141\n",
      "\n",
      "Epoch 02927: val_loss did not improve from 179.48197\n",
      "Epoch 2928/5000\n",
      "ecpch:2927,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2030 - val_loss: 194.1105\n",
      "\n",
      "Epoch 02928: val_loss did not improve from 179.48197\n",
      "Epoch 2929/5000\n",
      "ecpch:2928,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2046 - val_loss: 194.1157\n",
      "\n",
      "Epoch 02929: val_loss did not improve from 179.48197\n",
      "Epoch 2930/5000\n",
      "ecpch:2929,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2027 - val_loss: 194.1188\n",
      "\n",
      "Epoch 02930: val_loss did not improve from 179.48197\n",
      "Epoch 2931/5000\n",
      "ecpch:2930,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2058 - val_loss: 194.1161\n",
      "\n",
      "Epoch 02931: val_loss did not improve from 179.48197\n",
      "Epoch 2932/5000\n",
      "ecpch:2931,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2044 - val_loss: 194.1032\n",
      "\n",
      "Epoch 02932: val_loss did not improve from 179.48197\n",
      "Epoch 2933/5000\n",
      "ecpch:2932,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2043 - val_loss: 194.1044\n",
      "\n",
      "Epoch 02933: val_loss did not improve from 179.48197\n",
      "Epoch 2934/5000\n",
      "ecpch:2933,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2049 - val_loss: 194.1130\n",
      "\n",
      "Epoch 02934: val_loss did not improve from 179.48197\n",
      "Epoch 2935/5000\n",
      "ecpch:2934,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2021 - val_loss: 194.1127\n",
      "\n",
      "Epoch 02935: val_loss did not improve from 179.48197\n",
      "Epoch 2936/5000\n",
      "ecpch:2935,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2039 - val_loss: 194.1166\n",
      "\n",
      "Epoch 02936: val_loss did not improve from 179.48197\n",
      "Epoch 2937/5000\n",
      "ecpch:2936,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2025 - val_loss: 194.1086\n",
      "\n",
      "Epoch 02937: val_loss did not improve from 179.48197\n",
      "Epoch 2938/5000\n",
      "ecpch:2937,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2035 - val_loss: 194.1124\n",
      "\n",
      "Epoch 02938: val_loss did not improve from 179.48197\n",
      "Epoch 2939/5000\n",
      "ecpch:2938,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2026 - val_loss: 194.1181\n",
      "\n",
      "Epoch 02939: val_loss did not improve from 179.48197\n",
      "Epoch 2940/5000\n",
      "ecpch:2939,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2023 - val_loss: 194.1084\n",
      "\n",
      "Epoch 02940: val_loss did not improve from 179.48197\n",
      "Epoch 2941/5000\n",
      "ecpch:2940,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2023 - val_loss: 194.1142\n",
      "\n",
      "Epoch 02941: val_loss did not improve from 179.48197\n",
      "Epoch 2942/5000\n",
      "ecpch:2941,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2015 - val_loss: 194.1126\n",
      "\n",
      "Epoch 02942: val_loss did not improve from 179.48197\n",
      "Epoch 2943/5000\n",
      "ecpch:2942,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2016 - val_loss: 194.1088\n",
      "\n",
      "Epoch 02943: val_loss did not improve from 179.48197\n",
      "Epoch 2944/5000\n",
      "ecpch:2943,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2011 - val_loss: 194.1087\n",
      "\n",
      "Epoch 02944: val_loss did not improve from 179.48197\n",
      "Epoch 2945/5000\n",
      "ecpch:2944,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2002 - val_loss: 194.1183\n",
      "\n",
      "Epoch 02945: val_loss did not improve from 179.48197\n",
      "Epoch 2946/5000\n",
      "ecpch:2945,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2014 - val_loss: 194.1124\n",
      "\n",
      "Epoch 02946: val_loss did not improve from 179.48197\n",
      "Epoch 2947/5000\n",
      "ecpch:2946,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2000 - val_loss: 194.1164\n",
      "\n",
      "Epoch 02947: val_loss did not improve from 179.48197\n",
      "Epoch 2948/5000\n",
      "ecpch:2947,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 55.2011 - val_loss: 194.1196\n",
      "\n",
      "Epoch 02948: val_loss did not improve from 179.48197\n",
      "Epoch 2949/5000\n",
      "ecpch:2948,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2006 - val_loss: 194.1209\n",
      "\n",
      "Epoch 02949: val_loss did not improve from 179.48197\n",
      "Epoch 2950/5000\n",
      "ecpch:2949,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.2001 - val_loss: 194.1166\n",
      "\n",
      "Epoch 02950: val_loss did not improve from 179.48197\n",
      "Epoch 2951/5000\n",
      "ecpch:2950,learn rate 0.000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1996 - val_loss: 194.1197\n",
      "\n",
      "Epoch 02951: val_loss did not improve from 179.48197\n",
      "Epoch 2952/5000\n",
      "ecpch:2951,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.2001 - val_loss: 194.1157\n",
      "\n",
      "Epoch 02952: val_loss did not improve from 179.48197\n",
      "Epoch 2953/5000\n",
      "ecpch:2952,learn rate 0.000001\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 55.1991 - val_loss: 194.1148\n",
      "\n",
      "Epoch 02953: val_loss did not improve from 179.48197\n",
      "Epoch 2954/5000\n",
      "ecpch:2953,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1998 - val_loss: 194.1208\n",
      "\n",
      "Epoch 02954: val_loss did not improve from 179.48197\n",
      "Epoch 2955/5000\n",
      "ecpch:2954,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1989 - val_loss: 194.1132\n",
      "\n",
      "Epoch 02955: val_loss did not improve from 179.48197\n",
      "Epoch 2956/5000\n",
      "ecpch:2955,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1998 - val_loss: 194.1112\n",
      "\n",
      "Epoch 02956: val_loss did not improve from 179.48197\n",
      "Epoch 2957/5000\n",
      "ecpch:2956,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1991 - val_loss: 194.1154\n",
      "\n",
      "Epoch 02957: val_loss did not improve from 179.48197\n",
      "Epoch 2958/5000\n",
      "ecpch:2957,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1990 - val_loss: 194.1175\n",
      "\n",
      "Epoch 02958: val_loss did not improve from 179.48197\n",
      "Epoch 2959/5000\n",
      "ecpch:2958,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1988 - val_loss: 194.1146\n",
      "\n",
      "Epoch 02959: val_loss did not improve from 179.48197\n",
      "Epoch 2960/5000\n",
      "ecpch:2959,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1982 - val_loss: 194.1158\n",
      "\n",
      "Epoch 02960: val_loss did not improve from 179.48197\n",
      "Epoch 2961/5000\n",
      "ecpch:2960,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1982 - val_loss: 194.1171\n",
      "\n",
      "Epoch 02961: val_loss did not improve from 179.48197\n",
      "Epoch 2962/5000\n",
      "ecpch:2961,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1980 - val_loss: 194.1199\n",
      "\n",
      "Epoch 02962: val_loss did not improve from 179.48197\n",
      "Epoch 2963/5000\n",
      "ecpch:2962,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1976 - val_loss: 194.1129\n",
      "\n",
      "Epoch 02963: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 02963: ReduceLROnPlateau reducing learning rate to 7.986714649632631e-07.\n",
      "Epoch 2964/5000\n",
      "ecpch:2963,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1978 - val_loss: 194.1197\n",
      "\n",
      "Epoch 02964: val_loss did not improve from 179.48197\n",
      "Epoch 2965/5000\n",
      "ecpch:2964,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1969 - val_loss: 194.1180\n",
      "\n",
      "Epoch 02965: val_loss did not improve from 179.48197\n",
      "Epoch 2966/5000\n",
      "ecpch:2965,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1973 - val_loss: 194.1095\n",
      "\n",
      "Epoch 02966: val_loss did not improve from 179.48197\n",
      "Epoch 2967/5000\n",
      "ecpch:2966,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1972 - val_loss: 194.1199\n",
      "\n",
      "Epoch 02967: val_loss did not improve from 179.48197\n",
      "Epoch 2968/5000\n",
      "ecpch:2967,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1966 - val_loss: 194.1203\n",
      "\n",
      "Epoch 02968: val_loss did not improve from 179.48197\n",
      "Epoch 2969/5000\n",
      "ecpch:2968,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1977 - val_loss: 194.1166\n",
      "\n",
      "Epoch 02969: val_loss did not improve from 179.48197\n",
      "Epoch 2970/5000\n",
      "ecpch:2969,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1955 - val_loss: 194.1157\n",
      "\n",
      "Epoch 02970: val_loss did not improve from 179.48197\n",
      "Epoch 2971/5000\n",
      "ecpch:2970,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1973 - val_loss: 194.1154\n",
      "\n",
      "Epoch 02971: val_loss did not improve from 179.48197\n",
      "Epoch 2972/5000\n",
      "ecpch:2971,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1955 - val_loss: 194.1180\n",
      "\n",
      "Epoch 02972: val_loss did not improve from 179.48197\n",
      "Epoch 2973/5000\n",
      "ecpch:2972,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1977 - val_loss: 194.1196\n",
      "\n",
      "Epoch 02973: val_loss did not improve from 179.48197\n",
      "Epoch 2974/5000\n",
      "ecpch:2973,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1969 - val_loss: 194.1113\n",
      "\n",
      "Epoch 02974: val_loss did not improve from 179.48197\n",
      "Epoch 2975/5000\n",
      "ecpch:2974,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1965 - val_loss: 194.1126\n",
      "\n",
      "Epoch 02975: val_loss did not improve from 179.48197\n",
      "Epoch 2976/5000\n",
      "ecpch:2975,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1970 - val_loss: 194.1215\n",
      "\n",
      "Epoch 02976: val_loss did not improve from 179.48197\n",
      "Epoch 2977/5000\n",
      "ecpch:2976,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1950 - val_loss: 194.1191\n",
      "\n",
      "Epoch 02977: val_loss did not improve from 179.48197\n",
      "Epoch 2978/5000\n",
      "ecpch:2977,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1955 - val_loss: 194.1182\n",
      "\n",
      "Epoch 02978: val_loss did not improve from 179.48197\n",
      "Epoch 2979/5000\n",
      "ecpch:2978,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1953 - val_loss: 194.1206\n",
      "\n",
      "Epoch 02979: val_loss did not improve from 179.48197\n",
      "Epoch 2980/5000\n",
      "ecpch:2979,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1949 - val_loss: 194.1230\n",
      "\n",
      "Epoch 02980: val_loss did not improve from 179.48197\n",
      "Epoch 2981/5000\n",
      "ecpch:2980,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1947 - val_loss: 194.1202\n",
      "\n",
      "Epoch 02981: val_loss did not improve from 179.48197\n",
      "Epoch 2982/5000\n",
      "ecpch:2981,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1939 - val_loss: 194.1158\n",
      "\n",
      "Epoch 02982: val_loss did not improve from 179.48197\n",
      "Epoch 2983/5000\n",
      "ecpch:2982,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1938 - val_loss: 194.1239\n",
      "\n",
      "Epoch 02983: val_loss did not improve from 179.48197\n",
      "Epoch 2984/5000\n",
      "ecpch:2983,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1945 - val_loss: 194.1189\n",
      "\n",
      "Epoch 02984: val_loss did not improve from 179.48197\n",
      "Epoch 2985/5000\n",
      "ecpch:2984,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1934 - val_loss: 194.1224\n",
      "\n",
      "Epoch 02985: val_loss did not improve from 179.48197\n",
      "Epoch 2986/5000\n",
      "ecpch:2985,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1949 - val_loss: 194.1188\n",
      "\n",
      "Epoch 02986: val_loss did not improve from 179.48197\n",
      "Epoch 2987/5000\n",
      "ecpch:2986,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1938 - val_loss: 194.1259\n",
      "\n",
      "Epoch 02987: val_loss did not improve from 179.48197\n",
      "Epoch 2988/5000\n",
      "ecpch:2987,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1946 - val_loss: 194.1235\n",
      "\n",
      "Epoch 02988: val_loss did not improve from 179.48197\n",
      "Epoch 2989/5000\n",
      "ecpch:2988,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1945 - val_loss: 194.1158\n",
      "\n",
      "Epoch 02989: val_loss did not improve from 179.48197\n",
      "Epoch 2990/5000\n",
      "ecpch:2989,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1932 - val_loss: 194.1147\n",
      "\n",
      "Epoch 02990: val_loss did not improve from 179.48197\n",
      "Epoch 2991/5000\n",
      "ecpch:2990,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1933 - val_loss: 194.1259\n",
      "\n",
      "Epoch 02991: val_loss did not improve from 179.48197\n",
      "Epoch 2992/5000\n",
      "ecpch:2991,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1933 - val_loss: 194.1199\n",
      "\n",
      "Epoch 02992: val_loss did not improve from 179.48197\n",
      "Epoch 2993/5000\n",
      "ecpch:2992,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1932 - val_loss: 194.1227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 02993: val_loss did not improve from 179.48197\n",
      "Epoch 2994/5000\n",
      "ecpch:2993,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1925 - val_loss: 194.1190\n",
      "\n",
      "Epoch 02994: val_loss did not improve from 179.48197\n",
      "Epoch 2995/5000\n",
      "ecpch:2994,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1925 - val_loss: 194.1249\n",
      "\n",
      "Epoch 02995: val_loss did not improve from 179.48197\n",
      "Epoch 2996/5000\n",
      "ecpch:2995,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1927 - val_loss: 194.1201\n",
      "\n",
      "Epoch 02996: val_loss did not improve from 179.48197\n",
      "Epoch 2997/5000\n",
      "ecpch:2996,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1920 - val_loss: 194.1236\n",
      "\n",
      "Epoch 02997: val_loss did not improve from 179.48197\n",
      "Epoch 2998/5000\n",
      "ecpch:2997,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1917 - val_loss: 194.1212\n",
      "\n",
      "Epoch 02998: val_loss did not improve from 179.48197\n",
      "Epoch 2999/5000\n",
      "ecpch:2998,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1916 - val_loss: 194.1183\n",
      "\n",
      "Epoch 02999: val_loss did not improve from 179.48197\n",
      "Epoch 3000/5000\n",
      "ecpch:2999,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1908 - val_loss: 194.1146\n",
      "\n",
      "Epoch 03000: val_loss did not improve from 179.48197\n",
      "Epoch 3001/5000\n",
      "ecpch:3000,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1919 - val_loss: 194.1155\n",
      "\n",
      "Epoch 03001: val_loss did not improve from 179.48197\n",
      "Epoch 3002/5000\n",
      "ecpch:3001,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1911 - val_loss: 194.1200\n",
      "\n",
      "Epoch 03002: val_loss did not improve from 179.48197\n",
      "Epoch 3003/5000\n",
      "ecpch:3002,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1922 - val_loss: 194.1228\n",
      "\n",
      "Epoch 03003: val_loss did not improve from 179.48197\n",
      "Epoch 3004/5000\n",
      "ecpch:3003,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1908 - val_loss: 194.1083\n",
      "\n",
      "Epoch 03004: val_loss did not improve from 179.48197\n",
      "Epoch 3005/5000\n",
      "ecpch:3004,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1917 - val_loss: 194.1157\n",
      "\n",
      "Epoch 03005: val_loss did not improve from 179.48197\n",
      "Epoch 3006/5000\n",
      "ecpch:3005,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1915 - val_loss: 194.1274\n",
      "\n",
      "Epoch 03006: val_loss did not improve from 179.48197\n",
      "Epoch 3007/5000\n",
      "ecpch:3006,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1903 - val_loss: 194.1268\n",
      "\n",
      "Epoch 03007: val_loss did not improve from 179.48197\n",
      "Epoch 3008/5000\n",
      "ecpch:3007,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1902 - val_loss: 194.1229\n",
      "\n",
      "Epoch 03008: val_loss did not improve from 179.48197\n",
      "Epoch 3009/5000\n",
      "ecpch:3008,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1893 - val_loss: 194.1220\n",
      "\n",
      "Epoch 03009: val_loss did not improve from 179.48197\n",
      "Epoch 3010/5000\n",
      "ecpch:3009,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1898 - val_loss: 194.1227\n",
      "\n",
      "Epoch 03010: val_loss did not improve from 179.48197\n",
      "Epoch 3011/5000\n",
      "ecpch:3010,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1892 - val_loss: 194.1231\n",
      "\n",
      "Epoch 03011: val_loss did not improve from 179.48197\n",
      "Epoch 3012/5000\n",
      "ecpch:3011,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1891 - val_loss: 194.1205\n",
      "\n",
      "Epoch 03012: val_loss did not improve from 179.48197\n",
      "Epoch 3013/5000\n",
      "ecpch:3012,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1890 - val_loss: 194.1296\n",
      "\n",
      "Epoch 03013: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 03013: ReduceLROnPlateau reducing learning rate to 7.188043184669369e-07.\n",
      "Epoch 3014/5000\n",
      "ecpch:3013,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1885 - val_loss: 194.1214\n",
      "\n",
      "Epoch 03014: val_loss did not improve from 179.48197\n",
      "Epoch 3015/5000\n",
      "ecpch:3014,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1892 - val_loss: 194.1221\n",
      "\n",
      "Epoch 03015: val_loss did not improve from 179.48197\n",
      "Epoch 3016/5000\n",
      "ecpch:3015,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1884 - val_loss: 194.1187\n",
      "\n",
      "Epoch 03016: val_loss did not improve from 179.48197\n",
      "Epoch 3017/5000\n",
      "ecpch:3016,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1892 - val_loss: 194.1185\n",
      "\n",
      "Epoch 03017: val_loss did not improve from 179.48197\n",
      "Epoch 3018/5000\n",
      "ecpch:3017,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1888 - val_loss: 194.1199\n",
      "\n",
      "Epoch 03018: val_loss did not improve from 179.48197\n",
      "Epoch 3019/5000\n",
      "ecpch:3018,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1879 - val_loss: 194.1249\n",
      "\n",
      "Epoch 03019: val_loss did not improve from 179.48197\n",
      "Epoch 3020/5000\n",
      "ecpch:3019,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1878 - val_loss: 194.1291\n",
      "\n",
      "Epoch 03020: val_loss did not improve from 179.48197\n",
      "Epoch 3021/5000\n",
      "ecpch:3020,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1880 - val_loss: 194.1274\n",
      "\n",
      "Epoch 03021: val_loss did not improve from 179.48197\n",
      "Epoch 3022/5000\n",
      "ecpch:3021,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1876 - val_loss: 194.1260\n",
      "\n",
      "Epoch 03022: val_loss did not improve from 179.48197\n",
      "Epoch 3023/5000\n",
      "ecpch:3022,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1877 - val_loss: 194.1225\n",
      "\n",
      "Epoch 03023: val_loss did not improve from 179.48197\n",
      "Epoch 3024/5000\n",
      "ecpch:3023,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1873 - val_loss: 194.1212\n",
      "\n",
      "Epoch 03024: val_loss did not improve from 179.48197\n",
      "Epoch 3025/5000\n",
      "ecpch:3024,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1877 - val_loss: 194.1240\n",
      "\n",
      "Epoch 03025: val_loss did not improve from 179.48197\n",
      "Epoch 3026/5000\n",
      "ecpch:3025,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1874 - val_loss: 194.1221\n",
      "\n",
      "Epoch 03026: val_loss did not improve from 179.48197\n",
      "Epoch 3027/5000\n",
      "ecpch:3026,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1871 - val_loss: 194.1250\n",
      "\n",
      "Epoch 03027: val_loss did not improve from 179.48197\n",
      "Epoch 3028/5000\n",
      "ecpch:3027,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1865 - val_loss: 194.1190\n",
      "\n",
      "Epoch 03028: val_loss did not improve from 179.48197\n",
      "Epoch 3029/5000\n",
      "ecpch:3028,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1871 - val_loss: 194.1206\n",
      "\n",
      "Epoch 03029: val_loss did not improve from 179.48197\n",
      "Epoch 3030/5000\n",
      "ecpch:3029,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1866 - val_loss: 194.1256\n",
      "\n",
      "Epoch 03030: val_loss did not improve from 179.48197\n",
      "Epoch 3031/5000\n",
      "ecpch:3030,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1864 - val_loss: 194.1264\n",
      "\n",
      "Epoch 03031: val_loss did not improve from 179.48197\n",
      "Epoch 3032/5000\n",
      "ecpch:3031,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1864 - val_loss: 194.1211\n",
      "\n",
      "Epoch 03032: val_loss did not improve from 179.48197\n",
      "Epoch 3033/5000\n",
      "ecpch:3032,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1859 - val_loss: 194.1254\n",
      "\n",
      "Epoch 03033: val_loss did not improve from 179.48197\n",
      "Epoch 3034/5000\n",
      "ecpch:3033,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1855 - val_loss: 194.1266\n",
      "\n",
      "Epoch 03034: val_loss did not improve from 179.48197\n",
      "Epoch 3035/5000\n",
      "ecpch:3034,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1856 - val_loss: 194.1205\n",
      "\n",
      "Epoch 03035: val_loss did not improve from 179.48197\n",
      "Epoch 3036/5000\n",
      "ecpch:3035,learn rate 0.000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1854 - val_loss: 194.1208\n",
      "\n",
      "Epoch 03036: val_loss did not improve from 179.48197\n",
      "Epoch 3037/5000\n",
      "ecpch:3036,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1855 - val_loss: 194.1218\n",
      "\n",
      "Epoch 03037: val_loss did not improve from 179.48197\n",
      "Epoch 3038/5000\n",
      "ecpch:3037,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1850 - val_loss: 194.1241\n",
      "\n",
      "Epoch 03038: val_loss did not improve from 179.48197\n",
      "Epoch 3039/5000\n",
      "ecpch:3038,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1855 - val_loss: 194.1309\n",
      "\n",
      "Epoch 03039: val_loss did not improve from 179.48197\n",
      "Epoch 3040/5000\n",
      "ecpch:3039,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1845 - val_loss: 194.1285\n",
      "\n",
      "Epoch 03040: val_loss did not improve from 179.48197\n",
      "Epoch 3041/5000\n",
      "ecpch:3040,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1853 - val_loss: 194.1213\n",
      "\n",
      "Epoch 03041: val_loss did not improve from 179.48197\n",
      "Epoch 3042/5000\n",
      "ecpch:3041,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1845 - val_loss: 194.1298\n",
      "\n",
      "Epoch 03042: val_loss did not improve from 179.48197\n",
      "Epoch 3043/5000\n",
      "ecpch:3042,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1855 - val_loss: 194.1250\n",
      "\n",
      "Epoch 03043: val_loss did not improve from 179.48197\n",
      "Epoch 3044/5000\n",
      "ecpch:3043,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1846 - val_loss: 194.1244\n",
      "\n",
      "Epoch 03044: val_loss did not improve from 179.48197\n",
      "Epoch 3045/5000\n",
      "ecpch:3044,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1843 - val_loss: 194.1218\n",
      "\n",
      "Epoch 03045: val_loss did not improve from 179.48197\n",
      "Epoch 3046/5000\n",
      "ecpch:3045,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1842 - val_loss: 194.1271\n",
      "\n",
      "Epoch 03046: val_loss did not improve from 179.48197\n",
      "Epoch 3047/5000\n",
      "ecpch:3046,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1837 - val_loss: 194.1260\n",
      "\n",
      "Epoch 03047: val_loss did not improve from 179.48197\n",
      "Epoch 3048/5000\n",
      "ecpch:3047,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1840 - val_loss: 194.1263\n",
      "\n",
      "Epoch 03048: val_loss did not improve from 179.48197\n",
      "Epoch 3049/5000\n",
      "ecpch:3048,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1834 - val_loss: 194.1266\n",
      "\n",
      "Epoch 03049: val_loss did not improve from 179.48197\n",
      "Epoch 3050/5000\n",
      "ecpch:3049,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1833 - val_loss: 194.1279\n",
      "\n",
      "Epoch 03050: val_loss did not improve from 179.48197\n",
      "Epoch 3051/5000\n",
      "ecpch:3050,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1839 - val_loss: 194.1230\n",
      "\n",
      "Epoch 03051: val_loss did not improve from 179.48197\n",
      "Epoch 3052/5000\n",
      "ecpch:3051,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1830 - val_loss: 194.1245\n",
      "\n",
      "Epoch 03052: val_loss did not improve from 179.48197\n",
      "Epoch 3053/5000\n",
      "ecpch:3052,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1844 - val_loss: 194.1283\n",
      "\n",
      "Epoch 03053: val_loss did not improve from 179.48197\n",
      "Epoch 3054/5000\n",
      "ecpch:3053,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1836 - val_loss: 194.1204\n",
      "\n",
      "Epoch 03054: val_loss did not improve from 179.48197\n",
      "Epoch 3055/5000\n",
      "ecpch:3054,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1836 - val_loss: 194.1261\n",
      "\n",
      "Epoch 03055: val_loss did not improve from 179.48197\n",
      "Epoch 3056/5000\n",
      "ecpch:3055,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1835 - val_loss: 194.1309\n",
      "\n",
      "Epoch 03056: val_loss did not improve from 179.48197\n",
      "Epoch 3057/5000\n",
      "ecpch:3056,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1831 - val_loss: 194.1283\n",
      "\n",
      "Epoch 03057: val_loss did not improve from 179.48197\n",
      "Epoch 3058/5000\n",
      "ecpch:3057,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1830 - val_loss: 194.1221\n",
      "\n",
      "Epoch 03058: val_loss did not improve from 179.48197\n",
      "Epoch 3059/5000\n",
      "ecpch:3058,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1824 - val_loss: 194.1202\n",
      "\n",
      "Epoch 03059: val_loss did not improve from 179.48197\n",
      "Epoch 3060/5000\n",
      "ecpch:3059,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1827 - val_loss: 194.1300\n",
      "\n",
      "Epoch 03060: val_loss did not improve from 179.48197\n",
      "Epoch 3061/5000\n",
      "ecpch:3060,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1822 - val_loss: 194.1242\n",
      "\n",
      "Epoch 03061: val_loss did not improve from 179.48197\n",
      "Epoch 3062/5000\n",
      "ecpch:3061,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1814 - val_loss: 194.1280\n",
      "\n",
      "Epoch 03062: val_loss did not improve from 179.48197\n",
      "Epoch 3063/5000\n",
      "ecpch:3062,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1814 - val_loss: 194.1353\n",
      "\n",
      "Epoch 03063: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 03063: ReduceLROnPlateau reducing learning rate to 6.4692387127252e-07.\n",
      "Epoch 3064/5000\n",
      "ecpch:3063,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1813 - val_loss: 194.1312\n",
      "\n",
      "Epoch 03064: val_loss did not improve from 179.48197\n",
      "Epoch 3065/5000\n",
      "ecpch:3064,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1810 - val_loss: 194.1244\n",
      "\n",
      "Epoch 03065: val_loss did not improve from 179.48197\n",
      "Epoch 3066/5000\n",
      "ecpch:3065,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1811 - val_loss: 194.1269\n",
      "\n",
      "Epoch 03066: val_loss did not improve from 179.48197\n",
      "Epoch 3067/5000\n",
      "ecpch:3066,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1804 - val_loss: 194.1277\n",
      "\n",
      "Epoch 03067: val_loss did not improve from 179.48197\n",
      "Epoch 3068/5000\n",
      "ecpch:3067,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1813 - val_loss: 194.1282\n",
      "\n",
      "Epoch 03068: val_loss did not improve from 179.48197\n",
      "Epoch 3069/5000\n",
      "ecpch:3068,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1801 - val_loss: 194.1278\n",
      "\n",
      "Epoch 03069: val_loss did not improve from 179.48197\n",
      "Epoch 3070/5000\n",
      "ecpch:3069,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1810 - val_loss: 194.1275\n",
      "\n",
      "Epoch 03070: val_loss did not improve from 179.48197\n",
      "Epoch 3071/5000\n",
      "ecpch:3070,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1803 - val_loss: 194.1333\n",
      "\n",
      "Epoch 03071: val_loss did not improve from 179.48197\n",
      "Epoch 3072/5000\n",
      "ecpch:3071,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1807 - val_loss: 194.1321\n",
      "\n",
      "Epoch 03072: val_loss did not improve from 179.48197\n",
      "Epoch 3073/5000\n",
      "ecpch:3072,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1801 - val_loss: 194.1282\n",
      "\n",
      "Epoch 03073: val_loss did not improve from 179.48197\n",
      "Epoch 3074/5000\n",
      "ecpch:3073,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1799 - val_loss: 194.1292\n",
      "\n",
      "Epoch 03074: val_loss did not improve from 179.48197\n",
      "Epoch 3075/5000\n",
      "ecpch:3074,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1800 - val_loss: 194.1217\n",
      "\n",
      "Epoch 03075: val_loss did not improve from 179.48197\n",
      "Epoch 3076/5000\n",
      "ecpch:3075,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1794 - val_loss: 194.1324\n",
      "\n",
      "Epoch 03076: val_loss did not improve from 179.48197\n",
      "Epoch 3077/5000\n",
      "ecpch:3076,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1796 - val_loss: 194.1319\n",
      "\n",
      "Epoch 03077: val_loss did not improve from 179.48197\n",
      "Epoch 3078/5000\n",
      "ecpch:3077,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1789 - val_loss: 194.1245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 03078: val_loss did not improve from 179.48197\n",
      "Epoch 3079/5000\n",
      "ecpch:3078,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1789 - val_loss: 194.1316\n",
      "\n",
      "Epoch 03079: val_loss did not improve from 179.48197\n",
      "Epoch 3080/5000\n",
      "ecpch:3079,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1787 - val_loss: 194.1313\n",
      "\n",
      "Epoch 03080: val_loss did not improve from 179.48197\n",
      "Epoch 3081/5000\n",
      "ecpch:3080,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1782 - val_loss: 194.1229\n",
      "\n",
      "Epoch 03081: val_loss did not improve from 179.48197\n",
      "Epoch 3082/5000\n",
      "ecpch:3081,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1785 - val_loss: 194.1277\n",
      "\n",
      "Epoch 03082: val_loss did not improve from 179.48197\n",
      "Epoch 3083/5000\n",
      "ecpch:3082,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1779 - val_loss: 194.1245\n",
      "\n",
      "Epoch 03083: val_loss did not improve from 179.48197\n",
      "Epoch 3084/5000\n",
      "ecpch:3083,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1787 - val_loss: 194.1306\n",
      "\n",
      "Epoch 03084: val_loss did not improve from 179.48197\n",
      "Epoch 3085/5000\n",
      "ecpch:3084,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1779 - val_loss: 194.1299\n",
      "\n",
      "Epoch 03085: val_loss did not improve from 179.48197\n",
      "Epoch 3086/5000\n",
      "ecpch:3085,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1780 - val_loss: 194.1332\n",
      "\n",
      "Epoch 03086: val_loss did not improve from 179.48197\n",
      "Epoch 3087/5000\n",
      "ecpch:3086,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1774 - val_loss: 194.1324\n",
      "\n",
      "Epoch 03087: val_loss did not improve from 179.48197\n",
      "Epoch 3088/5000\n",
      "ecpch:3087,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1773 - val_loss: 194.1348\n",
      "\n",
      "Epoch 03088: val_loss did not improve from 179.48197\n",
      "Epoch 3089/5000\n",
      "ecpch:3088,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1776 - val_loss: 194.1340\n",
      "\n",
      "Epoch 03089: val_loss did not improve from 179.48197\n",
      "Epoch 3090/5000\n",
      "ecpch:3089,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1772 - val_loss: 194.1327\n",
      "\n",
      "Epoch 03090: val_loss did not improve from 179.48197\n",
      "Epoch 3091/5000\n",
      "ecpch:3090,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1774 - val_loss: 194.1328\n",
      "\n",
      "Epoch 03091: val_loss did not improve from 179.48197\n",
      "Epoch 3092/5000\n",
      "ecpch:3091,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1768 - val_loss: 194.1297\n",
      "\n",
      "Epoch 03092: val_loss did not improve from 179.48197\n",
      "Epoch 3093/5000\n",
      "ecpch:3092,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1768 - val_loss: 194.1298\n",
      "\n",
      "Epoch 03093: val_loss did not improve from 179.48197\n",
      "Epoch 3094/5000\n",
      "ecpch:3093,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1765 - val_loss: 194.1294\n",
      "\n",
      "Epoch 03094: val_loss did not improve from 179.48197\n",
      "Epoch 3095/5000\n",
      "ecpch:3094,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1764 - val_loss: 194.1278\n",
      "\n",
      "Epoch 03095: val_loss did not improve from 179.48197\n",
      "Epoch 3096/5000\n",
      "ecpch:3095,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1768 - val_loss: 194.1235\n",
      "\n",
      "Epoch 03096: val_loss did not improve from 179.48197\n",
      "Epoch 3097/5000\n",
      "ecpch:3096,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1762 - val_loss: 194.1345\n",
      "\n",
      "Epoch 03097: val_loss did not improve from 179.48197\n",
      "Epoch 3098/5000\n",
      "ecpch:3097,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1761 - val_loss: 194.1318\n",
      "\n",
      "Epoch 03098: val_loss did not improve from 179.48197\n",
      "Epoch 3099/5000\n",
      "ecpch:3098,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1759 - val_loss: 194.1355\n",
      "\n",
      "Epoch 03099: val_loss did not improve from 179.48197\n",
      "Epoch 3100/5000\n",
      "ecpch:3099,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1759 - val_loss: 194.1254\n",
      "\n",
      "Epoch 03100: val_loss did not improve from 179.48197\n",
      "Epoch 3101/5000\n",
      "ecpch:3100,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1761 - val_loss: 194.1255\n",
      "\n",
      "Epoch 03101: val_loss did not improve from 179.48197\n",
      "Epoch 3102/5000\n",
      "ecpch:3101,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1757 - val_loss: 194.1288\n",
      "\n",
      "Epoch 03102: val_loss did not improve from 179.48197\n",
      "Epoch 3103/5000\n",
      "ecpch:3102,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1759 - val_loss: 194.1290\n",
      "\n",
      "Epoch 03103: val_loss did not improve from 179.48197\n",
      "Epoch 3104/5000\n",
      "ecpch:3103,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1763 - val_loss: 194.1289\n",
      "\n",
      "Epoch 03104: val_loss did not improve from 179.48197\n",
      "Epoch 3105/5000\n",
      "ecpch:3104,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1751 - val_loss: 194.1368\n",
      "\n",
      "Epoch 03105: val_loss did not improve from 179.48197\n",
      "Epoch 3106/5000\n",
      "ecpch:3105,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 55.1762 - val_loss: 194.1296\n",
      "\n",
      "Epoch 03106: val_loss did not improve from 179.48197\n",
      "Epoch 3107/5000\n",
      "ecpch:3106,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1747 - val_loss: 194.1256\n",
      "\n",
      "Epoch 03107: val_loss did not improve from 179.48197\n",
      "Epoch 3108/5000\n",
      "ecpch:3107,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1772 - val_loss: 194.1248\n",
      "\n",
      "Epoch 03108: val_loss did not improve from 179.48197\n",
      "Epoch 3109/5000\n",
      "ecpch:3108,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1762 - val_loss: 194.1323\n",
      "\n",
      "Epoch 03109: val_loss did not improve from 179.48197\n",
      "Epoch 3110/5000\n",
      "ecpch:3109,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1753 - val_loss: 194.1327\n",
      "\n",
      "Epoch 03110: val_loss did not improve from 179.48197\n",
      "Epoch 3111/5000\n",
      "ecpch:3110,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1754 - val_loss: 194.1293\n",
      "\n",
      "Epoch 03111: val_loss did not improve from 179.48197\n",
      "Epoch 3112/5000\n",
      "ecpch:3111,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1750 - val_loss: 194.1259\n",
      "\n",
      "Epoch 03112: val_loss did not improve from 179.48197\n",
      "Epoch 3113/5000\n",
      "ecpch:3112,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1746 - val_loss: 194.1363\n",
      "\n",
      "Epoch 03113: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 03113: ReduceLROnPlateau reducing learning rate to 5.822314790293603e-07.\n",
      "Epoch 3114/5000\n",
      "ecpch:3113,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 55.1750 - val_loss: 194.1335\n",
      "\n",
      "Epoch 03114: val_loss did not improve from 179.48197\n",
      "Epoch 3115/5000\n",
      "ecpch:3114,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1742 - val_loss: 194.1275\n",
      "\n",
      "Epoch 03115: val_loss did not improve from 179.48197\n",
      "Epoch 3116/5000\n",
      "ecpch:3115,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1743 - val_loss: 194.1314\n",
      "\n",
      "Epoch 03116: val_loss did not improve from 179.48197\n",
      "Epoch 3117/5000\n",
      "ecpch:3116,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1740 - val_loss: 194.1355\n",
      "\n",
      "Epoch 03117: val_loss did not improve from 179.48197\n",
      "Epoch 3118/5000\n",
      "ecpch:3117,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1740 - val_loss: 194.1317\n",
      "\n",
      "Epoch 03118: val_loss did not improve from 179.48197\n",
      "Epoch 3119/5000\n",
      "ecpch:3118,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1738 - val_loss: 194.1306\n",
      "\n",
      "Epoch 03119: val_loss did not improve from 179.48197\n",
      "Epoch 3120/5000\n",
      "ecpch:3119,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1735 - val_loss: 194.1315\n",
      "\n",
      "Epoch 03120: val_loss did not improve from 179.48197\n",
      "Epoch 3121/5000\n",
      "ecpch:3120,learn rate 0.000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1736 - val_loss: 194.1332\n",
      "\n",
      "Epoch 03121: val_loss did not improve from 179.48197\n",
      "Epoch 3122/5000\n",
      "ecpch:3121,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1733 - val_loss: 194.1371\n",
      "\n",
      "Epoch 03122: val_loss did not improve from 179.48197\n",
      "Epoch 3123/5000\n",
      "ecpch:3122,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1730 - val_loss: 194.1296\n",
      "\n",
      "Epoch 03123: val_loss did not improve from 179.48197\n",
      "Epoch 3124/5000\n",
      "ecpch:3123,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1729 - val_loss: 194.1302\n",
      "\n",
      "Epoch 03124: val_loss did not improve from 179.48197\n",
      "Epoch 3125/5000\n",
      "ecpch:3124,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1725 - val_loss: 194.1351\n",
      "\n",
      "Epoch 03125: val_loss did not improve from 179.48197\n",
      "Epoch 3126/5000\n",
      "ecpch:3125,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1730 - val_loss: 194.1300\n",
      "\n",
      "Epoch 03126: val_loss did not improve from 179.48197\n",
      "Epoch 3127/5000\n",
      "ecpch:3126,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1722 - val_loss: 194.1364\n",
      "\n",
      "Epoch 03127: val_loss did not improve from 179.48197\n",
      "Epoch 3128/5000\n",
      "ecpch:3127,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1727 - val_loss: 194.1369\n",
      "\n",
      "Epoch 03128: val_loss did not improve from 179.48197\n",
      "Epoch 3129/5000\n",
      "ecpch:3128,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1719 - val_loss: 194.1300\n",
      "\n",
      "Epoch 03129: val_loss did not improve from 179.48197\n",
      "Epoch 3130/5000\n",
      "ecpch:3129,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1721 - val_loss: 194.1357\n",
      "\n",
      "Epoch 03130: val_loss did not improve from 179.48197\n",
      "Epoch 3131/5000\n",
      "ecpch:3130,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1718 - val_loss: 194.1351\n",
      "\n",
      "Epoch 03131: val_loss did not improve from 179.48197\n",
      "Epoch 3132/5000\n",
      "ecpch:3131,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1714 - val_loss: 194.1303\n",
      "\n",
      "Epoch 03132: val_loss did not improve from 179.48197\n",
      "Epoch 3133/5000\n",
      "ecpch:3132,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1713 - val_loss: 194.1344\n",
      "\n",
      "Epoch 03133: val_loss did not improve from 179.48197\n",
      "Epoch 3134/5000\n",
      "ecpch:3133,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1716 - val_loss: 194.1387\n",
      "\n",
      "Epoch 03134: val_loss did not improve from 179.48197\n",
      "Epoch 3135/5000\n",
      "ecpch:3134,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1713 - val_loss: 194.1272\n",
      "\n",
      "Epoch 03135: val_loss did not improve from 179.48197\n",
      "Epoch 3136/5000\n",
      "ecpch:3135,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1708 - val_loss: 194.1387\n",
      "\n",
      "Epoch 03136: val_loss did not improve from 179.48197\n",
      "Epoch 3137/5000\n",
      "ecpch:3136,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1707 - val_loss: 194.1317\n",
      "\n",
      "Epoch 03137: val_loss did not improve from 179.48197\n",
      "Epoch 3138/5000\n",
      "ecpch:3137,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1707 - val_loss: 194.1350\n",
      "\n",
      "Epoch 03138: val_loss did not improve from 179.48197\n",
      "Epoch 3139/5000\n",
      "ecpch:3138,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1710 - val_loss: 194.1363\n",
      "\n",
      "Epoch 03139: val_loss did not improve from 179.48197\n",
      "Epoch 3140/5000\n",
      "ecpch:3139,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1706 - val_loss: 194.1370\n",
      "\n",
      "Epoch 03140: val_loss did not improve from 179.48197\n",
      "Epoch 3141/5000\n",
      "ecpch:3140,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1704 - val_loss: 194.1325\n",
      "\n",
      "Epoch 03141: val_loss did not improve from 179.48197\n",
      "Epoch 3142/5000\n",
      "ecpch:3141,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1702 - val_loss: 194.1349\n",
      "\n",
      "Epoch 03142: val_loss did not improve from 179.48197\n",
      "Epoch 3143/5000\n",
      "ecpch:3142,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1700 - val_loss: 194.1354\n",
      "\n",
      "Epoch 03143: val_loss did not improve from 179.48197\n",
      "Epoch 3144/5000\n",
      "ecpch:3143,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1703 - val_loss: 194.1285\n",
      "\n",
      "Epoch 03144: val_loss did not improve from 179.48197\n",
      "Epoch 3145/5000\n",
      "ecpch:3144,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1700 - val_loss: 194.1372\n",
      "\n",
      "Epoch 03145: val_loss did not improve from 179.48197\n",
      "Epoch 3146/5000\n",
      "ecpch:3145,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1699 - val_loss: 194.1365\n",
      "\n",
      "Epoch 03146: val_loss did not improve from 179.48197\n",
      "Epoch 3147/5000\n",
      "ecpch:3146,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1696 - val_loss: 194.1405\n",
      "\n",
      "Epoch 03147: val_loss did not improve from 179.48197\n",
      "Epoch 3148/5000\n",
      "ecpch:3147,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1696 - val_loss: 194.1330\n",
      "\n",
      "Epoch 03148: val_loss did not improve from 179.48197\n",
      "Epoch 3149/5000\n",
      "ecpch:3148,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1695 - val_loss: 194.1298\n",
      "\n",
      "Epoch 03149: val_loss did not improve from 179.48197\n",
      "Epoch 3150/5000\n",
      "ecpch:3149,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1691 - val_loss: 194.1372\n",
      "\n",
      "Epoch 03150: val_loss did not improve from 179.48197\n",
      "Epoch 3151/5000\n",
      "ecpch:3150,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1691 - val_loss: 194.1351\n",
      "\n",
      "Epoch 03151: val_loss did not improve from 179.48197\n",
      "Epoch 3152/5000\n",
      "ecpch:3151,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1692 - val_loss: 194.1367\n",
      "\n",
      "Epoch 03152: val_loss did not improve from 179.48197\n",
      "Epoch 3153/5000\n",
      "ecpch:3152,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1688 - val_loss: 194.1332\n",
      "\n",
      "Epoch 03153: val_loss did not improve from 179.48197\n",
      "Epoch 3154/5000\n",
      "ecpch:3153,learn rate 0.000001\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 55.1686 - val_loss: 194.1370\n",
      "\n",
      "Epoch 03154: val_loss did not improve from 179.48197\n",
      "Epoch 3155/5000\n",
      "ecpch:3154,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1690 - val_loss: 194.1407\n",
      "\n",
      "Epoch 03155: val_loss did not improve from 179.48197\n",
      "Epoch 3156/5000\n",
      "ecpch:3155,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1688 - val_loss: 194.1323\n",
      "\n",
      "Epoch 03156: val_loss did not improve from 179.48197\n",
      "Epoch 3157/5000\n",
      "ecpch:3156,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1684 - val_loss: 194.1417\n",
      "\n",
      "Epoch 03157: val_loss did not improve from 179.48197\n",
      "Epoch 3158/5000\n",
      "ecpch:3157,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1687 - val_loss: 194.1344\n",
      "\n",
      "Epoch 03158: val_loss did not improve from 179.48197\n",
      "Epoch 3159/5000\n",
      "ecpch:3158,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1679 - val_loss: 194.1371\n",
      "\n",
      "Epoch 03159: val_loss did not improve from 179.48197\n",
      "Epoch 3160/5000\n",
      "ecpch:3159,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1680 - val_loss: 194.1329\n",
      "\n",
      "Epoch 03160: val_loss did not improve from 179.48197\n",
      "Epoch 3161/5000\n",
      "ecpch:3160,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1688 - val_loss: 194.1328\n",
      "\n",
      "Epoch 03161: val_loss did not improve from 179.48197\n",
      "Epoch 3162/5000\n",
      "ecpch:3161,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1676 - val_loss: 194.1318\n",
      "\n",
      "Epoch 03162: val_loss did not improve from 179.48197\n",
      "Epoch 3163/5000\n",
      "ecpch:3162,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1686 - val_loss: 194.1352\n",
      "\n",
      "Epoch 03163: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 03163: ReduceLROnPlateau reducing learning rate to 5.240083055468858e-07.\n",
      "Epoch 3164/5000\n",
      "ecpch:3163,learn rate 0.000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1676 - val_loss: 194.1359\n",
      "\n",
      "Epoch 03164: val_loss did not improve from 179.48197\n",
      "Epoch 3165/5000\n",
      "ecpch:3164,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1684 - val_loss: 194.1371\n",
      "\n",
      "Epoch 03165: val_loss did not improve from 179.48197\n",
      "Epoch 3166/5000\n",
      "ecpch:3165,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1680 - val_loss: 194.1383\n",
      "\n",
      "Epoch 03166: val_loss did not improve from 179.48197\n",
      "Epoch 3167/5000\n",
      "ecpch:3166,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1680 - val_loss: 194.1271\n",
      "\n",
      "Epoch 03167: val_loss did not improve from 179.48197\n",
      "Epoch 3168/5000\n",
      "ecpch:3167,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1679 - val_loss: 194.1385\n",
      "\n",
      "Epoch 03168: val_loss did not improve from 179.48197\n",
      "Epoch 3169/5000\n",
      "ecpch:3168,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1675 - val_loss: 194.1347\n",
      "\n",
      "Epoch 03169: val_loss did not improve from 179.48197\n",
      "Epoch 3170/5000\n",
      "ecpch:3169,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1676 - val_loss: 194.1311\n",
      "\n",
      "Epoch 03170: val_loss did not improve from 179.48197\n",
      "Epoch 3171/5000\n",
      "ecpch:3170,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1669 - val_loss: 194.1366\n",
      "\n",
      "Epoch 03171: val_loss did not improve from 179.48197\n",
      "Epoch 3172/5000\n",
      "ecpch:3171,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1670 - val_loss: 194.1384\n",
      "\n",
      "Epoch 03172: val_loss did not improve from 179.48197\n",
      "Epoch 3173/5000\n",
      "ecpch:3172,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1673 - val_loss: 194.1327\n",
      "\n",
      "Epoch 03173: val_loss did not improve from 179.48197\n",
      "Epoch 3174/5000\n",
      "ecpch:3173,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1664 - val_loss: 194.1308\n",
      "\n",
      "Epoch 03174: val_loss did not improve from 179.48197\n",
      "Epoch 3175/5000\n",
      "ecpch:3174,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1677 - val_loss: 194.1322\n",
      "\n",
      "Epoch 03175: val_loss did not improve from 179.48197\n",
      "Epoch 3176/5000\n",
      "ecpch:3175,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1670 - val_loss: 194.1450\n",
      "\n",
      "Epoch 03176: val_loss did not improve from 179.48197\n",
      "Epoch 3177/5000\n",
      "ecpch:3176,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1671 - val_loss: 194.1367\n",
      "\n",
      "Epoch 03177: val_loss did not improve from 179.48197\n",
      "Epoch 3178/5000\n",
      "ecpch:3177,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1670 - val_loss: 194.1362\n",
      "\n",
      "Epoch 03178: val_loss did not improve from 179.48197\n",
      "Epoch 3179/5000\n",
      "ecpch:3178,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1666 - val_loss: 194.1323\n",
      "\n",
      "Epoch 03179: val_loss did not improve from 179.48197\n",
      "Epoch 3180/5000\n",
      "ecpch:3179,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1668 - val_loss: 194.1354\n",
      "\n",
      "Epoch 03180: val_loss did not improve from 179.48197\n",
      "Epoch 3181/5000\n",
      "ecpch:3180,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1664 - val_loss: 194.1383\n",
      "\n",
      "Epoch 03181: val_loss did not improve from 179.48197\n",
      "Epoch 3182/5000\n",
      "ecpch:3181,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1665 - val_loss: 194.1344\n",
      "\n",
      "Epoch 03182: val_loss did not improve from 179.48197\n",
      "Epoch 3183/5000\n",
      "ecpch:3182,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 55.1670 - val_loss: 194.1369\n",
      "\n",
      "Epoch 03183: val_loss did not improve from 179.48197\n",
      "Epoch 3184/5000\n",
      "ecpch:3183,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1660 - val_loss: 194.1385\n",
      "\n",
      "Epoch 03184: val_loss did not improve from 179.48197\n",
      "Epoch 3185/5000\n",
      "ecpch:3184,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1662 - val_loss: 194.1377\n",
      "\n",
      "Epoch 03185: val_loss did not improve from 179.48197\n",
      "Epoch 3186/5000\n",
      "ecpch:3185,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1661 - val_loss: 194.1327\n",
      "\n",
      "Epoch 03186: val_loss did not improve from 179.48197\n",
      "Epoch 3187/5000\n",
      "ecpch:3186,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1661 - val_loss: 194.1371\n",
      "\n",
      "Epoch 03187: val_loss did not improve from 179.48197\n",
      "Epoch 3188/5000\n",
      "ecpch:3187,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1658 - val_loss: 194.1364\n",
      "\n",
      "Epoch 03188: val_loss did not improve from 179.48197\n",
      "Epoch 3189/5000\n",
      "ecpch:3188,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1657 - val_loss: 194.1399\n",
      "\n",
      "Epoch 03189: val_loss did not improve from 179.48197\n",
      "Epoch 3190/5000\n",
      "ecpch:3189,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1660 - val_loss: 194.1375\n",
      "\n",
      "Epoch 03190: val_loss did not improve from 179.48197\n",
      "Epoch 3191/5000\n",
      "ecpch:3190,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1647 - val_loss: 194.1302\n",
      "\n",
      "Epoch 03191: val_loss did not improve from 179.48197\n",
      "Epoch 3192/5000\n",
      "ecpch:3191,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1661 - val_loss: 194.1378\n",
      "\n",
      "Epoch 03192: val_loss did not improve from 179.48197\n",
      "Epoch 3193/5000\n",
      "ecpch:3192,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1655 - val_loss: 194.1405\n",
      "\n",
      "Epoch 03193: val_loss did not improve from 179.48197\n",
      "Epoch 3194/5000\n",
      "ecpch:3193,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1650 - val_loss: 194.1420\n",
      "\n",
      "Epoch 03194: val_loss did not improve from 179.48197\n",
      "Epoch 3195/5000\n",
      "ecpch:3194,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1659 - val_loss: 194.1371\n",
      "\n",
      "Epoch 03195: val_loss did not improve from 179.48197\n",
      "Epoch 3196/5000\n",
      "ecpch:3195,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1644 - val_loss: 194.1288\n",
      "\n",
      "Epoch 03196: val_loss did not improve from 179.48197\n",
      "Epoch 3197/5000\n",
      "ecpch:3196,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1653 - val_loss: 194.1332\n",
      "\n",
      "Epoch 03197: val_loss did not improve from 179.48197\n",
      "Epoch 3198/5000\n",
      "ecpch:3197,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1653 - val_loss: 194.1376\n",
      "\n",
      "Epoch 03198: val_loss did not improve from 179.48197\n",
      "Epoch 3199/5000\n",
      "ecpch:3198,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1638 - val_loss: 194.1451\n",
      "\n",
      "Epoch 03199: val_loss did not improve from 179.48197\n",
      "Epoch 3200/5000\n",
      "ecpch:3199,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1654 - val_loss: 194.1394\n",
      "\n",
      "Epoch 03200: val_loss did not improve from 179.48197\n",
      "Epoch 3201/5000\n",
      "ecpch:3200,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1645 - val_loss: 194.1376\n",
      "\n",
      "Epoch 03201: val_loss did not improve from 179.48197\n",
      "Epoch 3202/5000\n",
      "ecpch:3201,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1642 - val_loss: 194.1401\n",
      "\n",
      "Epoch 03202: val_loss did not improve from 179.48197\n",
      "Epoch 3203/5000\n",
      "ecpch:3202,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1647 - val_loss: 194.1336\n",
      "\n",
      "Epoch 03203: val_loss did not improve from 179.48197\n",
      "Epoch 3204/5000\n",
      "ecpch:3203,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1633 - val_loss: 194.1376\n",
      "\n",
      "Epoch 03204: val_loss did not improve from 179.48197\n",
      "Epoch 3205/5000\n",
      "ecpch:3204,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1643 - val_loss: 194.1386\n",
      "\n",
      "Epoch 03205: val_loss did not improve from 179.48197\n",
      "Epoch 3206/5000\n",
      "ecpch:3205,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1640 - val_loss: 194.1323\n",
      "\n",
      "Epoch 03206: val_loss did not improve from 179.48197\n",
      "Epoch 3207/5000\n",
      "ecpch:3206,learn rate 0.000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1629 - val_loss: 194.1417\n",
      "\n",
      "Epoch 03207: val_loss did not improve from 179.48197\n",
      "Epoch 3208/5000\n",
      "ecpch:3207,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1640 - val_loss: 194.1352\n",
      "\n",
      "Epoch 03208: val_loss did not improve from 179.48197\n",
      "Epoch 3209/5000\n",
      "ecpch:3208,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1637 - val_loss: 194.1374\n",
      "\n",
      "Epoch 03209: val_loss did not improve from 179.48197\n",
      "Epoch 3210/5000\n",
      "ecpch:3209,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1631 - val_loss: 194.1296\n",
      "\n",
      "Epoch 03210: val_loss did not improve from 179.48197\n",
      "Epoch 3211/5000\n",
      "ecpch:3210,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 55.1637 - val_loss: 194.1384\n",
      "\n",
      "Epoch 03211: val_loss did not improve from 179.48197\n",
      "Epoch 3212/5000\n",
      "ecpch:3211,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1623 - val_loss: 194.1406\n",
      "\n",
      "Epoch 03212: val_loss did not improve from 179.48197\n",
      "Epoch 3213/5000\n",
      "ecpch:3212,learn rate 0.000001\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1634 - val_loss: 194.1412\n",
      "\n",
      "Epoch 03213: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 03213: ReduceLROnPlateau reducing learning rate to 4.71607495455828e-07.\n",
      "Epoch 3214/5000\n",
      "ecpch:3213,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1627 - val_loss: 194.1455\n",
      "\n",
      "Epoch 03214: val_loss did not improve from 179.48197\n",
      "Epoch 3215/5000\n",
      "ecpch:3214,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1625 - val_loss: 194.1392\n",
      "\n",
      "Epoch 03215: val_loss did not improve from 179.48197\n",
      "Epoch 3216/5000\n",
      "ecpch:3215,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1626 - val_loss: 194.1382\n",
      "\n",
      "Epoch 03216: val_loss did not improve from 179.48197\n",
      "Epoch 3217/5000\n",
      "ecpch:3216,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1616 - val_loss: 194.1389\n",
      "\n",
      "Epoch 03217: val_loss did not improve from 179.48197\n",
      "Epoch 3218/5000\n",
      "ecpch:3217,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1622 - val_loss: 194.1348\n",
      "\n",
      "Epoch 03218: val_loss did not improve from 179.48197\n",
      "Epoch 3219/5000\n",
      "ecpch:3218,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1613 - val_loss: 194.1439\n",
      "\n",
      "Epoch 03219: val_loss did not improve from 179.48197\n",
      "Epoch 3220/5000\n",
      "ecpch:3219,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1618 - val_loss: 194.1409\n",
      "\n",
      "Epoch 03220: val_loss did not improve from 179.48197\n",
      "Epoch 3221/5000\n",
      "ecpch:3220,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1611 - val_loss: 194.1405\n",
      "\n",
      "Epoch 03221: val_loss did not improve from 179.48197\n",
      "Epoch 3222/5000\n",
      "ecpch:3221,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1616 - val_loss: 194.1361\n",
      "\n",
      "Epoch 03222: val_loss did not improve from 179.48197\n",
      "Epoch 3223/5000\n",
      "ecpch:3222,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 55.1611 - val_loss: 194.1415\n",
      "\n",
      "Epoch 03223: val_loss did not improve from 179.48197\n",
      "Epoch 3224/5000\n",
      "ecpch:3223,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1613 - val_loss: 194.1400\n",
      "\n",
      "Epoch 03224: val_loss did not improve from 179.48197\n",
      "Epoch 3225/5000\n",
      "ecpch:3224,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1609 - val_loss: 194.1408\n",
      "\n",
      "Epoch 03225: val_loss did not improve from 179.48197\n",
      "Epoch 3226/5000\n",
      "ecpch:3225,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1613 - val_loss: 194.1364\n",
      "\n",
      "Epoch 03226: val_loss did not improve from 179.48197\n",
      "Epoch 3227/5000\n",
      "ecpch:3226,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1611 - val_loss: 194.1409\n",
      "\n",
      "Epoch 03227: val_loss did not improve from 179.48197\n",
      "Epoch 3228/5000\n",
      "ecpch:3227,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1602 - val_loss: 194.1414\n",
      "\n",
      "Epoch 03228: val_loss did not improve from 179.48197\n",
      "Epoch 3229/5000\n",
      "ecpch:3228,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1607 - val_loss: 194.1428\n",
      "\n",
      "Epoch 03229: val_loss did not improve from 179.48197\n",
      "Epoch 3230/5000\n",
      "ecpch:3229,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1604 - val_loss: 194.1372\n",
      "\n",
      "Epoch 03230: val_loss did not improve from 179.48197\n",
      "Epoch 3231/5000\n",
      "ecpch:3230,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1602 - val_loss: 194.1403\n",
      "\n",
      "Epoch 03231: val_loss did not improve from 179.48197\n",
      "Epoch 3232/5000\n",
      "ecpch:3231,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1603 - val_loss: 194.1426\n",
      "\n",
      "Epoch 03232: val_loss did not improve from 179.48197\n",
      "Epoch 3233/5000\n",
      "ecpch:3232,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1598 - val_loss: 194.1428\n",
      "\n",
      "Epoch 03233: val_loss did not improve from 179.48197\n",
      "Epoch 3234/5000\n",
      "ecpch:3233,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1602 - val_loss: 194.1427\n",
      "\n",
      "Epoch 03234: val_loss did not improve from 179.48197\n",
      "Epoch 3235/5000\n",
      "ecpch:3234,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1597 - val_loss: 194.1380\n",
      "\n",
      "Epoch 03235: val_loss did not improve from 179.48197\n",
      "Epoch 3236/5000\n",
      "ecpch:3235,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1603 - val_loss: 194.1369\n",
      "\n",
      "Epoch 03236: val_loss did not improve from 179.48197\n",
      "Epoch 3237/5000\n",
      "ecpch:3236,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1597 - val_loss: 194.1431\n",
      "\n",
      "Epoch 03237: val_loss did not improve from 179.48197\n",
      "Epoch 3238/5000\n",
      "ecpch:3237,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1605 - val_loss: 194.1426\n",
      "\n",
      "Epoch 03238: val_loss did not improve from 179.48197\n",
      "Epoch 3239/5000\n",
      "ecpch:3238,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1602 - val_loss: 194.1366\n",
      "\n",
      "Epoch 03239: val_loss did not improve from 179.48197\n",
      "Epoch 3240/5000\n",
      "ecpch:3239,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1597 - val_loss: 194.1383\n",
      "\n",
      "Epoch 03240: val_loss did not improve from 179.48197\n",
      "Epoch 3241/5000\n",
      "ecpch:3240,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1600 - val_loss: 194.1383\n",
      "\n",
      "Epoch 03241: val_loss did not improve from 179.48197\n",
      "Epoch 3242/5000\n",
      "ecpch:3241,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1595 - val_loss: 194.1412\n",
      "\n",
      "Epoch 03242: val_loss did not improve from 179.48197\n",
      "Epoch 3243/5000\n",
      "ecpch:3242,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1593 - val_loss: 194.1401\n",
      "\n",
      "Epoch 03243: val_loss did not improve from 179.48197\n",
      "Epoch 3244/5000\n",
      "ecpch:3243,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1593 - val_loss: 194.1458\n",
      "\n",
      "Epoch 03244: val_loss did not improve from 179.48197\n",
      "Epoch 3245/5000\n",
      "ecpch:3244,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1591 - val_loss: 194.1454\n",
      "\n",
      "Epoch 03245: val_loss did not improve from 179.48197\n",
      "Epoch 3246/5000\n",
      "ecpch:3245,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1591 - val_loss: 194.1399\n",
      "\n",
      "Epoch 03246: val_loss did not improve from 179.48197\n",
      "Epoch 3247/5000\n",
      "ecpch:3246,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1586 - val_loss: 194.1432\n",
      "\n",
      "Epoch 03247: val_loss did not improve from 179.48197\n",
      "Epoch 3248/5000\n",
      "ecpch:3247,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1588 - val_loss: 194.1380\n",
      "\n",
      "Epoch 03248: val_loss did not improve from 179.48197\n",
      "Epoch 3249/5000\n",
      "ecpch:3248,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1582 - val_loss: 194.1381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 03249: val_loss did not improve from 179.48197\n",
      "Epoch 3250/5000\n",
      "ecpch:3249,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1587 - val_loss: 194.1389\n",
      "\n",
      "Epoch 03250: val_loss did not improve from 179.48197\n",
      "Epoch 3251/5000\n",
      "ecpch:3250,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1582 - val_loss: 194.1457\n",
      "\n",
      "Epoch 03251: val_loss did not improve from 179.48197\n",
      "Epoch 3252/5000\n",
      "ecpch:3251,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1581 - val_loss: 194.1369\n",
      "\n",
      "Epoch 03252: val_loss did not improve from 179.48197\n",
      "Epoch 3253/5000\n",
      "ecpch:3252,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1579 - val_loss: 194.1400\n",
      "\n",
      "Epoch 03253: val_loss did not improve from 179.48197\n",
      "Epoch 3254/5000\n",
      "ecpch:3253,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1577 - val_loss: 194.1407\n",
      "\n",
      "Epoch 03254: val_loss did not improve from 179.48197\n",
      "Epoch 3255/5000\n",
      "ecpch:3254,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1575 - val_loss: 194.1442\n",
      "\n",
      "Epoch 03255: val_loss did not improve from 179.48197\n",
      "Epoch 3256/5000\n",
      "ecpch:3255,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1576 - val_loss: 194.1429\n",
      "\n",
      "Epoch 03256: val_loss did not improve from 179.48197\n",
      "Epoch 3257/5000\n",
      "ecpch:3256,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1572 - val_loss: 194.1438\n",
      "\n",
      "Epoch 03257: val_loss did not improve from 179.48197\n",
      "Epoch 3258/5000\n",
      "ecpch:3257,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1577 - val_loss: 194.1383\n",
      "\n",
      "Epoch 03258: val_loss did not improve from 179.48197\n",
      "Epoch 3259/5000\n",
      "ecpch:3258,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1572 - val_loss: 194.1429\n",
      "\n",
      "Epoch 03259: val_loss did not improve from 179.48197\n",
      "Epoch 3260/5000\n",
      "ecpch:3259,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1570 - val_loss: 194.1426\n",
      "\n",
      "Epoch 03260: val_loss did not improve from 179.48197\n",
      "Epoch 3261/5000\n",
      "ecpch:3260,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1569 - val_loss: 194.1369\n",
      "\n",
      "Epoch 03261: val_loss did not improve from 179.48197\n",
      "Epoch 3262/5000\n",
      "ecpch:3261,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1568 - val_loss: 194.1448\n",
      "\n",
      "Epoch 03262: val_loss did not improve from 179.48197\n",
      "Epoch 3263/5000\n",
      "ecpch:3262,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1568 - val_loss: 194.1421\n",
      "\n",
      "Epoch 03263: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 03263: ReduceLROnPlateau reducing learning rate to 4.244467561420606e-07.\n",
      "Epoch 3264/5000\n",
      "ecpch:3263,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1566 - val_loss: 194.1477\n",
      "\n",
      "Epoch 03264: val_loss did not improve from 179.48197\n",
      "Epoch 3265/5000\n",
      "ecpch:3264,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1567 - val_loss: 194.1407\n",
      "\n",
      "Epoch 03265: val_loss did not improve from 179.48197\n",
      "Epoch 3266/5000\n",
      "ecpch:3265,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1565 - val_loss: 194.1443\n",
      "\n",
      "Epoch 03266: val_loss did not improve from 179.48197\n",
      "Epoch 3267/5000\n",
      "ecpch:3266,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1563 - val_loss: 194.1449\n",
      "\n",
      "Epoch 03267: val_loss did not improve from 179.48197\n",
      "Epoch 3268/5000\n",
      "ecpch:3267,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1567 - val_loss: 194.1450\n",
      "\n",
      "Epoch 03268: val_loss did not improve from 179.48197\n",
      "Epoch 3269/5000\n",
      "ecpch:3268,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1559 - val_loss: 194.1395\n",
      "\n",
      "Epoch 03269: val_loss did not improve from 179.48197\n",
      "Epoch 3270/5000\n",
      "ecpch:3269,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1563 - val_loss: 194.1445\n",
      "\n",
      "Epoch 03270: val_loss did not improve from 179.48197\n",
      "Epoch 3271/5000\n",
      "ecpch:3270,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1558 - val_loss: 194.1438\n",
      "\n",
      "Epoch 03271: val_loss did not improve from 179.48197\n",
      "Epoch 3272/5000\n",
      "ecpch:3271,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1558 - val_loss: 194.1438\n",
      "\n",
      "Epoch 03272: val_loss did not improve from 179.48197\n",
      "Epoch 3273/5000\n",
      "ecpch:3272,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1558 - val_loss: 194.1487\n",
      "\n",
      "Epoch 03273: val_loss did not improve from 179.48197\n",
      "Epoch 3274/5000\n",
      "ecpch:3273,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1555 - val_loss: 194.1383\n",
      "\n",
      "Epoch 03274: val_loss did not improve from 179.48197\n",
      "Epoch 3275/5000\n",
      "ecpch:3274,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1556 - val_loss: 194.1486\n",
      "\n",
      "Epoch 03275: val_loss did not improve from 179.48197\n",
      "Epoch 3276/5000\n",
      "ecpch:3275,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1553 - val_loss: 194.1451\n",
      "\n",
      "Epoch 03276: val_loss did not improve from 179.48197\n",
      "Epoch 3277/5000\n",
      "ecpch:3276,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1556 - val_loss: 194.1405\n",
      "\n",
      "Epoch 03277: val_loss did not improve from 179.48197\n",
      "Epoch 3278/5000\n",
      "ecpch:3277,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1553 - val_loss: 194.1473\n",
      "\n",
      "Epoch 03278: val_loss did not improve from 179.48197\n",
      "Epoch 3279/5000\n",
      "ecpch:3278,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1551 - val_loss: 194.1425\n",
      "\n",
      "Epoch 03279: val_loss did not improve from 179.48197\n",
      "Epoch 3280/5000\n",
      "ecpch:3279,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1555 - val_loss: 194.1455\n",
      "\n",
      "Epoch 03280: val_loss did not improve from 179.48197\n",
      "Epoch 3281/5000\n",
      "ecpch:3280,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1549 - val_loss: 194.1451\n",
      "\n",
      "Epoch 03281: val_loss did not improve from 179.48197\n",
      "Epoch 3282/5000\n",
      "ecpch:3281,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1549 - val_loss: 194.1474\n",
      "\n",
      "Epoch 03282: val_loss did not improve from 179.48197\n",
      "Epoch 3283/5000\n",
      "ecpch:3282,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1550 - val_loss: 194.1463\n",
      "\n",
      "Epoch 03283: val_loss did not improve from 179.48197\n",
      "Epoch 3284/5000\n",
      "ecpch:3283,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1547 - val_loss: 194.1431\n",
      "\n",
      "Epoch 03284: val_loss did not improve from 179.48197\n",
      "Epoch 3285/5000\n",
      "ecpch:3284,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1547 - val_loss: 194.1420\n",
      "\n",
      "Epoch 03285: val_loss did not improve from 179.48197\n",
      "Epoch 3286/5000\n",
      "ecpch:3285,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1546 - val_loss: 194.1414\n",
      "\n",
      "Epoch 03286: val_loss did not improve from 179.48197\n",
      "Epoch 3287/5000\n",
      "ecpch:3286,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1544 - val_loss: 194.1446\n",
      "\n",
      "Epoch 03287: val_loss did not improve from 179.48197\n",
      "Epoch 3288/5000\n",
      "ecpch:3287,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1545 - val_loss: 194.1515\n",
      "\n",
      "Epoch 03288: val_loss did not improve from 179.48197\n",
      "Epoch 3289/5000\n",
      "ecpch:3288,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1549 - val_loss: 194.1513\n",
      "\n",
      "Epoch 03289: val_loss did not improve from 179.48197\n",
      "Epoch 3290/5000\n",
      "ecpch:3289,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1542 - val_loss: 194.1399\n",
      "\n",
      "Epoch 03290: val_loss did not improve from 179.48197\n",
      "Epoch 3291/5000\n",
      "ecpch:3290,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1549 - val_loss: 194.1386\n",
      "\n",
      "Epoch 03291: val_loss did not improve from 179.48197\n",
      "Epoch 3292/5000\n",
      "ecpch:3291,learn rate 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1544 - val_loss: 194.1512\n",
      "\n",
      "Epoch 03292: val_loss did not improve from 179.48197\n",
      "Epoch 3293/5000\n",
      "ecpch:3292,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1548 - val_loss: 194.1491\n",
      "\n",
      "Epoch 03293: val_loss did not improve from 179.48197\n",
      "Epoch 3294/5000\n",
      "ecpch:3293,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1546 - val_loss: 194.1428\n",
      "\n",
      "Epoch 03294: val_loss did not improve from 179.48197\n",
      "Epoch 3295/5000\n",
      "ecpch:3294,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 55.1540 - val_loss: 194.1407\n",
      "\n",
      "Epoch 03295: val_loss did not improve from 179.48197\n",
      "Epoch 3296/5000\n",
      "ecpch:3295,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1538 - val_loss: 194.1428\n",
      "\n",
      "Epoch 03296: val_loss did not improve from 179.48197\n",
      "Epoch 3297/5000\n",
      "ecpch:3296,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1540 - val_loss: 194.1424\n",
      "\n",
      "Epoch 03297: val_loss did not improve from 179.48197\n",
      "Epoch 3298/5000\n",
      "ecpch:3297,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1536 - val_loss: 194.1387\n",
      "\n",
      "Epoch 03298: val_loss did not improve from 179.48197\n",
      "Epoch 3299/5000\n",
      "ecpch:3298,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1537 - val_loss: 194.1482\n",
      "\n",
      "Epoch 03299: val_loss did not improve from 179.48197\n",
      "Epoch 3300/5000\n",
      "ecpch:3299,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1532 - val_loss: 194.1532\n",
      "\n",
      "Epoch 03300: val_loss did not improve from 179.48197\n",
      "Epoch 3301/5000\n",
      "ecpch:3300,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1536 - val_loss: 194.1426\n",
      "\n",
      "Epoch 03301: val_loss did not improve from 179.48197\n",
      "Epoch 3302/5000\n",
      "ecpch:3301,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1531 - val_loss: 194.1439\n",
      "\n",
      "Epoch 03302: val_loss did not improve from 179.48197\n",
      "Epoch 3303/5000\n",
      "ecpch:3302,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1535 - val_loss: 194.1476\n",
      "\n",
      "Epoch 03303: val_loss did not improve from 179.48197\n",
      "Epoch 3304/5000\n",
      "ecpch:3303,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1530 - val_loss: 194.1440\n",
      "\n",
      "Epoch 03304: val_loss did not improve from 179.48197\n",
      "Epoch 3305/5000\n",
      "ecpch:3304,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1535 - val_loss: 194.1464\n",
      "\n",
      "Epoch 03305: val_loss did not improve from 179.48197\n",
      "Epoch 3306/5000\n",
      "ecpch:3305,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1530 - val_loss: 194.1369\n",
      "\n",
      "Epoch 03306: val_loss did not improve from 179.48197\n",
      "Epoch 3307/5000\n",
      "ecpch:3306,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1533 - val_loss: 194.1420\n",
      "\n",
      "Epoch 03307: val_loss did not improve from 179.48197\n",
      "Epoch 3308/5000\n",
      "ecpch:3307,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1531 - val_loss: 194.1458\n",
      "\n",
      "Epoch 03308: val_loss did not improve from 179.48197\n",
      "Epoch 3309/5000\n",
      "ecpch:3308,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1528 - val_loss: 194.1469\n",
      "\n",
      "Epoch 03309: val_loss did not improve from 179.48197\n",
      "Epoch 3310/5000\n",
      "ecpch:3309,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 55.1526 - val_loss: 194.1415\n",
      "\n",
      "Epoch 03310: val_loss did not improve from 179.48197\n",
      "Epoch 3311/5000\n",
      "ecpch:3310,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1526 - val_loss: 194.1370\n",
      "\n",
      "Epoch 03311: val_loss did not improve from 179.48197\n",
      "Epoch 3312/5000\n",
      "ecpch:3311,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1523 - val_loss: 194.1442\n",
      "\n",
      "Epoch 03312: val_loss did not improve from 179.48197\n",
      "Epoch 3313/5000\n",
      "ecpch:3312,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1527 - val_loss: 194.1480\n",
      "\n",
      "Epoch 03313: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 03313: ReduceLROnPlateau reducing learning rate to 3.8200209075967e-07.\n",
      "Epoch 3314/5000\n",
      "ecpch:3313,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1523 - val_loss: 194.1457\n",
      "\n",
      "Epoch 03314: val_loss did not improve from 179.48197\n",
      "Epoch 3315/5000\n",
      "ecpch:3314,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1520 - val_loss: 194.1481\n",
      "\n",
      "Epoch 03315: val_loss did not improve from 179.48197\n",
      "Epoch 3316/5000\n",
      "ecpch:3315,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1517 - val_loss: 194.1441\n",
      "\n",
      "Epoch 03316: val_loss did not improve from 179.48197\n",
      "Epoch 3317/5000\n",
      "ecpch:3316,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1519 - val_loss: 194.1449\n",
      "\n",
      "Epoch 03317: val_loss did not improve from 179.48197\n",
      "Epoch 3318/5000\n",
      "ecpch:3317,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1517 - val_loss: 194.1446\n",
      "\n",
      "Epoch 03318: val_loss did not improve from 179.48197\n",
      "Epoch 3319/5000\n",
      "ecpch:3318,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1518 - val_loss: 194.1446\n",
      "\n",
      "Epoch 03319: val_loss did not improve from 179.48197\n",
      "Epoch 3320/5000\n",
      "ecpch:3319,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1518 - val_loss: 194.1490\n",
      "\n",
      "Epoch 03320: val_loss did not improve from 179.48197\n",
      "Epoch 3321/5000\n",
      "ecpch:3320,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1516 - val_loss: 194.1484\n",
      "\n",
      "Epoch 03321: val_loss did not improve from 179.48197\n",
      "Epoch 3322/5000\n",
      "ecpch:3321,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1515 - val_loss: 194.1489\n",
      "\n",
      "Epoch 03322: val_loss did not improve from 179.48197\n",
      "Epoch 3323/5000\n",
      "ecpch:3322,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1511 - val_loss: 194.1484\n",
      "\n",
      "Epoch 03323: val_loss did not improve from 179.48197\n",
      "Epoch 3324/5000\n",
      "ecpch:3323,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1510 - val_loss: 194.1455\n",
      "\n",
      "Epoch 03324: val_loss did not improve from 179.48197\n",
      "Epoch 3325/5000\n",
      "ecpch:3324,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1512 - val_loss: 194.1426\n",
      "\n",
      "Epoch 03325: val_loss did not improve from 179.48197\n",
      "Epoch 3326/5000\n",
      "ecpch:3325,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1509 - val_loss: 194.1487\n",
      "\n",
      "Epoch 03326: val_loss did not improve from 179.48197\n",
      "Epoch 3327/5000\n",
      "ecpch:3326,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1512 - val_loss: 194.1478\n",
      "\n",
      "Epoch 03327: val_loss did not improve from 179.48197\n",
      "Epoch 3328/5000\n",
      "ecpch:3327,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1507 - val_loss: 194.1479\n",
      "\n",
      "Epoch 03328: val_loss did not improve from 179.48197\n",
      "Epoch 3329/5000\n",
      "ecpch:3328,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1510 - val_loss: 194.1452\n",
      "\n",
      "Epoch 03329: val_loss did not improve from 179.48197\n",
      "Epoch 3330/5000\n",
      "ecpch:3329,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1508 - val_loss: 194.1452\n",
      "\n",
      "Epoch 03330: val_loss did not improve from 179.48197\n",
      "Epoch 3331/5000\n",
      "ecpch:3330,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1507 - val_loss: 194.1390\n",
      "\n",
      "Epoch 03331: val_loss did not improve from 179.48197\n",
      "Epoch 3332/5000\n",
      "ecpch:3331,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1506 - val_loss: 194.1474\n",
      "\n",
      "Epoch 03332: val_loss did not improve from 179.48197\n",
      "Epoch 3333/5000\n",
      "ecpch:3332,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 55.1502 - val_loss: 194.1467\n",
      "\n",
      "Epoch 03333: val_loss did not improve from 179.48197\n",
      "Epoch 3334/5000\n",
      "ecpch:3333,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1502 - val_loss: 194.1487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 03334: val_loss did not improve from 179.48197\n",
      "Epoch 3335/5000\n",
      "ecpch:3334,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1503 - val_loss: 194.1476\n",
      "\n",
      "Epoch 03335: val_loss did not improve from 179.48197\n",
      "Epoch 3336/5000\n",
      "ecpch:3335,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1499 - val_loss: 194.1484\n",
      "\n",
      "Epoch 03336: val_loss did not improve from 179.48197\n",
      "Epoch 3337/5000\n",
      "ecpch:3336,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1503 - val_loss: 194.1471\n",
      "\n",
      "Epoch 03337: val_loss did not improve from 179.48197\n",
      "Epoch 3338/5000\n",
      "ecpch:3337,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1499 - val_loss: 194.1515\n",
      "\n",
      "Epoch 03338: val_loss did not improve from 179.48197\n",
      "Epoch 3339/5000\n",
      "ecpch:3338,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1501 - val_loss: 194.1470\n",
      "\n",
      "Epoch 03339: val_loss did not improve from 179.48197\n",
      "Epoch 3340/5000\n",
      "ecpch:3339,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1498 - val_loss: 194.1519\n",
      "\n",
      "Epoch 03340: val_loss did not improve from 179.48197\n",
      "Epoch 3341/5000\n",
      "ecpch:3340,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1499 - val_loss: 194.1526\n",
      "\n",
      "Epoch 03341: val_loss did not improve from 179.48197\n",
      "Epoch 3342/5000\n",
      "ecpch:3341,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1497 - val_loss: 194.1439\n",
      "\n",
      "Epoch 03342: val_loss did not improve from 179.48197\n",
      "Epoch 3343/5000\n",
      "ecpch:3342,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1496 - val_loss: 194.1485\n",
      "\n",
      "Epoch 03343: val_loss did not improve from 179.48197\n",
      "Epoch 3344/5000\n",
      "ecpch:3343,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1497 - val_loss: 194.1450\n",
      "\n",
      "Epoch 03344: val_loss did not improve from 179.48197\n",
      "Epoch 3345/5000\n",
      "ecpch:3344,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1493 - val_loss: 194.1505\n",
      "\n",
      "Epoch 03345: val_loss did not improve from 179.48197\n",
      "Epoch 3346/5000\n",
      "ecpch:3345,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1490 - val_loss: 194.1451\n",
      "\n",
      "Epoch 03346: val_loss did not improve from 179.48197\n",
      "Epoch 3347/5000\n",
      "ecpch:3346,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1492 - val_loss: 194.1422\n",
      "\n",
      "Epoch 03347: val_loss did not improve from 179.48197\n",
      "Epoch 3348/5000\n",
      "ecpch:3347,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1491 - val_loss: 194.1454\n",
      "\n",
      "Epoch 03348: val_loss did not improve from 179.48197\n",
      "Epoch 3349/5000\n",
      "ecpch:3348,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1491 - val_loss: 194.1503\n",
      "\n",
      "Epoch 03349: val_loss did not improve from 179.48197\n",
      "Epoch 3350/5000\n",
      "ecpch:3349,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1490 - val_loss: 194.1524\n",
      "\n",
      "Epoch 03350: val_loss did not improve from 179.48197\n",
      "Epoch 3351/5000\n",
      "ecpch:3350,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1489 - val_loss: 194.1452\n",
      "\n",
      "Epoch 03351: val_loss did not improve from 179.48197\n",
      "Epoch 3352/5000\n",
      "ecpch:3351,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1486 - val_loss: 194.1476\n",
      "\n",
      "Epoch 03352: val_loss did not improve from 179.48197\n",
      "Epoch 3353/5000\n",
      "ecpch:3352,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1487 - val_loss: 194.1508\n",
      "\n",
      "Epoch 03353: val_loss did not improve from 179.48197\n",
      "Epoch 3354/5000\n",
      "ecpch:3353,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1485 - val_loss: 194.1529\n",
      "\n",
      "Epoch 03354: val_loss did not improve from 179.48197\n",
      "Epoch 3355/5000\n",
      "ecpch:3354,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1488 - val_loss: 194.1489\n",
      "\n",
      "Epoch 03355: val_loss did not improve from 179.48197\n",
      "Epoch 3356/5000\n",
      "ecpch:3355,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1484 - val_loss: 194.1467\n",
      "\n",
      "Epoch 03356: val_loss did not improve from 179.48197\n",
      "Epoch 3357/5000\n",
      "ecpch:3356,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1487 - val_loss: 194.1483\n",
      "\n",
      "Epoch 03357: val_loss did not improve from 179.48197\n",
      "Epoch 3358/5000\n",
      "ecpch:3357,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1483 - val_loss: 194.1461\n",
      "\n",
      "Epoch 03358: val_loss did not improve from 179.48197\n",
      "Epoch 3359/5000\n",
      "ecpch:3358,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1487 - val_loss: 194.1437\n",
      "\n",
      "Epoch 03359: val_loss did not improve from 179.48197\n",
      "Epoch 3360/5000\n",
      "ecpch:3359,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1483 - val_loss: 194.1472\n",
      "\n",
      "Epoch 03360: val_loss did not improve from 179.48197\n",
      "Epoch 3361/5000\n",
      "ecpch:3360,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1479 - val_loss: 194.1451\n",
      "\n",
      "Epoch 03361: val_loss did not improve from 179.48197\n",
      "Epoch 3362/5000\n",
      "ecpch:3361,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1480 - val_loss: 194.1452\n",
      "\n",
      "Epoch 03362: val_loss did not improve from 179.48197\n",
      "Epoch 3363/5000\n",
      "ecpch:3362,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1478 - val_loss: 194.1482\n",
      "\n",
      "Epoch 03363: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 03363: ReduceLROnPlateau reducing learning rate to 3.438018893575645e-07.\n",
      "Epoch 3364/5000\n",
      "ecpch:3363,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1481 - val_loss: 194.1481\n",
      "\n",
      "Epoch 03364: val_loss did not improve from 179.48197\n",
      "Epoch 3365/5000\n",
      "ecpch:3364,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1476 - val_loss: 194.1461\n",
      "\n",
      "Epoch 03365: val_loss did not improve from 179.48197\n",
      "Epoch 3366/5000\n",
      "ecpch:3365,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1479 - val_loss: 194.1527\n",
      "\n",
      "Epoch 03366: val_loss did not improve from 179.48197\n",
      "Epoch 3367/5000\n",
      "ecpch:3366,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1475 - val_loss: 194.1427\n",
      "\n",
      "Epoch 03367: val_loss did not improve from 179.48197\n",
      "Epoch 3368/5000\n",
      "ecpch:3367,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1479 - val_loss: 194.1524\n",
      "\n",
      "Epoch 03368: val_loss did not improve from 179.48197\n",
      "Epoch 3369/5000\n",
      "ecpch:3368,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1478 - val_loss: 194.1475\n",
      "\n",
      "Epoch 03369: val_loss did not improve from 179.48197\n",
      "Epoch 3370/5000\n",
      "ecpch:3369,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1472 - val_loss: 194.1512\n",
      "\n",
      "Epoch 03370: val_loss did not improve from 179.48197\n",
      "Epoch 3371/5000\n",
      "ecpch:3370,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 55.1471 - val_loss: 194.1437\n",
      "\n",
      "Epoch 03371: val_loss did not improve from 179.48197\n",
      "Epoch 3372/5000\n",
      "ecpch:3371,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1472 - val_loss: 194.1467\n",
      "\n",
      "Epoch 03372: val_loss did not improve from 179.48197\n",
      "Epoch 3373/5000\n",
      "ecpch:3372,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1471 - val_loss: 194.1458\n",
      "\n",
      "Epoch 03373: val_loss did not improve from 179.48197\n",
      "Epoch 3374/5000\n",
      "ecpch:3373,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1471 - val_loss: 194.1508\n",
      "\n",
      "Epoch 03374: val_loss did not improve from 179.48197\n",
      "Epoch 3375/5000\n",
      "ecpch:3374,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1467 - val_loss: 194.1506\n",
      "\n",
      "Epoch 03375: val_loss did not improve from 179.48197\n",
      "Epoch 3376/5000\n",
      "ecpch:3375,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1468 - val_loss: 194.1485\n",
      "\n",
      "Epoch 03376: val_loss did not improve from 179.48197\n",
      "Epoch 3377/5000\n",
      "ecpch:3376,learn rate 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1463 - val_loss: 194.1496\n",
      "\n",
      "Epoch 03377: val_loss did not improve from 179.48197\n",
      "Epoch 3378/5000\n",
      "ecpch:3377,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1466 - val_loss: 194.1437\n",
      "\n",
      "Epoch 03378: val_loss did not improve from 179.48197\n",
      "Epoch 3379/5000\n",
      "ecpch:3378,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1463 - val_loss: 194.1410\n",
      "\n",
      "Epoch 03379: val_loss did not improve from 179.48197\n",
      "Epoch 3380/5000\n",
      "ecpch:3379,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1463 - val_loss: 194.1460\n",
      "\n",
      "Epoch 03380: val_loss did not improve from 179.48197\n",
      "Epoch 3381/5000\n",
      "ecpch:3380,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1460 - val_loss: 194.1480\n",
      "\n",
      "Epoch 03381: val_loss did not improve from 179.48197\n",
      "Epoch 3382/5000\n",
      "ecpch:3381,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1462 - val_loss: 194.1488\n",
      "\n",
      "Epoch 03382: val_loss did not improve from 179.48197\n",
      "Epoch 3383/5000\n",
      "ecpch:3382,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1462 - val_loss: 194.1511\n",
      "\n",
      "Epoch 03383: val_loss did not improve from 179.48197\n",
      "Epoch 3384/5000\n",
      "ecpch:3383,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1460 - val_loss: 194.1528\n",
      "\n",
      "Epoch 03384: val_loss did not improve from 179.48197\n",
      "Epoch 3385/5000\n",
      "ecpch:3384,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1457 - val_loss: 194.1576\n",
      "\n",
      "Epoch 03385: val_loss did not improve from 179.48197\n",
      "Epoch 3386/5000\n",
      "ecpch:3385,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1459 - val_loss: 194.1476\n",
      "\n",
      "Epoch 03386: val_loss did not improve from 179.48197\n",
      "Epoch 3387/5000\n",
      "ecpch:3386,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1456 - val_loss: 194.1496\n",
      "\n",
      "Epoch 03387: val_loss did not improve from 179.48197\n",
      "Epoch 3388/5000\n",
      "ecpch:3387,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1458 - val_loss: 194.1484\n",
      "\n",
      "Epoch 03388: val_loss did not improve from 179.48197\n",
      "Epoch 3389/5000\n",
      "ecpch:3388,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1455 - val_loss: 194.1489\n",
      "\n",
      "Epoch 03389: val_loss did not improve from 179.48197\n",
      "Epoch 3390/5000\n",
      "ecpch:3389,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1457 - val_loss: 194.1522\n",
      "\n",
      "Epoch 03390: val_loss did not improve from 179.48197\n",
      "Epoch 3391/5000\n",
      "ecpch:3390,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1455 - val_loss: 194.1500\n",
      "\n",
      "Epoch 03391: val_loss did not improve from 179.48197\n",
      "Epoch 3392/5000\n",
      "ecpch:3391,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1453 - val_loss: 194.1501\n",
      "\n",
      "Epoch 03392: val_loss did not improve from 179.48197\n",
      "Epoch 3393/5000\n",
      "ecpch:3392,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1454 - val_loss: 194.1499\n",
      "\n",
      "Epoch 03393: val_loss did not improve from 179.48197\n",
      "Epoch 3394/5000\n",
      "ecpch:3393,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1449 - val_loss: 194.1495\n",
      "\n",
      "Epoch 03394: val_loss did not improve from 179.48197\n",
      "Epoch 3395/5000\n",
      "ecpch:3394,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1449 - val_loss: 194.1510\n",
      "\n",
      "Epoch 03395: val_loss did not improve from 179.48197\n",
      "Epoch 3396/5000\n",
      "ecpch:3395,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1451 - val_loss: 194.1482\n",
      "\n",
      "Epoch 03396: val_loss did not improve from 179.48197\n",
      "Epoch 3397/5000\n",
      "ecpch:3396,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1447 - val_loss: 194.1548\n",
      "\n",
      "Epoch 03397: val_loss did not improve from 179.48197\n",
      "Epoch 3398/5000\n",
      "ecpch:3397,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1448 - val_loss: 194.1513\n",
      "\n",
      "Epoch 03398: val_loss did not improve from 179.48197\n",
      "Epoch 3399/5000\n",
      "ecpch:3398,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1450 - val_loss: 194.1525\n",
      "\n",
      "Epoch 03399: val_loss did not improve from 179.48197\n",
      "Epoch 3400/5000\n",
      "ecpch:3399,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1445 - val_loss: 194.1521\n",
      "\n",
      "Epoch 03400: val_loss did not improve from 179.48197\n",
      "Epoch 3401/5000\n",
      "ecpch:3400,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1450 - val_loss: 194.1510\n",
      "\n",
      "Epoch 03401: val_loss did not improve from 179.48197\n",
      "Epoch 3402/5000\n",
      "ecpch:3401,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1443 - val_loss: 194.1478\n",
      "\n",
      "Epoch 03402: val_loss did not improve from 179.48197\n",
      "Epoch 3403/5000\n",
      "ecpch:3402,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1448 - val_loss: 194.1534\n",
      "\n",
      "Epoch 03403: val_loss did not improve from 179.48197\n",
      "Epoch 3404/5000\n",
      "ecpch:3403,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1443 - val_loss: 194.1466\n",
      "\n",
      "Epoch 03404: val_loss did not improve from 179.48197\n",
      "Epoch 3405/5000\n",
      "ecpch:3404,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1447 - val_loss: 194.1516\n",
      "\n",
      "Epoch 03405: val_loss did not improve from 179.48197\n",
      "Epoch 3406/5000\n",
      "ecpch:3405,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1444 - val_loss: 194.1494\n",
      "\n",
      "Epoch 03406: val_loss did not improve from 179.48197\n",
      "Epoch 3407/5000\n",
      "ecpch:3406,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1448 - val_loss: 194.1504\n",
      "\n",
      "Epoch 03407: val_loss did not improve from 179.48197\n",
      "Epoch 3408/5000\n",
      "ecpch:3407,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 55.1445 - val_loss: 194.1481\n",
      "\n",
      "Epoch 03408: val_loss did not improve from 179.48197\n",
      "Epoch 3409/5000\n",
      "ecpch:3408,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1442 - val_loss: 194.1488\n",
      "\n",
      "Epoch 03409: val_loss did not improve from 179.48197\n",
      "Epoch 3410/5000\n",
      "ecpch:3409,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1443 - val_loss: 194.1477\n",
      "\n",
      "Epoch 03410: val_loss did not improve from 179.48197\n",
      "Epoch 3411/5000\n",
      "ecpch:3410,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1438 - val_loss: 194.1551\n",
      "\n",
      "Epoch 03411: val_loss did not improve from 179.48197\n",
      "Epoch 3412/5000\n",
      "ecpch:3411,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1444 - val_loss: 194.1492\n",
      "\n",
      "Epoch 03412: val_loss did not improve from 179.48197\n",
      "Epoch 3413/5000\n",
      "ecpch:3412,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1435 - val_loss: 194.1462\n",
      "\n",
      "Epoch 03413: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 03413: ReduceLROnPlateau reducing learning rate to 3.0942171065362344e-07.\n",
      "Epoch 3414/5000\n",
      "ecpch:3413,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1443 - val_loss: 194.1459\n",
      "\n",
      "Epoch 03414: val_loss did not improve from 179.48197\n",
      "Epoch 3415/5000\n",
      "ecpch:3414,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1436 - val_loss: 194.1519\n",
      "\n",
      "Epoch 03415: val_loss did not improve from 179.48197\n",
      "Epoch 3416/5000\n",
      "ecpch:3415,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1441 - val_loss: 194.1568\n",
      "\n",
      "Epoch 03416: val_loss did not improve from 179.48197\n",
      "Epoch 3417/5000\n",
      "ecpch:3416,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1440 - val_loss: 194.1489\n",
      "\n",
      "Epoch 03417: val_loss did not improve from 179.48197\n",
      "Epoch 3418/5000\n",
      "ecpch:3417,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1437 - val_loss: 194.1495\n",
      "\n",
      "Epoch 03418: val_loss did not improve from 179.48197\n",
      "Epoch 3419/5000\n",
      "ecpch:3418,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1436 - val_loss: 194.1487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 03419: val_loss did not improve from 179.48197\n",
      "Epoch 3420/5000\n",
      "ecpch:3419,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1431 - val_loss: 194.1542\n",
      "\n",
      "Epoch 03420: val_loss did not improve from 179.48197\n",
      "Epoch 3421/5000\n",
      "ecpch:3420,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1434 - val_loss: 194.1526\n",
      "\n",
      "Epoch 03421: val_loss did not improve from 179.48197\n",
      "Epoch 3422/5000\n",
      "ecpch:3421,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1430 - val_loss: 194.1460\n",
      "\n",
      "Epoch 03422: val_loss did not improve from 179.48197\n",
      "Epoch 3423/5000\n",
      "ecpch:3422,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1434 - val_loss: 194.1525\n",
      "\n",
      "Epoch 03423: val_loss did not improve from 179.48197\n",
      "Epoch 3424/5000\n",
      "ecpch:3423,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1428 - val_loss: 194.1488\n",
      "\n",
      "Epoch 03424: val_loss did not improve from 179.48197\n",
      "Epoch 3425/5000\n",
      "ecpch:3424,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1433 - val_loss: 194.1514\n",
      "\n",
      "Epoch 03425: val_loss did not improve from 179.48197\n",
      "Epoch 3426/5000\n",
      "ecpch:3425,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1429 - val_loss: 194.1509\n",
      "\n",
      "Epoch 03426: val_loss did not improve from 179.48197\n",
      "Epoch 3427/5000\n",
      "ecpch:3426,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1429 - val_loss: 194.1482\n",
      "\n",
      "Epoch 03427: val_loss did not improve from 179.48197\n",
      "Epoch 3428/5000\n",
      "ecpch:3427,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1427 - val_loss: 194.1439\n",
      "\n",
      "Epoch 03428: val_loss did not improve from 179.48197\n",
      "Epoch 3429/5000\n",
      "ecpch:3428,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1423 - val_loss: 194.1519\n",
      "\n",
      "Epoch 03429: val_loss did not improve from 179.48197\n",
      "Epoch 3430/5000\n",
      "ecpch:3429,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1423 - val_loss: 194.1516\n",
      "\n",
      "Epoch 03430: val_loss did not improve from 179.48197\n",
      "Epoch 3431/5000\n",
      "ecpch:3430,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1424 - val_loss: 194.1578\n",
      "\n",
      "Epoch 03431: val_loss did not improve from 179.48197\n",
      "Epoch 3432/5000\n",
      "ecpch:3431,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 55.1419 - val_loss: 194.1487\n",
      "\n",
      "Epoch 03432: val_loss did not improve from 179.48197\n",
      "Epoch 3433/5000\n",
      "ecpch:3432,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 55.1422 - val_loss: 194.1511\n",
      "\n",
      "Epoch 03433: val_loss did not improve from 179.48197\n",
      "Epoch 3434/5000\n",
      "ecpch:3433,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1420 - val_loss: 194.1540\n",
      "\n",
      "Epoch 03434: val_loss did not improve from 179.48197\n",
      "Epoch 3435/5000\n",
      "ecpch:3434,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1423 - val_loss: 194.1520\n",
      "\n",
      "Epoch 03435: val_loss did not improve from 179.48197\n",
      "Epoch 3436/5000\n",
      "ecpch:3435,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1419 - val_loss: 194.1525\n",
      "\n",
      "Epoch 03436: val_loss did not improve from 179.48197\n",
      "Epoch 3437/5000\n",
      "ecpch:3436,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1425 - val_loss: 194.1506\n",
      "\n",
      "Epoch 03437: val_loss did not improve from 179.48197\n",
      "Epoch 3438/5000\n",
      "ecpch:3437,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1420 - val_loss: 194.1508\n",
      "\n",
      "Epoch 03438: val_loss did not improve from 179.48197\n",
      "Epoch 3439/5000\n",
      "ecpch:3438,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1420 - val_loss: 194.1486\n",
      "\n",
      "Epoch 03439: val_loss did not improve from 179.48197\n",
      "Epoch 3440/5000\n",
      "ecpch:3439,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1417 - val_loss: 194.1517\n",
      "\n",
      "Epoch 03440: val_loss did not improve from 179.48197\n",
      "Epoch 3441/5000\n",
      "ecpch:3440,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1419 - val_loss: 194.1478\n",
      "\n",
      "Epoch 03441: val_loss did not improve from 179.48197\n",
      "Epoch 3442/5000\n",
      "ecpch:3441,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 55.1419 - val_loss: 194.1518\n",
      "\n",
      "Epoch 03442: val_loss did not improve from 179.48197\n",
      "Epoch 3443/5000\n",
      "ecpch:3442,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1415 - val_loss: 194.1500\n",
      "\n",
      "Epoch 03443: val_loss did not improve from 179.48197\n",
      "Epoch 3444/5000\n",
      "ecpch:3443,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1416 - val_loss: 194.1526\n",
      "\n",
      "Epoch 03444: val_loss did not improve from 179.48197\n",
      "Epoch 3445/5000\n",
      "ecpch:3444,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1415 - val_loss: 194.1519\n",
      "\n",
      "Epoch 03445: val_loss did not improve from 179.48197\n",
      "Epoch 3446/5000\n",
      "ecpch:3445,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1411 - val_loss: 194.1519\n",
      "\n",
      "Epoch 03446: val_loss did not improve from 179.48197\n",
      "Epoch 3447/5000\n",
      "ecpch:3446,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1413 - val_loss: 194.1477\n",
      "\n",
      "Epoch 03447: val_loss did not improve from 179.48197\n",
      "Epoch 3448/5000\n",
      "ecpch:3447,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1412 - val_loss: 194.1573\n",
      "\n",
      "Epoch 03448: val_loss did not improve from 179.48197\n",
      "Epoch 3449/5000\n",
      "ecpch:3448,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1413 - val_loss: 194.1534\n",
      "\n",
      "Epoch 03449: val_loss did not improve from 179.48197\n",
      "Epoch 3450/5000\n",
      "ecpch:3449,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1412 - val_loss: 194.1457\n",
      "\n",
      "Epoch 03450: val_loss did not improve from 179.48197\n",
      "Epoch 3451/5000\n",
      "ecpch:3450,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1412 - val_loss: 194.1494\n",
      "\n",
      "Epoch 03451: val_loss did not improve from 179.48197\n",
      "Epoch 3452/5000\n",
      "ecpch:3451,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1411 - val_loss: 194.1475\n",
      "\n",
      "Epoch 03452: val_loss did not improve from 179.48197\n",
      "Epoch 3453/5000\n",
      "ecpch:3452,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1407 - val_loss: 194.1529\n",
      "\n",
      "Epoch 03453: val_loss did not improve from 179.48197\n",
      "Epoch 3454/5000\n",
      "ecpch:3453,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1409 - val_loss: 194.1520\n",
      "\n",
      "Epoch 03454: val_loss did not improve from 179.48197\n",
      "Epoch 3455/5000\n",
      "ecpch:3454,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1405 - val_loss: 194.1496\n",
      "\n",
      "Epoch 03455: val_loss did not improve from 179.48197\n",
      "Epoch 3456/5000\n",
      "ecpch:3455,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 55.1406 - val_loss: 194.1534\n",
      "\n",
      "Epoch 03456: val_loss did not improve from 179.48197\n",
      "Epoch 3457/5000\n",
      "ecpch:3456,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1407 - val_loss: 194.1480\n",
      "\n",
      "Epoch 03457: val_loss did not improve from 179.48197\n",
      "Epoch 3458/5000\n",
      "ecpch:3457,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1405 - val_loss: 194.1546\n",
      "\n",
      "Epoch 03458: val_loss did not improve from 179.48197\n",
      "Epoch 3459/5000\n",
      "ecpch:3458,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1403 - val_loss: 194.1530\n",
      "\n",
      "Epoch 03459: val_loss did not improve from 179.48197\n",
      "Epoch 3460/5000\n",
      "ecpch:3459,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1404 - val_loss: 194.1516\n",
      "\n",
      "Epoch 03460: val_loss did not improve from 179.48197\n",
      "Epoch 3461/5000\n",
      "ecpch:3460,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1402 - val_loss: 194.1551\n",
      "\n",
      "Epoch 03461: val_loss did not improve from 179.48197\n",
      "Epoch 3462/5000\n",
      "ecpch:3461,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1399 - val_loss: 194.1571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 03462: val_loss did not improve from 179.48197\n",
      "Epoch 3463/5000\n",
      "ecpch:3462,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1403 - val_loss: 194.1541\n",
      "\n",
      "Epoch 03463: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 03463: ReduceLROnPlateau reducing learning rate to 2.784795498200765e-07.\n",
      "Epoch 3464/5000\n",
      "ecpch:3463,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1398 - val_loss: 194.1494\n",
      "\n",
      "Epoch 03464: val_loss did not improve from 179.48197\n",
      "Epoch 3465/5000\n",
      "ecpch:3464,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1402 - val_loss: 194.1524\n",
      "\n",
      "Epoch 03465: val_loss did not improve from 179.48197\n",
      "Epoch 3466/5000\n",
      "ecpch:3465,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1399 - val_loss: 194.1543\n",
      "\n",
      "Epoch 03466: val_loss did not improve from 179.48197\n",
      "Epoch 3467/5000\n",
      "ecpch:3466,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1401 - val_loss: 194.1521\n",
      "\n",
      "Epoch 03467: val_loss did not improve from 179.48197\n",
      "Epoch 3468/5000\n",
      "ecpch:3467,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1397 - val_loss: 194.1507\n",
      "\n",
      "Epoch 03468: val_loss did not improve from 179.48197\n",
      "Epoch 3469/5000\n",
      "ecpch:3468,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1404 - val_loss: 194.1508\n",
      "\n",
      "Epoch 03469: val_loss did not improve from 179.48197\n",
      "Epoch 3470/5000\n",
      "ecpch:3469,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1400 - val_loss: 194.1459\n",
      "\n",
      "Epoch 03470: val_loss did not improve from 179.48197\n",
      "Epoch 3471/5000\n",
      "ecpch:3470,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1399 - val_loss: 194.1485\n",
      "\n",
      "Epoch 03471: val_loss did not improve from 179.48197\n",
      "Epoch 3472/5000\n",
      "ecpch:3471,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1400 - val_loss: 194.1557\n",
      "\n",
      "Epoch 03472: val_loss did not improve from 179.48197\n",
      "Epoch 3473/5000\n",
      "ecpch:3472,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1396 - val_loss: 194.1551\n",
      "\n",
      "Epoch 03473: val_loss did not improve from 179.48197\n",
      "Epoch 3474/5000\n",
      "ecpch:3473,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1396 - val_loss: 194.1515\n",
      "\n",
      "Epoch 03474: val_loss did not improve from 179.48197\n",
      "Epoch 3475/5000\n",
      "ecpch:3474,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1397 - val_loss: 194.1513\n",
      "\n",
      "Epoch 03475: val_loss did not improve from 179.48197\n",
      "Epoch 3476/5000\n",
      "ecpch:3475,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1394 - val_loss: 194.1518\n",
      "\n",
      "Epoch 03476: val_loss did not improve from 179.48197\n",
      "Epoch 3477/5000\n",
      "ecpch:3476,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1394 - val_loss: 194.1539\n",
      "\n",
      "Epoch 03477: val_loss did not improve from 179.48197\n",
      "Epoch 3478/5000\n",
      "ecpch:3477,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1393 - val_loss: 194.1533\n",
      "\n",
      "Epoch 03478: val_loss did not improve from 179.48197\n",
      "Epoch 3479/5000\n",
      "ecpch:3478,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1393 - val_loss: 194.1505\n",
      "\n",
      "Epoch 03479: val_loss did not improve from 179.48197\n",
      "Epoch 3480/5000\n",
      "ecpch:3479,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 55.1391 - val_loss: 194.1530\n",
      "\n",
      "Epoch 03480: val_loss did not improve from 179.48197\n",
      "Epoch 3481/5000\n",
      "ecpch:3480,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1391 - val_loss: 194.1574\n",
      "\n",
      "Epoch 03481: val_loss did not improve from 179.48197\n",
      "Epoch 3482/5000\n",
      "ecpch:3481,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1388 - val_loss: 194.1545\n",
      "\n",
      "Epoch 03482: val_loss did not improve from 179.48197\n",
      "Epoch 3483/5000\n",
      "ecpch:3482,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1391 - val_loss: 194.1544\n",
      "\n",
      "Epoch 03483: val_loss did not improve from 179.48197\n",
      "Epoch 3484/5000\n",
      "ecpch:3483,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1387 - val_loss: 194.1558\n",
      "\n",
      "Epoch 03484: val_loss did not improve from 179.48197\n",
      "Epoch 3485/5000\n",
      "ecpch:3484,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1391 - val_loss: 194.1549\n",
      "\n",
      "Epoch 03485: val_loss did not improve from 179.48197\n",
      "Epoch 3486/5000\n",
      "ecpch:3485,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1390 - val_loss: 194.1536\n",
      "\n",
      "Epoch 03486: val_loss did not improve from 179.48197\n",
      "Epoch 3487/5000\n",
      "ecpch:3486,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1386 - val_loss: 194.1508\n",
      "\n",
      "Epoch 03487: val_loss did not improve from 179.48197\n",
      "Epoch 3488/5000\n",
      "ecpch:3487,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1387 - val_loss: 194.1570\n",
      "\n",
      "Epoch 03488: val_loss did not improve from 179.48197\n",
      "Epoch 3489/5000\n",
      "ecpch:3488,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1383 - val_loss: 194.1566\n",
      "\n",
      "Epoch 03489: val_loss did not improve from 179.48197\n",
      "Epoch 3490/5000\n",
      "ecpch:3489,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 55.1382 - val_loss: 194.1502\n",
      "\n",
      "Epoch 03490: val_loss did not improve from 179.48197\n",
      "Epoch 3491/5000\n",
      "ecpch:3490,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1386 - val_loss: 194.1496\n",
      "\n",
      "Epoch 03491: val_loss did not improve from 179.48197\n",
      "Epoch 3492/5000\n",
      "ecpch:3491,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1384 - val_loss: 194.1514\n",
      "\n",
      "Epoch 03492: val_loss did not improve from 179.48197\n",
      "Epoch 3493/5000\n",
      "ecpch:3492,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1385 - val_loss: 194.1518\n",
      "\n",
      "Epoch 03493: val_loss did not improve from 179.48197\n",
      "Epoch 3494/5000\n",
      "ecpch:3493,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1381 - val_loss: 194.1513\n",
      "\n",
      "Epoch 03494: val_loss did not improve from 179.48197\n",
      "Epoch 3495/5000\n",
      "ecpch:3494,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1381 - val_loss: 194.1573\n",
      "\n",
      "Epoch 03495: val_loss did not improve from 179.48197\n",
      "Epoch 3496/5000\n",
      "ecpch:3495,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1384 - val_loss: 194.1536\n",
      "\n",
      "Epoch 03496: val_loss did not improve from 179.48197\n",
      "Epoch 3497/5000\n",
      "ecpch:3496,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1379 - val_loss: 194.1539\n",
      "\n",
      "Epoch 03497: val_loss did not improve from 179.48197\n",
      "Epoch 3498/5000\n",
      "ecpch:3497,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1381 - val_loss: 194.1548\n",
      "\n",
      "Epoch 03498: val_loss did not improve from 179.48197\n",
      "Epoch 3499/5000\n",
      "ecpch:3498,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1376 - val_loss: 194.1501\n",
      "\n",
      "Epoch 03499: val_loss did not improve from 179.48197\n",
      "Epoch 3500/5000\n",
      "ecpch:3499,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1378 - val_loss: 194.1543\n",
      "\n",
      "Epoch 03500: val_loss did not improve from 179.48197\n",
      "Epoch 3501/5000\n",
      "ecpch:3500,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1375 - val_loss: 194.1590\n",
      "\n",
      "Epoch 03501: val_loss did not improve from 179.48197\n",
      "Epoch 3502/5000\n",
      "ecpch:3501,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1377 - val_loss: 194.1537\n",
      "\n",
      "Epoch 03502: val_loss did not improve from 179.48197\n",
      "Epoch 3503/5000\n",
      "ecpch:3502,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1374 - val_loss: 194.1522\n",
      "\n",
      "Epoch 03503: val_loss did not improve from 179.48197\n",
      "Epoch 3504/5000\n",
      "ecpch:3503,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1373 - val_loss: 194.1569\n",
      "\n",
      "Epoch 03504: val_loss did not improve from 179.48197\n",
      "Epoch 3505/5000\n",
      "ecpch:3504,learn rate 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1373 - val_loss: 194.1537\n",
      "\n",
      "Epoch 03505: val_loss did not improve from 179.48197\n",
      "Epoch 3506/5000\n",
      "ecpch:3505,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1373 - val_loss: 194.1535\n",
      "\n",
      "Epoch 03506: val_loss did not improve from 179.48197\n",
      "Epoch 3507/5000\n",
      "ecpch:3506,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1376 - val_loss: 194.1506\n",
      "\n",
      "Epoch 03507: val_loss did not improve from 179.48197\n",
      "Epoch 3508/5000\n",
      "ecpch:3507,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1371 - val_loss: 194.1530\n",
      "\n",
      "Epoch 03508: val_loss did not improve from 179.48197\n",
      "Epoch 3509/5000\n",
      "ecpch:3508,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1373 - val_loss: 194.1539\n",
      "\n",
      "Epoch 03509: val_loss did not improve from 179.48197\n",
      "Epoch 3510/5000\n",
      "ecpch:3509,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1370 - val_loss: 194.1531\n",
      "\n",
      "Epoch 03510: val_loss did not improve from 179.48197\n",
      "Epoch 3511/5000\n",
      "ecpch:3510,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1377 - val_loss: 194.1510\n",
      "\n",
      "Epoch 03511: val_loss did not improve from 179.48197\n",
      "Epoch 3512/5000\n",
      "ecpch:3511,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1372 - val_loss: 194.1540\n",
      "\n",
      "Epoch 03512: val_loss did not improve from 179.48197\n",
      "Epoch 3513/5000\n",
      "ecpch:3512,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1370 - val_loss: 194.1569\n",
      "\n",
      "Epoch 03513: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 03513: ReduceLROnPlateau reducing learning rate to 2.5063159228011503e-07.\n",
      "Epoch 3514/5000\n",
      "ecpch:3513,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1368 - val_loss: 194.1505\n",
      "\n",
      "Epoch 03514: val_loss did not improve from 179.48197\n",
      "Epoch 3515/5000\n",
      "ecpch:3514,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1368 - val_loss: 194.1539\n",
      "\n",
      "Epoch 03515: val_loss did not improve from 179.48197\n",
      "Epoch 3516/5000\n",
      "ecpch:3515,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 55.1370 - val_loss: 194.1516\n",
      "\n",
      "Epoch 03516: val_loss did not improve from 179.48197\n",
      "Epoch 3517/5000\n",
      "ecpch:3516,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1364 - val_loss: 194.1573\n",
      "\n",
      "Epoch 03517: val_loss did not improve from 179.48197\n",
      "Epoch 3518/5000\n",
      "ecpch:3517,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1367 - val_loss: 194.1582\n",
      "\n",
      "Epoch 03518: val_loss did not improve from 179.48197\n",
      "Epoch 3519/5000\n",
      "ecpch:3518,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1362 - val_loss: 194.1608\n",
      "\n",
      "Epoch 03519: val_loss did not improve from 179.48197\n",
      "Epoch 3520/5000\n",
      "ecpch:3519,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1365 - val_loss: 194.1594\n",
      "\n",
      "Epoch 03520: val_loss did not improve from 179.48197\n",
      "Epoch 3521/5000\n",
      "ecpch:3520,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1362 - val_loss: 194.1551\n",
      "\n",
      "Epoch 03521: val_loss did not improve from 179.48197\n",
      "Epoch 3522/5000\n",
      "ecpch:3521,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1365 - val_loss: 194.1542\n",
      "\n",
      "Epoch 03522: val_loss did not improve from 179.48197\n",
      "Epoch 3523/5000\n",
      "ecpch:3522,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1362 - val_loss: 194.1558\n",
      "\n",
      "Epoch 03523: val_loss did not improve from 179.48197\n",
      "Epoch 3524/5000\n",
      "ecpch:3523,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1365 - val_loss: 194.1559\n",
      "\n",
      "Epoch 03524: val_loss did not improve from 179.48197\n",
      "Epoch 3525/5000\n",
      "ecpch:3524,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1358 - val_loss: 194.1602\n",
      "\n",
      "Epoch 03525: val_loss did not improve from 179.48197\n",
      "Epoch 3526/5000\n",
      "ecpch:3525,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1363 - val_loss: 194.1603\n",
      "\n",
      "Epoch 03526: val_loss did not improve from 179.48197\n",
      "Epoch 3527/5000\n",
      "ecpch:3526,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1360 - val_loss: 194.1585\n",
      "\n",
      "Epoch 03527: val_loss did not improve from 179.48197\n",
      "Epoch 3528/5000\n",
      "ecpch:3527,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1365 - val_loss: 194.1564\n",
      "\n",
      "Epoch 03528: val_loss did not improve from 179.48197\n",
      "Epoch 3529/5000\n",
      "ecpch:3528,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1364 - val_loss: 194.1536\n",
      "\n",
      "Epoch 03529: val_loss did not improve from 179.48197\n",
      "Epoch 3530/5000\n",
      "ecpch:3529,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1356 - val_loss: 194.1560\n",
      "\n",
      "Epoch 03530: val_loss did not improve from 179.48197\n",
      "Epoch 3531/5000\n",
      "ecpch:3530,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1358 - val_loss: 194.1523\n",
      "\n",
      "Epoch 03531: val_loss did not improve from 179.48197\n",
      "Epoch 3532/5000\n",
      "ecpch:3531,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1356 - val_loss: 194.1544\n",
      "\n",
      "Epoch 03532: val_loss did not improve from 179.48197\n",
      "Epoch 3533/5000\n",
      "ecpch:3532,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1355 - val_loss: 194.1557\n",
      "\n",
      "Epoch 03533: val_loss did not improve from 179.48197\n",
      "Epoch 3534/5000\n",
      "ecpch:3533,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1357 - val_loss: 194.1578\n",
      "\n",
      "Epoch 03534: val_loss did not improve from 179.48197\n",
      "Epoch 3535/5000\n",
      "ecpch:3534,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1353 - val_loss: 194.1542\n",
      "\n",
      "Epoch 03535: val_loss did not improve from 179.48197\n",
      "Epoch 3536/5000\n",
      "ecpch:3535,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1356 - val_loss: 194.1567\n",
      "\n",
      "Epoch 03536: val_loss did not improve from 179.48197\n",
      "Epoch 3537/5000\n",
      "ecpch:3536,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1351 - val_loss: 194.1555\n",
      "\n",
      "Epoch 03537: val_loss did not improve from 179.48197\n",
      "Epoch 3538/5000\n",
      "ecpch:3537,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1355 - val_loss: 194.1522\n",
      "\n",
      "Epoch 03538: val_loss did not improve from 179.48197\n",
      "Epoch 3539/5000\n",
      "ecpch:3538,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1350 - val_loss: 194.1575\n",
      "\n",
      "Epoch 03539: val_loss did not improve from 179.48197\n",
      "Epoch 3540/5000\n",
      "ecpch:3539,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1355 - val_loss: 194.1564\n",
      "\n",
      "Epoch 03540: val_loss did not improve from 179.48197\n",
      "Epoch 3541/5000\n",
      "ecpch:3540,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1351 - val_loss: 194.1562\n",
      "\n",
      "Epoch 03541: val_loss did not improve from 179.48197\n",
      "Epoch 3542/5000\n",
      "ecpch:3541,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1355 - val_loss: 194.1570\n",
      "\n",
      "Epoch 03542: val_loss did not improve from 179.48197\n",
      "Epoch 3543/5000\n",
      "ecpch:3542,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 55.1352 - val_loss: 194.1578\n",
      "\n",
      "Epoch 03543: val_loss did not improve from 179.48197\n",
      "Epoch 3544/5000\n",
      "ecpch:3543,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 55.1348 - val_loss: 194.1554\n",
      "\n",
      "Epoch 03544: val_loss did not improve from 179.48197\n",
      "Epoch 3545/5000\n",
      "ecpch:3544,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 55.1350 - val_loss: 194.1554\n",
      "\n",
      "Epoch 03545: val_loss did not improve from 179.48197\n",
      "Epoch 3546/5000\n",
      "ecpch:3545,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1348 - val_loss: 194.1595\n",
      "\n",
      "Epoch 03546: val_loss did not improve from 179.48197\n",
      "Epoch 3547/5000\n",
      "ecpch:3546,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1347 - val_loss: 194.1497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 03547: val_loss did not improve from 179.48197\n",
      "Epoch 3548/5000\n",
      "ecpch:3547,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1344 - val_loss: 194.1533\n",
      "\n",
      "Epoch 03548: val_loss did not improve from 179.48197\n",
      "Epoch 3549/5000\n",
      "ecpch:3548,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1348 - val_loss: 194.1585\n",
      "\n",
      "Epoch 03549: val_loss did not improve from 179.48197\n",
      "Epoch 3550/5000\n",
      "ecpch:3549,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1344 - val_loss: 194.1541\n",
      "\n",
      "Epoch 03550: val_loss did not improve from 179.48197\n",
      "Epoch 3551/5000\n",
      "ecpch:3550,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1346 - val_loss: 194.1596\n",
      "\n",
      "Epoch 03551: val_loss did not improve from 179.48197\n",
      "Epoch 3552/5000\n",
      "ecpch:3551,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1343 - val_loss: 194.1580\n",
      "\n",
      "Epoch 03552: val_loss did not improve from 179.48197\n",
      "Epoch 3553/5000\n",
      "ecpch:3552,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1342 - val_loss: 194.1517\n",
      "\n",
      "Epoch 03553: val_loss did not improve from 179.48197\n",
      "Epoch 3554/5000\n",
      "ecpch:3553,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1342 - val_loss: 194.1585\n",
      "\n",
      "Epoch 03554: val_loss did not improve from 179.48197\n",
      "Epoch 3555/5000\n",
      "ecpch:3554,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1342 - val_loss: 194.1605\n",
      "\n",
      "Epoch 03555: val_loss did not improve from 179.48197\n",
      "Epoch 3556/5000\n",
      "ecpch:3555,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1342 - val_loss: 194.1595\n",
      "\n",
      "Epoch 03556: val_loss did not improve from 179.48197\n",
      "Epoch 3557/5000\n",
      "ecpch:3556,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1340 - val_loss: 194.1575\n",
      "\n",
      "Epoch 03557: val_loss did not improve from 179.48197\n",
      "Epoch 3558/5000\n",
      "ecpch:3557,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1341 - val_loss: 194.1563\n",
      "\n",
      "Epoch 03558: val_loss did not improve from 179.48197\n",
      "Epoch 3559/5000\n",
      "ecpch:3558,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1338 - val_loss: 194.1539\n",
      "\n",
      "Epoch 03559: val_loss did not improve from 179.48197\n",
      "Epoch 3560/5000\n",
      "ecpch:3559,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1337 - val_loss: 194.1599\n",
      "\n",
      "Epoch 03560: val_loss did not improve from 179.48197\n",
      "Epoch 3561/5000\n",
      "ecpch:3560,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1339 - val_loss: 194.1587\n",
      "\n",
      "Epoch 03561: val_loss did not improve from 179.48197\n",
      "Epoch 3562/5000\n",
      "ecpch:3561,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1337 - val_loss: 194.1553\n",
      "\n",
      "Epoch 03562: val_loss did not improve from 179.48197\n",
      "Epoch 3563/5000\n",
      "ecpch:3562,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1336 - val_loss: 194.1539\n",
      "\n",
      "Epoch 03563: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 03563: ReduceLROnPlateau reducing learning rate to 2.255684279361958e-07.\n",
      "Epoch 3564/5000\n",
      "ecpch:3563,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1334 - val_loss: 194.1613\n",
      "\n",
      "Epoch 03564: val_loss did not improve from 179.48197\n",
      "Epoch 3565/5000\n",
      "ecpch:3564,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1335 - val_loss: 194.1523\n",
      "\n",
      "Epoch 03565: val_loss did not improve from 179.48197\n",
      "Epoch 3566/5000\n",
      "ecpch:3565,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1335 - val_loss: 194.1515\n",
      "\n",
      "Epoch 03566: val_loss did not improve from 179.48197\n",
      "Epoch 3567/5000\n",
      "ecpch:3566,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1337 - val_loss: 194.1549\n",
      "\n",
      "Epoch 03567: val_loss did not improve from 179.48197\n",
      "Epoch 3568/5000\n",
      "ecpch:3567,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1333 - val_loss: 194.1535\n",
      "\n",
      "Epoch 03568: val_loss did not improve from 179.48197\n",
      "Epoch 3569/5000\n",
      "ecpch:3568,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1334 - val_loss: 194.1580\n",
      "\n",
      "Epoch 03569: val_loss did not improve from 179.48197\n",
      "Epoch 3570/5000\n",
      "ecpch:3569,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1336 - val_loss: 194.1569\n",
      "\n",
      "Epoch 03570: val_loss did not improve from 179.48197\n",
      "Epoch 3571/5000\n",
      "ecpch:3570,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1333 - val_loss: 194.1544\n",
      "\n",
      "Epoch 03571: val_loss did not improve from 179.48197\n",
      "Epoch 3572/5000\n",
      "ecpch:3571,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1332 - val_loss: 194.1570\n",
      "\n",
      "Epoch 03572: val_loss did not improve from 179.48197\n",
      "Epoch 3573/5000\n",
      "ecpch:3572,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1331 - val_loss: 194.1526\n",
      "\n",
      "Epoch 03573: val_loss did not improve from 179.48197\n",
      "Epoch 3574/5000\n",
      "ecpch:3573,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1329 - val_loss: 194.1550\n",
      "\n",
      "Epoch 03574: val_loss did not improve from 179.48197\n",
      "Epoch 3575/5000\n",
      "ecpch:3574,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1328 - val_loss: 194.1586\n",
      "\n",
      "Epoch 03575: val_loss did not improve from 179.48197\n",
      "Epoch 3576/5000\n",
      "ecpch:3575,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1329 - val_loss: 194.1546\n",
      "\n",
      "Epoch 03576: val_loss did not improve from 179.48197\n",
      "Epoch 3577/5000\n",
      "ecpch:3576,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1329 - val_loss: 194.1591\n",
      "\n",
      "Epoch 03577: val_loss did not improve from 179.48197\n",
      "Epoch 3578/5000\n",
      "ecpch:3577,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1327 - val_loss: 194.1577\n",
      "\n",
      "Epoch 03578: val_loss did not improve from 179.48197\n",
      "Epoch 3579/5000\n",
      "ecpch:3578,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1327 - val_loss: 194.1620\n",
      "\n",
      "Epoch 03579: val_loss did not improve from 179.48197\n",
      "Epoch 3580/5000\n",
      "ecpch:3579,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1327 - val_loss: 194.1541\n",
      "\n",
      "Epoch 03580: val_loss did not improve from 179.48197\n",
      "Epoch 3581/5000\n",
      "ecpch:3580,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1327 - val_loss: 194.1613\n",
      "\n",
      "Epoch 03581: val_loss did not improve from 179.48197\n",
      "Epoch 3582/5000\n",
      "ecpch:3581,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1325 - val_loss: 194.1611\n",
      "\n",
      "Epoch 03582: val_loss did not improve from 179.48197\n",
      "Epoch 3583/5000\n",
      "ecpch:3582,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1325 - val_loss: 194.1538\n",
      "\n",
      "Epoch 03583: val_loss did not improve from 179.48197\n",
      "Epoch 3584/5000\n",
      "ecpch:3583,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1324 - val_loss: 194.1521\n",
      "\n",
      "Epoch 03584: val_loss did not improve from 179.48197\n",
      "Epoch 3585/5000\n",
      "ecpch:3584,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1323 - val_loss: 194.1577\n",
      "\n",
      "Epoch 03585: val_loss did not improve from 179.48197\n",
      "Epoch 3586/5000\n",
      "ecpch:3585,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1324 - val_loss: 194.1555\n",
      "\n",
      "Epoch 03586: val_loss did not improve from 179.48197\n",
      "Epoch 3587/5000\n",
      "ecpch:3586,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1322 - val_loss: 194.1608\n",
      "\n",
      "Epoch 03587: val_loss did not improve from 179.48197\n",
      "Epoch 3588/5000\n",
      "ecpch:3587,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1323 - val_loss: 194.1559\n",
      "\n",
      "Epoch 03588: val_loss did not improve from 179.48197\n",
      "Epoch 3589/5000\n",
      "ecpch:3588,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1325 - val_loss: 194.1532\n",
      "\n",
      "Epoch 03589: val_loss did not improve from 179.48197\n",
      "Epoch 3590/5000\n",
      "ecpch:3589,learn rate 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1321 - val_loss: 194.1547\n",
      "\n",
      "Epoch 03590: val_loss did not improve from 179.48197\n",
      "Epoch 3591/5000\n",
      "ecpch:3590,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1321 - val_loss: 194.1569\n",
      "\n",
      "Epoch 03591: val_loss did not improve from 179.48197\n",
      "Epoch 3592/5000\n",
      "ecpch:3591,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1323 - val_loss: 194.1548\n",
      "\n",
      "Epoch 03592: val_loss did not improve from 179.48197\n",
      "Epoch 3593/5000\n",
      "ecpch:3592,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1318 - val_loss: 194.1547\n",
      "\n",
      "Epoch 03593: val_loss did not improve from 179.48197\n",
      "Epoch 3594/5000\n",
      "ecpch:3593,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1323 - val_loss: 194.1639\n",
      "\n",
      "Epoch 03594: val_loss did not improve from 179.48197\n",
      "Epoch 3595/5000\n",
      "ecpch:3594,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1321 - val_loss: 194.1585\n",
      "\n",
      "Epoch 03595: val_loss did not improve from 179.48197\n",
      "Epoch 3596/5000\n",
      "ecpch:3595,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1320 - val_loss: 194.1594\n",
      "\n",
      "Epoch 03596: val_loss did not improve from 179.48197\n",
      "Epoch 3597/5000\n",
      "ecpch:3596,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1318 - val_loss: 194.1593\n",
      "\n",
      "Epoch 03597: val_loss did not improve from 179.48197\n",
      "Epoch 3598/5000\n",
      "ecpch:3597,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1320 - val_loss: 194.1599\n",
      "\n",
      "Epoch 03598: val_loss did not improve from 179.48197\n",
      "Epoch 3599/5000\n",
      "ecpch:3598,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1317 - val_loss: 194.1587\n",
      "\n",
      "Epoch 03599: val_loss did not improve from 179.48197\n",
      "Epoch 3600/5000\n",
      "ecpch:3599,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1324 - val_loss: 194.1589\n",
      "\n",
      "Epoch 03600: val_loss did not improve from 179.48197\n",
      "Epoch 3601/5000\n",
      "ecpch:3600,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1322 - val_loss: 194.1536\n",
      "\n",
      "Epoch 03601: val_loss did not improve from 179.48197\n",
      "Epoch 3602/5000\n",
      "ecpch:3601,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1318 - val_loss: 194.1534\n",
      "\n",
      "Epoch 03602: val_loss did not improve from 179.48197\n",
      "Epoch 3603/5000\n",
      "ecpch:3602,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1320 - val_loss: 194.1627\n",
      "\n",
      "Epoch 03603: val_loss did not improve from 179.48197\n",
      "Epoch 3604/5000\n",
      "ecpch:3603,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1315 - val_loss: 194.1532\n",
      "\n",
      "Epoch 03604: val_loss did not improve from 179.48197\n",
      "Epoch 3605/5000\n",
      "ecpch:3604,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 55.1316 - val_loss: 194.1542\n",
      "\n",
      "Epoch 03605: val_loss did not improve from 179.48197\n",
      "Epoch 3606/5000\n",
      "ecpch:3605,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1312 - val_loss: 194.1591\n",
      "\n",
      "Epoch 03606: val_loss did not improve from 179.48197\n",
      "Epoch 3607/5000\n",
      "ecpch:3606,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1314 - val_loss: 194.1553\n",
      "\n",
      "Epoch 03607: val_loss did not improve from 179.48197\n",
      "Epoch 3608/5000\n",
      "ecpch:3607,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1312 - val_loss: 194.1569\n",
      "\n",
      "Epoch 03608: val_loss did not improve from 179.48197\n",
      "Epoch 3609/5000\n",
      "ecpch:3608,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1311 - val_loss: 194.1549\n",
      "\n",
      "Epoch 03609: val_loss did not improve from 179.48197\n",
      "Epoch 3610/5000\n",
      "ecpch:3609,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1313 - val_loss: 194.1593\n",
      "\n",
      "Epoch 03610: val_loss did not improve from 179.48197\n",
      "Epoch 3611/5000\n",
      "ecpch:3610,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1311 - val_loss: 194.1610\n",
      "\n",
      "Epoch 03611: val_loss did not improve from 179.48197\n",
      "Epoch 3612/5000\n",
      "ecpch:3611,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1313 - val_loss: 194.1597\n",
      "\n",
      "Epoch 03612: val_loss did not improve from 179.48197\n",
      "Epoch 3613/5000\n",
      "ecpch:3612,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1308 - val_loss: 194.1547\n",
      "\n",
      "Epoch 03613: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 03613: ReduceLROnPlateau reducing learning rate to 2.0301158514257623e-07.\n",
      "Epoch 3614/5000\n",
      "ecpch:3613,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1311 - val_loss: 194.1587\n",
      "\n",
      "Epoch 03614: val_loss did not improve from 179.48197\n",
      "Epoch 3615/5000\n",
      "ecpch:3614,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1309 - val_loss: 194.1581\n",
      "\n",
      "Epoch 03615: val_loss did not improve from 179.48197\n",
      "Epoch 3616/5000\n",
      "ecpch:3615,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1312 - val_loss: 194.1593\n",
      "\n",
      "Epoch 03616: val_loss did not improve from 179.48197\n",
      "Epoch 3617/5000\n",
      "ecpch:3616,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1311 - val_loss: 194.1606\n",
      "\n",
      "Epoch 03617: val_loss did not improve from 179.48197\n",
      "Epoch 3618/5000\n",
      "ecpch:3617,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1306 - val_loss: 194.1565\n",
      "\n",
      "Epoch 03618: val_loss did not improve from 179.48197\n",
      "Epoch 3619/5000\n",
      "ecpch:3618,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1307 - val_loss: 194.1560\n",
      "\n",
      "Epoch 03619: val_loss did not improve from 179.48197\n",
      "Epoch 3620/5000\n",
      "ecpch:3619,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1307 - val_loss: 194.1574\n",
      "\n",
      "Epoch 03620: val_loss did not improve from 179.48197\n",
      "Epoch 3621/5000\n",
      "ecpch:3620,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1311 - val_loss: 194.1539\n",
      "\n",
      "Epoch 03621: val_loss did not improve from 179.48197\n",
      "Epoch 3622/5000\n",
      "ecpch:3621,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1306 - val_loss: 194.1620\n",
      "\n",
      "Epoch 03622: val_loss did not improve from 179.48197\n",
      "Epoch 3623/5000\n",
      "ecpch:3622,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1309 - val_loss: 194.1656\n",
      "\n",
      "Epoch 03623: val_loss did not improve from 179.48197\n",
      "Epoch 3624/5000\n",
      "ecpch:3623,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1305 - val_loss: 194.1641\n",
      "\n",
      "Epoch 03624: val_loss did not improve from 179.48197\n",
      "Epoch 3625/5000\n",
      "ecpch:3624,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1309 - val_loss: 194.1610\n",
      "\n",
      "Epoch 03625: val_loss did not improve from 179.48197\n",
      "Epoch 3626/5000\n",
      "ecpch:3625,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1308 - val_loss: 194.1553\n",
      "\n",
      "Epoch 03626: val_loss did not improve from 179.48197\n",
      "Epoch 3627/5000\n",
      "ecpch:3626,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1304 - val_loss: 194.1582\n",
      "\n",
      "Epoch 03627: val_loss did not improve from 179.48197\n",
      "Epoch 3628/5000\n",
      "ecpch:3627,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1305 - val_loss: 194.1599\n",
      "\n",
      "Epoch 03628: val_loss did not improve from 179.48197\n",
      "Epoch 3629/5000\n",
      "ecpch:3628,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1303 - val_loss: 194.1536\n",
      "\n",
      "Epoch 03629: val_loss did not improve from 179.48197\n",
      "Epoch 3630/5000\n",
      "ecpch:3629,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1303 - val_loss: 194.1598\n",
      "\n",
      "Epoch 03630: val_loss did not improve from 179.48197\n",
      "Epoch 3631/5000\n",
      "ecpch:3630,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1301 - val_loss: 194.1639\n",
      "\n",
      "Epoch 03631: val_loss did not improve from 179.48197\n",
      "Epoch 3632/5000\n",
      "ecpch:3631,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1299 - val_loss: 194.1560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 03632: val_loss did not improve from 179.48197\n",
      "Epoch 3633/5000\n",
      "ecpch:3632,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1299 - val_loss: 194.1606\n",
      "\n",
      "Epoch 03633: val_loss did not improve from 179.48197\n",
      "Epoch 3634/5000\n",
      "ecpch:3633,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1298 - val_loss: 194.1648\n",
      "\n",
      "Epoch 03634: val_loss did not improve from 179.48197\n",
      "Epoch 3635/5000\n",
      "ecpch:3634,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1298 - val_loss: 194.1542\n",
      "\n",
      "Epoch 03635: val_loss did not improve from 179.48197\n",
      "Epoch 3636/5000\n",
      "ecpch:3635,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1298 - val_loss: 194.1574\n",
      "\n",
      "Epoch 03636: val_loss did not improve from 179.48197\n",
      "Epoch 3637/5000\n",
      "ecpch:3636,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1297 - val_loss: 194.1602\n",
      "\n",
      "Epoch 03637: val_loss did not improve from 179.48197\n",
      "Epoch 3638/5000\n",
      "ecpch:3637,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1299 - val_loss: 194.1596\n",
      "\n",
      "Epoch 03638: val_loss did not improve from 179.48197\n",
      "Epoch 3639/5000\n",
      "ecpch:3638,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1297 - val_loss: 194.1593\n",
      "\n",
      "Epoch 03639: val_loss did not improve from 179.48197\n",
      "Epoch 3640/5000\n",
      "ecpch:3639,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1294 - val_loss: 194.1572\n",
      "\n",
      "Epoch 03640: val_loss did not improve from 179.48197\n",
      "Epoch 3641/5000\n",
      "ecpch:3640,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1297 - val_loss: 194.1605\n",
      "\n",
      "Epoch 03641: val_loss did not improve from 179.48197\n",
      "Epoch 3642/5000\n",
      "ecpch:3641,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1296 - val_loss: 194.1573\n",
      "\n",
      "Epoch 03642: val_loss did not improve from 179.48197\n",
      "Epoch 3643/5000\n",
      "ecpch:3642,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1295 - val_loss: 194.1564\n",
      "\n",
      "Epoch 03643: val_loss did not improve from 179.48197\n",
      "Epoch 3644/5000\n",
      "ecpch:3643,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1295 - val_loss: 194.1605\n",
      "\n",
      "Epoch 03644: val_loss did not improve from 179.48197\n",
      "Epoch 3645/5000\n",
      "ecpch:3644,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1293 - val_loss: 194.1622\n",
      "\n",
      "Epoch 03645: val_loss did not improve from 179.48197\n",
      "Epoch 3646/5000\n",
      "ecpch:3645,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1293 - val_loss: 194.1612\n",
      "\n",
      "Epoch 03646: val_loss did not improve from 179.48197\n",
      "Epoch 3647/5000\n",
      "ecpch:3646,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1291 - val_loss: 194.1614\n",
      "\n",
      "Epoch 03647: val_loss did not improve from 179.48197\n",
      "Epoch 3648/5000\n",
      "ecpch:3647,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1295 - val_loss: 194.1569\n",
      "\n",
      "Epoch 03648: val_loss did not improve from 179.48197\n",
      "Epoch 3649/5000\n",
      "ecpch:3648,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1292 - val_loss: 194.1523\n",
      "\n",
      "Epoch 03649: val_loss did not improve from 179.48197\n",
      "Epoch 3650/5000\n",
      "ecpch:3649,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1293 - val_loss: 194.1619\n",
      "\n",
      "Epoch 03650: val_loss did not improve from 179.48197\n",
      "Epoch 3651/5000\n",
      "ecpch:3650,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1290 - val_loss: 194.1573\n",
      "\n",
      "Epoch 03651: val_loss did not improve from 179.48197\n",
      "Epoch 3652/5000\n",
      "ecpch:3651,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1293 - val_loss: 194.1598\n",
      "\n",
      "Epoch 03652: val_loss did not improve from 179.48197\n",
      "Epoch 3653/5000\n",
      "ecpch:3652,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 55.1290 - val_loss: 194.1647\n",
      "\n",
      "Epoch 03653: val_loss did not improve from 179.48197\n",
      "Epoch 3654/5000\n",
      "ecpch:3653,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1295 - val_loss: 194.1600\n",
      "\n",
      "Epoch 03654: val_loss did not improve from 179.48197\n",
      "Epoch 3655/5000\n",
      "ecpch:3654,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1296 - val_loss: 194.1530\n",
      "\n",
      "Epoch 03655: val_loss did not improve from 179.48197\n",
      "Epoch 3656/5000\n",
      "ecpch:3655,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1287 - val_loss: 194.1596\n",
      "\n",
      "Epoch 03656: val_loss did not improve from 179.48197\n",
      "Epoch 3657/5000\n",
      "ecpch:3656,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1293 - val_loss: 194.1634\n",
      "\n",
      "Epoch 03657: val_loss did not improve from 179.48197\n",
      "Epoch 3658/5000\n",
      "ecpch:3657,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1289 - val_loss: 194.1567\n",
      "\n",
      "Epoch 03658: val_loss did not improve from 179.48197\n",
      "Epoch 3659/5000\n",
      "ecpch:3658,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1294 - val_loss: 194.1539\n",
      "\n",
      "Epoch 03659: val_loss did not improve from 179.48197\n",
      "Epoch 3660/5000\n",
      "ecpch:3659,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1294 - val_loss: 194.1603\n",
      "\n",
      "Epoch 03660: val_loss did not improve from 179.48197\n",
      "Epoch 3661/5000\n",
      "ecpch:3660,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1287 - val_loss: 194.1648\n",
      "\n",
      "Epoch 03661: val_loss did not improve from 179.48197\n",
      "Epoch 3662/5000\n",
      "ecpch:3661,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 55.1293 - val_loss: 194.1607\n",
      "\n",
      "Epoch 03662: val_loss did not improve from 179.48197\n",
      "Epoch 3663/5000\n",
      "ecpch:3662,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1296 - val_loss: 194.1540\n",
      "\n",
      "Epoch 03663: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 03663: ReduceLROnPlateau reducing learning rate to 1.8271042279138783e-07.\n",
      "Epoch 3664/5000\n",
      "ecpch:3663,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1285 - val_loss: 194.1595\n",
      "\n",
      "Epoch 03664: val_loss did not improve from 179.48197\n",
      "Epoch 3665/5000\n",
      "ecpch:3664,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1292 - val_loss: 194.1615\n",
      "\n",
      "Epoch 03665: val_loss did not improve from 179.48197\n",
      "Epoch 3666/5000\n",
      "ecpch:3665,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1290 - val_loss: 194.1569\n",
      "\n",
      "Epoch 03666: val_loss did not improve from 179.48197\n",
      "Epoch 3667/5000\n",
      "ecpch:3666,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1284 - val_loss: 194.1559\n",
      "\n",
      "Epoch 03667: val_loss did not improve from 179.48197\n",
      "Epoch 3668/5000\n",
      "ecpch:3667,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1287 - val_loss: 194.1635\n",
      "\n",
      "Epoch 03668: val_loss did not improve from 179.48197\n",
      "Epoch 3669/5000\n",
      "ecpch:3668,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1282 - val_loss: 194.1635\n",
      "\n",
      "Epoch 03669: val_loss did not improve from 179.48197\n",
      "Epoch 3670/5000\n",
      "ecpch:3669,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1286 - val_loss: 194.1602\n",
      "\n",
      "Epoch 03670: val_loss did not improve from 179.48197\n",
      "Epoch 3671/5000\n",
      "ecpch:3670,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1283 - val_loss: 194.1610\n",
      "\n",
      "Epoch 03671: val_loss did not improve from 179.48197\n",
      "Epoch 3672/5000\n",
      "ecpch:3671,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1282 - val_loss: 194.1624\n",
      "\n",
      "Epoch 03672: val_loss did not improve from 179.48197\n",
      "Epoch 3673/5000\n",
      "ecpch:3672,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1282 - val_loss: 194.1547\n",
      "\n",
      "Epoch 03673: val_loss did not improve from 179.48197\n",
      "Epoch 3674/5000\n",
      "ecpch:3673,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1281 - val_loss: 194.1616\n",
      "\n",
      "Epoch 03674: val_loss did not improve from 179.48197\n",
      "Epoch 3675/5000\n",
      "ecpch:3674,learn rate 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1283 - val_loss: 194.1620\n",
      "\n",
      "Epoch 03675: val_loss did not improve from 179.48197\n",
      "Epoch 3676/5000\n",
      "ecpch:3675,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1277 - val_loss: 194.1600\n",
      "\n",
      "Epoch 03676: val_loss did not improve from 179.48197\n",
      "Epoch 3677/5000\n",
      "ecpch:3676,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 55.1281 - val_loss: 194.1623\n",
      "\n",
      "Epoch 03677: val_loss did not improve from 179.48197\n",
      "Epoch 3678/5000\n",
      "ecpch:3677,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1277 - val_loss: 194.1588\n",
      "\n",
      "Epoch 03678: val_loss did not improve from 179.48197\n",
      "Epoch 3679/5000\n",
      "ecpch:3678,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1281 - val_loss: 194.1601\n",
      "\n",
      "Epoch 03679: val_loss did not improve from 179.48197\n",
      "Epoch 3680/5000\n",
      "ecpch:3679,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1279 - val_loss: 194.1550\n",
      "\n",
      "Epoch 03680: val_loss did not improve from 179.48197\n",
      "Epoch 3681/5000\n",
      "ecpch:3680,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1279 - val_loss: 194.1575\n",
      "\n",
      "Epoch 03681: val_loss did not improve from 179.48197\n",
      "Epoch 3682/5000\n",
      "ecpch:3681,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1278 - val_loss: 194.1605\n",
      "\n",
      "Epoch 03682: val_loss did not improve from 179.48197\n",
      "Epoch 3683/5000\n",
      "ecpch:3682,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1275 - val_loss: 194.1593\n",
      "\n",
      "Epoch 03683: val_loss did not improve from 179.48197\n",
      "Epoch 3684/5000\n",
      "ecpch:3683,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1278 - val_loss: 194.1585\n",
      "\n",
      "Epoch 03684: val_loss did not improve from 179.48197\n",
      "Epoch 3685/5000\n",
      "ecpch:3684,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1275 - val_loss: 194.1558\n",
      "\n",
      "Epoch 03685: val_loss did not improve from 179.48197\n",
      "Epoch 3686/5000\n",
      "ecpch:3685,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1277 - val_loss: 194.1606\n",
      "\n",
      "Epoch 03686: val_loss did not improve from 179.48197\n",
      "Epoch 3687/5000\n",
      "ecpch:3686,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1276 - val_loss: 194.1613\n",
      "\n",
      "Epoch 03687: val_loss did not improve from 179.48197\n",
      "Epoch 3688/5000\n",
      "ecpch:3687,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1277 - val_loss: 194.1630\n",
      "\n",
      "Epoch 03688: val_loss did not improve from 179.48197\n",
      "Epoch 3689/5000\n",
      "ecpch:3688,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1275 - val_loss: 194.1534\n",
      "\n",
      "Epoch 03689: val_loss did not improve from 179.48197\n",
      "Epoch 3690/5000\n",
      "ecpch:3689,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1275 - val_loss: 194.1560\n",
      "\n",
      "Epoch 03690: val_loss did not improve from 179.48197\n",
      "Epoch 3691/5000\n",
      "ecpch:3690,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1272 - val_loss: 194.1579\n",
      "\n",
      "Epoch 03691: val_loss did not improve from 179.48197\n",
      "Epoch 3692/5000\n",
      "ecpch:3691,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1274 - val_loss: 194.1583\n",
      "\n",
      "Epoch 03692: val_loss did not improve from 179.48197\n",
      "Epoch 3693/5000\n",
      "ecpch:3692,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1273 - val_loss: 194.1615\n",
      "\n",
      "Epoch 03693: val_loss did not improve from 179.48197\n",
      "Epoch 3694/5000\n",
      "ecpch:3693,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1271 - val_loss: 194.1613\n",
      "\n",
      "Epoch 03694: val_loss did not improve from 179.48197\n",
      "Epoch 3695/5000\n",
      "ecpch:3694,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1271 - val_loss: 194.1531\n",
      "\n",
      "Epoch 03695: val_loss did not improve from 179.48197\n",
      "Epoch 3696/5000\n",
      "ecpch:3695,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1270 - val_loss: 194.1638\n",
      "\n",
      "Epoch 03696: val_loss did not improve from 179.48197\n",
      "Epoch 3697/5000\n",
      "ecpch:3696,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1270 - val_loss: 194.1683\n",
      "\n",
      "Epoch 03697: val_loss did not improve from 179.48197\n",
      "Epoch 3698/5000\n",
      "ecpch:3697,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1271 - val_loss: 194.1621\n",
      "\n",
      "Epoch 03698: val_loss did not improve from 179.48197\n",
      "Epoch 3699/5000\n",
      "ecpch:3698,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1270 - val_loss: 194.1610\n",
      "\n",
      "Epoch 03699: val_loss did not improve from 179.48197\n",
      "Epoch 3700/5000\n",
      "ecpch:3699,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1268 - val_loss: 194.1632\n",
      "\n",
      "Epoch 03700: val_loss did not improve from 179.48197\n",
      "Epoch 3701/5000\n",
      "ecpch:3700,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1267 - val_loss: 194.1600\n",
      "\n",
      "Epoch 03701: val_loss did not improve from 179.48197\n",
      "Epoch 3702/5000\n",
      "ecpch:3701,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1269 - val_loss: 194.1537\n",
      "\n",
      "Epoch 03702: val_loss did not improve from 179.48197\n",
      "Epoch 3703/5000\n",
      "ecpch:3702,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1266 - val_loss: 194.1636\n",
      "\n",
      "Epoch 03703: val_loss did not improve from 179.48197\n",
      "Epoch 3704/5000\n",
      "ecpch:3703,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1267 - val_loss: 194.1624\n",
      "\n",
      "Epoch 03704: val_loss did not improve from 179.48197\n",
      "Epoch 3705/5000\n",
      "ecpch:3704,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1263 - val_loss: 194.1573\n",
      "\n",
      "Epoch 03705: val_loss did not improve from 179.48197\n",
      "Epoch 3706/5000\n",
      "ecpch:3705,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1269 - val_loss: 194.1571\n",
      "\n",
      "Epoch 03706: val_loss did not improve from 179.48197\n",
      "Epoch 3707/5000\n",
      "ecpch:3706,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1265 - val_loss: 194.1582\n",
      "\n",
      "Epoch 03707: val_loss did not improve from 179.48197\n",
      "Epoch 3708/5000\n",
      "ecpch:3707,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1270 - val_loss: 194.1615\n",
      "\n",
      "Epoch 03708: val_loss did not improve from 179.48197\n",
      "Epoch 3709/5000\n",
      "ecpch:3708,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1270 - val_loss: 194.1616\n",
      "\n",
      "Epoch 03709: val_loss did not improve from 179.48197\n",
      "Epoch 3710/5000\n",
      "ecpch:3709,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1264 - val_loss: 194.1619\n",
      "\n",
      "Epoch 03710: val_loss did not improve from 179.48197\n",
      "Epoch 3711/5000\n",
      "ecpch:3710,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1265 - val_loss: 194.1639\n",
      "\n",
      "Epoch 03711: val_loss did not improve from 179.48197\n",
      "Epoch 3712/5000\n",
      "ecpch:3711,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1264 - val_loss: 194.1610\n",
      "\n",
      "Epoch 03712: val_loss did not improve from 179.48197\n",
      "Epoch 3713/5000\n",
      "ecpch:3712,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1264 - val_loss: 194.1561\n",
      "\n",
      "Epoch 03713: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 03713: ReduceLROnPlateau reducing learning rate to 1.6443938051224906e-07.\n",
      "Epoch 3714/5000\n",
      "ecpch:3713,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1262 - val_loss: 194.1614\n",
      "\n",
      "Epoch 03714: val_loss did not improve from 179.48197\n",
      "Epoch 3715/5000\n",
      "ecpch:3714,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1263 - val_loss: 194.1601\n",
      "\n",
      "Epoch 03715: val_loss did not improve from 179.48197\n",
      "Epoch 3716/5000\n",
      "ecpch:3715,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1263 - val_loss: 194.1636\n",
      "\n",
      "Epoch 03716: val_loss did not improve from 179.48197\n",
      "Epoch 3717/5000\n",
      "ecpch:3716,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1260 - val_loss: 194.1647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 03717: val_loss did not improve from 179.48197\n",
      "Epoch 3718/5000\n",
      "ecpch:3717,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1261 - val_loss: 194.1639\n",
      "\n",
      "Epoch 03718: val_loss did not improve from 179.48197\n",
      "Epoch 3719/5000\n",
      "ecpch:3718,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1261 - val_loss: 194.1593\n",
      "\n",
      "Epoch 03719: val_loss did not improve from 179.48197\n",
      "Epoch 3720/5000\n",
      "ecpch:3719,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1260 - val_loss: 194.1577\n",
      "\n",
      "Epoch 03720: val_loss did not improve from 179.48197\n",
      "Epoch 3721/5000\n",
      "ecpch:3720,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1262 - val_loss: 194.1646\n",
      "\n",
      "Epoch 03721: val_loss did not improve from 179.48197\n",
      "Epoch 3722/5000\n",
      "ecpch:3721,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1257 - val_loss: 194.1647\n",
      "\n",
      "Epoch 03722: val_loss did not improve from 179.48197\n",
      "Epoch 3723/5000\n",
      "ecpch:3722,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1259 - val_loss: 194.1631\n",
      "\n",
      "Epoch 03723: val_loss did not improve from 179.48197\n",
      "Epoch 3724/5000\n",
      "ecpch:3723,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1258 - val_loss: 194.1618\n",
      "\n",
      "Epoch 03724: val_loss did not improve from 179.48197\n",
      "Epoch 3725/5000\n",
      "ecpch:3724,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1260 - val_loss: 194.1572\n",
      "\n",
      "Epoch 03725: val_loss did not improve from 179.48197\n",
      "Epoch 3726/5000\n",
      "ecpch:3725,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1259 - val_loss: 194.1590\n",
      "\n",
      "Epoch 03726: val_loss did not improve from 179.48197\n",
      "Epoch 3727/5000\n",
      "ecpch:3726,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1257 - val_loss: 194.1627\n",
      "\n",
      "Epoch 03727: val_loss did not improve from 179.48197\n",
      "Epoch 3728/5000\n",
      "ecpch:3727,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1257 - val_loss: 194.1590\n",
      "\n",
      "Epoch 03728: val_loss did not improve from 179.48197\n",
      "Epoch 3729/5000\n",
      "ecpch:3728,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1256 - val_loss: 194.1618\n",
      "\n",
      "Epoch 03729: val_loss did not improve from 179.48197\n",
      "Epoch 3730/5000\n",
      "ecpch:3729,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1254 - val_loss: 194.1595\n",
      "\n",
      "Epoch 03730: val_loss did not improve from 179.48197\n",
      "Epoch 3731/5000\n",
      "ecpch:3730,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1255 - val_loss: 194.1629\n",
      "\n",
      "Epoch 03731: val_loss did not improve from 179.48197\n",
      "Epoch 3732/5000\n",
      "ecpch:3731,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1254 - val_loss: 194.1635\n",
      "\n",
      "Epoch 03732: val_loss did not improve from 179.48197\n",
      "Epoch 3733/5000\n",
      "ecpch:3732,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1255 - val_loss: 194.1595\n",
      "\n",
      "Epoch 03733: val_loss did not improve from 179.48197\n",
      "Epoch 3734/5000\n",
      "ecpch:3733,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1253 - val_loss: 194.1574\n",
      "\n",
      "Epoch 03734: val_loss did not improve from 179.48197\n",
      "Epoch 3735/5000\n",
      "ecpch:3734,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1256 - val_loss: 194.1599\n",
      "\n",
      "Epoch 03735: val_loss did not improve from 179.48197\n",
      "Epoch 3736/5000\n",
      "ecpch:3735,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1254 - val_loss: 194.1627\n",
      "\n",
      "Epoch 03736: val_loss did not improve from 179.48197\n",
      "Epoch 3737/5000\n",
      "ecpch:3736,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1251 - val_loss: 194.1567\n",
      "\n",
      "Epoch 03737: val_loss did not improve from 179.48197\n",
      "Epoch 3738/5000\n",
      "ecpch:3737,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1254 - val_loss: 194.1640\n",
      "\n",
      "Epoch 03738: val_loss did not improve from 179.48197\n",
      "Epoch 3739/5000\n",
      "ecpch:3738,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1252 - val_loss: 194.1636\n",
      "\n",
      "Epoch 03739: val_loss did not improve from 179.48197\n",
      "Epoch 3740/5000\n",
      "ecpch:3739,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1252 - val_loss: 194.1586\n",
      "\n",
      "Epoch 03740: val_loss did not improve from 179.48197\n",
      "Epoch 3741/5000\n",
      "ecpch:3740,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1251 - val_loss: 194.1621\n",
      "\n",
      "Epoch 03741: val_loss did not improve from 179.48197\n",
      "Epoch 3742/5000\n",
      "ecpch:3741,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1251 - val_loss: 194.1585\n",
      "\n",
      "Epoch 03742: val_loss did not improve from 179.48197\n",
      "Epoch 3743/5000\n",
      "ecpch:3742,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1251 - val_loss: 194.1614\n",
      "\n",
      "Epoch 03743: val_loss did not improve from 179.48197\n",
      "Epoch 3744/5000\n",
      "ecpch:3743,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1248 - val_loss: 194.1595\n",
      "\n",
      "Epoch 03744: val_loss did not improve from 179.48197\n",
      "Epoch 3745/5000\n",
      "ecpch:3744,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1250 - val_loss: 194.1633\n",
      "\n",
      "Epoch 03745: val_loss did not improve from 179.48197\n",
      "Epoch 3746/5000\n",
      "ecpch:3745,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1247 - val_loss: 194.1613\n",
      "\n",
      "Epoch 03746: val_loss did not improve from 179.48197\n",
      "Epoch 3747/5000\n",
      "ecpch:3746,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1251 - val_loss: 194.1571\n",
      "\n",
      "Epoch 03747: val_loss did not improve from 179.48197\n",
      "Epoch 3748/5000\n",
      "ecpch:3747,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1247 - val_loss: 194.1586\n",
      "\n",
      "Epoch 03748: val_loss did not improve from 179.48197\n",
      "Epoch 3749/5000\n",
      "ecpch:3748,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1250 - val_loss: 194.1643\n",
      "\n",
      "Epoch 03749: val_loss did not improve from 179.48197\n",
      "Epoch 3750/5000\n",
      "ecpch:3749,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1246 - val_loss: 194.1583\n",
      "\n",
      "Epoch 03750: val_loss did not improve from 179.48197\n",
      "Epoch 3751/5000\n",
      "ecpch:3750,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1253 - val_loss: 194.1609\n",
      "\n",
      "Epoch 03751: val_loss did not improve from 179.48197\n",
      "Epoch 3752/5000\n",
      "ecpch:3751,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1251 - val_loss: 194.1563\n",
      "\n",
      "Epoch 03752: val_loss did not improve from 179.48197\n",
      "Epoch 3753/5000\n",
      "ecpch:3752,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1245 - val_loss: 194.1628\n",
      "\n",
      "Epoch 03753: val_loss did not improve from 179.48197\n",
      "Epoch 3754/5000\n",
      "ecpch:3753,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1248 - val_loss: 194.1585\n",
      "\n",
      "Epoch 03754: val_loss did not improve from 179.48197\n",
      "Epoch 3755/5000\n",
      "ecpch:3754,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1246 - val_loss: 194.1631\n",
      "\n",
      "Epoch 03755: val_loss did not improve from 179.48197\n",
      "Epoch 3756/5000\n",
      "ecpch:3755,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1247 - val_loss: 194.1639\n",
      "\n",
      "Epoch 03756: val_loss did not improve from 179.48197\n",
      "Epoch 3757/5000\n",
      "ecpch:3756,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1247 - val_loss: 194.1646\n",
      "\n",
      "Epoch 03757: val_loss did not improve from 179.48197\n",
      "Epoch 3758/5000\n",
      "ecpch:3757,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1246 - val_loss: 194.1629\n",
      "\n",
      "Epoch 03758: val_loss did not improve from 179.48197\n",
      "Epoch 3759/5000\n",
      "ecpch:3758,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1245 - val_loss: 194.1693\n",
      "\n",
      "Epoch 03759: val_loss did not improve from 179.48197\n",
      "Epoch 3760/5000\n",
      "ecpch:3759,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1244 - val_loss: 194.1629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 03760: val_loss did not improve from 179.48197\n",
      "Epoch 3761/5000\n",
      "ecpch:3760,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1242 - val_loss: 194.1677\n",
      "\n",
      "Epoch 03761: val_loss did not improve from 179.48197\n",
      "Epoch 3762/5000\n",
      "ecpch:3761,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1244 - val_loss: 194.1645\n",
      "\n",
      "Epoch 03762: val_loss did not improve from 179.48197\n",
      "Epoch 3763/5000\n",
      "ecpch:3762,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1242 - val_loss: 194.1650\n",
      "\n",
      "Epoch 03763: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 03763: ReduceLROnPlateau reducing learning rate to 1.4799544629795493e-07.\n",
      "Epoch 3764/5000\n",
      "ecpch:3763,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1242 - val_loss: 194.1611\n",
      "\n",
      "Epoch 03764: val_loss did not improve from 179.48197\n",
      "Epoch 3765/5000\n",
      "ecpch:3764,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1242 - val_loss: 194.1622\n",
      "\n",
      "Epoch 03765: val_loss did not improve from 179.48197\n",
      "Epoch 3766/5000\n",
      "ecpch:3765,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1244 - val_loss: 194.1601\n",
      "\n",
      "Epoch 03766: val_loss did not improve from 179.48197\n",
      "Epoch 3767/5000\n",
      "ecpch:3766,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1242 - val_loss: 194.1592\n",
      "\n",
      "Epoch 03767: val_loss did not improve from 179.48197\n",
      "Epoch 3768/5000\n",
      "ecpch:3767,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1240 - val_loss: 194.1592\n",
      "\n",
      "Epoch 03768: val_loss did not improve from 179.48197\n",
      "Epoch 3769/5000\n",
      "ecpch:3768,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1240 - val_loss: 194.1622\n",
      "\n",
      "Epoch 03769: val_loss did not improve from 179.48197\n",
      "Epoch 3770/5000\n",
      "ecpch:3769,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1239 - val_loss: 194.1647\n",
      "\n",
      "Epoch 03770: val_loss did not improve from 179.48197\n",
      "Epoch 3771/5000\n",
      "ecpch:3770,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1238 - val_loss: 194.1666\n",
      "\n",
      "Epoch 03771: val_loss did not improve from 179.48197\n",
      "Epoch 3772/5000\n",
      "ecpch:3771,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 55.1240 - val_loss: 194.1609\n",
      "\n",
      "Epoch 03772: val_loss did not improve from 179.48197\n",
      "Epoch 3773/5000\n",
      "ecpch:3772,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1237 - val_loss: 194.1610\n",
      "\n",
      "Epoch 03773: val_loss did not improve from 179.48197\n",
      "Epoch 3774/5000\n",
      "ecpch:3773,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1238 - val_loss: 194.1618\n",
      "\n",
      "Epoch 03774: val_loss did not improve from 179.48197\n",
      "Epoch 3775/5000\n",
      "ecpch:3774,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1237 - val_loss: 194.1598\n",
      "\n",
      "Epoch 03775: val_loss did not improve from 179.48197\n",
      "Epoch 3776/5000\n",
      "ecpch:3775,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1238 - val_loss: 194.1602\n",
      "\n",
      "Epoch 03776: val_loss did not improve from 179.48197\n",
      "Epoch 3777/5000\n",
      "ecpch:3776,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1235 - val_loss: 194.1630\n",
      "\n",
      "Epoch 03777: val_loss did not improve from 179.48197\n",
      "Epoch 3778/5000\n",
      "ecpch:3777,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1237 - val_loss: 194.1615\n",
      "\n",
      "Epoch 03778: val_loss did not improve from 179.48197\n",
      "Epoch 3779/5000\n",
      "ecpch:3778,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1234 - val_loss: 194.1617\n",
      "\n",
      "Epoch 03779: val_loss did not improve from 179.48197\n",
      "Epoch 3780/5000\n",
      "ecpch:3779,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1236 - val_loss: 194.1610\n",
      "\n",
      "Epoch 03780: val_loss did not improve from 179.48197\n",
      "Epoch 3781/5000\n",
      "ecpch:3780,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1234 - val_loss: 194.1634\n",
      "\n",
      "Epoch 03781: val_loss did not improve from 179.48197\n",
      "Epoch 3782/5000\n",
      "ecpch:3781,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1234 - val_loss: 194.1645\n",
      "\n",
      "Epoch 03782: val_loss did not improve from 179.48197\n",
      "Epoch 3783/5000\n",
      "ecpch:3782,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1234 - val_loss: 194.1591\n",
      "\n",
      "Epoch 03783: val_loss did not improve from 179.48197\n",
      "Epoch 3784/5000\n",
      "ecpch:3783,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1235 - val_loss: 194.1639\n",
      "\n",
      "Epoch 03784: val_loss did not improve from 179.48197\n",
      "Epoch 3785/5000\n",
      "ecpch:3784,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1233 - val_loss: 194.1633\n",
      "\n",
      "Epoch 03785: val_loss did not improve from 179.48197\n",
      "Epoch 3786/5000\n",
      "ecpch:3785,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1236 - val_loss: 194.1601\n",
      "\n",
      "Epoch 03786: val_loss did not improve from 179.48197\n",
      "Epoch 3787/5000\n",
      "ecpch:3786,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1235 - val_loss: 194.1601\n",
      "\n",
      "Epoch 03787: val_loss did not improve from 179.48197\n",
      "Epoch 3788/5000\n",
      "ecpch:3787,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1234 - val_loss: 194.1644\n",
      "\n",
      "Epoch 03788: val_loss did not improve from 179.48197\n",
      "Epoch 3789/5000\n",
      "ecpch:3788,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1234 - val_loss: 194.1619\n",
      "\n",
      "Epoch 03789: val_loss did not improve from 179.48197\n",
      "Epoch 3790/5000\n",
      "ecpch:3789,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1233 - val_loss: 194.1586\n",
      "\n",
      "Epoch 03790: val_loss did not improve from 179.48197\n",
      "Epoch 3791/5000\n",
      "ecpch:3790,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1231 - val_loss: 194.1621\n",
      "\n",
      "Epoch 03791: val_loss did not improve from 179.48197\n",
      "Epoch 3792/5000\n",
      "ecpch:3791,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1231 - val_loss: 194.1656\n",
      "\n",
      "Epoch 03792: val_loss did not improve from 179.48197\n",
      "Epoch 3793/5000\n",
      "ecpch:3792,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1232 - val_loss: 194.1671\n",
      "\n",
      "Epoch 03793: val_loss did not improve from 179.48197\n",
      "Epoch 3794/5000\n",
      "ecpch:3793,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1231 - val_loss: 194.1624\n",
      "\n",
      "Epoch 03794: val_loss did not improve from 179.48197\n",
      "Epoch 3795/5000\n",
      "ecpch:3794,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1231 - val_loss: 194.1634\n",
      "\n",
      "Epoch 03795: val_loss did not improve from 179.48197\n",
      "Epoch 3796/5000\n",
      "ecpch:3795,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1232 - val_loss: 194.1645\n",
      "\n",
      "Epoch 03796: val_loss did not improve from 179.48197\n",
      "Epoch 3797/5000\n",
      "ecpch:3796,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1228 - val_loss: 194.1611\n",
      "\n",
      "Epoch 03797: val_loss did not improve from 179.48197\n",
      "Epoch 3798/5000\n",
      "ecpch:3797,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1229 - val_loss: 194.1630\n",
      "\n",
      "Epoch 03798: val_loss did not improve from 179.48197\n",
      "Epoch 3799/5000\n",
      "ecpch:3798,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1227 - val_loss: 194.1637\n",
      "\n",
      "Epoch 03799: val_loss did not improve from 179.48197\n",
      "Epoch 3800/5000\n",
      "ecpch:3799,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1231 - val_loss: 194.1591\n",
      "\n",
      "Epoch 03800: val_loss did not improve from 179.48197\n",
      "Epoch 3801/5000\n",
      "ecpch:3800,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1231 - val_loss: 194.1645\n",
      "\n",
      "Epoch 03801: val_loss did not improve from 179.48197\n",
      "Epoch 3802/5000\n",
      "ecpch:3801,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1230 - val_loss: 194.1611\n",
      "\n",
      "Epoch 03802: val_loss did not improve from 179.48197\n",
      "Epoch 3803/5000\n",
      "ecpch:3802,learn rate 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 11ms/step - loss: 55.1230 - val_loss: 194.1612\n",
      "\n",
      "Epoch 03803: val_loss did not improve from 179.48197\n",
      "Epoch 3804/5000\n",
      "ecpch:3803,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1228 - val_loss: 194.1586\n",
      "\n",
      "Epoch 03804: val_loss did not improve from 179.48197\n",
      "Epoch 3805/5000\n",
      "ecpch:3804,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1226 - val_loss: 194.1550\n",
      "\n",
      "Epoch 03805: val_loss did not improve from 179.48197\n",
      "Epoch 3806/5000\n",
      "ecpch:3805,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1227 - val_loss: 194.1643\n",
      "\n",
      "Epoch 03806: val_loss did not improve from 179.48197\n",
      "Epoch 3807/5000\n",
      "ecpch:3806,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1227 - val_loss: 194.1652\n",
      "\n",
      "Epoch 03807: val_loss did not improve from 179.48197\n",
      "Epoch 3808/5000\n",
      "ecpch:3807,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1227 - val_loss: 194.1586\n",
      "\n",
      "Epoch 03808: val_loss did not improve from 179.48197\n",
      "Epoch 3809/5000\n",
      "ecpch:3808,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1226 - val_loss: 194.1662\n",
      "\n",
      "Epoch 03809: val_loss did not improve from 179.48197\n",
      "Epoch 3810/5000\n",
      "ecpch:3809,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1224 - val_loss: 194.1622\n",
      "\n",
      "Epoch 03810: val_loss did not improve from 179.48197\n",
      "Epoch 3811/5000\n",
      "ecpch:3810,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1227 - val_loss: 194.1596\n",
      "\n",
      "Epoch 03811: val_loss did not improve from 179.48197\n",
      "Epoch 3812/5000\n",
      "ecpch:3811,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1226 - val_loss: 194.1657\n",
      "\n",
      "Epoch 03812: val_loss did not improve from 179.48197\n",
      "Epoch 3813/5000\n",
      "ecpch:3812,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1224 - val_loss: 194.1627\n",
      "\n",
      "Epoch 03813: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 03813: ReduceLROnPlateau reducing learning rate to 1.331959055050902e-07.\n",
      "Epoch 3814/5000\n",
      "ecpch:3813,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1222 - val_loss: 194.1603\n",
      "\n",
      "Epoch 03814: val_loss did not improve from 179.48197\n",
      "Epoch 3815/5000\n",
      "ecpch:3814,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1223 - val_loss: 194.1628\n",
      "\n",
      "Epoch 03815: val_loss did not improve from 179.48197\n",
      "Epoch 3816/5000\n",
      "ecpch:3815,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1224 - val_loss: 194.1655\n",
      "\n",
      "Epoch 03816: val_loss did not improve from 179.48197\n",
      "Epoch 3817/5000\n",
      "ecpch:3816,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1223 - val_loss: 194.1632\n",
      "\n",
      "Epoch 03817: val_loss did not improve from 179.48197\n",
      "Epoch 3818/5000\n",
      "ecpch:3817,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1223 - val_loss: 194.1505\n",
      "\n",
      "Epoch 03818: val_loss did not improve from 179.48197\n",
      "Epoch 3819/5000\n",
      "ecpch:3818,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1220 - val_loss: 194.1653\n",
      "\n",
      "Epoch 03819: val_loss did not improve from 179.48197\n",
      "Epoch 3820/5000\n",
      "ecpch:3819,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1221 - val_loss: 194.1645\n",
      "\n",
      "Epoch 03820: val_loss did not improve from 179.48197\n",
      "Epoch 3821/5000\n",
      "ecpch:3820,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1220 - val_loss: 194.1674\n",
      "\n",
      "Epoch 03821: val_loss did not improve from 179.48197\n",
      "Epoch 3822/5000\n",
      "ecpch:3821,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1220 - val_loss: 194.1612\n",
      "\n",
      "Epoch 03822: val_loss did not improve from 179.48197\n",
      "Epoch 3823/5000\n",
      "ecpch:3822,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1219 - val_loss: 194.1647\n",
      "\n",
      "Epoch 03823: val_loss did not improve from 179.48197\n",
      "Epoch 3824/5000\n",
      "ecpch:3823,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1218 - val_loss: 194.1659\n",
      "\n",
      "Epoch 03824: val_loss did not improve from 179.48197\n",
      "Epoch 3825/5000\n",
      "ecpch:3824,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1219 - val_loss: 194.1623\n",
      "\n",
      "Epoch 03825: val_loss did not improve from 179.48197\n",
      "Epoch 3826/5000\n",
      "ecpch:3825,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1220 - val_loss: 194.1639\n",
      "\n",
      "Epoch 03826: val_loss did not improve from 179.48197\n",
      "Epoch 3827/5000\n",
      "ecpch:3826,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1217 - val_loss: 194.1654\n",
      "\n",
      "Epoch 03827: val_loss did not improve from 179.48197\n",
      "Epoch 3828/5000\n",
      "ecpch:3827,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1217 - val_loss: 194.1678\n",
      "\n",
      "Epoch 03828: val_loss did not improve from 179.48197\n",
      "Epoch 3829/5000\n",
      "ecpch:3828,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1218 - val_loss: 194.1638\n",
      "\n",
      "Epoch 03829: val_loss did not improve from 179.48197\n",
      "Epoch 3830/5000\n",
      "ecpch:3829,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1216 - val_loss: 194.1608\n",
      "\n",
      "Epoch 03830: val_loss did not improve from 179.48197\n",
      "Epoch 3831/5000\n",
      "ecpch:3830,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1217 - val_loss: 194.1667\n",
      "\n",
      "Epoch 03831: val_loss did not improve from 179.48197\n",
      "Epoch 3832/5000\n",
      "ecpch:3831,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1216 - val_loss: 194.1639\n",
      "\n",
      "Epoch 03832: val_loss did not improve from 179.48197\n",
      "Epoch 3833/5000\n",
      "ecpch:3832,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1215 - val_loss: 194.1660\n",
      "\n",
      "Epoch 03833: val_loss did not improve from 179.48197\n",
      "Epoch 3834/5000\n",
      "ecpch:3833,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1217 - val_loss: 194.1648\n",
      "\n",
      "Epoch 03834: val_loss did not improve from 179.48197\n",
      "Epoch 3835/5000\n",
      "ecpch:3834,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 55.1216 - val_loss: 194.1695\n",
      "\n",
      "Epoch 03835: val_loss did not improve from 179.48197\n",
      "Epoch 3836/5000\n",
      "ecpch:3835,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1213 - val_loss: 194.1644\n",
      "\n",
      "Epoch 03836: val_loss did not improve from 179.48197\n",
      "Epoch 3837/5000\n",
      "ecpch:3836,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1213 - val_loss: 194.1680\n",
      "\n",
      "Epoch 03837: val_loss did not improve from 179.48197\n",
      "Epoch 3838/5000\n",
      "ecpch:3837,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1214 - val_loss: 194.1602\n",
      "\n",
      "Epoch 03838: val_loss did not improve from 179.48197\n",
      "Epoch 3839/5000\n",
      "ecpch:3838,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1212 - val_loss: 194.1625\n",
      "\n",
      "Epoch 03839: val_loss did not improve from 179.48197\n",
      "Epoch 3840/5000\n",
      "ecpch:3839,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1216 - val_loss: 194.1617\n",
      "\n",
      "Epoch 03840: val_loss did not improve from 179.48197\n",
      "Epoch 3841/5000\n",
      "ecpch:3840,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 55.1214 - val_loss: 194.1649\n",
      "\n",
      "Epoch 03841: val_loss did not improve from 179.48197\n",
      "Epoch 3842/5000\n",
      "ecpch:3841,learn rate 0.000000\n",
      "64/64 [==============================] - 0s 8ms/step - loss: 55.1214 - val_loss: 194.1602\n",
      "\n",
      "Epoch 03842: val_loss did not improve from 179.48197\n",
      "Epoch 3843/5000\n",
      "ecpch:3842,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1213 - val_loss: 194.1589\n",
      "\n",
      "Epoch 03843: val_loss did not improve from 179.48197\n",
      "Epoch 3844/5000\n",
      "ecpch:3843,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1213 - val_loss: 194.1675\n",
      "\n",
      "Epoch 03844: val_loss did not improve from 179.48197\n",
      "Epoch 3845/5000\n",
      "ecpch:3844,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1213 - val_loss: 194.1709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 03845: val_loss did not improve from 179.48197\n",
      "Epoch 3846/5000\n",
      "ecpch:3845,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1212 - val_loss: 194.1582\n",
      "\n",
      "Epoch 03846: val_loss did not improve from 179.48197\n",
      "Epoch 3847/5000\n",
      "ecpch:3846,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1212 - val_loss: 194.1693\n",
      "\n",
      "Epoch 03847: val_loss did not improve from 179.48197\n",
      "Epoch 3848/5000\n",
      "ecpch:3847,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1212 - val_loss: 194.1611\n",
      "\n",
      "Epoch 03848: val_loss did not improve from 179.48197\n",
      "Epoch 3849/5000\n",
      "ecpch:3848,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1211 - val_loss: 194.1655\n",
      "\n",
      "Epoch 03849: val_loss did not improve from 179.48197\n",
      "Epoch 3850/5000\n",
      "ecpch:3849,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1210 - val_loss: 194.1633\n",
      "\n",
      "Epoch 03850: val_loss did not improve from 179.48197\n",
      "Epoch 3851/5000\n",
      "ecpch:3850,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1209 - val_loss: 194.1668\n",
      "\n",
      "Epoch 03851: val_loss did not improve from 179.48197\n",
      "Epoch 3852/5000\n",
      "ecpch:3851,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1212 - val_loss: 194.1597\n",
      "\n",
      "Epoch 03852: val_loss did not improve from 179.48197\n",
      "Epoch 3853/5000\n",
      "ecpch:3852,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1210 - val_loss: 194.1609\n",
      "\n",
      "Epoch 03853: val_loss did not improve from 179.48197\n",
      "Epoch 3854/5000\n",
      "ecpch:3853,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1211 - val_loss: 194.1608\n",
      "\n",
      "Epoch 03854: val_loss did not improve from 179.48197\n",
      "Epoch 3855/5000\n",
      "ecpch:3854,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1209 - val_loss: 194.1616\n",
      "\n",
      "Epoch 03855: val_loss did not improve from 179.48197\n",
      "Epoch 3856/5000\n",
      "ecpch:3855,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1208 - val_loss: 194.1679\n",
      "\n",
      "Epoch 03856: val_loss did not improve from 179.48197\n",
      "Epoch 3857/5000\n",
      "ecpch:3856,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1209 - val_loss: 194.1602\n",
      "\n",
      "Epoch 03857: val_loss did not improve from 179.48197\n",
      "Epoch 3858/5000\n",
      "ecpch:3857,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1208 - val_loss: 194.1634\n",
      "\n",
      "Epoch 03858: val_loss did not improve from 179.48197\n",
      "Epoch 3859/5000\n",
      "ecpch:3858,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1209 - val_loss: 194.1610\n",
      "\n",
      "Epoch 03859: val_loss did not improve from 179.48197\n",
      "Epoch 3860/5000\n",
      "ecpch:3859,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1206 - val_loss: 194.1668\n",
      "\n",
      "Epoch 03860: val_loss did not improve from 179.48197\n",
      "Epoch 3861/5000\n",
      "ecpch:3860,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1209 - val_loss: 194.1601\n",
      "\n",
      "Epoch 03861: val_loss did not improve from 179.48197\n",
      "Epoch 3862/5000\n",
      "ecpch:3861,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1206 - val_loss: 194.1643\n",
      "\n",
      "Epoch 03862: val_loss did not improve from 179.48197\n",
      "Epoch 3863/5000\n",
      "ecpch:3862,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1207 - val_loss: 194.1699\n",
      "\n",
      "Epoch 03863: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 03863: ReduceLROnPlateau reducing learning rate to 1.1987632007048887e-07.\n",
      "Epoch 3864/5000\n",
      "ecpch:3863,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1205 - val_loss: 194.1636\n",
      "\n",
      "Epoch 03864: val_loss did not improve from 179.48197\n",
      "Epoch 3865/5000\n",
      "ecpch:3864,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1207 - val_loss: 194.1658\n",
      "\n",
      "Epoch 03865: val_loss did not improve from 179.48197\n",
      "Epoch 3866/5000\n",
      "ecpch:3865,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1204 - val_loss: 194.1628\n",
      "\n",
      "Epoch 03866: val_loss did not improve from 179.48197\n",
      "Epoch 3867/5000\n",
      "ecpch:3866,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1207 - val_loss: 194.1634\n",
      "\n",
      "Epoch 03867: val_loss did not improve from 179.48197\n",
      "Epoch 3868/5000\n",
      "ecpch:3867,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1204 - val_loss: 194.1677\n",
      "\n",
      "Epoch 03868: val_loss did not improve from 179.48197\n",
      "Epoch 3869/5000\n",
      "ecpch:3868,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1206 - val_loss: 194.1577\n",
      "\n",
      "Epoch 03869: val_loss did not improve from 179.48197\n",
      "Epoch 3870/5000\n",
      "ecpch:3869,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1202 - val_loss: 194.1663\n",
      "\n",
      "Epoch 03870: val_loss did not improve from 179.48197\n",
      "Epoch 3871/5000\n",
      "ecpch:3870,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1204 - val_loss: 194.1646\n",
      "\n",
      "Epoch 03871: val_loss did not improve from 179.48197\n",
      "Epoch 3872/5000\n",
      "ecpch:3871,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1204 - val_loss: 194.1656\n",
      "\n",
      "Epoch 03872: val_loss did not improve from 179.48197\n",
      "Epoch 3873/5000\n",
      "ecpch:3872,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1206 - val_loss: 194.1600\n",
      "\n",
      "Epoch 03873: val_loss did not improve from 179.48197\n",
      "Epoch 3874/5000\n",
      "ecpch:3873,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1205 - val_loss: 194.1632\n",
      "\n",
      "Epoch 03874: val_loss did not improve from 179.48197\n",
      "Epoch 3875/5000\n",
      "ecpch:3874,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1202 - val_loss: 194.1647\n",
      "\n",
      "Epoch 03875: val_loss did not improve from 179.48197\n",
      "Epoch 3876/5000\n",
      "ecpch:3875,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1205 - val_loss: 194.1633\n",
      "\n",
      "Epoch 03876: val_loss did not improve from 179.48197\n",
      "Epoch 3877/5000\n",
      "ecpch:3876,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1202 - val_loss: 194.1688\n",
      "\n",
      "Epoch 03877: val_loss did not improve from 179.48197\n",
      "Epoch 3878/5000\n",
      "ecpch:3877,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1202 - val_loss: 194.1609\n",
      "\n",
      "Epoch 03878: val_loss did not improve from 179.48197\n",
      "Epoch 3879/5000\n",
      "ecpch:3878,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1202 - val_loss: 194.1659\n",
      "\n",
      "Epoch 03879: val_loss did not improve from 179.48197\n",
      "Epoch 3880/5000\n",
      "ecpch:3879,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1202 - val_loss: 194.1669\n",
      "\n",
      "Epoch 03880: val_loss did not improve from 179.48197\n",
      "Epoch 3881/5000\n",
      "ecpch:3880,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1201 - val_loss: 194.1640\n",
      "\n",
      "Epoch 03881: val_loss did not improve from 179.48197\n",
      "Epoch 3882/5000\n",
      "ecpch:3881,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1200 - val_loss: 194.1630\n",
      "\n",
      "Epoch 03882: val_loss did not improve from 179.48197\n",
      "Epoch 3883/5000\n",
      "ecpch:3882,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1200 - val_loss: 194.1642\n",
      "\n",
      "Epoch 03883: val_loss did not improve from 179.48197\n",
      "Epoch 3884/5000\n",
      "ecpch:3883,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1200 - val_loss: 194.1690\n",
      "\n",
      "Epoch 03884: val_loss did not improve from 179.48197\n",
      "Epoch 3885/5000\n",
      "ecpch:3884,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1201 - val_loss: 194.1655\n",
      "\n",
      "Epoch 03885: val_loss did not improve from 179.48197\n",
      "Epoch 3886/5000\n",
      "ecpch:3885,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1200 - val_loss: 194.1599\n",
      "\n",
      "Epoch 03886: val_loss did not improve from 179.48197\n",
      "Epoch 3887/5000\n",
      "ecpch:3886,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1199 - val_loss: 194.1616\n",
      "\n",
      "Epoch 03887: val_loss did not improve from 179.48197\n",
      "Epoch 3888/5000\n",
      "ecpch:3887,learn rate 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1199 - val_loss: 194.1622\n",
      "\n",
      "Epoch 03888: val_loss did not improve from 179.48197\n",
      "Epoch 3889/5000\n",
      "ecpch:3888,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1200 - val_loss: 194.1647\n",
      "\n",
      "Epoch 03889: val_loss did not improve from 179.48197\n",
      "Epoch 3890/5000\n",
      "ecpch:3889,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1198 - val_loss: 194.1669\n",
      "\n",
      "Epoch 03890: val_loss did not improve from 179.48197\n",
      "Epoch 3891/5000\n",
      "ecpch:3890,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1199 - val_loss: 194.1632\n",
      "\n",
      "Epoch 03891: val_loss did not improve from 179.48197\n",
      "Epoch 3892/5000\n",
      "ecpch:3891,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1198 - val_loss: 194.1602\n",
      "\n",
      "Epoch 03892: val_loss did not improve from 179.48197\n",
      "Epoch 3893/5000\n",
      "ecpch:3892,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1197 - val_loss: 194.1554\n",
      "\n",
      "Epoch 03893: val_loss did not improve from 179.48197\n",
      "Epoch 3894/5000\n",
      "ecpch:3893,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1197 - val_loss: 194.1693\n",
      "\n",
      "Epoch 03894: val_loss did not improve from 179.48197\n",
      "Epoch 3895/5000\n",
      "ecpch:3894,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1196 - val_loss: 194.1668\n",
      "\n",
      "Epoch 03895: val_loss did not improve from 179.48197\n",
      "Epoch 3896/5000\n",
      "ecpch:3895,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1195 - val_loss: 194.1629\n",
      "\n",
      "Epoch 03896: val_loss did not improve from 179.48197\n",
      "Epoch 3897/5000\n",
      "ecpch:3896,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1195 - val_loss: 194.1675\n",
      "\n",
      "Epoch 03897: val_loss did not improve from 179.48197\n",
      "Epoch 3898/5000\n",
      "ecpch:3897,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1195 - val_loss: 194.1607\n",
      "\n",
      "Epoch 03898: val_loss did not improve from 179.48197\n",
      "Epoch 3899/5000\n",
      "ecpch:3898,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1195 - val_loss: 194.1637\n",
      "\n",
      "Epoch 03899: val_loss did not improve from 179.48197\n",
      "Epoch 3900/5000\n",
      "ecpch:3899,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1194 - val_loss: 194.1642\n",
      "\n",
      "Epoch 03900: val_loss did not improve from 179.48197\n",
      "Epoch 3901/5000\n",
      "ecpch:3900,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1194 - val_loss: 194.1689\n",
      "\n",
      "Epoch 03901: val_loss did not improve from 179.48197\n",
      "Epoch 3902/5000\n",
      "ecpch:3901,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1193 - val_loss: 194.1641\n",
      "\n",
      "Epoch 03902: val_loss did not improve from 179.48197\n",
      "Epoch 3903/5000\n",
      "ecpch:3902,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1194 - val_loss: 194.1635\n",
      "\n",
      "Epoch 03903: val_loss did not improve from 179.48197\n",
      "Epoch 3904/5000\n",
      "ecpch:3903,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1192 - val_loss: 194.1626\n",
      "\n",
      "Epoch 03904: val_loss did not improve from 179.48197\n",
      "Epoch 3905/5000\n",
      "ecpch:3904,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1194 - val_loss: 194.1661\n",
      "\n",
      "Epoch 03905: val_loss did not improve from 179.48197\n",
      "Epoch 3906/5000\n",
      "ecpch:3905,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1192 - val_loss: 194.1638\n",
      "\n",
      "Epoch 03906: val_loss did not improve from 179.48197\n",
      "Epoch 3907/5000\n",
      "ecpch:3906,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1193 - val_loss: 194.1598\n",
      "\n",
      "Epoch 03907: val_loss did not improve from 179.48197\n",
      "Epoch 3908/5000\n",
      "ecpch:3907,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1192 - val_loss: 194.1665\n",
      "\n",
      "Epoch 03908: val_loss did not improve from 179.48197\n",
      "Epoch 3909/5000\n",
      "ecpch:3908,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1192 - val_loss: 194.1658\n",
      "\n",
      "Epoch 03909: val_loss did not improve from 179.48197\n",
      "Epoch 3910/5000\n",
      "ecpch:3909,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1190 - val_loss: 194.1638\n",
      "\n",
      "Epoch 03910: val_loss did not improve from 179.48197\n",
      "Epoch 3911/5000\n",
      "ecpch:3910,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1192 - val_loss: 194.1674\n",
      "\n",
      "Epoch 03911: val_loss did not improve from 179.48197\n",
      "Epoch 3912/5000\n",
      "ecpch:3911,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1190 - val_loss: 194.1631\n",
      "\n",
      "Epoch 03912: val_loss did not improve from 179.48197\n",
      "Epoch 3913/5000\n",
      "ecpch:3912,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1191 - val_loss: 194.1596\n",
      "\n",
      "Epoch 03913: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 03913: ReduceLROnPlateau reducing learning rate to 1.0788868678446307e-07.\n",
      "Epoch 3914/5000\n",
      "ecpch:3913,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1191 - val_loss: 194.1601\n",
      "\n",
      "Epoch 03914: val_loss did not improve from 179.48197\n",
      "Epoch 3915/5000\n",
      "ecpch:3914,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1189 - val_loss: 194.1632\n",
      "\n",
      "Epoch 03915: val_loss did not improve from 179.48197\n",
      "Epoch 3916/5000\n",
      "ecpch:3915,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1189 - val_loss: 194.1693\n",
      "\n",
      "Epoch 03916: val_loss did not improve from 179.48197\n",
      "Epoch 3917/5000\n",
      "ecpch:3916,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1191 - val_loss: 194.1700\n",
      "\n",
      "Epoch 03917: val_loss did not improve from 179.48197\n",
      "Epoch 3918/5000\n",
      "ecpch:3917,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1190 - val_loss: 194.1637\n",
      "\n",
      "Epoch 03918: val_loss did not improve from 179.48197\n",
      "Epoch 3919/5000\n",
      "ecpch:3918,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1190 - val_loss: 194.1704\n",
      "\n",
      "Epoch 03919: val_loss did not improve from 179.48197\n",
      "Epoch 3920/5000\n",
      "ecpch:3919,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1189 - val_loss: 194.1663\n",
      "\n",
      "Epoch 03920: val_loss did not improve from 179.48197\n",
      "Epoch 3921/5000\n",
      "ecpch:3920,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1188 - val_loss: 194.1616\n",
      "\n",
      "Epoch 03921: val_loss did not improve from 179.48197\n",
      "Epoch 3922/5000\n",
      "ecpch:3921,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1190 - val_loss: 194.1600\n",
      "\n",
      "Epoch 03922: val_loss did not improve from 179.48197\n",
      "Epoch 3923/5000\n",
      "ecpch:3922,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1188 - val_loss: 194.1610\n",
      "\n",
      "Epoch 03923: val_loss did not improve from 179.48197\n",
      "Epoch 3924/5000\n",
      "ecpch:3923,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1187 - val_loss: 194.1656\n",
      "\n",
      "Epoch 03924: val_loss did not improve from 179.48197\n",
      "Epoch 3925/5000\n",
      "ecpch:3924,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1187 - val_loss: 194.1628\n",
      "\n",
      "Epoch 03925: val_loss did not improve from 179.48197\n",
      "Epoch 3926/5000\n",
      "ecpch:3925,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1186 - val_loss: 194.1666\n",
      "\n",
      "Epoch 03926: val_loss did not improve from 179.48197\n",
      "Epoch 3927/5000\n",
      "ecpch:3926,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1187 - val_loss: 194.1689\n",
      "\n",
      "Epoch 03927: val_loss did not improve from 179.48197\n",
      "Epoch 3928/5000\n",
      "ecpch:3927,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1186 - val_loss: 194.1622\n",
      "\n",
      "Epoch 03928: val_loss did not improve from 179.48197\n",
      "Epoch 3929/5000\n",
      "ecpch:3928,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1188 - val_loss: 194.1657\n",
      "\n",
      "Epoch 03929: val_loss did not improve from 179.48197\n",
      "Epoch 3930/5000\n",
      "ecpch:3929,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1186 - val_loss: 194.1694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 03930: val_loss did not improve from 179.48197\n",
      "Epoch 3931/5000\n",
      "ecpch:3930,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1184 - val_loss: 194.1653\n",
      "\n",
      "Epoch 03931: val_loss did not improve from 179.48197\n",
      "Epoch 3932/5000\n",
      "ecpch:3931,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1187 - val_loss: 194.1681\n",
      "\n",
      "Epoch 03932: val_loss did not improve from 179.48197\n",
      "Epoch 3933/5000\n",
      "ecpch:3932,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1185 - val_loss: 194.1635\n",
      "\n",
      "Epoch 03933: val_loss did not improve from 179.48197\n",
      "Epoch 3934/5000\n",
      "ecpch:3933,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1185 - val_loss: 194.1625\n",
      "\n",
      "Epoch 03934: val_loss did not improve from 179.48197\n",
      "Epoch 3935/5000\n",
      "ecpch:3934,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1186 - val_loss: 194.1644\n",
      "\n",
      "Epoch 03935: val_loss did not improve from 179.48197\n",
      "Epoch 3936/5000\n",
      "ecpch:3935,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1185 - val_loss: 194.1662\n",
      "\n",
      "Epoch 03936: val_loss did not improve from 179.48197\n",
      "Epoch 3937/5000\n",
      "ecpch:3936,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1183 - val_loss: 194.1697\n",
      "\n",
      "Epoch 03937: val_loss did not improve from 179.48197\n",
      "Epoch 3938/5000\n",
      "ecpch:3937,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1184 - val_loss: 194.1640\n",
      "\n",
      "Epoch 03938: val_loss did not improve from 179.48197\n",
      "Epoch 3939/5000\n",
      "ecpch:3938,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1184 - val_loss: 194.1687\n",
      "\n",
      "Epoch 03939: val_loss did not improve from 179.48197\n",
      "Epoch 3940/5000\n",
      "ecpch:3939,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1182 - val_loss: 194.1661\n",
      "\n",
      "Epoch 03940: val_loss did not improve from 179.48197\n",
      "Epoch 3941/5000\n",
      "ecpch:3940,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1184 - val_loss: 194.1629\n",
      "\n",
      "Epoch 03941: val_loss did not improve from 179.48197\n",
      "Epoch 3942/5000\n",
      "ecpch:3941,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1183 - val_loss: 194.1731\n",
      "\n",
      "Epoch 03942: val_loss did not improve from 179.48197\n",
      "Epoch 3943/5000\n",
      "ecpch:3942,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1184 - val_loss: 194.1644\n",
      "\n",
      "Epoch 03943: val_loss did not improve from 179.48197\n",
      "Epoch 3944/5000\n",
      "ecpch:3943,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1182 - val_loss: 194.1668\n",
      "\n",
      "Epoch 03944: val_loss did not improve from 179.48197\n",
      "Epoch 3945/5000\n",
      "ecpch:3944,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1181 - val_loss: 194.1681\n",
      "\n",
      "Epoch 03945: val_loss did not improve from 179.48197\n",
      "Epoch 3946/5000\n",
      "ecpch:3945,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1180 - val_loss: 194.1650\n",
      "\n",
      "Epoch 03946: val_loss did not improve from 179.48197\n",
      "Epoch 3947/5000\n",
      "ecpch:3946,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1181 - val_loss: 194.1638\n",
      "\n",
      "Epoch 03947: val_loss did not improve from 179.48197\n",
      "Epoch 3948/5000\n",
      "ecpch:3947,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1180 - val_loss: 194.1671\n",
      "\n",
      "Epoch 03948: val_loss did not improve from 179.48197\n",
      "Epoch 3949/5000\n",
      "ecpch:3948,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1180 - val_loss: 194.1596\n",
      "\n",
      "Epoch 03949: val_loss did not improve from 179.48197\n",
      "Epoch 3950/5000\n",
      "ecpch:3949,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1179 - val_loss: 194.1623\n",
      "\n",
      "Epoch 03950: val_loss did not improve from 179.48197\n",
      "Epoch 3951/5000\n",
      "ecpch:3950,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 55.1181 - val_loss: 194.1635\n",
      "\n",
      "Epoch 03951: val_loss did not improve from 179.48197\n",
      "Epoch 3952/5000\n",
      "ecpch:3951,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1179 - val_loss: 194.1599\n",
      "\n",
      "Epoch 03952: val_loss did not improve from 179.48197\n",
      "Epoch 3953/5000\n",
      "ecpch:3952,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1180 - val_loss: 194.1652\n",
      "\n",
      "Epoch 03953: val_loss did not improve from 179.48197\n",
      "Epoch 3954/5000\n",
      "ecpch:3953,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1178 - val_loss: 194.1616\n",
      "\n",
      "Epoch 03954: val_loss did not improve from 179.48197\n",
      "Epoch 3955/5000\n",
      "ecpch:3954,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1178 - val_loss: 194.1615\n",
      "\n",
      "Epoch 03955: val_loss did not improve from 179.48197\n",
      "Epoch 3956/5000\n",
      "ecpch:3955,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1178 - val_loss: 194.1676\n",
      "\n",
      "Epoch 03956: val_loss did not improve from 179.48197\n",
      "Epoch 3957/5000\n",
      "ecpch:3956,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1180 - val_loss: 194.1678\n",
      "\n",
      "Epoch 03957: val_loss did not improve from 179.48197\n",
      "Epoch 3958/5000\n",
      "ecpch:3957,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1179 - val_loss: 194.1654\n",
      "\n",
      "Epoch 03958: val_loss did not improve from 179.48197\n",
      "Epoch 3959/5000\n",
      "ecpch:3958,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1179 - val_loss: 194.1659\n",
      "\n",
      "Epoch 03959: val_loss did not improve from 179.48197\n",
      "Epoch 3960/5000\n",
      "ecpch:3959,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1179 - val_loss: 194.1622\n",
      "\n",
      "Epoch 03960: val_loss did not improve from 179.48197\n",
      "Epoch 3961/5000\n",
      "ecpch:3960,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 55.1175 - val_loss: 194.1611\n",
      "\n",
      "Epoch 03961: val_loss did not improve from 179.48197\n",
      "Epoch 3962/5000\n",
      "ecpch:3961,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1178 - val_loss: 194.1642\n",
      "\n",
      "Epoch 03962: val_loss did not improve from 179.48197\n",
      "Epoch 3963/5000\n",
      "ecpch:3962,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1176 - val_loss: 194.1614\n",
      "\n",
      "Epoch 03963: val_loss did not improve from 179.48197\n",
      "\n",
      "Epoch 03963: ReduceLROnPlateau reducing learning rate to 9.709981938499369e-08.\n",
      "Epoch 3964/5000\n",
      "ecpch:3963,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1178 - val_loss: 194.1645\n",
      "\n",
      "Epoch 03964: val_loss did not improve from 179.48197\n",
      "Epoch 3965/5000\n",
      "ecpch:3964,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1176 - val_loss: 194.1603\n",
      "\n",
      "Epoch 03965: val_loss did not improve from 179.48197\n",
      "Epoch 3966/5000\n",
      "ecpch:3965,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1176 - val_loss: 194.1616\n",
      "\n",
      "Epoch 03966: val_loss did not improve from 179.48197\n",
      "Epoch 3967/5000\n",
      "ecpch:3966,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1175 - val_loss: 194.1611\n",
      "\n",
      "Epoch 03967: val_loss did not improve from 179.48197\n",
      "Epoch 3968/5000\n",
      "ecpch:3967,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1173 - val_loss: 194.1669\n",
      "\n",
      "Epoch 03968: val_loss did not improve from 179.48197\n",
      "Epoch 3969/5000\n",
      "ecpch:3968,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1174 - val_loss: 194.1632\n",
      "\n",
      "Epoch 03969: val_loss did not improve from 179.48197\n",
      "Epoch 3970/5000\n",
      "ecpch:3969,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1175 - val_loss: 194.1703\n",
      "\n",
      "Epoch 03970: val_loss did not improve from 179.48197\n",
      "Epoch 3971/5000\n",
      "ecpch:3970,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 55.1173 - val_loss: 194.1604\n",
      "\n",
      "Epoch 03971: val_loss did not improve from 179.48197\n",
      "Epoch 3972/5000\n",
      "ecpch:3971,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1174 - val_loss: 194.1609\n",
      "\n",
      "Epoch 03972: val_loss did not improve from 179.48197\n",
      "Epoch 3973/5000\n",
      "ecpch:3972,learn rate 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1174 - val_loss: 194.1666\n",
      "\n",
      "Epoch 03973: val_loss did not improve from 179.48197\n",
      "Epoch 3974/5000\n",
      "ecpch:3973,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1174 - val_loss: 194.1698\n",
      "\n",
      "Epoch 03974: val_loss did not improve from 179.48197\n",
      "Epoch 3975/5000\n",
      "ecpch:3974,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1173 - val_loss: 194.1675\n",
      "\n",
      "Epoch 03975: val_loss did not improve from 179.48197\n",
      "Epoch 3976/5000\n",
      "ecpch:3975,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1173 - val_loss: 194.1612\n",
      "\n",
      "Epoch 03976: val_loss did not improve from 179.48197\n",
      "Epoch 3977/5000\n",
      "ecpch:3976,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1173 - val_loss: 194.1661\n",
      "\n",
      "Epoch 03977: val_loss did not improve from 179.48197\n",
      "Epoch 3978/5000\n",
      "ecpch:3977,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1171 - val_loss: 194.1679\n",
      "\n",
      "Epoch 03978: val_loss did not improve from 179.48197\n",
      "Epoch 3979/5000\n",
      "ecpch:3978,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1173 - val_loss: 194.1687\n",
      "\n",
      "Epoch 03979: val_loss did not improve from 179.48197\n",
      "Epoch 3980/5000\n",
      "ecpch:3979,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1173 - val_loss: 194.1665\n",
      "\n",
      "Epoch 03980: val_loss did not improve from 179.48197\n",
      "Epoch 3981/5000\n",
      "ecpch:3980,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1172 - val_loss: 194.1590\n",
      "\n",
      "Epoch 03981: val_loss did not improve from 179.48197\n",
      "Epoch 3982/5000\n",
      "ecpch:3981,learn rate 0.000000\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 55.1172 - val_loss: 194.1659\n",
      "\n",
      "Epoch 03982: val_loss did not improve from 179.48197\n",
      "Epoch 3983/5000\n",
      "ecpch:3982,learn rate 0.000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-81ab9332488f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mvae_cifar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# vae_cifar.fit_generator(generator,epochs=epoch,steps_per_epoch=50000//batch,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#                         validation_data=(X_test,None),callbacks=callback())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    210\u001b[0m                         val_outs = test_loop(model, val_f, val_ins,\n\u001b[1;32m    211\u001b[0m                                              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                                              verbose=0)\n\u001b[0m\u001b[1;32m    213\u001b[0m                         \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                         \u001b[0;31m# Same labels assumed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2657\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2658\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_make_callable_from_options'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2659\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SESSION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m             \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mcandidate_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_default\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3866\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0mmanager\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0musing\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3867\u001b[0m     \"\"\"\n\u001b[0;32m-> 3868\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_default_graph_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_controller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3870\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36mhelper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_GeneratorContextManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, args, kwds)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# Issue 19330: ensure context manager instances have good docstrings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch=64\n",
    "epoch=5000\n",
    "\n",
    "vae_cifar.fit(X_train[0:64],batch_size=batch,epochs=epoch,validation_data=(X_test,None),callbacks=callback())\n",
    "# vae_cifar.fit_generator(generator,epochs=epoch,steps_per_epoch=50000//batch,\n",
    "#                         validation_data=(X_test,None),callbacks=callback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_encoder='outputs/cifar_encoder'\n",
    "cifar_decoder='outputs/cifar_decoder'\n",
    "encoder_cifar.save(cifar_encoder)\n",
    "decoder_cifar.save(cifar_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_distribution(encoder_cifar,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model(decoder_cifar,n=5,dim=32,reshaper=lambda x:np.reshape(x,(-1,32,32,3)),channels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc40680fdd8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize']=(3,3)\n",
    "plt.imshow(np.reshape(X_test[11],(32,32,3)))\n",
    "# print(np.reshape(X_test[9],(32,32,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

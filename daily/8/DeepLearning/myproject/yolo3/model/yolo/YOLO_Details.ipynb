{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.confident loss:\n",
    ">confident loss consist of positive and negative loss,notice the number of negative for a\n",
    "example is more than positive, so the Strategy The code using is f(i,j),mean that ony the j that saticfy that  max iou of some predict box with all groudTrue valid box is less 0.5,use to compute for negative loss\n",
    "\n",
    "\n",
    "\n",
    "$$L_{conf}=\\frac{1}{N}\\sum_iL_{conf}^{(i)}\\ \\ $$ \n",
    "$$L_{conf}^{(i)}=\\sum_{j}I[y_{j}^{(i)}=1]log\\hat{\\sigma(y_{j}^{(i)})} +\n",
    "\\sum_{j}I[y_{j}^{(i)}=0]f(i,j)log(1-\\hat{\\sigma(y_{j}^{(i)})})\\ $$\n",
    "$$f(i,j)=\\max{iou(predict\\_box_{j}^{(i)},gt\\_boxes)} <0.5$$\n",
    "$$note: j\\ is\\ entry\\ of\\ features,eg:(13,13,3)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.box loss\n",
    "> suppose tx,ty,tw,th is the output of YoloNet(feature),using box regression on tx,ty,tw,th,instead native on tx,ty,tw,ty,so transformation have made as below,also\n",
    "introduce box size punishment function f(i,j)\n",
    "$$L_{box}=\\frac{1}{N}\\sum_{i}L_{box}^{(i)}$$ \n",
    "$$L_{box}^{(i)}=\\sum_{j}I[y_{j}^{(i)}=1]f(i,j)\\{\n",
    "\\|\\sigma(t_{j,x}^{(i)})-b_{j,x}^{(i)}\\|^{2}\n",
    "+\\|\\sigma(t_{j,y}^{(i)})-b_{j,y}^{(i)}\\|^{2} \n",
    "+|t_{j,w}^{(i)}-b_{j,w}^{(i)}\\|^{2}\n",
    "+\\|t_{j,h}^{(i)}-b_{j,h}^{(i)}\\|^{2} \\} $$\n",
    "\n",
    "$$b_{j,x}^{(i)}=\\frac{y_{j,x}^{(i)}-a_{j,x}}{W^{(i)}}$$\n",
    "$$b_{j,y}^{(i)}=\\frac{y_{j,y}^{(i)}-a_{j,y}}{H^{(i)}}$$\n",
    "$$b_{j,w}^{(i)}=log\\frac{y_{j,w}^{(i)}}{a_{j,w}}$$\n",
    "$$b_{j,h}^{(i)}=log\\frac{y_{j,h}^{(i)}}{a_{j,h}}$$\n",
    "$$f(i,j)=2-\\frac{y_{j,w}y_{j,h}}{W^{(i)}H^{(i)}}$$\n",
    "\n",
    "$W,H$ is width and height of a anchor_grid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.classification loss\n",
    ">classificaion using sigmoid insted of sofmax\n",
    "$$L_{cls}=\\frac{1}{N}\\sum_{i}L_{cls}^{(i)}$$\n",
    "$$L_{cls}^{(i)}=\\sum_{j}I[y_{j,conf}^{(i)}=1]\\sum_{k}I[y_{j,k}=1]log\\sigma(\\hat{y_{j,k}^{(i)}})$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

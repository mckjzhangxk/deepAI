{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-90fa55a1f917>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-90fa55a1f917>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    https://github.com/google/sentencepiece\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "https://github.com/google/sentencepiece\n",
    "tf.split\n",
    "tf.contrib.framework.nest.\n",
    "tf.contrib.lookup.index_table_from_file\n",
    "tf.gfile.Glob\n",
    "tf.data.TextLineDataset\n",
    "\n",
    "tf.data.Dataset.zip\n",
    "tf.data.Dataset.shard\n",
    "tf.data.Dataset.shuffle\n",
    "tf.data.Dataset.map\n",
    "tf.data.Dataset.filter\n",
    "tf.data.Dataset.from_tensor_slices\n",
    "tf.contrib.seq2seq.tile_batch\n",
    "tf.contrib.rnn.BasicLSTMCell\n",
    "\n",
    "tf.string.split\n",
    "tf.slice\n",
    "tf.layer.Dense\n",
    "tf.nn.dymatic.rnn\n",
    "tf.nn.bidirection_dymatic_rnn\n",
    "\n",
    "tf.contrib.seq2seq.BaseDecoder\n",
    "tf.contrib.seq2seq.BeamSearchDecoder\n",
    "tf.contrib.seq2seq.BeamSearchDecoderOutput\n",
    "tf.contrib.seq2seq.BeamSearchDecoderState\n",
    "\n",
    "\n",
    "tf.contrib.seq2seq.TrainHelper\n",
    "tf.contrib.seq2seq.GreedEmbeddingHelper\n",
    "tf.contrib.seq2seq.SampleEmbeddingHelper\n",
    "tf.contrib.seq2seq.dynamic_decoder\n",
    "\n",
    "tf.contrib.rnn.BasicLSTMCell\n",
    "tf.contrib.rnn.DropoutWrapper\n",
    "tf.contrib.rnn.MultiRNNCell\n",
    "\n",
    "tf.Summary\n",
    "tf.Summary.Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BatchedInput(\n",
    "    collections.namedtuple(\"BatchedInput\",\n",
    "                           (\"initializer\", \"source\", \"target_input\",\n",
    "                            \"target_output\", \"source_sequence_length\",\n",
    "                            \"target_sequence_length\"))):\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_iterator(src_dataset,\n",
    "                 tgt_dataset,\n",
    "                 src_vocab_table,\n",
    "                 tgt_vocab_table,\n",
    "                 batch_size,\n",
    "                 sos,\n",
    "                 eos,\n",
    "                 random_seed,\n",
    "                 num_buckets,\n",
    "                 src_max_len=None,\n",
    "                 tgt_max_len=None,\n",
    "                 num_parallel_calls=4,\n",
    "                 output_buffer_size=None,\n",
    "                 skip_count=None,\n",
    "                 num_shards=1,\n",
    "                 shard_index=0,\n",
    "                 reshuffle_each_iteration=True,\n",
    "                 use_char_encode=False):\n",
    "  output_buffer_size = batch_size * 1000\n",
    "\n",
    "\n",
    "  src_tgt_dataset = tf.data.Dataset.zip((src_dataset, tgt_dataset))\n",
    "\n",
    "  tgt_sos_id='0'\n",
    "  tgt_eos_id='1'\n",
    "  src_sos_id='0'\n",
    "  src_eos_id='1'\n",
    "\n",
    " #把一行转化成一个个单词序列\n",
    "  src_tgt_dataset = src_tgt_dataset.map(\n",
    "      lambda src, tgt: (\n",
    "          tf.string_split([src]).values, tf.string_split([tgt]).values),\n",
    "      num_parallel_calls=num_parallel_calls).prefetch(output_buffer_size)\n",
    "\n",
    "  # Filter zero length input sequences.\n",
    "  src_tgt_dataset = src_tgt_dataset.filter(\n",
    "      lambda src, tgt: tf.logical_and(tf.size(src) > 0, tf.size(tgt) > 0))\n",
    "\n",
    "\n",
    "  # Convert the word strings to ids.  Word strings that are not in the\n",
    "\n",
    "#   src_tgt_dataset = src_tgt_dataset.map(\n",
    "#         lambda src, tgt: (tf.cast(src_vocab_table.lookup(src), tf.int32),\n",
    "#                           tf.cast(tgt_vocab_table.lookup(tgt), tf.int32)),\n",
    "#         num_parallel_calls=num_parallel_calls)\n",
    "  #src_tgt_dataset是单词序列,序列值是单词索引\n",
    "  src_tgt_dataset = src_tgt_dataset.prefetch(output_buffer_size)\n",
    "  # Create a tgt_input prefixed with <sos> and a tgt_output suffixed with <eos>.\n",
    "  #对目标头为加入了tgt_sos_id,tgt_eos_id,(src,tgt)->(src,<sos>+tgt,tgt+<eos>)\n",
    "  src_tgt_dataset = src_tgt_dataset.map(\n",
    "      lambda src, tgt: (src,\n",
    "                        tf.concat(([tgt_sos_id], tgt), 0),\n",
    "                        tf.concat((tgt, [tgt_eos_id]), 0)),\n",
    "      num_parallel_calls=num_parallel_calls).prefetch(output_buffer_size)\n",
    "  # Add in sequence lengths.\n",
    "\n",
    "  src_tgt_dataset = src_tgt_dataset.map(\n",
    "        lambda src, tgt_in, tgt_out: (\n",
    "            src, tgt_in, tgt_out, tf.size(src), tf.size(tgt_in)),\n",
    "        num_parallel_calls=num_parallel_calls)\n",
    "  #src_tgt_dataset 表示(src,tgt_in,tgt_out,src.size,tgt_in.size)\n",
    "  src_tgt_dataset = src_tgt_dataset.prefetch(output_buffer_size)\n",
    "\n",
    "  # Bucket by source sequence length (buckets for lengths 0-9, 10-19, ...)\n",
    "  '''\n",
    "  x是一个(src,tgtin,tgtout,size(src),size(tgt))的数据集,\n",
    "  返回批处理的数据库,shape=(N,) 每个元素是一个(src,tgtin,tgtout,size(src),size(tgt))\n",
    "  由于每一行长度不同(src,tgin,tgout),会做pad处理,pad_value分别是src_eos_id,tgt_eos_id,tgt_eos_id\n",
    "  '''\n",
    "  def batching_func(x):\n",
    "    return x.padded_batch(\n",
    "        batch_size,\n",
    "        # The first three entries are the source and target line rows;\n",
    "        # these have unknown-length vectors.  The last two entries are\n",
    "        # the source and target row sizes; these are scalars.\n",
    "        padded_shapes=(\n",
    "            tf.TensorShape([None]),  # src\n",
    "            tf.TensorShape([None]),  # tgt_input\n",
    "            tf.TensorShape([None]),  # tgt_output\n",
    "            tf.TensorShape([]),  # src_len\n",
    "            tf.TensorShape([])),  # tgt_len\n",
    "        # Pad the source and target sequences with eos tokens.\n",
    "        # (Though notice we don't generally need to do this since\n",
    "        # later on we will be masking out calculations past the true sequence.\n",
    "        padding_values=(\n",
    "            src_eos_id,  # src\n",
    "            tgt_eos_id,  # tgt_input\n",
    "            tgt_eos_id,  # tgt_output\n",
    "            0,  # src_len -- unused\n",
    "            0))  # tgt_len -- unused\n",
    "\n",
    "\n",
    "  batched_dataset = batching_func(src_tgt_dataset)\n",
    "  batched_iter = batched_dataset.make_initializable_iterator()\n",
    "  (src_ids, tgt_input_ids, tgt_output_ids, src_seq_len,\n",
    "   tgt_seq_len) = (batched_iter.get_next())\n",
    "  return BatchedInput(\n",
    "      initializer=batched_iter.initializer,\n",
    "      source=src_ids,\n",
    "      target_input=tgt_input_ids,\n",
    "      target_output=tgt_output_ids,\n",
    "      source_sequence_length=src_seq_len,\n",
    "      target_sequence_length=tgt_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src_dataset=tf.data.TextLineDataset('/home/zhangxk/AIProject/nmt/nmt/scripts/iwsl515/train.en')\n",
    "tgt_dataset=tf.data.TextLineDataset('/home/zhangxk/AIProject/nmt/nmt/scripts/iwsl515/train.vi')\n",
    "src_vocab_table=tf.contrib.lookup.index_table_from_file('/home/zhangxk/AIProject/nmt/nmt/scripts/iwsl515/vocab.en')\n",
    "tgt_vocab_table=tf.contrib.lookup.index_table_from_file('/home/zhangxk/AIProject/nmt/nmt/scripts/iwsl515/vocab.vi')\n",
    "batch_size=9\n",
    "sos,eos='<sos>','<eos>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batchinput=get_iterator(src_dataset,\n",
    "                 tgt_dataset,\n",
    "                 src_vocab_table,\n",
    "                 tgt_vocab_table,\n",
    "                 batch_size,\n",
    "                 sos,\n",
    "                 eos,\n",
    "                 random_seed=0,\n",
    "                 num_buckets=1,\n",
    "                 num_shards=1,\n",
    "                 shard_index=0,\n",
    "                 reshuffle_each_iteration=False,\n",
    "                 use_char_encode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"IteratorGetNext_1:0\", shape=(?, ?), dtype=string)\n",
      "Tensor(\"IteratorGetNext_1:1\", shape=(?, ?), dtype=string)\n",
      "Tensor(\"IteratorGetNext_1:3\", shape=(?,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(batchinput.source)\n",
    "print(batchinput.target_input)\n",
    "print(batchinput.source_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 50)\n",
      "(9, 77)\n",
      "(9, 77)\n",
      "[ 9 50 27 31 13 31 11 10 18]\n",
      "[11 77 31 31 19 39 17 11 25]\n",
      "xxxxxxxxx\n",
      "(9, 44)\n",
      "(9, 62)\n",
      "(9, 62)\n",
      "[29 12 23 44 43 30 22 29 17]\n",
      "[37 19 26 62 51 35 21 32 17]\n",
      "xxxxxxxxx\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    sess.run(batchinput.initializer)\n",
    "    for i in range(2):\n",
    "        x=sess.run([batchinput.source,\n",
    "                     batchinput.target_input,\n",
    "                     batchinput.target_output,\n",
    "                    batchinput.source_sequence_length,\n",
    "                    batchinput.target_sequence_length])\n",
    "        print(x[0].shape)\n",
    "        print(x[1].shape)\n",
    "        print(x[2].shape)\n",
    "        print(x[3])\n",
    "        print(x[4])\n",
    "        print('xxxxxxxxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 31)\n",
      "(3, 39)\n",
      "(3, 39)\n",
      "[31 13 31]\n",
      "[31 19 39]\n"
     ]
    }
   ],
   "source": [
    "print(x[0].shape)\n",
    "print(x[1].shape)\n",
    "print(x[2].shape)\n",
    "print(x[3])\n",
    "print(x[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-463916fc8962>:6: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(LSTMStateTuple(c=<tf.Tensor 'my/MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros:0' shape=(22, 128) dtype=float32>, h=<tf.Tensor 'my/MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros_1:0' shape=(22, 128) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'my/MultiRNNCellZeroState/BasicLSTMCellZeroState_1/zeros:0' shape=(22, 256) dtype=float32>, h=<tf.Tensor 'my/MultiRNNCellZeroState/BasicLSTMCellZeroState_1/zeros_1:0' shape=(22, 256) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'my/MultiRNNCellZeroState/BasicLSTMCellZeroState_2/zeros:0' shape=(22, 512) dtype=float32>, h=<tf.Tensor 'my/MultiRNNCellZeroState/BasicLSTMCellZeroState_2/zeros_1:0' shape=(22, 512) dtype=float32>))\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "BATCH,T,D=22,10,64\n",
    "X=tf.placeholder(dtype=tf.float32,shape=[BATCH,T,D])\n",
    "with tf.variable_scope('my',tf.AUTO_REUSE):\n",
    "    ndims=[128,256,512]\n",
    "    cells=[tf.contrib.rnn.BasicLSTMCell(d) for d in ndims]\n",
    "#state_is_tuple,有多少成返回的state是个tuple,就有多少个元素,每个元素又是LSTMStateTuple,保存lstm的s,h,都是tensor类型\n",
    "    complete_cell=tf.contrib.rnn.MultiRNNCell(cells,state_is_tuple=True)\n",
    "    zero_state=complete_cell.zero_state(BATCH,dtype=tf.float32)\n",
    "    states=zero_state\n",
    "    outputs=[]\n",
    "    for t in range(T):\n",
    "        output,states=complete_cell(X[:,t,:],states)\n",
    "        outputs.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'my/my/multi_rnn_cell/cell_2/basic_lstm_cell/Mul_2:0' shape=(22, 512) dtype=float32>, <tf.Tensor 'my/my/multi_rnn_cell/cell_2/basic_lstm_cell/Mul_5:0' shape=(22, 512) dtype=float32>, <tf.Tensor 'my/my/multi_rnn_cell/cell_2/basic_lstm_cell/Mul_8:0' shape=(22, 512) dtype=float32>, <tf.Tensor 'my/my/multi_rnn_cell/cell_2/basic_lstm_cell/Mul_11:0' shape=(22, 512) dtype=float32>, <tf.Tensor 'my/my/multi_rnn_cell/cell_2/basic_lstm_cell/Mul_14:0' shape=(22, 512) dtype=float32>, <tf.Tensor 'my/my/multi_rnn_cell/cell_2/basic_lstm_cell/Mul_17:0' shape=(22, 512) dtype=float32>, <tf.Tensor 'my/my/multi_rnn_cell/cell_2/basic_lstm_cell/Mul_20:0' shape=(22, 512) dtype=float32>, <tf.Tensor 'my/my/multi_rnn_cell/cell_2/basic_lstm_cell/Mul_23:0' shape=(22, 512) dtype=float32>, <tf.Tensor 'my/my/multi_rnn_cell/cell_2/basic_lstm_cell/Mul_26:0' shape=(22, 512) dtype=float32>, <tf.Tensor 'my/my/multi_rnn_cell/cell_2/basic_lstm_cell/Mul_29:0' shape=(22, 512) dtype=float32>]\n",
      "10\n",
      "(LSTMStateTuple(c=<tf.Tensor 'my/my/multi_rnn_cell/cell_0/basic_lstm_cell/Add_19:0' shape=(22, 128) dtype=float32>, h=<tf.Tensor 'my/my/multi_rnn_cell/cell_0/basic_lstm_cell/Mul_29:0' shape=(22, 128) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'my/my/multi_rnn_cell/cell_1/basic_lstm_cell/Add_19:0' shape=(22, 256) dtype=float32>, h=<tf.Tensor 'my/my/multi_rnn_cell/cell_1/basic_lstm_cell/Mul_29:0' shape=(22, 256) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'my/my/multi_rnn_cell/cell_2/basic_lstm_cell/Add_19:0' shape=(22, 512) dtype=float32>, h=<tf.Tensor 'my/my/multi_rnn_cell/cell_2/basic_lstm_cell/Mul_29:0' shape=(22, 512) dtype=float32>))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#总结:对于MultiRNNCell单元,\\n\\n输入:\\n    X:[N,T]\\n    state:(l1_state,l2_state,...ln_state)\\n    li_state:LSTMStateTuple(c:Tensor,h:Tensor)\\n输出\\n    output:(N,ln_ndims),最后一次的h\\n    state:(l1_state,l2_state,...ln_state),li_state:LSTMStateTuple(c:Tensor,h:Tensor)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(outputs) #output是最高层的输出,shape(N,D_last_layer)\n",
    "print(len(outputs))\n",
    "print(states) #(outputs,(layer1_state,layer2_state,layer3_state))\n",
    "'''\n",
    "#总结:对于MultiRNNCell单元,\n",
    "\n",
    "输入:\n",
    "    X:[N,T]\n",
    "    state:(l1_state,l2_state,...ln_state)\n",
    "    li_state:LSTMStateTuple(c:Tensor,h:Tensor)\n",
    "输出\n",
    "    output:(N,ln_ndims),最后一次的h\n",
    "    state:(l1_state,l2_state,...ln_state),li_state:LSTMStateTuple(c:Tensor,h:Tensor)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "BATCH,T,D=22,10,64\n",
    "X=tf.placeholder(dtype=tf.float32,shape=[BATCH,T,D])\n",
    "with tf.variable_scope('mMmM',reuse=tf.AUTO_REUSE):\n",
    "    ndims=[32,64]\n",
    "    cells=[tf.contrib.rnn.BasicLSTMCell(d) for d in ndims]\n",
    "    complete_cell=tf.contrib.rnn.MultiRNNCell(cells)\n",
    "    \n",
    "    output,states=tf.nn.dynamic_rnn(complete_cell,X,\n",
    "                      sequence_length=None,\n",
    "                      initial_state=None,\n",
    "                      dtype=tf.float32,\n",
    "                      swap_memory=True,\n",
    "                      time_major=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"mMmM/rnn/transpose_1:0\", shape=(22, 10, 64), dtype=float32)\n",
      "(LSTMStateTuple(c=<tf.Tensor 'mMmM/rnn/while/Exit_3:0' shape=(22, 32) dtype=float32>, h=<tf.Tensor 'mMmM/rnn/while/Exit_4:0' shape=(22, 32) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'mMmM/rnn/while/Exit_5:0' shape=(22, 64) dtype=float32>, h=<tf.Tensor 'mMmM/rnn/while/Exit_6:0' shape=(22, 64) dtype=float32>))\n"
     ]
    }
   ],
   "source": [
    "print(output)\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#bi_direction rnn\n",
    "tf.reset_default_graph()\n",
    "BATCH,T,D=22,10,64\n",
    "X=tf.placeholder(dtype=tf.float32,shape=[BATCH,T,D])\n",
    "\n",
    "with tf.variable_scope('bi',reuse=tf.AUTO_REUSE):\n",
    "    ndims=[32,64]\n",
    "    cells=[tf.contrib.rnn.BasicLSTMCell(d) for d in ndims]\n",
    "    forward_cell=tf.contrib.rnn.MultiRNNCell(cells)\n",
    "    #注意,要new一边不能用上面的cells,不然不会创建新的weight\n",
    "    cells=[tf.contrib.rnn.BasicLSTMCell(d) for d in ndims]\n",
    "    backward_cell=tf.contrib.rnn.MultiRNNCell(cells)\n",
    "    \n",
    "    output,states=tf.nn.bidirectional_dynamic_rnn(forward_cell,backward_cell,X,dtype=tf.float32,time_major=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((LSTMStateTuple(c=<tf.Tensor 'bi/bidirectional_rnn/fw/fw/while/Exit_3:0' shape=(22, 32) dtype=float32>, h=<tf.Tensor 'bi/bidirectional_rnn/fw/fw/while/Exit_4:0' shape=(22, 32) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'bi/bidirectional_rnn/fw/fw/while/Exit_5:0' shape=(22, 64) dtype=float32>, h=<tf.Tensor 'bi/bidirectional_rnn/fw/fw/while/Exit_6:0' shape=(22, 64) dtype=float32>)), (LSTMStateTuple(c=<tf.Tensor 'bi/bidirectional_rnn/bw/bw/while/Exit_3:0' shape=(22, 32) dtype=float32>, h=<tf.Tensor 'bi/bidirectional_rnn/bw/bw/while/Exit_4:0' shape=(22, 32) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'bi/bidirectional_rnn/bw/bw/while/Exit_5:0' shape=(22, 64) dtype=float32>, h=<tf.Tensor 'bi/bidirectional_rnn/bw/bw/while/Exit_6:0' shape=(22, 64) dtype=float32>)))\n",
      "((LSTMStateTuple(c=<tf.Tensor 'tile_batch/Reshape:0' shape=(66, 32) dtype=float32>, h=<tf.Tensor 'tile_batch/Reshape_1:0' shape=(66, 32) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'tile_batch/Reshape_2:0' shape=(66, 64) dtype=float32>, h=<tf.Tensor 'tile_batch/Reshape_3:0' shape=(66, 64) dtype=float32>)), (LSTMStateTuple(c=<tf.Tensor 'tile_batch/Reshape_4:0' shape=(66, 32) dtype=float32>, h=<tf.Tensor 'tile_batch/Reshape_5:0' shape=(66, 32) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'tile_batch/Reshape_6:0' shape=(66, 64) dtype=float32>, h=<tf.Tensor 'tile_batch/Reshape_7:0' shape=(66, 64) dtype=float32>)))\n"
     ]
    }
   ],
   "source": [
    "# print(output)\n",
    "print(states)\n",
    "beam_states=tf.contrib.seq2seq.tile_batch(states,3)\n",
    "print(beam_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'bi/bidirectional_rnn/fw/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0' shape=(96, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'bi/bidirectional_rnn/fw/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'bi/bidirectional_rnn/fw/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0' shape=(96, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'bi/bidirectional_rnn/fw/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'bi/bidirectional_rnn/bw/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0' shape=(96, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'bi/bidirectional_rnn/bw/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'bi/bidirectional_rnn/bw/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0' shape=(96, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'bi/bidirectional_rnn/bw/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0' shape=(256,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(20, 5, 2), dtype=int32)\n",
      "(<tf.Tensor 'tile_batch/Reshape:0' shape=(60, 5, 2) dtype=int32>, <tf.Tensor 'tile_batch/Reshape_1:0' shape=(60, 5, 2) dtype=int32>)\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "tf.reset_default_graph()\n",
    "s=tf.constant(value=1,shape=[20,5,2])\n",
    "h=tf.constant(value=1,shape=[20,5,2])\n",
    "print(s)\n",
    "c=tf.contrib.seq2seq.tile_batch((s,h),3)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.contrib.seq2seq.python.ops.helper.TrainingHelper object at 0x7fc31c584eb8>\n",
      "<tensorflow.contrib.seq2seq.python.ops.basic_decoder.BasicDecoder object at 0x7fc31d7d43c8>\n"
     ]
    }
   ],
   "source": [
    "#decoder\n",
    "tf.reset_default_graph()\n",
    "BATCH,T,D=22,10,17\n",
    "X=tf.placeholder(dtype=tf.float32,shape=[BATCH,T,D])\n",
    "X_len=tf.placeholder(dtype=tf.int32,shape=[BATCH])\n",
    "with tf.variable_scope('decoder'):\n",
    "    dims=[32,64]\n",
    "    cells=[tf.contrib.rnn.BasicLSTMCell(d) for d in dims]\n",
    "    decode_cell=tf.contrib.rnn.MultiRNNCell(cells)\n",
    "    decode_init_state=decode_cell.zero_state(BATCH,tf.float32)\n",
    "    #decoder network\n",
    "    helper=tf.contrib.seq2seq.TrainingHelper(X,X_len)\n",
    "    print(helper)\n",
    "    mydecoder=tf.contrib.seq2seq.BasicDecoder(decode_cell,helper,decode_init_state)\n",
    "    print(mydecoder)\n",
    "    final_outputs, final_state, final_sequence_lengths=tf.contrib.seq2seq.dynamic_decode(mydecoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicDecoderOutput(rnn_output=<tf.Tensor 'decoder/decoder/transpose:0' shape=(22, ?, 64) dtype=float32>, sample_id=<tf.Tensor 'decoder/decoder/transpose_1:0' shape=(22, ?) dtype=int32>)\n"
     ]
    }
   ],
   "source": [
    "print(final_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(LSTMStateTuple(c=<tf.Tensor 'decoder/decoder/while/Exit_3:0' shape=(22, 32) dtype=float32>, h=<tf.Tensor 'decoder/decoder/while/Exit_4:0' shape=(22, 32) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'decoder/decoder/while/Exit_5:0' shape=(22, 64) dtype=float32>, h=<tf.Tensor 'decoder/decoder/while/Exit_6:0' shape=(22, 64) dtype=float32>))\n"
     ]
    }
   ],
   "source": [
    "print(final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"decoder/decoder/while/Exit_9:0\", shape=(22,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(final_sequence_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-61562cd14232>:13: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n"
     ]
    }
   ],
   "source": [
    "#inference,sample and greed\n",
    "tf.reset_default_graph()\n",
    "BATCH,D=22,17\n",
    "X=tf.placeholder(dtype=tf.float32,shape=[BATCH,D])\n",
    "X_len=tf.placeholder(dtype=tf.int32,shape=[BATCH])\n",
    "\n",
    "embeding=tf.constant(dtype=tf.float32,shape=[10000,67],value=1.0)\n",
    "sos=tf.constant(0,shape=[BATCH])\n",
    "eos=tf.constant(1,shape=[])\n",
    "\n",
    "with tf.variable_scope('decoder'):\n",
    "    dims=[32,64]\n",
    "    cells=[tf.contrib.rnn.BasicLSTMCell(d) for d in dims]\n",
    "    decode_cell=tf.contrib.rnn.MultiRNNCell(cells)\n",
    "    decode_init_state=decode_cell.zero_state(BATCH,tf.float32)\n",
    "    \n",
    "#     helper=tf.contrib.seq2seq.GreedyEmbeddingHelper(embeding,sos,eos)\n",
    "    helper=tf.contrib.seq2seq.SampleEmbeddingHelper(embeding,sos,eos,softmax_temperature=1.0)\n",
    "    decoder=tf.contrib.seq2seq.BasicDecoder(decode_cell,helper,decode_init_state)\n",
    "    final_output,final_state,final_len=tf.contrib.seq2seq.dynamic_decode(decoder,maximum_iterations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicDecoderOutput(rnn_output=<tf.Tensor 'decoder/decoder/transpose:0' shape=(22, ?, 64) dtype=float32>, sample_id=<tf.Tensor 'decoder/decoder/transpose_1:0' shape=(22, ?) dtype=int32>)\n"
     ]
    }
   ],
   "source": [
    "print(final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#inference beam search!\n",
    "tf.reset_default_graph()\n",
    "BATCH,D=22,17\n",
    "BW=3\n",
    "X=tf.placeholder(dtype=tf.float32,shape=[BATCH,D])\n",
    "X_len=tf.placeholder(dtype=tf.int32,shape=[BATCH])\n",
    "sos=tf.constant(0,shape=[BATCH])\n",
    "eos=tf.constant(1,shape=[])\n",
    "embeding=tf.constant(dtype=tf.float32,shape=[10000,67],value=1.0)\n",
    "\n",
    "with tf.variable_scope('decoder'):\n",
    "    dims=[32,64]\n",
    "    cells=[tf.contrib.rnn.BasicLSTMCell(d) for d in dims]\n",
    "    decode_cell=tf.contrib.rnn.MultiRNNCell(cells)\n",
    "    decode_init_state=decode_cell.zero_state(BATCH,tf.float32)\n",
    "    decode_init_state=tf.contrib.seq2seq.tile_batch(decode_init_state,BW)\n",
    "    decoder=tf.contrib.seq2seq.BeamSearchDecoder(decode_cell,embeding,sos,eos,decode_init_state,BW)\n",
    "    final_output,final_state,final_len=tf.contrib.seq2seq.dynamic_decode(decoder,maximum_iterations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"decoder/decoder/while/Exit_14:0\", shape=(22, 3), dtype=int32)\n",
      "BeamSearchDecoderState(cell_state=(LSTMStateTuple(c=<tf.Tensor 'decoder/decoder/while/Exit_5:0' shape=(22, 3, 32) dtype=float32>, h=<tf.Tensor 'decoder/decoder/while/Exit_6:0' shape=(22, 3, 32) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'decoder/decoder/while/Exit_7:0' shape=(22, 3, 64) dtype=float32>, h=<tf.Tensor 'decoder/decoder/while/Exit_8:0' shape=(22, 3, 64) dtype=float32>)), log_probs=<tf.Tensor 'decoder/decoder/while/Exit_9:0' shape=(22, 3) dtype=float32>, finished=<tf.Tensor 'decoder/decoder/while/Exit_10:0' shape=(22, 3) dtype=bool>, lengths=<tf.Tensor 'decoder/decoder/while/Exit_11:0' shape=(22, 3) dtype=int64>, accumulated_attention_probs=())\n"
     ]
    }
   ],
   "source": [
    "print(final_len)\n",
    "print(final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FinalBeamSearchDecoderOutput(predicted_ids=<tf.Tensor 'decoder/decoder/transpose:0' shape=(22, ?, 3) dtype=int32>, beam_search_decoder_output=BeamSearchDecoderOutput(scores=<tf.Tensor 'decoder/decoder/transpose_1:0' shape=(22, ?, 3) dtype=float32>, predicted_ids=<tf.Tensor 'decoder/decoder/transpose_2:0' shape=(22, ?, 3) dtype=int32>, parent_ids=<tf.Tensor 'decoder/decoder/transpose_3:0' shape=(22, ?, 3) dtype=int32>))\n"
     ]
    }
   ],
   "source": [
    "print(final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LSTMStateTuple(c=<tf.Tensor 'decoder/decoder/while/Exit_5:0' shape=(22, 3, 32) dtype=float32>, h=<tf.Tensor 'decoder/decoder/while/Exit_6:0' shape=(22, 3, 32) dtype=float32>),\n",
       " LSTMStateTuple(c=<tf.Tensor 'decoder/decoder/while/Exit_7:0' shape=(22, 3, 64) dtype=float32>, h=<tf.Tensor 'decoder/decoder/while/Exit_8:0' shape=(22, 3, 64) dtype=float32>))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state.cell_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output.predicted_ids.shape[0].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.sequence_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#graph\n",
    "\n",
    "def common_network(X):\n",
    "    with tf.variable_scope('mynn',reuse=tf.AUTO_REUSE):\n",
    "        W=tf.get_variable('W',shape=(),dtype=tf.float32,initializer=tf.constant_initializer(3.0))\n",
    "    return X*W\n",
    "def train_net():\n",
    "    X=tf.constant(12.0,name='train_X')\n",
    "    return common_network(X)\n",
    "def infer_net():\n",
    "    X=tf.constant(10.0,name='infer_X')\n",
    "    return common_network(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'mynn/W:0' shape=() dtype=float32_ref>]\n",
      "36.0\n",
      "[<tf.Variable 'mynn/W:0' shape=() dtype=float32_ref>]\n",
      "30.0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "g1=tf.Graph()\n",
    "with g1.as_default():\n",
    "    Y_train=train_net()\n",
    "    print(tf.trainable_variables())\n",
    "    sess1=tf.Session()\n",
    "    sess1.run(tf.global_variables_initializer())\n",
    "    print(sess1.run(Y_train))\n",
    "g2=tf.Graph()\n",
    "with g2.as_default():\n",
    "    Y_infer=infer_net()\n",
    "    print(tf.trainable_variables())\n",
    "    sess2=tf.Session()\n",
    "    sess2.run(tf.global_variables_initializer())\n",
    "    print(sess2.run(Y_infer))\n",
    "# Y_infer=infer_net()\n",
    "\n",
    "# sess1=tf.Session(graph=g1)\n",
    "# # sess2=tf.Session()\n",
    "# sess1.run(tf.global_variables_initializer())\n",
    "# print(sess1.run(Y_train))\n",
    "# print(sess1.run(Y_infer))\n",
    "\n",
    "# sess2.run(tf.global_variables_initializer())\n",
    "# print(sess2.run(Y_train))\n",
    "# print(sess2.run(Y_infer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper object at 0x7fdea8949898>\n"
     ]
    }
   ],
   "source": [
    "#attention\n",
    "tf.reset_default_graph()\n",
    "BATCH,T=22,15\n",
    "T1=11\n",
    "embed_size=122\n",
    "#这里没有定义encoder,假设encoder的输出是encoder_size,\n",
    "encoder_size=9\n",
    "memory=tf.constant(1.0,shape=[BATCH,T1,encoder_size],dtype=tf.float32)\n",
    "X=tf.placeholder(dtype=tf.float32,shape=[BATCH,T,embed_size])\n",
    "X_len=tf.placeholder(dtype=tf.int32,shape=[BATCH])\n",
    "dims=[128,256]\n",
    "cell_list=[tf.contrib.rnn.BasicRNNCell(d) for d in dims]\n",
    "cells=tf.contrib.rnn.MultiRNNCell(cell_list,state_is_tuple=True)\n",
    "\n",
    "attention_depth=256\n",
    "attention_mechanism=tf.contrib.seq2seq.LuongAttention(attention_depth,memory,dtype=tf.float32)\n",
    "\n",
    "# alignments_size:序列的长度\n",
    "# batch_size\n",
    "# keys:(batch,alignments_size,attention_depth),\n",
    "#           Tensor(\"LuongAttention/memory_layer/Tensordot:0\", shape=(22, 10, 256), dtype=float32)\n",
    "# memory_layer:把memory,hs经过memory_layer转化成和ht相同的维度后,计算score,ht * W * hs\n",
    "# state_size:T\n",
    "#values:传入的memory\n",
    "# print(attention_mechanism.values)\n",
    "# init_atten=attention_mechanism.initial_state(BATCH,tf.float32)\n",
    "# query=tf.constant(1.0,shape=[BATCH,attention_depth])\n",
    "# attention_mechanism(query,init_atten)\n",
    "cells=tf.contrib.seq2seq.AttentionWrapper(cells,attention_mechanism,\n",
    "                                    attention_layer_size=None,\n",
    "                                    alignment_history=True,\n",
    "                                    output_attention=True)\n",
    "print(cells)\n",
    "initial_state=cells.zero_state(BATCH,tf.float32)\n",
    "# # print(initial_state)\n",
    "helper=tf.contrib.seq2seq.TrainingHelper(X,X_len)\n",
    "decoder=tf.contrib.seq2seq.BasicDecoder(cells,helper,initial_state)\n",
    "rnn_output=tf.contrib.seq2seq.dynamic_decode(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicDecoderOutput(rnn_output=<tf.Tensor 'decoder/transpose:0' shape=(22, ?, 9) dtype=float32>, sample_id=<tf.Tensor 'decoder/transpose_1:0' shape=(22, ?) dtype=int32>)\n",
      "AttentionWrapperState(cell_state=(<tf.Tensor 'decoder/while/Exit_3:0' shape=(22, 128) dtype=float32>, <tf.Tensor 'decoder/while/Exit_4:0' shape=(22, 256) dtype=float32>), attention=<tf.Tensor 'decoder/while/Exit_5:0' shape=(22, 9) dtype=float32>, time=<tf.Tensor 'decoder/while/Exit_6:0' shape=() dtype=int32>, alignments=<tf.Tensor 'decoder/while/Exit_7:0' shape=(22, 11) dtype=float32>, alignment_history=<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7fdea86cbac8>, attention_state=<tf.Tensor 'decoder/while/Exit_9:0' shape=(22, 11) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "print(rnn_output[0])\n",
    "print(rnn_output[1])\n",
    "# for  v in tf.trainable_variables():\n",
    "#     print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"TensorArrayStack_1/TensorArrayGatherV3:0\", shape=(?, 22, 11), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "attention_images = (rnn_output[1].alignment_history.stack())\n",
    "print(attention_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttentionWrapperState(cell_state=(<tf.Tensor 'decoder/while/Exit_3:0' shape=(22, 128) dtype=float32>, <tf.Tensor 'decoder/while/Exit_4:0' shape=(22, 256) dtype=float32>), attention=<tf.Tensor 'decoder/while/Exit_5:0' shape=(22, 256) dtype=float32>, time=<tf.Tensor 'decoder/while/Exit_6:0' shape=() dtype=int32>, alignments=<tf.Tensor 'decoder/while/Exit_7:0' shape=(22, 10) dtype=float32>, alignment_history=(), attention_state=<tf.Tensor 'decoder/while/Exit_8:0' shape=(22, 10) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "print(rnn_output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tf.contrib.framework.nest.map_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N,D1,D2,D3=128,31,64,96\n",
    "X1=tf.constant(value=1.0,shape=[N,D1])\n",
    "X2=tf.constant(value=1.0,shape=[N,D2])\n",
    "X3=tf.constant(value=1.0,shape=[N,D3])\n",
    "def func(X1,X2,X3):\n",
    "    D1=X1.get_shape().as_list()[-1]\n",
    "    D2=X2.get_shape().as_list()[-1]\n",
    "    return tf.split(X2,[D1,D2-D1],axis=-1)\n",
    "NEWX2,_=tf.contrib.framework.nest.map_structure(func,X1,X2,X3)\n",
    "NEWX2.get_shape().assert_is_compatible_with(X1.get_shape())\n",
    "tf.contrib.framework.nest.assert_same_structure(X1,X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.contrib.framework.nest.assert_same_structure(X1,X3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

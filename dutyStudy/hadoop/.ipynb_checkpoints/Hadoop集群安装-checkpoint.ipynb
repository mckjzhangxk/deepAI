{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a href='https://hadoop.apache.org/docs/r3.1.1/hadoop-project-dist/hadoop-common/SingleCluster.html#Pseudo-Distributed_Operation'>伪集群安装</a>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1.安装必备.\n",
    "    * -jdK\n",
    "    * -SSH 免密码登录"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.配置etc/hadoop/hadoop-env.sh\n",
    "    * 加入export JAVA_HOME=/usr/java/latest\n",
    "     *   export HDFS_NAMENODE_USER=root\n",
    "      *  export HDFS_DATANODE_USER=root\n",
    "       * export HDFS_SECONDARYNAMENODE_USER=root\n",
    "2.配置免密码登录:\n",
    "   注意，你要把你的namenode节点的公共密钥导入其他节点\n",
    "   \n",
    "  * ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa  //生成密钥文件\n",
    "  * scp -p ~/.ssh/id_rsa.pub >>  node2:~/.ssh/authorized_keys  //这个才是应该输入的命令，下面2只是理解用/\n",
    "  \n",
    "  \n",
    "  * cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys //导入公钥,所有的集群机器密钥\n",
    "  * chmod 0600 ~/.ssh/authorized_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-b7332b511cf7>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-b7332b511cf7>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    3.配置文件\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "3.配置文件\n",
    "A.etc/hadoop/core-site.xml:，主要针对NAMENODE\n",
    "<configuration>\n",
    "    <property>\n",
    "        <name>fs.defaultFS</name>\n",
    "        <value>hdfs://node1:9820</value>\n",
    "    </property>\n",
    "    <property>\n",
    "        <name>hadoop.tmp.dir</name>\n",
    "        <value>/root/tmp</value>\n",
    "    </property>\n",
    "</configuration>\n",
    "\n",
    "B.etc/hadoop/hdfs-site.xml:    \n",
    "<configuration>\n",
    "    <property>\n",
    "        <name>dfs.replication</name>\n",
    "        <value>1</value>\n",
    "    </property>\n",
    "    <property>\n",
    "        <name>dfs.namenode.secondary.http-address</name>\n",
    "        <value>node1:9868</value>\n",
    "    </property>\n",
    "</configuration>\n",
    "c.修改worker,localhost改成node1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "4.启动\n",
    "    1.格式化,会生成clusterId:bin/hdfs namenode -format\n",
    "    2.sbin/start-dfs.sh,启动所有节点(NAME,DATA,SECONDARY)\n",
    "    3.http://localhost:9870/客户端管理工具\n",
    "    4.ss -nsl查看端口信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 集群的配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A.把hadoop 拷贝到其他的机器下:\n",
    "    scp -r hadoop_dir node2:`pwd`\n",
    "B.etc/hadoop/hdfs-site.xml: \n",
    "    <configuration>\n",
    "    <property>\n",
    "        <name>dfs.replication</name>\n",
    "        <value>3</value>\n",
    "    </property>\n",
    "    <property>\n",
    "        <name>dfs.namenode.secondary.http-address</name>\n",
    "        <value>node2:9868</value>\n",
    "    </property>\n",
    "</configuration>\n",
    "c.修改worker,localhost改成node2,node3，node4\n",
    "\n",
    "启动操作:\n",
    "    格式化:hdfs namenode -format //在hadoop.tmp.dir下面生成的fsImage就是namenode的metadata\n",
    "    启动:start-dfs.sh\n",
    "    jps可以查看java进程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <a href='https://hadoop.apache.org/docs/r3.1.1/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html#Configuration_details'>高可用配置</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1.hadoop_env.sh:\n",
    "    取消HDFS_SECONDARYNAMENODE_USER\n",
    "    添加export HDFS_ZKFC_USER=root\n",
    "        export HDFS_JOURNALNODE_USER=root\n",
    "2.core-site.xml:\n",
    "    A.修改hadoop.tmp.dir为一个新的/root/dfs/ha\n",
    "    \n",
    "    B.\n",
    "<property>\n",
    "  <name>hadoop.tmp.dir</name>\n",
    "  <value>/root/dfs/ha</value>\n",
    "</property>\n",
    "\n",
    "<!--配置HA后,由于有多个NN,所有这里指定服务名称-->\n",
    "<property>\n",
    "  <name>fs.defaultFS</name>\n",
    "  <value>hdfs://myzxk</value>\n",
    "</property>\n",
    "<!--提供zookeeper 服务地址-->\n",
    "<property>\n",
    "   <name>ha.zookeeper.quorum</name>\n",
    "   <value>node2:2181,node3:2181,node4:2181</value>\n",
    "</property>\n",
    "\n",
    "3.hdfs-site.xml \n",
    "<!--定义服务名 -->\n",
    "<property>\n",
    "  <name>dfs.nameservices</name>\n",
    "  <value>myzxk</value>\n",
    "</property>\n",
    "<!--定义服务名称下的NameNode的名称-->\n",
    "<property>\n",
    "  <name>dfs.ha.namenodes.myzxk</name>\n",
    "  <value>nn1,nn2</value>\n",
    "</property>\n",
    "\n",
    "<!--关于节点通信的配置,这个是逻辑名香真实物理的映射 -->\n",
    "<property>\n",
    "  <name>dfs.namenode.rpc-address.myzxk.nn1</name>\n",
    "  <value>node1:8020</value>\n",
    "</property>\n",
    "<property>\n",
    "  <name>dfs.namenode.rpc-address.myzxk.nn2</name>\n",
    "  <value>node2:8020</value>\n",
    "</property>\n",
    "<!-- 同上,对HTTP通信的配置-->\n",
    "<property>\n",
    "  <name>dfs.namenode.http-address.myzxk.nn1</name>\n",
    "  <value>node1:9870</value>\n",
    "</property>\n",
    "<property>\n",
    "  <name>dfs.namenode.http-address.myzxk.nn2</name>\n",
    "  <value>node2:9870</value>\n",
    "</property>\n",
    "<!--journal是用于主,备份NameNode同步用的,这里要指定这些joirnal服务的地址,并设在一个ID,表示这些是一个cluter的journal服务,共同还维护主,备份节点的\n",
    "同步 -->\n",
    "<property>\n",
    "  <name>dfs.namenode.shared.edits.dir</name>\n",
    "  <value>qjournal://node1:8485;node2:8485;node3:8485/mycluster</value>\n",
    "</property>\n",
    "<!--这个代理类,适用于帮助客户端,解析active NN的,因为配置了多个,所以必须给客户端一个代理,来找到active NN-->\n",
    "<property>\n",
    "  <name>dfs.client.failover.proxy.provider.myzxk</name>\n",
    "  <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>\n",
    "</property>\n",
    "\n",
    "<!--为保证主NN当机,从NN顺利提升自己为主,并不产生SPLIT-BRAIN,从NN要有某种机制,先试图关掉当前的NN,然后提升自己,这里选用HADOOP自带的sshfence-->\n",
    "<property>\n",
    "      <name>dfs.ha.fencing.methods</name>\n",
    "      <value>sshfence</value>\n",
    "</property>\n",
    "<!--sshfence是登录目标机器,杀掉进程,所有要配置无密钥登录-->\n",
    "<property>\n",
    "      <name>dfs.ha.fencing.ssh.private-key-files</name>\n",
    "      <value>/root/.ssh/id_rsa</value>\n",
    "</property>\n",
    "\n",
    "<!--joirnal服务器,保存NN状态的目录地址-->\n",
    "<property>\n",
    "  <name>dfs.journalnode.edits.dir</name>\n",
    "  <value>/root/dfs/ha/journalFile</value>\n",
    "</property>\n",
    "\n",
    "<!--允许失败自启动,自动故障转移-->\n",
    "<property>\n",
    "   <name>dfs.ha.automatic-failover.enabled</name>\n",
    "   <value>true</value>\n",
    "</property>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.1 <a href='http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_zkMulitServerSetup'>ZOOKeeper的安装</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-0555cd1493ed>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-0555cd1493ed>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    1.选择好要部署的机器,解压ZOOKeeper,配置环境变量.\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "1.选择好要部署的机器,解压ZOOKeeper,配置环境变量.\n",
    "2.conf/zoo.cfg :\n",
    "    tickTime=2000\n",
    "    dataDir=/root/zookeeper/\n",
    "    clientPort=2181\n",
    "    initLimit=5\n",
    "    syncLimit=2\n",
    "    server.1=zoo1:2888:3888\n",
    "    server.2=zoo2:2888:3888\n",
    "    server.3=zoo3:2888:3888\n",
    "    //1,2,3是id\n",
    "3.在dataDir=/root/zookeeper/,下面创建myid文件,包含每个机器设在的id\n",
    "4.分发节点scp -r zookeeper3.4.6 node3:`pwd`/scp -r zookeeper3.4.6 node4:`pwd`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.2 ZooKeeper 启动,停止,查看,(机器要求半数节点启动)\n",
    "* zkServer.sh start\n",
    "* zkServer.sh status\n",
    "* zkServer.sh stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.1 同步 主从NN 的metadata数据<a href='https://hadoop.apache.org/docs/r3.1.1/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html#Deployment_details'>help</a>\n",
    "    1.启动所有的journalnode节点.hdfs --daemon start journalnode  //hadoop-daemon.sh start journalnode\n",
    "    2.格式化主NN,并观察clusterID\n",
    "        hdfs namenode -format\n",
    "    3.standby NN同步主NN:在从机器上输入:\n",
    "        hdfs --daemon start namenode  //先在主NN,启动namenode ,或者hadoop-daemon.sh start namenode\n",
    "        hdfs namenode -bootstrapStandby //再从从节点同步"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.格式化 zookeeper <a href='https://hadoop.apache.org/docs/r3.1.1/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html#Initializing_HA_state_in_ZooKeeper'>help</a>\n",
    "    hdfs zkfc -formatZK //观察zookeeper 下目录变化\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### D.启动集群;\n",
    "    start-dfs.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
